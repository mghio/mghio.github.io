<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[抓包分析 TCP 握手和挥手]]></title>
    <url>%2Fpost%2F216a8d02.html</url>
    <content type="text"><![CDATA[前言首先需要明确的是 TCP 是一个可靠传输协议，它的所有特点最终都是为了这个可靠传输服务。在网上看到过很多文章讲 TCP 连接的三次握手和断开连接的四次挥手，但是都太过于理论，看完感觉总是似懂非懂。反复思考过后，觉得我自己还是偏工程型的人，要学习这些理论性的知识，最好的方式还是要通过实际案例来理解，这样才会具象深刻。本文通过 Wireshark 抓包来分析 TCP 三次握手和四次挥手，如果你也对这些理论感觉似懂非懂，那么强烈建议你也结合抓包实践来强化理解这些理论性的知识。 三次握手TCP 建立连接的三次握手是连接的双方协商确认一些信息（Sequence number、Maximum Segment Size、Window Size 等），Sequence number 有两个作用：一个是 SYN 标识位为 1 时作为初始序列号（ISN），则实际第一个数据字节的序列号和相应 ACK 中的确认号就是这个序列号加 1；另一个是 SYN 标识位为 0 时，则是当前会话的 segment（传输层叫 segment，网络层叫 packet，数据链路层叫 frame）的第一个数据字节的累积序列号。Maximum Segment Size 简称 MSS，表示最大一个 segment 中能传输的信息（不含 TCP、IP 头部）。Window Size 表示发送方接收窗口的大小。下面看看我在本地访问博客 mghio 的三次握手过程： 图中三个小红框表示与服务器建立连接的三次握手。 第一步，client 端（这个示例也就是浏览器）发送 SYN 到 server 端； 第二步，server 端收到 SYN 消息后，回复 SYN + ACK 到client 端，ACK 表示已经收到了 client 的 SYN 消息； 第三步，client 端收到回复 SYN + ACK 后，也回复一个 ACK 表示收到了 server 端的 SYN + ACK 了，其实 到这一步，client 端的 60469 端口已经是 ESTABLISHED 状态了。可以看到，其实三次握手的核心目的就是双方互相告知对象自己的 Sequence number，蓝框是 client 端的初始 Sequence number 和 client 端回复的 ACK，绿框是 server 端的初始 Sequence number 和 client 端回复的 ACK。这样协商好初始 Sequence number 后，发送数据包时发送端就可以判断丢包和进行丢包重传了。 三次握手还有一个目的是协商一些信息（上图中黄色方框是 Maximum Segment Size，粉色方框是 Window Size）。 到这里，就可以知道平常所说的建立TCP连接本质是为了实现 TCP 可靠传输做的前置准备工作，实际上物理层并没有这个连接在那里。TCP 建立连接之后时拥有和维护一些状态信息，这个状态信息就包含了 Sequence number、MSS、Window Size 等，TCP 握手就是协商出来这些初始值。而这些状态才是我们平时所说的 TCP 连接的本质。因为这个太重要了，我还要再次强调一下，TCP 是一个可靠传输协议，它的所有特点最终都是为了这个可靠传输服务。 四次挥手下面再来看看，当关闭浏览器页面是发生断开连接的四次挥手过程: 相信你已经发现了，上图抓包抓到的不是四次挥手，而是三次挥手，这是为何呢？ 这是由于 TCP 的时延机制（因为系统内核并不知道应用能不能立即关闭），当被挥手端（这里是 server 的 443 端口）第一次收到挥手端（这里是 client 的 63612 端口）的 FIN 请求时，并不会立即发送 ACK，而是会经过一段延迟时间后再发送，但是此时被挥手端也没有数据发送，就会向挥手端发送 FIN 请求，这里就可能造成被挥手端发送的 FIN 与 ACK 一起被挥手端收到，导致出现第二、三次挥手合并为一次的现象，也就最终呈现出“三次挥手”的情况。 断开连接四次挥手分为如下四步（假设没有出现挥手合并的情况）： 第一步，client 端主动发送 FIN 包给 server 端； 第二步，server 端回复 ACK（对应第一步 FIN 包的 ACK）给 client，表示 server 知道 client 端要断开了； 第三步，server 端发送 FIN 包给 client 端，表示 server 端也没有数据要发送了，可以断开了； 第四步，client 端回复 ACK 包给 server 端，表示既然双发都已发送 FIN 包表示可以断开，那么就真的断开了啊。 下面是 TCP 连接流转状态图（其中 CLOSED 状态是虚拟的，实际上并不存在），这个图很重要，记住这个图后基本上所有的 TCP 网络问题就可以解决。 其中比较难以理解的是 TIME_WAIT 状态，主动关闭的那一端会经历这个状态。这一端停留在这个状态的最长时间是 Maximum segment lifetime（MSL）的 2 倍，大部分时候被简称之为 2MSL。存在 TIME_WAIT 状态有如下两个原因： 要可靠的实现 TCP 全双工连接终止； 让老的重复 segment 在网络中消失（一个 sement 在网络中存活的最长时间为 1 个 MSL，一来一回就是 2 MSL）； 为什么握手是三次，而挥手是四次？嘿嘿，这是个经典的面试题，其实大部分人都背过挥手是四次的原因：因为 TCP 是全双工（双向）的，所以回收需要四次……。但是再反问下：握手也是双向的，但是为什么是只要三次呢？ 网上流传的资料都说 TCP 是双向的，所以回收需要四次，但是握手也是双向（握手双方都在告知对方自己的初始 Sequence number），那么为什么就不用四次握手呢？所以凡事需要多问几个为什么，要有探索和怀疑精神。 你再仔细回看上面三次握手的第二步（SYN + ACK），其实是可以拆分为两步的：第一步回复 ACK，第二步再发 SYN 也是完全可以的，只是效率会比较低，这样的话三次握手不也变成四次握手了。 看起来四次挥手主要是收到第一个 FIN 包后单独回复了一个 ACK 包这里多了一次，如果能像握手那样也回复 FIN + ACK 那么四次挥手也就变成三次了。这里再贴一下上面这个挥手的抓包图： 这个图中第二个红框就是 server 端回复的 FIN + ACK 包，这样四次挥手变成三次了（如果一个包算一次的话）。这里使用四次挥手原因主要是：被动关闭端在收到 FIN 后，知道主动关闭端要关闭了，然后系统内核层会通知应用层要关闭，此时应用层可能还需要做些关闭前的准备工作，可能还有数据没发送完，所以系统内核先回复一个 ACK 包，然后等应用层准备好了主动调 close 关闭时再发 FIN 包。 而握手过程中就没有这个准备过程了，所以可以立即发送 SYN + ACK（在这里的两步合成一步了，提高效率）。挥手过程中系统内核在收到对方的 FIN 后，只能 ACK，不能主动替应用来 FIN，因为系统内核并不知道应用能不能立即关闭。 总结TCP 是一个很复杂的协议，为了实现可靠传输以及处理各种网络传输中的 N 多问题，有一些很经典的解决方案，比如其中的网络拥塞控制算法、滑动窗口、数据重传等。强烈建议你去读一下 rfc793 和 TCP/IP 详解 卷1：协议 这本书。 如果你是那些纯看理论就能掌握好一门技能，然后还能举三反一的人，那我很佩服你；如果不是，那么学习理论知识注意要结合实践来强化理解理论，要经过反反复复才能比较好地掌握一个知识，讲究技巧，必要时要学会通过工具来达到目的。 最后 TCP 所有特性基本上核心都是为了实现可靠传输这个目标来服务的，然后有一些是出于优化性能的目的。]]></content>
      <categories>
        <category>network</category>
        <category>TCP</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 中 @EnableXXX 注解的套路]]></title>
    <url>%2Fpost%2Faa9d18bf.html</url>
    <content type="text"><![CDATA[前言在 Spring 框架中有很多实用的功能，不需要写大量的配置代码，只需添加几个注解即可开启。 其中一个重要原因是那些 @EnableXXX 注解，它可以让你通过在配置类加上简单的注解来快速地开启诸如事务管理（@EnableTransactionManagement）、Spring MVC（@EnableWebMvc）或定时任务（@EnableScheduling）等功能。这些看起来简单的注解语句提供了很多功能，但它们的内部机制从表面上看却不太明显。 一方面，对于使用者来说用这么少的代码获得这么多实用的功能是很好的，但另一方面，如果你不了解某个东西的内部是如何工作的，就会使调试和解决问题更加困难。 设计目标Spring 框架中那些 @EnableXXX 注解的设计目标是允许用户用最少的代码来开启复杂使用的功能。 此外，用户必须能够使用简单的默认值，或者允许手动配置该代码。最后，代码的复杂性要向框架使用者隐藏掉。 简而言之，让使用者设置大量的 Bean，并选择性地配置它们，而不必知道这些 Bean 的细节（或真正被设置的内容）。下面来看看具体的几个例子： @EnableScheduling (导入一个 @Configuration 类)首先要知道的是，@EnableXXX 注解并不神奇。实际上在 BeanFactory 中并不知道这些注解的具体内容，而且在 BeanFactory 类中，核心功能和特定注解（如 @EnableWebMvc）或它们所存放的 jar 包（如 spring-web）之间没有任何依赖关系。 让我们看一下 @EnableScheduling，下面看看它是如何工作的。 定义一个 SchedulingConfig 配置类，如下所示： 12345@Configuration@EnableSchedulingpublic class SchedulingConfig &#123; // some bean in here&#125; 上面的内容没有什么特别之处。只是一个用 @EnableScheduling 注释的标准 Java 配置。@EnableScheduling 让你以设定的频率执行某些方法。例如，你可以每 10 分钟运行 BankService.transferMoneyToMghio()。 @EnableScheduling 注解源码如下： 1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Import(SchedulingConfiguration.class)@Documentedpublic @interface EnableScheduling &#123;&#125; 上面的 EnableScheduling 注解，我们可以看到它只是一个标准的类级注解（@Target/@Retention），应该包含在 JavaDocs 中（@Documented），但是它有一个 Spring 特有的注解（@Import）。 @Import 是将一切联系起来的关键。 在这种情况下，由于我们的 SchedulingConfig 被注解为 @EnableScheduling，当 BeanFactory 解析文件时（内部是ConfigurationClassPostProcessor 在解析它），它也会发现 @Import(SchedulingConfiguration.class) 注解，它将导入该值中定义的类。 在这个注解中，就是 SchedulingConfiguration。 这里导入是什么意思呢？在这种情况下，它只是被当作另一个 Spring Bean。 SchedulingConfiguration 实际上被注解为@Configuration，所以 BeanFactory 会把它看作是另一个配置类，所有在该类中定义的 Bean 都会被拉入你的应用上下文，就像你自己定义了另一个 @Configuration 类一样。 如果我们检查 SchedulingConfiguration，我们可以看到它只定义了一个Bean（一个Post Processor），它负责我们上面描述的调度工作，源码如下： 1234567891011@Configuration@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public class SchedulingConfiguration &#123; @Bean(name = TaskManagementConfigUtils.SCHEDULED_ANNOTATION_PROCESSOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public ScheduledAnnotationBeanPostProcessor scheduledAnnotationProcessor() &#123; return new ScheduledAnnotationBeanPostProcessor(); &#125;&#125; 也许你会问，如果想配置 SchedulingConfiguration 中定义的 bean 呢？ 这里也只是在处理普通的Bean。 所以你对其它 Bean 所使用的机制也适用于此。 在这种情况下，ScheduledAnnotationBeanPostProcessor 使用一个标准的 Spring Bean 生命周期（postProcessAfterInitialization）来发现应用程序上下文何时被刷新。 当符合条件时，它会检查是否有任何 Bean 实现了 SchedulingConfigurer，如果有，就使用这些 Bean 来配置自己。 其实这一点并不明细（在 IDE 中也不太容易找到），但它与 BeanFactory 是完全分离的，而且是一个相当常见的模式，一个 Bean 被用来配置另一个 Bean。 而现在我们可以把所有的点连接起来，它（在某种程度上）很容易找到（你可以 Google 一下文档或阅读一下 JavaDocs）。 @EnableTransactionManagement（导入一个 ImportSelector）在上一个示例中，我们讨论了像 @EnableScheduling 这样的注解如何使用 @Import 来导入另一个 @Configuration 类并使其所有的 Bean 对你的应用程序可用（和可配置）。但是如果你想根据某些配置加载不同的 Bean 集，会发生什么呢？ @EnableTransactionManagement 就是一个很好的例子。TransactioConfig 定义如下： 12345@Configuration@EnableTransactionManagement(mode = AdviceMode.ASPECTJ)public class TransactioConfig &#123; // some bean in here&#125; 再一次，上面没有什么特别之处。只是一个用@EnableTransactionManagement注释的标准Java配置。唯一与之前的例子有些不同的是，用户为注释指定了一个参数（mode=AdviceMode.ASPECTJ）。 @EnableTransactionManagement注解本身看起来像这样。 123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(TransactionManagementConfigurationSelector.class)public @interface EnableTransactionManagement &#123; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125; 和前面一样，一个相当标准的注解，尽管这次它有一些参数。 然而，正如前文提到，@Import 注解是将一切联系在一起的关键，这一点再次得到证实。 但区别在于，这次我们导入的是 TransactionManagementConfigurationSelector 这个类，通过源码可以发现，其实它不是一个被 @Configuration 注解的类。 TransactionManagementConfigurationSelector 是一个实现ImportSelector 的类。 ImportSelector 的目的是让你的代码选择在运行时加载哪些配置类。 它有一个方法，接收关于注解的一些元数据，并返回一个类名数组。 在这种情况下，TransactionManagementConfigurationSelector 会查看模式并根据模式返回一些类。其中的 selectImports 方法源码如下： 123456789101112@Overrideprotected String[] selectImports(AdviceMode adviceMode) &#123; switch (adviceMode) &#123; case PROXY: return new String[] &#123;AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName()&#125;; case ASPECTJ: return new String[] &#123;determineTransactionAspectClass()&#125;; default: return null; &#125;&#125; 这些类中的大多数是 @Configuration（例如 ProxyTransactionManagementConfiguration），通过前文介绍我们知道它们会像前面一样工作。 对于 @Configuration 类，它们被加载和配置的方式与我们之前看到的完全一样。 所以简而言之，我们可以使用 @Import 和 @Configuration 类来加载一套标准的 Bean，或者使用 @Import 和 ImportSelector 来加载一套在运行时决定的 Bean。 @EnableAspectJAutoProxy (在 Bean 定义层导入)@Import 支持的最后一种情况，即当你想直接处理 BeanRegistry（工厂）时。如果你需要操作Bean Factory或者在Bean定义层处理Bean，那么这种情况就适合你，它与上面的情况非常相似。 你的 AspectJProxyConfig 可能看起来像。 12345@Configuration@EnableAspectJAutoProxy public class AspectJProxyConfig &#123; // some bean in here&#125; 再一次，上面定义没有什么特别的东西。只是一个用 @EnableAspectJAutoProxy 注释的标准 Java 配置。 下面是@EnableAspectJAutoProxy 的源代码。 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy &#123; boolean proxyTargetClass() default false; boolean exposeProxy() default false;&#125; 和前面一样，@Import 是关键，但这次它指向 AspectJAutoProxyRegistrar，它既没有 @Configuration 注解，也没有实现 ImportSelector 接口。 这次使用的是实现了 ImportBeanDefinitionRegistrar。 这个接口提供了对 Bean 注册中心（Bean Registry）和注解元数据的访问，因此我们可以在运行时根据注解中的参数来操作 Bean 注册表。 如果你仔细看过前面的示例，你可以看到我们忽略的类也是 ImportBeanDefinitionRegistrar。 在 @Configuration 类不够用的时候，这些类会直接操作 BeanFactory。 所以现在我们已经涵盖了 @EnableXXX 注解使用 @Import 将各种 Bean 引入你的应用上下文的所有不同方式。 它们要么直接引入一组 @Configuration 类，这些类中的所有 Bean 都被导入到你的应用上下文中。 或者它们引入一个 ImportSelector 接口实现类，在运行时选择一组 @Configuration 类并将这些 Bean 导入到你的应用上下文中。 最后，他们引入一个ImportBeanDefinitionRegistrars，可以直接与 BeanFactory 在 BeanDefinition 级别上合作。 结论总的来说，个人认为这种将 Bean 导入应用上下文的方法很好，因为它使框架使用者的使用某个功能非常容易。不幸的是，它模糊了如何找到可用的选项以及如何配置它们。 此外，它没有直接利用 IDE 的优势，所以很难知道哪些 Bean 正在被创建（以及为什么）。 然而，现在我们知道了 @Import 注解，我们可以使用 IDE 来挖掘一下每个注解及其相关的配置类，并了解哪些 Bean 正在被创建，它们如何被添加到你的应用上下文中，以及如何配置它们。 希望对你有帮助~]]></content>
      <categories>
        <category>Spring</category>
        <category>Java</category>
        <category>实现原理</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>实现原理</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊二维码]]></title>
    <url>%2Fpost%2F9072a99a.html</url>
    <content type="text"><![CDATA[一维码（条形码）在介绍二维码之前，先来看看它的“大哥”一维码，一维码也叫条形码（好像在日常生活中都是叫这个），它是由不同宽度的黑条和白条按照一定的顺序排列组成的平行线图案，它的宽度记录着数据信息，长度没有记录信息，条形码常用于标出物品的生产国、制造厂家、商品名称、生产日期、图书分类号、邮件起止地点、类别、日期等信息，比如大部分食品包装袋背后都会印有条形码。 一维码的编码规则全球的条形码标准都是由一个叫GS1的非营利性组织管理和维护的，通常情况下条形码由 95 条红或黑色的平行竖线组成，前三条是由黑-白-黑 组成，中间的五条由白-黑-白-黑-白组成，最后的三条和前三条一样也是由黑-白-黑组成，这样就把一个条形码分为左、右两个部分。剩下的 84 (95-3-5-3=84) 条按每 7 条一组分为 12 组，每组对应着一个数字，不同的数字的具体表示因编码方式而有所不同，不过都遵循着一个规律：右侧部分每一组的白色竖线条数都是奇数个。这样不管你是正着扫描还是反着扫描都是可以识别的。 中国使用的条形码大部分都是 EAN-13 格式的，条形码数字编码的含义从左至右分别是前三位标识来源 国家编码 ，比如中国为：690–699，后面的 4 ~ 8 位数字代表的是厂商公司代码，但是位数不是固定的，紧接着后面 的 9~12 位是商品编码，第 13 位是校验码，这就意味着公司编码越短，剩余可用于商品编码的位数也越多，可表示的商品也就越多，当然公司代码出售价格也相应更昂贵，另外用在商品上的 EAN-13 条码是要到 国家物品编码中心 去申请的。 二维码二维码 是在一维码的基础之上扩展出来的，二维码有不同的种类，大体上可以分为这两种 ① 堆叠式/行排式二维条码 ② 矩阵式二维码，其中矩阵式二维码最为流行(下文的二维码指矩阵式二维码)，它与一维码所不同的是它的宽度和长度均有记录数据信息，存储的数据量更大，除此之外还增加了“定位点”和“容错机制”。通过“定位点”使读码机正确识别进行解读，所以二维码不管是从何种方向读取都是可以被识别的。 “容错机制”可以在没有识别到全部条码时也能正确推断和还原出原始的条码信息，维码的纠错级别，按照不同的纠错率（全部码字与可以纠错的码字的比率）分为 L (约 7%)、M (约 15%)、Q (约 25%)、H (约 30%) 四个不同的级别。比如下面的「mghio」公众号二维码尽管中间有公众号头像，但是依然可以正确识别出来就是这个“容错机制”的功能。不管是条形码（一维码）还是二维码其本质上都是对信息的编码，区别只是对信息的编码方式有所不同。 二维码的结构二维码的版本从 1 ~ 40 共 40 个不同的版本，每个版本的基本结构都是相同的，所不同的是每个版本的码元（构成二维码的方形黑白点）数量不同，从版本 1 (21 × 21 码元) 至版本 40 (177 × 177 码元) 依次递增。 二维码可以分为这几不同的功能区域，分别是版本信息、格式信息、数据及容错、定位标志、校正标志等主要区域，其中定位标识用来对二维码进行定位，版本信息表示二维码的版本，有 40 种不同版本的二维码，从版本 1 到版本 40 ，每一版本比前一个版本每边增加 4 个码元，数据及容错用于实际保存的二维码数据信息和用于修正二维码损坏带来的错误的纠错码字，二维码的编码规则比较复杂，感兴趣的朋友可以去看看它的编码规范。 普通二维码存在的问题以上介绍的这种普通二维码只是对文字、网址、电话等信息进行编码，不支持图片、音频、视频等内容，且生成二维码后内容无法改变，在信息内容较多时生成的二维码图案复杂，不容易识别和打印，正是由于存在这些特性故称之为静态二维码。静态二维码的好处就是无需联网也能识别，但是有些时候在线下场景经常需要打印二维码出来让用户去扫码，或者在一些运营场景下需要对用户的扫码情况进行数据统计和分析，再使用普通的二维码就无法提供这些功能了，这时候就要使用动态二维码了。 动态二维码（活码）及其原理动态二维码也称之为活码，关键就在于“活”，“活”就是内容可变，但是二维码不变。活码的优点其实就是静态二维码的缺点，支持随时修改二维码的内容且二维码图案不变，可跟踪扫描统计数据，支持存储大量文字、图片、文件、音视、视频等内容，同时生成的图案简单易扫。 实际上二维码是按照指定的规则编码后的一串字符串，通常大部分情况下是一个网址，在二维码出现之前，我们访问一个网址是打开浏览器输入网址后按下回车即可访问相应的网站，而有了二维码之后，我们使用软件扫描二维码，软件首先会做一次从二维码到文本的解析、转换，然后根据解析出来的文本结果判断是否是链接，是则跳转到这个链接，尽管对我们而言操作方式改变了，但其原理是相同的。 既然二维码背后是网址，要解决静态二维码生成后内容无法修改的问题，是不是只要把网址做成“活的”就行了，即可操控内容的链接，对外暴露的依然还是同一个网址，服务端只需要对这个网址做个二次跳转就行，实际上“活码”就是这么干的，这个对外暴露固定不变的网址也称为“活址”。此时脑海里浮现着计算机科学界一句著名的话： 计算机科学的任何一个问题，都可以通过增加一个中间层来解决。 上面的这个“活址”就是一个“中间层”的角色，屏蔽和隔离了二维码内容的变化，对外始终都只是暴露一个固定的网址。 静态二维码和动态二维码（活码）的区别 比较项 普通二维码 动态二维码(活码) 内容修改 不支持 可以随时修改 内容类型 支持文字、网址、电话等 支持文字、图片、文件、音视、视频等内容 二维码图案 内容越多越复杂 活码图案简单 数据统计 不支持 支持 样式排版 不支持 支持 总结本文主要对条形码、静态二维码和动态二维码的一些基本概念做了简单的介绍，想要深入了解二维码的实现细节和原理的朋友可以看看耗子叔的这篇文章 二维码的生成细节和原理 或者到 官网 查看相关文档。虽然现在绝大部分人对于二维码都非常熟悉，几乎每天都会进行着扫码操作，不过在人们的大脑中依然有一个“根深蒂固”的认知，认为一个二维码扫描之后只会出现一种固定的结果，在接触 活码 这个概念之前俺也是。你知道的越多，不知道的也越多。 参考资料 二维码的生成细节和原理 QR code.com]]></content>
      <categories>
        <category>二维码</category>
        <category>科技</category>
      </categories>
      <tags>
        <tag>二维码</tag>
        <tag>科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 内存模型]]></title>
    <url>%2Fpost%2F2a3a86ee.html</url>
    <content type="text"><![CDATA[前言在并发编程中，当多个线程同时访问同一个共享的可变变量时，会产生不确定的结果，所以要编写线程安全的代码，其本质上是对这些可变的共享变量的访问操作进行管理。导致这种不确定结果的原因就是可见性、有序性和原子性问题，Java 为解决可见性和有序性问题引入了 Java 内存模型，使用互斥方案（其核心实现技术是锁）来解决原子性问题。这篇先来看看解决可见性、有序性问题的 Java 内存模型（JMM）。 什么是 Java 内存模型Java 内存模型在维基百科上的定义如下： The Java memory model describes how threads in the Java programming language interact through memory. Together with the description of single-threaded execution of code, the memory model provides the semantics of the Java programming language. 内存模型限制的是共享变量，也就是存储在堆内存中的变量，在 Java 语言中，所有的实例变量、静态变量和数组元素都存储在堆内存之中。而方法参数、异常处理参数这些局部变量存储在方法栈帧之中，因此不会在线程之间共享，不会受到内存模型影响，也不存在内存可见性问题。 通常，在线程之间的通讯方式有共享内存和消息传递两种，很明显，Java 采用的是第一种即共享的内存模型，在共享的内存模型里，多线程之间共享程序的公共状态，通过读-写内存的方式来进行隐式通讯。 从抽象的角度来看，JMM 其实是定义了线程和主内存之间的关系，首先，多个线程之间的共享变量存储在主内存之中，同时每个线程都有一个自己私有的本地内存，本地内存中存储着该线程读或写共享变量的副本（注意：本地内存是 JMM 定义的抽象概念，实际上并不存在）。抽象模型如下图所示： 在这个抽象的内存模型中，在两个线程之间的通信（共享变量状态变更）时，会进行如下两个步骤： 线程 A 把在本地内存更新后的共享变量副本的值，刷新到主内存中。 线程 B 在使用到该共享变量时，到主内存中去读取线程 A 更新后的共享变量的值，并更新线程 B 本地内存的值。 JMM 本质上是在硬件（处理器）内存模型之上又做了一层抽象，使得应用开发人员只需要了解 JMM 就可以编写出正确的并发代码，而无需过多了解硬件层面的内存模型。 为什么需要 Java 内存模型在日常的程序开发中，为一些共享变量赋值的场景会经常碰到，假设一个线程为整型共享变量 count 做赋值操作（count = 9527;），此时就会有一个问题，其它读取该共享变量的线程在什么情况下获取到的变量值为 9527 呢？如果缺少同步的话，会有很多因素导致其它读取该变量的线程无法立即甚至是永远都无法看到该变量的最新值。 比如缓存就可能会改变写入共享变量副本提交到主内存的次序，保存在本地缓存的值，对于其它线程是不可见的；编译器为了优化性能，有时候会改变程序中语句执行的先后顺序，这些因素都有可能会导致其它线程无法看到共享变量的最新值。 在文章开头，提到了 JMM 主要是为了解决可见性和有序性问题，那么首先就要先搞清楚，导致可见性和有序性问题发生的本质原因是什么？现在的服务绝大部分都是运行在多核 CPU 的服务器上，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据就会有一致性问题了，当一个线程对共享变量的修改，另外一个线程无法立刻看到。导致可见性问题的本质原因是缓存。 有序性是指代码实际的执行顺序和代码定义的顺序一致，编译器为了优化性能，虽然会遵守 as-if-serial 语义（不管怎么重排序，在单线程下的执行结果不能改变），不过有时候编译器及解释器的优化也可能引发一些问题。比如：双重检查来创建单实例对象。下面是使用双重检查来实现延迟创建单例对象的代码： 123456789101112131415161718192021/** * @author mghio * @since 2021-08-22 */public class DoubleCheckedInstance &#123; private static DoubleCheckedInstance instance; public static DoubleCheckedInstance getInstance() &#123; if (instance == null) &#123; synchronized (DoubleCheckedInstance.class) &#123; if (instance == null) &#123; instance = new DoubleCheckedInstance(); &#125; &#125; &#125; return instance; &#125; &#125; 这里的 instance = new DoubleCheckedInstance();，看起来 Java 代码只有一行，应该是无法就行重排序的，实际上其编译后的实际指令是如下三步： 分配对象的内存空间 初始化对象 设置 instance 指向刚刚已经分配的内存地址 上面的第 2 步和第 3 步如果改变执行顺序也不会改变单线程的执行结果，也就是说可能会发生重排序，下图是一种多线程并发执行的场景： 此时线程 B 获取到的 instance 是没有初始化过的，如果此来访问 instance 的成员变量就可能触发空指针异常。导致有序性问题的本质原因是编译器优化。那你可能会想既然缓存和编译器优化是导致可见性问题和有序性问题的原因，那直接禁用掉不就可以彻底解决这些问题了吗，但是如果这么做了的话，程序的性能可能就会受到比较大的影响了。 其实可以换一种思路，能不能把这些禁用缓存和编译器优化的权利交给编码的工程师来处理，他们肯定最清楚什么时候需要禁用，这样就只需要提供按需禁用缓存和编译优化的方法即可，使用比较灵活。因此Java 内存模型就诞生了，它规范了 JVM 如何提供按需禁用缓存和编译优化的方法，规定了 JVM 必须遵守一组最小的保证，这个最小保证规定了线程对共享变量的写入操作何时对其它线程可见。 顺序一致性内存模型顺序一致性模型是一个理想化后的理论参考模型，处理器和编程语言的内存模型的设计都是参考的顺序一致性模型理论。其有如下两大特性： 一个线程中的所有操作必须按照程序的顺序来执行 所有的线程都只能看到一个单一的执行操作顺序，不管程序是否同步 在工程师视角下的顺序一致性模型如下： 顺序一致性模型有一个单一的全局内存，这个全局内存可以通过左右摇摆的开关可以连接到任意一个线程，每个线程都必须按照程序的顺序来执行内存的读和写操作。该理想模型下，任务时刻都只能有一个线程可以连接到内存，当多个线程并发执行时，就可以通过开关就可以把多个线程的读和写操作串行化。 顺序一致性模型中，所有操操作完全按照顺序串行执行，但是在 JMM 中就没有这个保证了，未同步的程序在 JMM 中不仅程序的执行顺序是无序的，而且由于本地内存的存在，所有线程看到的操作顺序也可能会不一致，比如一个线程把写共享变量保存在本地内存中，在还没有刷新到主内存前，其它线程是不可见的，只有更新到主内存后，其它线程才有可能看到。 JMM 对在正确同步的程序做了顺序一致性的保证，也就是程序的执行结果和该程序在顺序一致性内存模型中的执行结果相同。 Happens-Before 规则Happens-Before 规则是 JMM 中的核心概念，Happens-Before 概念最开始在 这篇论文 提出，其在论文中使用 Happens-Before 来定义分布式系统之间的偏序关系。在 JSR-133 中使用 Happens-Before 来指定两个操作之间的执行顺序。 JMM 正是通过这个规则来保证跨线程的内存可见性，Happens-Before 的含义是前面一个对共享变量的操作结果对该变量的后续操作是可见的，约束了编译器的优化行为，虽然允许编译器优化，但是优化后的代码必须要满足 Happens-Before 规则，这个规则给工程师做了这个保证：同步的多线程程序是按照 Happens-Before 指定的顺序来执行的。目的就是为了在不改变程序（单线程或者正确同步的多线程程序）执行结果的前提下，尽最大可能的提高程序执行的效率。 JSR-133 规范中定了如下 6 项 Happens-Before 规则： 程序顺序规则：一个线程中的每个操作，Happens-Before 该线程中的任意后续操作 监视器锁规则：对一个锁的解锁操作，Happens-Before 于后面对这个锁的加锁操作 volatile 规则对一个 volatile 类型的变量的写操作，Happens-Before 与任意后面对这个 volatile 变量的读操作 传递性规则：如果操作 A Happens-Before 于操作 B，并且操作 B Happens-Before 于操作 C，则操作 A Happens-Before 于操作 C start() 规则：如果一个线程 A 执行操作 threadB.start() 启动线程 B，那么线程 A 的 start() 操作 Happens-Before 于线程 B 的任意操作 join() 规则：如果线程 A 执行操作 threadB.join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于线程 A 从 threadB.join() 操作成功返回 JMM 的一个基本原则是：只要不改变单线程和正确同步的多线程的执行结果，编译器和处理器随便怎么优化都可以，实际上对于应用开发人员对于两个操作是否真的被重排序并不关心，真正关心的是执行结果不能被修改。因此 Happens-Before 本质上和 sa-if-serial 的语义是一致的，只是 sa-if-serial 只是保证在单线程下的执行结果不被改变。 总结本文主要介绍了内存模型的相关基础知识和相关概念，JMM 屏蔽了不同处理器内存模型之间的差异，在不同的处理器平台上给应用开发人员抽象出了统一的 Java 内存模型（JMM）。常见的处理器内存模型比 JMM 的要弱，因此 JVM 会在生成字节码指令时在适当的位置插入内存屏障（内存屏障的类型会因处理器平台而有所不同）来限制部分重排序。]]></content>
      <categories>
        <category>Java</category>
        <category>Memory</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象转换工具 MapStruct 介绍]]></title>
    <url>%2Fpost%2F42aa4c23.html</url>
    <content type="text"><![CDATA[前言在我们日常开发的分层结构的应用程序中，为了各层之间互相解耦，一般都会定义不同的对象用来在不同层之间传递数据，因此，就有了各种 XXXDTO、XXXVO、XXXBO 等基于数据库对象派生出来的对象，当在不同层之间传输数据时，不可避免地经常需要将这些对象进行相互转换。 此时一般处理两种处理方式：① 直接使用 Setter 和 Getter 方法转换、② 使用一些工具类进行转换（e.g. BeanUtil.copyProperties）。第一种方式如果对象属性比较多时，需要写很多的 Getter/Setter 代码。第二种方式看起来虽然比第一种方式要简单很多，但是因为其使用了反射，性能不太好，而且在使用中也有很多陷阱。而今天要介绍的主角 MapStruct 在不影响性能的情况下，同时解决了这两种方式存在的缺点。 MapStruct 是什么MapStruct 是一个代码生成器，它基于约定优于配置方法极大地简化了 Java bean 类型之间映射的实现。自动生成的映射转换代码只使用简单的方法调用，因此速度快、类型安全而且易于理解阅读，源码仓库 Github 地址 MapStruct。总的来说，有如下三个特点： 基于注解 在编译期自动生成映射转换代码 类型安全、高性能、无依赖性 MapStruct 使用步骤MapStruct 的使用比较简单，只需如下三步即可。 ① 引入依赖（这里以 Gradle 方式为例）1234dependencies &#123; implementation 'org.mapstruct:mapstruct:1.4.2.Final' annotationProcessor 'org.mapstruct:mapstruct-processor:1.4.2.Final'&#125; ② 创建相关转换对象1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class Doctor &#123; private Integer id; private String name;&#125; 1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class DoctorDTO &#123; private Integer id; private String name;&#125; ③ 创建转换器类（Mapper）需要注意的是，转换器不一定都要使用 Mapper 作为结尾，只是官方示例推荐以 XXXMapper 格式命名转换器名称，这里举例的是最简单的映射情况（字段名称和类型都完全匹配），只需要在转换器类上添加 @Mapper 注解即可，转换器代码如下所示： 1234567891011/** * @author mghio * @since 2021-08-08 */@Mapperpublic interface DoctorMapper &#123; DoctorMapper INSTANCE = Mappers.getMapper(DoctorMapper.class); DoctorDTO toDTO(Doctor doctor);&#125; 通过下面这个简单的测试来校验转换结果是否正确，测试代码如下： 12345678910111213141516171819202122/** * @author mghio * @since 2021-08-08 */public class DoctorTest &#123; @Test public void testToDTO() &#123; Integer doctorId = 9527; String doctorName = "mghio"; Doctor doctor = new Doctor(); doctor.setId(doctorId); doctor.setName(doctorName); DoctorDTO doctorDTO = DoctorMapper.INSTANCE.toDTO(doctor); assertEquals(doctorId, doctorDTO.getId()); assertEquals(doctorName, doctorDTO.getName()); &#125;&#125; 测试结果正常通过，说明使用 DoctorMapper 转换器达到我们的预期结果。 MapStruct 实现浅析在以上示例中，使用 MapStruct 通过简单的三步就实现了 Doctor 到 DoctorDTO 的转换，那么，MapStruct 是如何做到的呢？其实通过我们定义的转换器可以发现，转换器是接口类型的，而我们知道在 Java 中，接口是无法提供功能的，只是定义规范，具体干活的还是它的实现类。 因此我们可以大胆猜想，MapStruct 肯定给我们定义的转换器接口（DoctorMapper）生成了实现类，而通过 Mappers.getMapper(DoctorMapper.class) 获取到的转换器实际上是获取到了转化器接口的实现类。下面通过在测试类中 debug 来验证一下： 通过 debug 可以看出，DoctorMapper.INSTANCE 获取到的是接口的实现类 DoctorMapperImpl。这个转换器接口实现类是在编译期自动生成的，Gradle 项目是在 build/generated/sources/anotationProcessor/Java 下（Maven 项目在 target/generated-sources/annotations 目录下），生成以上示例转换器接口的实现类源码如下： 可以发现，自动生成的代码和我们平时手写的差不多，简单易懂，代码完全在编译期间生成，没有运行时依赖。和使用反射的实现方式相比还有一个有点就是，出错时很容易去 debug 实现源码来定位，而反射相对来说定位问题就要困难得多了。 常见使用场景介绍① 对象属性名称和类型完全相同从上文的示例可以看出，当属性名称和类型完全一致时，我们只需要定义一个转换器接口并添加 @Mapper 注解即可，然后 MapStruct 会自动生成实现类完成转换。示例代码如下: 1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class Source &#123; private Integer id; private String name;&#125; 1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class Target &#123; private Integer id; private String name;&#125; 1234567891011/** * @author mghio * @since 2021-08-08 */@Mapperpublic interface SourceMapper &#123; SourceMapper INSTANCE = Mappers.getMapper(SourceMapper.class); Target toTarget(Source source);&#125; ② 对象属性类型相同但是名称不同当对象属性类型相同但是属性名称不一样时，通过 @Mapping 注解来手动指定转换。示例代码如下： 1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class Source &#123; private Integer id; private String sourceName;&#125; 1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class Target &#123; private Integer id; private String targetName;&#125; 123456789101112/** * @author mghio * @since 2021-08-08 */@Mapperpublic interface SourceMapper &#123; SourceMapper INSTANCE = Mappers.getMapper(SourceMapper.class); @Mapping(source = "sourceName", target = "targetName") Target toTarget(Source source);&#125; ③ 在 Mapper 中使用自定义转换方法有时候，对于某些类型（比如：一个类的属性是自定义的类），无法以自动生成代码的形式进行处理。此时我们需要自定义类型转换的方法，在 JDK 7 之前的版本，就需要使用抽象类来定义转换 Mapper 了，在 JDK 8 以上的版本可以使用接口的默认方法来自定义类型转换的方法。示例代码如下： 12345678910111213/** * @author mghio * @since 2021-08-08 */@Datapublic class Source &#123; private Integer id; private String sourceName; private InnerSource innerSource;&#125; 1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class InnerSource &#123; private Integer deleted; private String name;&#125; 12345678910111213/** * @author mghio * @since 2021-08-08 */@Datapublic class Target &#123; private Integer id; private String targetName; private InnerTarget innerTarget;&#125; 1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class InnerTarget &#123; private Boolean isDeleted; private String name;&#125; 12345678910111213141516171819202122/** * @author mghio * @since 2021-08-08 */@Mapperpublic interface SourceMapper &#123; SourceMapper INSTANCE = Mappers.getMapper(SourceMapper.class); @Mapping(source = "sourceName", target = "targetName") Target toTarget(Source source); default InnerTarget innerTarget2InnerSource(InnerSource innerSource) &#123; if (innerSource == null) &#123; return null; &#125; InnerTarget innerTarget = new InnerTarget(); innerTarget.setIsDeleted(innerSource.getDeleted() == 1); innerTarget.setName(innerSource.getName()); return innerTarget; &#125;&#125; ④ 多个对象转换成一个对象返回在一些实际业务编码的过程中，不可避免地需要将多个对象转化为一个对象的场景，MapStruct 也能很好的支持，对于这种最终返回信息来源于多个类，我们可以通过配置来实现多对一的转换。示例代码如下： 1234567891011/** * @author mghio * @since 2021-08-08 */@Datapublic class Doctor &#123; private Integer id; private String name;&#125; 1234567891011/** * @author mghio * @since 2021-08-09 */@Datapublic class Address &#123; private String street; private Integer zipCode;&#125; 12345678910111213/** * @author mghio * @since 2021-08-09 */@Mapperpublic interface AddressMapper &#123; AddressMapper INSTANCE = Mappers.getMapper(AddressMapper.class); @Mapping(source = "doctor.id", target = "personId") @Mapping(source = "address.street", target = "streetDesc") DeliveryAddressDTO doctorAndAddress2DeliveryAddressDTO(Doctor doctor, Address address);&#125; 从这个示例中的转换器（AddressMapper）可以看出，当属性名称和类型完全匹配时同样可以自动转换，但是当来源对象有多个属性名称及类型完全和目标对象相同时，还是需要手动配置指定的，因为此时 MapStruct 也无法准确判断应该使用哪个属性转换。 获取转换器（Mapper）的几种方式获取转换器的方式根据 @Mapper 注解的 componentModel 属性不同而不同，支持以下四种不同的取值： default 默认方式，默认方式，使用工厂方式（Mappers.getMapper(Class)）来获取 cdi 此时生成的映射器是一个应用程序范围的 CDI bean，使用 @Inject 注解来获取 spring Spring 的方式，可以通过 @Autowired 注解来获取，在 Spring 框架中推荐使用此方式 jsr330 生成的映射器用 @javax.inject.Named 和 @Singleton 注解，通过 @Inject 来获取 ① 通过工厂方式获取上文的示例中都是通过工厂方式获取的，也就是使用 MapStruct 提供的 Mappers.getMapper(Class&lt;T&gt; clazz) 方法来获取指定类型的 Mapper。然后在调用的时候就不需要反复创建对象了，方法的最终实现是通过我们定义接口的类加载器加载 MapStruct 生成的实现类（类名称规则为：接口名称 + Impl），然后调用该类的无参构造器创建对象。核心源码如下所示： ② 使用依赖注入方式获取对于依赖注入（dependency injection），使用 Spring 框架开发的朋友们应该很熟悉了，工作中经常使用。MapStruct 也支持依赖注入的使用方式，并且官方也推荐使用依赖注入的方式获取。使用 Spring 依赖注入的方式只需要指定 @Mapper 注解的 componentModel = &quot;spring&quot; 即可，示例代码如下： 12345678910111213/** * @author mghio * @since 2021-08-08 */@Mapper(componentModel = "spring")public interface SourceMapper &#123; SourceMapper INSTANCE = Mappers.getMapper(SourceMapper.class); @Mapping(source = "sourceName", target = "targetName") Target toTarget(Source source);&#125; 我们可以使用 @Autowired 获取的原因是 SourceMapper 接口的实现类已经被注册为容器中一个 Bean 了，通过如下生成的接口实现类的代码也可以看到，在类上自动加上了 @Component 注解。 最后还有两个注意事项：① 当两个转换对象的属性不一致时（比如 DoctorDTO 中不存在 Doctor 对象中的某个字段），编译时会出现警告提示。可以在@Mapping 注解中配置 ignore = true，或者当不一致字段比较多时，可以直接设置 @Mapper 注解的 unmappedTargetPolicy 属性或unmappedSourcePolicy 属性设置为 ReportingPolicy.IGNORE。② 如果你项目中也使用了 Lombok，需要注意一下 Lombok 的版本至少是 1.18.10 或者以上才行，否则会出现编译失败的情况。刚开始用的时候我也踩到这个坑了。。。 总结本文介绍了对象转换工具 Mapstruct 库，以安全优雅的方式来减少我们的转换代码。从文中的示例中可以看出，Mapstruct 提供了大量的功能和配置，使我们能够以简单快捷的方式创建从简单到复杂的映射器。文中所介绍到的只是 Mapstruct 库的冰山一角，还有很多强大的功能文中没有提到，感兴趣的朋友可以自行查看 官方使用指南。]]></content>
      <categories>
        <category>Java</category>
        <category>MapStruct</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MapStruct</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 异步编程的几种方式]]></title>
    <url>%2Fpost%2Fe3d37c7a.html</url>
    <content type="text"><![CDATA[前言异步编程是让程序并发运行的一种手段。它允许多个事情同时发生，当程序调用需要长时间运行的方法时，它不会阻塞当前的执行流程，程序可以继续运行，当方法执行完成时通知给主线程根据需要获取其执行结果或者失败异常的原因。使用异步编程可以大大提高我们程序的吞吐量，可以更好的面对更高的并发场景并更好的利用现有的系统资源，同时也会一定程度上减少用户的等待时间等。本文我们一起来看看在 Java 语言中使用异步编程有哪些方式。 Thread 方式在 Java 语言中最简单使用异步编程的方式就是创建一个 Thread 来实现，如果你使用的 JDK 版本是 8 以上的话，可以使用 Lambda 表达式 会更加简洁。为了能更好的体现出异步的高效性，下面提供同步版本和异步版本的示例作为对照： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * @author mghio * @since 2021-08-01 */public class SyncWithAsyncDemo &#123; public static void doOneThing() &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("doOneThing ----&gt;&gt;&gt; success"); &#125; public static void doOtherThing() &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("doOtherThing ----&gt;&gt;&gt; success"); &#125; public synchronized static void main(String[] args) throws InterruptedException &#123; StopWatch stopWatch = new StopWatch("SyncWithAsyncDemo"); stopWatch.start(); // 同步调用版本 // testSynchronize(); // 异步调用版本 testAsynchronize(); stopWatch.stop(); System.out.println(stopWatch); &#125; private static void testAsynchronize() throws InterruptedException &#123; System.out.println("-------------------- testAsynchronize --------------------"); // 创建一个线程执行 doOneThing Thread doOneThingThread = new Thread(SyncWithAsyncDemo::doOneThing, "doOneThing-Thread"); doOneThingThread.start(); doOtherThing(); // 等待 doOneThing 线程执行完成 doOneThingThread.join(); &#125; private static void testSynchronize() &#123; System.out.println("-------------------- testSynchronize --------------------"); doOneThing(); doOtherThing(); &#125;&#125; 同步执行的运行如下： 注释掉同步调用版本的代码，得到异步执行的结果如下： 从两次的运行结果可以看出，同步版本耗时 4002 ms，异步版本执行耗时 2064 ms，异步执行耗时减少将近一半，可以看出使用异步编程后可以大大缩短程序运行时间。 上面的示例的异步线程代码在 main 方法内开启了一个线程 doOneThing-Thread 用来异步执行 doOneThing 任务，在这时该线程与 main 主线程并发运行，也就是任务 doOneThing 与任务 doOtherThing 并发运行，则等主线程运行完 doOtherThing 任务后同步等待线程 doOneThing 运行完毕，整体还是比较简单的。 但是这个示例只能作为示例使用，如果用到了生产环境发生事故后果自负，使用上面这种 Thread 方式异步编程存在两个明显的问题。 创建线程没有复用。我们知道频繁的线程创建与销毁是需要一部分开销的，而且示例里也没有限制线程的个数，如果使用不当可能会把系统线程用尽，从而引发事故，这个问题使用线程池可以解决。 异步任务无法获取最终的执行结果。示例中的这种方式是满足不了的，这时候就需要使用下面介绍的第二种 FutureTask 的方式了。 FutureTask 方式自 JDK 1.5 开始，引入了 Future 接口和实现 Future 接口的 FutureTask 类来表示异步计算结果。这个 FutureTask 类不仅实现了 Future 接口还实现了 Runnable 接口，表示一种可生成结果的 Runnable。其可以处于这三种状态： 未启动 当创建一个 FutureTask 没有执行 FutureTask.run() 方法之前 已启动 在 FutureTask.run() 方法执行的过程中 已完成 在 FutureTask.run() 方法正常执行结果或者调用了 FutureTask.cancel(boolean mayInterruptIfRunning) 方法以及在调用 FutureTask.run() 方法的过程中发生异常结束后 FutureTask 类实现了 Future 接口的开启和取消任务、查询任务是否完成、获取计算结果方法。要获取 FutureTask 任务的结果，我们只能通过调用 getXXX() 系列方法才能获取，当结果还没出来时候这些方法会被阻塞，同时这了任务可以是 Callable 类型（有返回结果），也可以是 Runnable 类型（无返回结果）。我们修改上面的示例把两个任务方法修改为返回 String 类型，使用 FutureTask 的方法如下： 123456789101112131415161718private static void testFutureTask() throws ExecutionException, InterruptedException &#123; System.out.println("-------------------- testFutureTask --------------------"); // 创建一个 FutureTask（doOneThing 任务） FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(FutureTaskDemo::doOneThing); // 使用线程池执行 doOneThing 任务 ForkJoinPool.commonPool().execute(futureTask); // 执行 doOtherThing 任务 String doOtherThingResult = doOtherThing(); // 同步等待线程执行 doOneThing 任务结束 String doOneThingResult = futureTask.get(); // 任务执行结果输出 System.out.println("doOneThingResult ----&gt;&gt;&gt; " + doOneThingResult); System.out.println("doOtherThingResult ----&gt;&gt;&gt; " + doOtherThingResult);&#125; 使用 FutureTask 异步编程方式的耗时和上面的 Thread 方式是差不多的，其本质都是另起一个线程去做 doOneThing 任务然后等待返回，运行结果如下： 这个示例中，doOneThing 和 doOtherThing 都是有返回值的任务（都返回 String 类型结果），我们在主线程 main 中创建一个异步任务 FutureTask 来执行 doOneThing，然后使用 ForkJoinPool.commonPool() 创建线程池（有关 ForkJoinPool 的介绍见 这里），然后调用了线程池的 execute 方法把 futureTask 提交到线程池来执行。 通过示例可以看到，虽然 FutureTask 提供了一些方法让我们获取任务的执行结果、任务是否完成等，但是使用还是比较复杂，在一些较为复杂的场景（比如多个 FutureTask 之间的关系表示）的编码还是比较繁琐，还是当我们调用 getXXX() 系列方法时还是会在任务执行完毕前阻塞调用线程，达不到异步编程的效果，基于这些问题，在 JDK 8 中引入了 CompletableFuture 类，下面来看看如何使用 CompletableFuture 来实现异步编程。 CompletableFuture 方式JDK 8 中引入了 CompletableFuture 类，实现了 Future 和 CompletionStage 接口，为异步编程提供了一些列方法，如 supplyAsync、runAsync 和 thenApplyAsync 等，除此之外 CompletableFuture 还有一个重要的功能就是可以让两个或者多个 CompletableFuture 进行运算来产生结果。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @author mghio * @since 2021-08-01 */public class CompletableFutureDemo &#123; public static CompletableFuture&lt;String&gt; doOneThing() &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return "doOneThing"; &#125;); &#125; public static CompletableFuture&lt;String&gt; doOtherThing(String parameter) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return parameter + " " + "doOtherThing"; &#125;); &#125; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; StopWatch stopWatch = new StopWatch("CompletableFutureDemo"); stopWatch.start(); // 异步执行版本 testCompletableFuture(); stopWatch.stop(); System.out.println(stopWatch); &#125; private static void testCompletableFuture() throws InterruptedException, ExecutionException &#123; // 先执行 doOneThing 任务，后执行 doOtherThing 任务 CompletableFuture&lt;String&gt; resultFuture = doOneThing().thenCompose(CompletableFutureDemo::doOtherThing); // 获取任务结果 String doOneThingResult = resultFuture.get(); // 获取执行结果 System.out.println("DoOneThing and DoOtherThing execute finished. result = " + doOneThingResult); &#125;&#125; 执行结果如下： 在主线程 main 中首先调用了方法 doOneThing() 方法开启了一个异步任务，并返回了对应的 CompletableFuture 对象，我们取名为 doOneThingFuture，然后在 doOneThingFuture 的基础上使用 CompletableFuture 的 thenCompose() 方法，让 doOneThingFuture 方法执行完成后，使用其执行结果作为 doOtherThing(String parameter) 方法的参数创建的异步任务返回。 我们不需要显式使用 ExecutorService，在 CompletableFuture 内部使用的是 Fork/Join 框架异步处理任务，因此，它使我们编写的异步代码更加简洁。此外，CompletableFuture 类功能很强大其提供了和很多方便的方法，更多关于 CompletableFuture 的使用请见 这篇。 总结本文介绍了在 Java 中的 JDK 使用异步编程的三种方式，这些是我们最基础的实现异步编程的工具，在其之上的还有 Guava 库提供的 ListenableFuture 和 Futures 类以及 Spring 框架提供的异步执行能力，使用 @Async 等注解实现异步处理，感兴趣的话可以自行学习了解。]]></content>
      <categories>
        <category>Java</category>
        <category>异步</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发之 Fork/Join 框架]]></title>
    <url>%2Fpost%2F30ff968d.html</url>
    <content type="text"><![CDATA[什么是 Fork/Join 框架Fork/Join 框架是一种在 JDK 7 引入的线程池，用于并行执行把一个大任务拆成多个小任务并行执行，最终汇总每个小任务结果得到大任务结果的特殊任务。通过其命名也很容易看出框架主要分为 Fork 和 Join 两个阶段，第一阶段 Fork 是把一个大任务拆分为多个子任务并行的执行，第二阶段 Join 是合并这些子任务的所有执行结果，最后得到大任务的结果。 这里不难发现其执行主要流程：首先判断一个任务是否足够小，如果任务足够小，则直接计算，否则，就拆分成几个更小的小任务分别计算，这个过程可以反复的拆分成一系列小任务。Fork/Join 框架是一种基于 分治 的算法，通过拆分大任务成多个独立的小任务，然后并行执行这些小任务，最后合并小任务的结果得到大任务的最终结果，通过并行计算以提高效率。 Fork/Join 框架使用示例下面通过一个计算列表中所有元素的总和的示例来看看 Fork/Join 框架是如何使用的，总的思路是：将这个列表分成许多子列表，然后对每个子列表的元素进行求和，然后，我们再计算所有这些值的总和就得到原始列表的和了。Fork/Join 框架中定义了 ForkJoinTask 来表示一个 Fork/Join 任务，其提供了 fork()、join() 等操作，通常情况下，我们并不需要直接继承这个 ForkJoinTask 类，而是使用框架提供的两个 ForkJoinTask 的子类： RecursiveAction 用于表示没有返回结果的 Fork/Join 任务。 RecursiveTask 用于表示有返回结果的 Fork/Join 任务。 很显然，在这个示例中是需要返回结果的，可以定义 SumAction 类继承自 RecursiveTask，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * @author mghio * @since 2021-07-25 */public class SumTask extends RecursiveTask&lt;Long&gt; &#123; private static final int SEQUENTIAL_THRESHOLD = 50; private final List&lt;Long&gt; data; public SumTask(List&lt;Long&gt; data) &#123; this.data = data; &#125; @Override protected Long compute() &#123; if (data.size() &lt;= SEQUENTIAL_THRESHOLD) &#123; long sum = computeSumDirectly(); System.out.format("Sum of %s: %d\n", data.toString(), sum); return sum; &#125; else &#123; int mid = data.size() / 2; SumTask firstSubtask = new SumTask(data.subList(0, mid)); SumTask secondSubtask = new SumTask(data.subList(mid, data.size())); // 执行子任务 firstSubtask.fork(); secondSubtask.fork(); // 等待子任务执行完成，并获取结果 long firstSubTaskResult = firstSubtask.join(); long secondSubTaskResult = secondSubtask.join(); return firstSubTaskResult + secondSubTaskResult; &#125; &#125; private long computeSumDirectly() &#123; long sum = 0; for (Long l : data) &#123; sum += l; &#125; return sum; &#125; public static void main(String[] args) &#123; Random random = new Random(); List&lt;Long&gt; data = random .longs(1_000, 1, 100) .boxed() .collect(Collectors.toList()); ForkJoinPool pool = new ForkJoinPool(); SumTask task = new SumTask(data); pool.invoke(task); System.out.println("Sum: " + pool.invoke(task)); &#125;&#125; 这里当列表大小小于 SEQUENTIAL_THRESHOLD 变量的值（阈值）时视为小任务，直接计算求和列表元素结果，否则再次拆分为小任务，运行结果如下： 通过这个示例代码可以发现，Fork/Join 框架 中 ForkJoinTask 任务与平常的一般任务的主要不同点在于：ForkJoinTask 需要实现抽象方法 compute() 来定义计算逻辑，在这个方法里一般通用的实现模板是，首先先判断当前任务是否是小任务，如果是，就执行执行任务，如果不是小任务，则再次拆分为两个子任务，然后当每个子任务调用 fork() 方法时，会再次进入到 compute() 方法中，检查当前任务是否需要再拆分为子任务，如果已经是小任务，则执行当前任务并返回结果，否则继续分割，最后调用 join() 方法等待所有子任务执行完成并获得执行结果。伪代码如下： 12345678if (problem is small) &#123; directly solve problem.&#125; else &#123; Step 1. split problem into independent parts. Step 2. fork new subtasks to solve each part. Step 3. join all subtasks. Step 4. compose result from subresults.&#125; Fork/Join 框架设计Fork/Join 框架核心思想是把一个大任务拆分成若干个小任务，然后汇总每个小任务的结果最终得到大任务的结果，如果让你设计一个这样的框架，你会如何实现呢？（建议思考一下），Fork/Join 框架的整个流程正如其名所示，分为两个步骤： 大任务分割 需要有这么一个的类，用来将大任务拆分为子任务，可能一次拆分后的子任务还是比较大，需要多次拆分，直到拆分出来的子任务符合我们定义的小任务才结束。 执行任务并合并任务结果 第一步拆分出来的子任务分别存放在一个个 双端队列 里面（P.S. 这里为什么要使用双端队列请看下文），然后每个队列启动一个线程从队列中获取任务执行。这些子任务的执行结果都会放到一个统一的队列中，然后再启动一个线程从这个队列中拿数据，最后合并这些数据返回。 Fork/Join 框架使用了如下两个类来完成以上两个步骤： ForkJoinTask 类 在上文的实例中也有提到，表示 ForkJoin 任务，在使用框架时首先必须先定义任务，通常只需要继承自 ForkJoinTask 类的子类 RecursiveAction(无返回结果) 或者 RecursiveTask(有返回结果)即可。 ForkJoinPool 从名字也可以猜到一二了，就是用来执行 ForkJoinTask 的线程池。大任务拆分出的子任务会添加到当前线程的双端队列的头部。 喜欢思考的你，心中想必会想到这么一种场景，当我们需要完成一个大任务时，会先把这个大任务拆分为多个独立的子任务，这些子任务会放到独立的队列中，并为每个队列都创建一个单独的线程去执行队列里的任务，即这里线程和队列时一对一的关系，那么当有的线程可能会先把自己队列的任务执行完成了，而有的线程则没有执行完成，这就导致一些先执行完任务的线程干等了，这是个好问题。 既然是做并发的，肯定要最大程度压榨计算机的性能，对于这种场景并发大师 Doug Lea 使用了工作窃取算法处理，使用工作窃取算法后，先完成自己队列中任务的线程会去其它线程的队列中”窃取“一个任务来执行，哈哈，一方有难，八方支援。但是此时这个线程和队列的持有线程会同时访问同一个队列，所以为了减少窃取任务的线程和被窃取任务的线程之间的竞争，ForkJoin 选择了双端队列这种数据结构，这样就可以按照这种规则执行任务了：被窃取任务的线程始终从队列头部获取任务并执行，窃取任务的线程使用从队列尾部获取任务执行。这个算法在绝大部分情况下都可以充分利用多线程进行并行计算，但是在双端队列里只有一个任务等极端情况下还是会存在一定程度的竞争。 Fork/Join 框架实现原理Fork/Join 框架的实现核心是 ForkJoinPool 类，该类的重要组成部分为 ForkJoinTask 数组和 ForkJoinWorkerThread 数组，其中 ForkJoinTask 数组用来存放框架使用者给提交给 ForkJoinPool 的任务，ForkJoinWorkerThread 数组则负责执行这些任务。任务有如下四种状态： NORMAL 已完成 CANCELLED 被取消 SIGNAL 信号 EXCEPTIONAL 发生异常 下面来看看这两个类的核心方法实现原理，首先来看 ForkJoinTask 的 fork() 方法，源码如下： 方法对于 ForkJoinWorkerThread 类型的线程，首先会调用 ForkJoinWorkerThread 的 workQueue 的 push() 方法异步的去执行这个任务，然后马上返回结果。继续跟进 ForkJoinPool 的 push() 方法，源码如下： 方法将当前任务添加到 ForkJoinTask 任务队列数组中，然后再调用 ForkJoinPool 的 signalWork 方法创建或者唤醒一个工作线程来执行该任务。然后再来看看 ForkJoinTask 的 join() 方法，方法源码如下： 方法首先调用了 doJoin() 方法，该方法返回当前任务的状态，根据返回的任务状态做不同的处理： 已完成状态则直接返回结果 被取消状态则直接抛出异常（CancellationException） 发生异常状态则直接抛出对应的异常 继续跟进 doJoin() 方法，方法源码如下： 方法首先判断当前任务状态是否已经执行完成，如果执行完成则直接返回任务状态。如果没有执行完成，则从任务数组中（workQueue）取出任务并执行，任务执行完成则设置任务状态为 NORMAL，如果出现异常则记录异常并设置任务状态为 EXCEPTIONAL（在 doExec() 方法中）。 总结本文主要介绍了 Java 并发框架中的 Fork/Join 框架的基本原理和其使用的工作窃取算法(work-stealing)、设计方式和部分实现源码。Fork/Join 框架在 JDK 的官方标准库中也有应用。比如 JDK 1.8+ 标准库提供的 Arrays.parallelSort(array) 可以进行并行排序，它的原理就是内部通过 Fork/Join 框架对大数组分拆进行并行排序，可以提高排序的速度，还有集合中的 Collection.parallelStream() 方法底层也是基于 Fork/Join 框架实现的，最后就是定义小任务的阈值往往是需要通过测试验证才能合理给出，并且保证程序可以达到最好的性能。]]></content>
      <categories>
        <category>Java</category>
        <category>并发</category>
        <category>Fork-Join</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>Fork-Join</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 的循环依赖问题]]></title>
    <url>%2Fpost%2Ff7a05eb0.html</url>
    <content type="text"><![CDATA[什么是循环依赖什么是循环依赖呢？可以把它拆分成循环和依赖两个部分来看，循环是指计算机领域中的循环，执行流程形成闭合回路；依赖就是完成这个动作的前提准备条件，和我们平常说的依赖大体上含义一致。放到 Spring 中来看就一个或多个 Bean 实例之间存在直接或间接的依赖关系，构成循环调用，循环依赖可以分为直接循环依赖和间接循环依赖，直接循环依赖的简单依赖场景：Bean A 依赖于 Bean B，然后 Bean B 又反过来依赖于 Bean A（Bean A -&gt; Bean B -&gt; Bean A），间接循环依赖的一个依赖场景：Bean A 依赖于 Bean B，Bean B 依赖于 Bean C，Bean C 依赖于 Bean A，中间多了一层，但是最终还是形成循环（Bean A -&gt; Bean B -&gt; Bean C -&gt; Bean A）。 循环依赖的类型第一种是自依赖，自己依赖自己从而形成循环依赖，一般情况下不会发生这种循环依赖，因为它很容易被我们发现。 第二种是直接依赖，发生在两个对象之间，比如：Bean A 依赖于 Bean B，然后 Bean B 又反过来依赖于 Bean A，如果比较细心的话肉眼也不难发现。 第三种是间接依赖，这种依赖类型发生在 3 个或者以上的对象依赖的场景，间接依赖最简单的场景：Bean A 依赖于 Bean B，Bean B 依赖于 Bean C，Bean C 依赖于 Bean A，可以想象当中间依赖的对象很多时，是很难发现这种循环依赖的，一般都是借助一些工具排查。 Spring 对几种循环依赖场景支持情况在介绍 Spring 对几种循环依赖场景的处理方式之前，先来看看在 Spring 中循环依赖会有哪些场景，大部分常见的场景总结如下图所示： 有句话说得好，源码之下无秘密，下面就通过源码探究这些场景 Spring 是否支持，以及支持的原因或者不支持的原因，话不多说，下面进入正题。 第 ① 种场景——单例 Bean 的 setter 注入这种使用方式也是最常用的方式之一，假设有两个 Service 分别为 OrderService（订单相关业务逻辑）和 TradeService（交易相关业务逻辑），代码如下： 123456789101112131415/** * @author mghio * @since 2021-07-17 */@Servicepublic class OrderService &#123; @Autowired private TradeService tradeService; public void testCreateOrder() &#123; // omit business logic ... &#125;&#125; 123456789101112131415/** * @author mghio * @since 2021-07-17 */@Servicepublic class TradeService &#123; @Autowired private OrderService orderService; public void testCreateTrade() &#123; // omit business logic ... &#125;&#125; 这种循环依赖场景，程序是可以正常运行的，从代码上看确实是有循环依赖了，也就是说 Spring 是支持这种循环依赖场景的，这里我们察觉不到循环依赖的原因是 Spring 已经默默地解决了。 假设没有做任何处理，按照正常的创建逻辑来执行的话，流程是这样的：容器先创建 OrderService，发现依赖于 TradeService，再创建 OrderService，又发现依赖于 TradeService … ，发生无限死循环，最后发生栈溢出错误，程序停止。为了支持这种常见的循环依赖场景，Spring 将创建对象分为如下几个步骤： 实例化一个新对象（在堆中），但此时尚未给对象属性赋值 给对象赋值 调用 BeanPostProcessor 的一些实现类的方法，在这个阶段，Bean 已经创建并赋值属性完成。这时候容器中所有实现 BeanPostProcessor 接口的类都会被调用（e.g. AOP） 初始化（如果实现了 InitializingBean，就会调用这个类的方法来完成类的初始化） 返回创建出来的实例 为此，Spring 引入了三级缓存来处理这个问题（三级缓存定义在 org.springframework.beans.factory.support.DefaultSingletonBeanRegistry 中），第一级缓存 singletonObjects 用于存放完全初始化好的 Bean，从该缓存中取出的 Bean 可以直接使用，第二级缓存 earlySingletonObjects 用于存放提前暴露的单例对象的缓存，存放原始的 Bean 对象（属性尚未赋值），用于解决循环依赖，第三级缓存 singletonFactories 用于存放单例对象工厂的缓存，存放 Bean 工厂对象，用于解决循环依赖。上述实例使用三级缓存的处理流程如下所示： 如果你看过三级缓存的定义源码的话，可能也有这样的疑问：为什么第三级的缓存的要定义成 Map&lt;String, ObjectFactory&lt;?&gt;&gt;，不能直接缓存对象吗？这里不能直接保存对象实例，因为这样就无法对其做增强处理了。详情可见类 org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean 方法部分源码如下： 第 ② 种场景——多例 Bean 的 setter 注入这种方式平常使用得相对较少，还是使用前文的两个 Service 作为示例，唯一不同的地方是现在都声明为多例了，示例代码如下： 12345678910111213141516/** * @author mghio * @since 2021-07-17 */@Service@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)public class OrderService &#123; @Autowired private TradeService tradeService; public void testCreateOrder() &#123; // omit business logic ... &#125;&#125; 12345678910111213141516/** * @author mghio * @since 2021-07-17 */@Service@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)public class TradeService &#123; @Autowired private OrderService orderService; public void testCreateTrade() &#123; // omit business logic ... &#125;&#125; 如果你在 Spring 中运行以上代码，是可以正常启动成功的，原因是在类 org.springframework.beans.factory.support.DefaultListableBeanFactory 的 preInstantiateSingletons() 方法预实例化处理时，过滤掉了多例类型的 Bean，方法部分代码如下： 但是如果此时有其它单例类型的 Bean 依赖到这些多例类型的 Bean 的时候，就会报如下所示的循环依赖错误了。 第 ③ 种场景——代理对象的 setter 注入这种场景也会经常碰到，有时候为了实现异步调用会在 XXXXService 类的方法上添加 @Async 注解，让方法对外部变成异步调用（前提要是要在启用类上添加启用注解哦 @EnableAsync），示例代码如下： 12345678910111213/** * @author mghio * @since 2021-07-17 */@EnableAsync@SpringBootApplicationpublic class BlogMghioCodeApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(BlogMghioCodeApplication.class, args); &#125;&#125; 1234567891011121314151617/** * @author mghio * @since 2021-07-17 */@Service@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)public class OrderService &#123; @Autowired private TradeService tradeService; @Async public void testCreateOrder() &#123; // omit business logic ... &#125;&#125; 12345678910111213141516/** * @author mghio * @since 2021-07-17 */@Service@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)public class TradeService &#123; @Autowired private OrderService orderService; public void testCreateTrade() &#123; // omit business logic ... &#125;&#125; 在标有 @Async 注解的场景下，在添加启用异步注解（@EnableAsync）后，代理对象会通过 AOP 自动生成。以上代码运行会抛出 BeanCurrentlyInCreationException 异常。运行的大致流程如下图所示： 源码在 org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory 类的方法 doCreateBean 中，会判断第二级缓存 earlySingletonObjects 中的对象是否等于原始对象，方法判断部分的源码如下： 二级缓存存放的对象是 AOP 生成出来的代理对象，和原始对象不相等，所以抛出了循环依赖错误。如果细看源码的话，会发现如果二级缓存是空的话会直接返回（因为比较的对象都没有，根本无法校验了），就不会报循环依赖的错误了，默认情况下，Spring 是按照文件全路径递归搜索，按路径 + 文件名 排序，排序靠前先加载，所以我们只要调整这两个类名称，让方法标有 @Async 注解的类排序在后面即可。 第 ④ 种场景——构造器注入构造器注入的场景很少，到目前为止我所接触过的公司项目和开源项目中还没遇到使用构造器注入的，虽然用得不多，但是需要知道 Spring 为什么不支持这种场景的循环依赖，构造器注入的示例代码如下： 123456789101112131415161718/** * @author mghio * @since 2021-07-17 */@Servicepublic class OrderService &#123; private TradeService tradeService; public OrderService(TradeService tradeService) &#123; this.tradeService = tradeService; &#125; public void testCreateOrder() &#123; // omit business logic ... &#125;&#125; 123456789101112131415161718/** * @author mghio * @since 2021-07-17 */@Servicepublic class TradeService &#123; private OrderService orderService; public TradeService(OrderService orderService) &#123; this.orderService = orderService; &#125; public void testCreateTrade() &#123; // omit business logic ... &#125;&#125; 构造器注入无法加入到第三级缓存当中，Spring 框架中的三级缓存在此场景下无用武之地，所以只能抛出异常，整体流程如下（虚线表示无法执行，为了直观也把下一步画出来了）: 第 ⑤ 种场景——DependsOn 循环依赖这种 DependsOn 循环依赖场景很少，一般情况下不怎么使用，了解一下会导致循环依赖的问题即可，@DependsOn 注解主要是用来指定实例化顺序的，示例代码如下： 12345678910111213141516/** * @author mghio * @since 2021-07-17 */@Service@DependsOn("tradeService")public class OrderService &#123; @Autowired private TradeService tradeService; public void testCreateOrder() &#123; // omit business logic ... &#125;&#125; 12345678910111213141516/** * @author mghio * @since 2021-07-17 */@Service@DependsOn("orderService")public class TradeService &#123; @Autowired private OrderService orderService; public void testCreateTrade() &#123; // omit business logic ... &#125;&#125; 通过上文，我们知道，如果这里的类没有标注 @DependsOn 注解的话是可以正常运行的，因为 Spring 支持单例 setter 注入，但是加了示例代码的 @DependsOn 注解后会报循环依赖错误，原因是在类 org.springframework.beans.factory.support.AbstractBeanFactory 的方法 doGetBean() 中检查了 dependsOn 的实例是否有循环依赖，如果有循环依赖则抛出循环依赖异常，方法判断部分代码如下： 总结本文主要介绍了什么是循环依赖以及 Spring 对各种循环依赖场景的处理，文中只列出了部分涉及到的源码，都标了所在源码中的位置，感兴趣的朋友可以去看看完整源码，最后 Spring 对各种循环依赖场景的支持情况如下图所示（P.S. Spring 版本：5.1.9.RELEASE）：]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>循环依赖</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>循环依赖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 整合 Feign 的原理]]></title>
    <url>%2Fpost%2F1d4949a7.html</url>
    <content type="text"><![CDATA[前言在 上篇 介绍了 Feign 的核心实现原理，在文末也提到了会再介绍其和 Spring Cloud 的整合原理，Spring 具有很强的扩展性，会把一些常用的解决方案通过 starter 的方式开放给开发者使用，在引入官方提供的 starter 后通常只需要添加一些注解即可使用相关功能（通常是 @EnableXXX）。下面就一起来看看 Spring Cloud 到底是如何整合 Feign 的。 整合原理浅析在 Spring 中一切都是围绕 Bean 来展开的工作，而所有的 Bean 都是基于 BeanDefinition 来生成的，可以说 BeanDefinition 是整个 Spring 帝国的基石，这个整合的关键也就是要如何生成 Feign 对应的 BeanDefinition。 要分析其整合原理，我们首先要从哪里入手呢？如果你看过 上篇 的话，在介绍结合 Spring Cloud 使用方式的例子时，第二步就是要在项目的 XXXApplication 上加添加 @EnableFeignClients 注解，我们可以从这里作为切入点，一步步深入分析其实现原理（通常相当一部分的 starter 一般都是在启动类中添加了开启相关功能的注解）。 进入 @EnableFeignClients 注解中，其源码如下： 从注解的源码可以发现，该注解除了定义几个参数（basePackages、defaultConfiguration、clients 等）外，还通过 @Import 引入了 FeignClientsRegistrar 类，一般 @Import 注解有如下功能（具体功能可见 官方 Java Doc）： 声明一个 Bean 导入 @Configuration 注解的配置类 导入 ImportSelector 的实现类 导入 ImportBeanDefinitionRegistrar 的实现类（这里使用这个功能） 到这里不难看出，整合实现的主要流程就在 FeignClientsRegistrar 类中了，让我们继续深入到类 FeignClientsRegistrar 的源码， 通过源码可知 FeignClientsRegistrar 实现 ImportBeanDefinitionRegistrar 接口，该接口从名字也不难看出其主要功能就是将所需要初始化的 BeanDefinition 注入到容器中，接口定义两个方法功能都是用来注入给定的 BeanDefinition 的，一个可自定义 beanName（通过实现 BeanNameGenerator 接口自定义生成 beanName 的逻辑），另一个使用默认的规则生成 beanName（类名首字母小写格式）。接口源码如下所示： 对 Spring 有一些了解的朋友们都知道，Spring 会在容器启动的过程中根据 BeanDefinition 的属性信息完成对类的初始化，并注入到容器中。所以这里 FeignClientsRegistrar 的终极目标就是将生成的代理类注入到 Spring 容器中。虽然 FeignClientsRegistrar 这个类的源码看起来比较多，但是从其终结目标来看，我们主要是看如何生成 BeanDefinition 的，通过源码可以发现其实现了 ImportBeanDefinitionRegistrar 接口，并且重写了 registerBeanDefinitions(AnnotationMetadata, BeanDefinitionRegistry) 方法，在这个方法里完成了一些 BeanDefinition 的生成和注册工作。源码如下： 整个过程主要分为如下两个步骤： 给 @EnableFeignClients 的全局默认配置（注解的 defaultConfiguration 属性）创建 BeanDefinition 对象并注入到容器中（对应上图中的第 ① 步） 给标有了 @FeignClient 的类创建 BeanDefinition 对象并注入到容器中（对应上图中的第 ② 步） 下面分别深入方法源码实现来看其具体实现原理，首先来看看第一步的方法 registerDefaultConfiguration(AnnotationMetadata, BeanDefinitionRegistry)，源码如下： 可以看到这里只是获取一下注解 @EnableFeignClients 的默认配置属性 defaultConfiguration 的值，最终的功能实现交给了 registerClientConfiguration(BeanDefinitionRegistry, Object, Object) 方法来完成，继续跟进深入该方法，其源码如下： 可以看到，全局默认配置的 BeanClazz 都是 FeignClientSpecification，然后这里将全局默认配置 configuration 设置为 BeanDefinition 构造器的输入参数，然后当调用构造器实例化时将这个参数传进去。到这里就已经把 @EnableFeignClients 的全局默认配置（注解的 defaultConfiguration 属性）创建出 BeanDefinition 对象并注入到容器中了，第一步到此完成，整体还是比较简单的。 下面再来看看第二步 给标有了 @FeignClient 的类创建 BeanDefinition 对象并注入到容器中 是如何实现的。深入第二步的方法 registerFeignClients(AnnotationMetadata, BeanDefinitionRegistry) 实现中，由于方法实现代码较多，使用截图会比较分散，所以用贴出源代码并在相关位置添加必要注释的方式进行： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public void registerFeignClients(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; // 最终获取到有 @FeignClient 注解类的集合 LinkedHashSet&lt;BeanDefinition&gt; candidateComponents = new LinkedHashSet&lt;&gt;(); // 获取 @EnableFeignClients 注解的属性 map Map&lt;String, Object&gt; attrs = metadata.getAnnotationAttributes(EnableFeignClients.class.getName()); // 获取 @EnableFeignClients 注解的 clients 属性 final Class&lt;?&gt;[] clients = attrs == null ? null : (Class&lt;?&gt;[]) attrs.get("clients"); if (clients == null || clients.length == 0) &#123; // 如果 @EnableFeignClients 注解未指定 clients 属性则扫描添加（扫描过滤条件为：标注有 @FeignClient 的类） ClassPathScanningCandidateComponentProvider scanner = getScanner(); scanner.setResourceLoader(this.resourceLoader); scanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class)); Set&lt;String&gt; basePackages = getBasePackages(metadata); for (String basePackage : basePackages) &#123; candidateComponents.addAll(scanner.findCandidateComponents(basePackage)); &#125; &#125; else &#123; // 如果 @EnableFeignClients 注解已指定 clients 属性，则直接添加，不再扫描（从这里可以看出，为了加快容器启动速度，建议都指定 clients 属性） for (Class&lt;?&gt; clazz : clients) &#123; candidateComponents.add(new AnnotatedGenericBeanDefinition(clazz)); &#125; &#125; // 遍历最终获取到的 @FeignClient 注解类的集合 for (BeanDefinition candidateComponent : candidateComponents) &#123; if (candidateComponent instanceof AnnotatedBeanDefinition) &#123; // verify annotated class is an interface // 验证带注释的类必须是接口，不是接口则直接抛出异常（大家可以想一想为什么只能是接口？） AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent; AnnotationMetadata annotationMetadata = beanDefinition.getMetadata(); Assert.isTrue(annotationMetadata.isInterface(), "@FeignClient can only be specified on an interface"); // 获取 @FeignClient 注解的属性值 Map&lt;String, Object&gt; attributes = annotationMetadata .getAnnotationAttributes(FeignClient.class.getCanonicalName()); // 获取 clientName 的值，也就是在构造器的参数值（具体获取逻辑可以参见 getClientName(Map&lt;String, Object&gt;) 方法 String name = getClientName(attributes); // 同上文第一步最后调用的方法，注入 @FeignClient 注解的配置对象到容器中 registerClientConfiguration(registry, name, attributes.get("configuration")); // 注入 @FeignClient 对象，该对象可以在其它类中通过 @Autowired 直接引入（e.g. XXXService） registerFeignClient(registry, annotationMetadata, attributes); &#125; &#125;&#125; 通过源码可以看到最后是通过方法 registerFeignClient(BeanDefinitionRegistry, AnnotationMetadata, Map&lt;String, Object&gt;) 注入的 @FeignClient 对象，继续深入该方法，源码如下： 方法实现比较长，最终目标是构造出 BeanDefinition 对象，然后通过 BeanDefinitionReaderUtils.registerBeanDefinition(BeanDefinitionHolder, BeanDefinitionRegistry) 注入到容器中。 其中关键的一步是从 @FeignClient 注解中获取信息并设置到 BeanDefinitionBuilder 中，BeanDefinitionBuilder 中注册的类是 FeignClientFactoryBean，这个类的功能正如它的名字一样是用来创建出 FeignClient 的 Bean 的，然后 Spring 会根据 FeignClientFactoryBean 生成对象并注入到容器中。 需要明确的一点是，实际上这里最终注入到容器当中的是 FeignClientFactoryBean 这个类，Spring 会在类初始化的时候会根据这个类来生成实例对象，就是调用 FeignClientFactoryBean.getObject() 方法，这个生成的对象就是我们实际使用的代理对象。下面再进入到类 FeignClientFactoryBean 的 getObject() 这个⽅法，源码如下： 可以看到这个方法是直接调用的类中的另一个方法 getTarget() 的，在继续跟进该方法，由于该方法实现代码较多，使用截图会比较分散，所以用贴出源代码并在相关位置添加必要注释的方式进行： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * @param &lt;T&gt; the target type of the Feign client * @return a &#123;@link Feign&#125; client created with the specified data and the context * information */&lt;T&gt; T getTarget() &#123; // 从 Spring 容器中获取 FeignContext Bean FeignContext context = beanFactory != null ? beanFactory.getBean(FeignContext.class) : applicationContext.getBean(FeignContext.class); // 根据获取到的 FeignContext 构建出 Feign.Builder Feign.Builder builder = feign(context); // 注解 @FeignClient 未指定 url 属性 if (!StringUtils.hasText(url)) &#123; // url 属性是固定访问某一个实例地址，如果未指定协议则拼接 http 请求协议 if (!name.startsWith("http")) &#123; url = "http://" + name; &#125; else &#123; url = name; &#125; // 格式化 url url += cleanPath(); // 生成代理和我们之前的代理一样，注解 @FeignClient 未指定 url 属性则返回一个带有负载均衡功能的客户端对象 return (T) loadBalance(builder, context, new HardCodedTarget&lt;&gt;(type, name, url)); &#125; // 注解 @FeignClient 已指定 url 属性 if (StringUtils.hasText(url) &amp;&amp; !url.startsWith("http")) &#123; url = "http://" + url; &#125; String url = this.url + cleanPath(); // 获取一个 client Client client = getOptional(context, Client.class); if (client != null) &#123; if (client instanceof FeignBlockingLoadBalancerClient) &#123; // not load balancing because we have a url, // but Spring Cloud LoadBalancer is on the classpath, so unwrap // 这里没有负载是因为我们有指定了 url client = ((FeignBlockingLoadBalancerClient) client).getDelegate(); &#125; builder.client(client); &#125; // 生成代理和我们之前的代理一样，最后被注入到 Spring 容器中 Targeter targeter = get(context, Targeter.class); return (T) targeter.target(this, builder, context, new HardCodedTarget&lt;&gt;(type, name, url));&#125; 通过源码得知 FeignClientFactoryBean 继承了 FactoryBean，其方法 FactoryBean.getObject 返回的就是 Feign 的代理对象，最后这个代理对象被注入到 Spring 容器中，我们就通过 @Autowired 可以直接注入使用了。同时还可以发现上面的代码分支最终都会走到如下代码： 12Targeter targeter = get(context, Targeter.class);return targeter.target(this, builder, context, target); 点进去深入 targeter.target 的源码，可以看到实际上这里创建的就是一个代理对象，也就是说在容器启动的时候，会为每个 @FeignClient 创建了一个代理对象。至此，Spring Cloud 和 Feign 整合原理的核心实现介绍完毕。 总结本文主要介绍了 Spring Cloud 整合 Feign 的原理。通过上文介绍，你已经知道 Srpring 会我们的标注的 @FeignClient 的接口创建了一个代理对象，那么有了这个代理对象我们就可以做增强处理（e.g. 前置增强、后置增强），那么你知道是如何实现的吗？感兴趣的朋友可以再翻翻源码寻找答案（温馨提示：增强逻辑在 InvocationHandler 中）。还有 Feign 与 Ribbon 和 Hystrix 等组件的协作，感兴趣的朋友可以自行下载源码学习了解。]]></content>
      <categories>
        <category>实现原理</category>
        <category>Feign</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>实现原理</tag>
        <tag>Feign</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Feign 实现原理]]></title>
    <url>%2Fpost%2F7d1b964a.html</url>
    <content type="text"><![CDATA[What is Feign?Feign 是⼀个 HTTP 请求的轻量级客户端框架。通过 接口 + 注解的方式发起 HTTP 请求调用，面向接口编程，而不是像 Java 中通过封装 HTTP 请求报文的方式直接调用。服务消费方拿到服务提供方的接⼝，然后像调⽤本地接⼝⽅法⼀样去调⽤，实际发出的是远程的请求。让我们更加便捷和优雅的去调⽤基于 HTTP 的 API，被⼴泛应⽤在 Spring Cloud 的解决⽅案中。开源项目地址：Feign，官方描述如下： Feign is a Java to HTTP client binder inspired by Retrofit, JAXRS-2.0, and WebSocket. Feign’s first goal was reducing the complexity of binding Denominator uniformly to HTTP APIs regardless of ReSTfulness. Why Feign?Feign 的首要目标就是减少 HTTP 调用的复杂性。在微服务调用的场景中，我们调用很多时候都是基于 HTTP 协议的服务，如果服务调用只使用提供 HTTP 调用服务的 HTTP Client 框架（e.g. Apache HttpComponnets、HttpURLConnection OkHttp 等），我们需要关注哪些问题呢？ 相比这些 HTTP 请求框架，Feign 封装了 HTTP 请求调用的流程，而且会强制使用者去养成面向接口编程的习惯（因为 Feign 本身就是要面向接口）。 Demo原生使用方式以获取 Feign 的 GitHub 开源项目的 Contributors 为例，原生方式使用 Feign 步骤有如下三步（这里以使用 Gradle 进行依赖管理的项目为例）：第一步： 引入相关依赖：implementation ‘io.github.openfeign:feign-core:11.0’在项目的 build.gradle 文件的依赖声明处 dependencies 添加该依赖声明即可。 第二步： 声明 HTTP 请求接口使用 Java 的接口和 Feign 的原生注解 @RequestLine 声明 HTTP 请求接口，从这里就可以看到 Feign 给使用者封装了 HTTP 的调用细节，极大的减少了 HTTP 调用的复杂性，只要定义接口即可。 第三步： 配置初始化 Feign 客户端最后一步配置初始化客户端，这一步主要是设置请求地址、编码（Encoder）、解码（Decoder）等。 通过定义接口，使用注解的方式描述接口的信息，就可以发起接口调用。最后请求结果如下： 结合 Spring Cloud 使用方式同样还是以获取 Feign 的 GitHub 开源项目的 Contributors 为例，结合 Spring Cloud 的使用方式有如下三步：第一步： 引入相关 starter 依赖：org.springframework.cloud:spring-cloud-starter-openfeign在项目的 build.gradle 文件的依赖声明处 dependencies 添加该依赖声明即可。 第二步： 在项目的启动类 XXXApplication 上添加 @EnableFeignClients 注解启用 Feign 客户端功能。 第三步： 创建 HTTP 调用接口，并添加声明 @FeignClient 注解。最后一步配置初始化客户端，这一步主要是设置请求地址（url）、编码（Encoder）、解码（Decoder）等，与原生使用方式不同的是，现在我们是通过 @FeignClient 注解配置的 Feign 客户端属性，同时请求的 URL 也是使用的 Spring MVC 提供的注解。 测试类如下所示： 运行结果如下： 可以看到这里是通过 @Autowired 注入刚刚定义的接口的，然后就可以直接使用其来发起 HTTP 请求了，使用是不是很方便、简洁。 Dive into Feign从上面第一个原生使用的例子可以看到，只是定了接口并没有具体的实现类，但是却可以在测试类中直接调用接口的方法来完成接口的调用，我们知道在 Java 里面接口是无法直接进行使用的，因此可以大胆猜测是 Feign 在背后默默生成了接口的代理实现类，也可以验证一下，只需在刚刚的测试类 debug 一下看看接口实际使用的是什么实现类： 从 debug 结果可知，框架生成了接口的代理实现类 HardCodedTarget 的对象 $Proxy14 来完成接口请求调用，和刚刚的猜测一致。Feign 主要是封装了 HTTP 请求调用，其整体架构如下： 测试类代码里面只在 GitHub github = Feign.builder().target(GitHub.class, “https://api.github.com&quot;); 用到了 Feign 框架的功能，所以我们选择从这里来深入源码，点击进入发现是 Feign 抽象类提供的方法，同样我们知道抽象类也是无法进行初始化的，所以肯定是有子类的，如果你刚刚有仔细观察上面的 debug 代码的话，可以发现有一个 ReflectiveFeign 类，这个类就是抽象类 Feign 的子类了。抽象类 feign.Feign 的部分源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public abstract class Feign &#123; ... public static Builder builder() &#123; return new Builder(); &#125; public abstract &lt;T&gt; T newInstance(Target&lt;T&gt; target); public static class Builder &#123; ... private final List&lt;RequestInterceptor&gt; requestInterceptors = new ArrayList&lt;RequestInterceptor&gt;(); private Logger.Level logLevel = Logger.Level.NONE; private Contract contract = new Contract.Default(); private Client client = new Client.Default(null, null); private Retryer retryer = new Retryer.Default(); private Logger logger = new NoOpLogger(); private Encoder encoder = new Encoder.Default(); private Decoder decoder = new Decoder.Default(); private QueryMapEncoder queryMapEncoder = new FieldQueryMapEncoder(); private ErrorDecoder errorDecoder = new ErrorDecoder.Default(); private Options options = new Options(); private InvocationHandlerFactory invocationHandlerFactory = new InvocationHandlerFactory.Default(); private boolean decode404; private boolean closeAfterDecode = true; private ExceptionPropagationPolicy propagationPolicy = NONE; private boolean forceDecoding = false; private List&lt;Capability&gt; capabilities = new ArrayList&lt;&gt;(); // 设置输入打印日志级别 public Builder logLevel(Logger.Level logLevel) &#123; this.logLevel = logLevel; return this; &#125; // 设置接口方法注解处理器（契约） public Builder contract(Contract contract) &#123; this.contract = contract; return this; &#125; // 设置使用的 Client（默认使用 JDK 的 HttpURLConnection） public Builder client(Client client) &#123; this.client = client; return this; &#125; // 设置重试器 public Builder retryer(Retryer retryer) &#123; this.retryer = retryer; return this; &#125; // 设置请求编码器 public Builder encoder(Encoder encoder) &#123; this.encoder = encoder; return this; &#125; // 设置响应解码器 public Builder decoder(Decoder decoder) &#123; this.decoder = decoder; return this; &#125; // 设置 404 返回结果解码器 public Builder decode404() &#123; this.decode404 = true; return this; &#125; // 设置错误解码器 public Builder errorDecoder(ErrorDecoder errorDecoder) &#123; this.errorDecoder = errorDecoder; return this; &#125; // 设置请求拦截器 public Builder requestInterceptors(Iterable&lt;RequestInterceptor&gt; requestInterceptors) &#123; this.requestInterceptors.clear(); for (RequestInterceptor requestInterceptor : requestInterceptors) &#123; this.requestInterceptors.add(requestInterceptor); &#125; return this; &#125; public &lt;T&gt; T target(Class&lt;T&gt; apiType, String url) &#123; return target(new HardCodedTarget&lt;T&gt;(apiType, url)); &#125; public &lt;T&gt; T target(Target&lt;T&gt; target) &#123; return build().newInstance(target); &#125; &#125; ...&#125; 可以看到在方法 public T target(Class apiType, String url) 中直接创建了 HardCodedTarget 对象出来，这个对象也是上面 debug 看到的对象。再继续深入，就来到了 feign.Feign 的 newInstance(Target target) 的方法了，是个抽象方法，其实现在子类 ReflectiveFeign 中，这个方法就是接口代理实现生成的地方，下面通过源码来看看实现逻辑是怎样的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ReflectiveFeign extends Feign &#123; ... private final ParseHandlersByName targetToHandlersByName; private final InvocationHandlerFactory factory; private final QueryMapEncoder queryMapEncoder; ReflectiveFeign(ParseHandlersByName targetToHandlersByName, InvocationHandlerFactory factory, QueryMapEncoder queryMapEncoder) &#123; this.targetToHandlersByName = targetToHandlersByName; this.factory = factory; this.queryMapEncoder = queryMapEncoder; &#125; @SuppressWarnings("unchecked") @Override public &lt;T&gt; T newInstance(Target&lt;T&gt; target) &#123; // &lt;类名#方法签名, MethodHandler&gt;，key 是通过 feign.Feign.configKey(Class targetType, Method method) 生成的 Map&lt;String, MethodHandler&gt; nameToHandler = targetToHandlersByName.apply(target); // 将 Map&lt;String, MethodHandler&gt; 转换为 Map&lt;Method, MethodHandler&gt; 方便调用 Map&lt;Method, MethodHandler&gt; methodToHandler = new LinkedHashMap&lt;Method, MethodHandler&gt;(); // 默认方法处理器 List&lt;DefaultMethodHandler&gt; defaultMethodHandlers = new LinkedList&lt;DefaultMethodHandler&gt;(); for (Method method : target.type().getMethods()) &#123; // 跳过 Object 类定于的方法 if (method.getDeclaringClass() == Object.class) &#123; continue; &#125; else if (Util.isDefault(method)) &#123; // 默认方法（接口声明的默认方法）使用默认的方法处理器 DefaultMethodHandler handler = new DefaultMethodHandler(method); defaultMethodHandlers.add(handler); methodToHandler.put(method, handler); &#125; else &#123; // 接口正常声明的方法（e.g. GitHub.listContributors(String, String)） methodToHandler.put(method, nameToHandler.get(Feign.configKey(target.type(), method))); &#125; &#125; // 生成 Feign 封装的 InvocationHandler InvocationHandler handler = factory.create(target, methodToHandler); // 基于 JDK 动态代理生成接口的代理类（e.g. Github 接口） T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(), new Class&lt;?&gt;[] &#123;target.type()&#125;, handler); for (DefaultMethodHandler defaultMethodHandler : defaultMethodHandlers) &#123; defaultMethodHandler.bindTo(proxy); &#125; return proxy; &#125;...&#125; 总体流程就是在方法 T newInstance(Target target) 生成一个含有 FeignInvocationHandler 的代理对象，FeignInvocationHandler 对象会持有 Map&lt;Method, MethodHandler&gt; map，代理对象调用的时候进入 FeignInvocationHandler#invoke 方法，根据调用的方法来获取对应 MethodHandler，然后再 MethodHandler 完成对方法的处理（处理 HTTP 请求等）。 下面再深入 MethodHandler，看看是如何完成对方法 HTTP 请求处理的，MethodHandler 是一个接口定义在 feign.InvocationHandlerFactory 接口中（P.S. 基础知识点，接口是可以在内部定义内部接口的哦），有两个实现类分别为 DefaultMethodHandler 和 SynchronousMethodHandler，第一个 DefaultMethodHandler 用来处理接口的默认方法，第二个是用来处理正常的接口方法的，一般情况下都是由该类来处理的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687final class SynchronousMethodHandler implements MethodHandler &#123; ... @Override public Object invoke(Object[] argv) throws Throwable &#123; // 获取 RequestTemplate 将请求参数封装成请求模板 RequestTemplate template = buildTemplateFromArgs.create(argv); Options options = findOptions(argv); // 请求重试器 Retryer retryer = this.retryer.clone(); while (true) &#123; try &#123; // 执行请求并解码后返回 return executeAndDecode(template, options); &#125; catch (RetryableException e) &#123; try &#123; // 发生重试异常则进行重试处理 retryer.continueOrPropagate(e); &#125; catch (RetryableException th) &#123; Throwable cause = th.getCause(); if (propagationPolicy == UNWRAP &amp;&amp; cause != null) &#123; throw cause; &#125; else &#123; throw th; &#125; &#125; if (logLevel != Logger.Level.NONE) &#123; logger.logRetry(metadata.configKey(), logLevel); &#125; continue; &#125; &#125; &#125; Object executeAndDecode(RequestTemplate template, Options options) throws Throwable &#123; // 从请求模板 RequestTemplate 构造请求参数对象 Request Request request = targetRequest(template); if (logLevel != Logger.Level.NONE) &#123; logger.logRequest(metadata.configKey(), logLevel, request); &#125; Response response; long start = System.nanoTime(); try &#123; // 通过 client（Apache HttpComponnets、HttpURLConnection OkHttp 等）执行 HTTP 请求调用，默认是 HttpURLConnection response = client.execute(request, options); // ensure the request is set. TODO: remove in Feign 12 response = response.toBuilder() .request(request) .requestTemplate(template) .build(); &#125; catch (IOException e) &#123; if (logLevel != Logger.Level.NONE) &#123; logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime(start)); &#125; throw errorExecuting(request, e); &#125; long elapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start); if (decoder != null) // 对返回结果进行解码操作 return decoder.decode(response, metadata.returnType()); CompletableFuture&lt;Object&gt; resultFuture = new CompletableFuture&lt;&gt;(); asyncResponseHandler.handleResponse(resultFuture, metadata.configKey(), response, metadata.returnType(), elapsedTime); try &#123; if (!resultFuture.isDone()) throw new IllegalStateException("Response handling not done"); return resultFuture.join(); &#125; catch (CompletionException e) &#123; Throwable cause = e.getCause(); if (cause != null) throw cause; throw e; &#125; &#125;...&#125; 至此，Feign 的核心实现流程介绍完毕，从代码上看 feign.SynchronousMethodHandler 的操作相对比较简单，主要是通过 client 完成请求，对响应进行解码以及异常处理操作，整体流程如下： SummaryFeign 通过给我们定义的目标接口（比如例子中的 GitHub）生成一个 HardCodedTarget 类型的代理对象，由 JDK 动态代理实现，生成代理的时候会根据注解来生成一个对应的 Map&lt;Method, MethodHandler&gt;，这个 Map 被 InvocationHandler 持有，接口方法调用的时候，进入 InvocationHandler 的 invoke 方法（为什么会进入这里？JDK 动态代理的基础知识）。 然后根据调用的方法从 Map&lt;Method, MethodHandler&gt; 获取对应的 MethodHandler，然后通过 MethodHandler 根据指定的 client 来完成对应处理， MethodHandler 中的实现类 DefaultMethodHandler 处理默认方法（接口的默认方法）的请求处理的，SynchronousMethodHandler 实现类是完成其它方法的 HTTP 请求的实现，这就是 Feign 的主要核心流程，源码已上传 Github。以上是 Feign 框架实现的核心流程介绍，Spring Cloud 是如何整合 Feign 的呢？请看下篇博文，敬请期待。s]]></content>
      <categories>
        <category>实现原理</category>
        <category>Feign</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>实现原理</tag>
        <tag>Feign</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[信息爆炸时代，该如何获取优质信息？]]></title>
    <url>%2Fpost%2F7f4af1a1.html</url>
    <content type="text"><![CDATA[前言我们现在所处的信息爆炸时代，如何强调快速获取信息都不为过，信息多种多样，有些能找到源头，有些则不能，有些能找到规律，有些则不一定能找到，信息的源头和获取渠道很重要。然而事实上，能够真正有效获取到优质信息并加以消化利用的人并不多。 在信息的获取的过程中，应该要具备筛选信息的能力，什么是官方信息，你要核实，什么是虚假信息，你要甄别。看到网上有些陷入杀猪盘的，负载累累。仔细思考一下，其实甄别筛选信息的能力真的是最大的问题。 当然一个人将信息并内化利用是一个很复杂的过程，每个人都有自己独到的方法。今天来聊聊应该如何去获取「优质信息」以及如何去过滤无用信息。下面分享几个获取信息的原则： 尽自己最大努力去获取“一手信息”这个原则的关键是，这里的“一手信息”是如何定义呢? 对于那些权威机构或者国家机构，或者专家大咖，或者作者本人所发布的信息绝大部分情况下都可以看作为一手信息，第一手信息，不是被别人理解过、消化过的二手信息。 尤其对于知识性的东西来说，更应该是这样。应该是原汁原味的，不应该是被添油加醋的。对于一手信息的价值为什么大于二手信息甚至多手信息呢？很简单，这个效应在股票或者投资市场会被放大的很明显，能够在第一时间获取到第一手信息，是能否准确快速判断出市场行情走向的关键因素之一。 收费的信息优于免费的信息对于这个原则，可能不是绝对，但至少在绝大部分情况下是正确的，对于现在很多“白嫖党”来说，可能确实要改一改自己的陋习了，要知道，其实免费反而最贵，因为它给你带来的负面作用或者时间成本，甚至可能会“毒害”你对于信息和知识的热情，当然也会有少部分人会把好的东西给开源或者免费掉。 国外大部分情况优于国内和上面的第二点一样，需要你带着审视和批判思维来看待了，国内整体的创作环境个人角色还是相关比较浮躁和恶劣的，尽管这些年有所改观，但当前的自媒体，包括一些所谓的大 V，也会有很多滥竽充数的文章，视频等内容，包括当前都说信息过载，其实准确来说，是垃圾信息过载，那些优质的内容与知识，毕竟少数。 有选择的相信专家，并关注他们的日常分享，但不要迷恋迷信专家，很多人会无脑喷当前所谓的砖家伪公知 ，但在大部分情况，专家是在某些领域沉淀研究了很多年，你可以看看别人的一些思路，观点，与框架性东西，在某些情况下，可能真会对自己有所启发。 通过信息的冗余和比对举一个简单的例子，如果今天巴菲特发表了一番言论，当然媒体会对此有记录和报道。但是，各种媒体可能记录有误差，而且可能还有意无意加入自己的看法，把不是巴菲特发表的言论加到他头上，这样就主观或客观地引入了错误信息。 此时如果你只从一个信息源了解信息，其实是很难判断所获得的是准确信息还是夹杂着一定的错误信息的。但是如果你能从多个信息源了解信息，虽然它们各自都有部分个人主观因素，但是由于各自角度的不同，很多噪音彼此可以抵消掉，获得的则是相对比较准确的信息。 要时刻警惕回音室响应，避免把自己关进一个封闭的信息圈子，这样慢慢的外部的信息就没法进来了，总之在获取信息的时候一定要尝试从不同维度，不同角度去摄取。 将信息分解到不同的维度过滤在中国，人们常常都会很纠结一个问题，「就是老婆和妈妈掉到水里后先救谁？」，如果仔细思考一下，这个两难问题的重要原因在于，我们要考虑的因素太多，以至于大家越想越糊涂。其实只要你细想就会发现，这个问题的关键是分清楚什么是我们该考虑的信息，什么是不用考虑的信息。 比如，如果你觉得孝是第一位的，或者觉得以后谁和我生活更长时间是第一位的，作出选择就没有什么难的。这时，你其实是将这个有很多干扰信息的问题，分解到了某些你能够区分的维度，比如孝的维度，或者和一起生活的时间的维度。 要主动去 pull 信息，不要总是等 push 信息这是最后一点，也是最重要的一点，这里的 pull 和 push 可能说得有点偏技术化，解释一下就是 pull 是说要目的地在网络上主动查询一些信息，而不是等各种 APP 给你推送信息，虽然主动查询信息可能会让你感到比较难受，但这是获取优质信息的第一步。 我个人是目前做技术相关的工作，对这点比较有感触，一个人的学习能力强不强，其实就像生存能力一样，一个重要判断点就是看这个人是能自己找食吃，还是要等别人“喂着吃”。 别人投喂给你的信息未必都是错的，都是坏的，比如某些自媒体的信息，但如果要获取到更为准确的信息，我建议你还是要去主动搜索核对一下，而不是单凭别人的一面之词。也就是说，别人是不会为你的后果负责的，而你要为自己的后果负责。 当然，以上是个人在选择信息源的一些原则和思考，希望可以对需要进行信息获取和筛选的朋友有所帮助。]]></content>
      <categories>
        <category>思考</category>
        <category>信息获取</category>
      </categories>
      <tags>
        <tag>思考</tag>
        <tag>信息获取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享几个好用的 Google 搜索技巧]]></title>
    <url>%2Fpost%2F4219480f.html</url>
    <content type="text"><![CDATA[搜索能力是被绝大多数人低估一项基本素质，绝大部分做编程技术相关的朋友应该都知道如何使用 Google，但是并不知道如何利用它的潜力。其实不管是 Google 还是 百度，会搜索的人一样都可以查找到需要的东西，不会搜索的人用什么都不好使。下面介绍一些 Google 常用的搜索技巧以及搜索快捷方式，可以帮助你更快，更准确地找到结果。Google 是世界上功能最强大的搜索引擎，它已经改变了我们查找信息的方式。 0. 使用准确的词组将您要搜索的关键字用引号引起来，Google 会进行精确的词组搜索。 语法：”[searchkey 1] [searchkey 2]” [searchkey 3] 1. 多个互斥的搜索条件使用 OR默认情况下，除非指定，否则 Google 会包含你搜索条件中的所有搜索关键字。通过在您的关键词之字输入OR，Google 会知道它可以查找一组或另一组。大写 OR，否则 Google 会认为它只是你的关键字的一部分。 语法：[searchkey 1] OR [searchkey 2] 2. 排除指定关键词通过在单词的前面添加减号，将单词从 Google 搜索中排除。 语法：-[searchkey to exclude] [searchkey to include] 3. 查找文本块中的所有单词使用 Google 的 allintext： 语法仅搜索网站的正文，而忽略链接，URL 和标题。 语法：allintext:[searchkeys] 4. 在文本 + 标题 + URL 等查找单词查找搜索词在不同位置的网页。即-在页面正文中，页面标题，URL 等中。为此，在您的关键字之前使用 intext:。 语法：intext:[searchkeys] 5. 标题搜索（单个关键字）在网页标题内搜索一个单词，然后在网页上的其他位置搜索另一个单词。为此，您需要将 intitle： 混合到您的搜索查询中。 语法：[searchkeys 1] intitle:[searchkeys 2] 6. 标题搜索（多个关键字）在网页标题中搜索查询中的所有关键字，在我们的搜索词之前使用 allintitle：。 语法：allintitle:[searchkey1 searchkey2] 7. 在 URL 中搜索使用 allinURL 可以很容易地在 URL 中搜索关键字 。 语法：allinURL:[searchkeys] 8. 在指定网站内搜索在网站内搜索单词-使用网站 URL 前面的 site： 语法，后跟您的搜索词。这会将搜索结果仅限制在该网站上。 语法：site:[website URL] [searchkeys] 9. Google 搜索定义通过在单词之前使用 define： 轻松地找到单词的定义，而无需访问词典网站。Google 将提供定义，并提供一个音频播放器来提供该单词的语音发音。 语法：define:[searchkey] 10. Google 搜索通配符（遗漏或未知词）没想到所有的话吗？加上 * 告诉 Google 为您填写空白，这对于歌曲歌词或书名搜索非常有效。 语法：[searchkeys 1] * [searchkeys 2] 11. Google 搜索文件类型搜索文件类型（例如 PowerPoint，PDF 等）时，请在搜索词中使用 filetype： 命令。 语法：[searchkeyword] filetype:[file type extension] 12. 转换计算使用 Google 可以进行任何度量转换。 语法：convert [data value + unit of measure] to [like unit of measure] 13. Google 搜索计算器在搜索栏中输入您的计算结果，将 Google 用作计算器。数值运算符: * 表示乘，+ 表示加，- 表示减，/ 表示除。 语法：[number] [operator] [number] 14. Google 图片搜索查找图像的名称，描述和类型。 语法：[searchkeyw] image type]]></content>
      <categories>
        <category>Google</category>
        <category>Search</category>
        <category>Tips</category>
      </categories>
      <tags>
        <tag>Google</tag>
        <tag>Search</tag>
        <tag>Tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论基础理论知识的重要性]]></title>
    <url>%2Fpost%2Fa328bfd.html</url>
    <content type="text"><![CDATA[前言在计算机行业工作的人们，最大的感触就是这个行业里总是会出现很多的新东西，各种技术、框架等等，变化无处不在，有很大一部分人都比较焦虑。在一些论坛或者社区里面总是有人在问如何学习一门新技术？怎样才能跟上技术的潮流？我想说是，我们应该打牢基础，应对变化，以不变应万变。 从变化中寻找不变的东西变化都是我们看到表面现象，本质的变化其实并没有多大。计算机发展的这几十年来，理论的层面变得不多，很多理论都是在几十年前就已经发现了的，只是在表现形式上变化比较大，夸张一点的甚至是一年一个样的都有。 所以想要应对这种变化就要抓住其本质不变的地方，也就是其背后的理论基础，打牢理论基础，提升自己的编程内功修养，一些与语言无关比较通用的东西要重点掌握，比如编程里面的一些设计模式、代码重用、解耦以及抽象能力等等。想要代码重用就必须得解耦，想要解耦就进行抽象，抽取出公共不变的东西，这些都是和语言无关的通用的技能。 基础知识决定你能飞多高当你有牢固的基础知识以后，其实也会更加容易的突破自己的技术和成长瓶颈。我认为在技术领域里面其实是不存在量变可以达到质变这么一说的。量变达到质变也是说只要我努力多写代码就能成为架构师，技术有一个质的突破，其实并不是这样的。 尽管你代码写得再多，如果不懂得背后的技术原理，不懂得科学的学习方法，不进行归纳总结输出，是永远达到质变的。所以必须学习和打牢基础理论知识，如果总是只学习一些浮于表面上的东西，当技术形式发生一些变化后，你会发现之前学习的知识已经用不到了，又得重新学习，而在技术世界里变化又是非常快的，所以很多都迷失在不停的学习技术形式之中，这也是造成一部分人感到焦虑的原因之一。 上层的技术实现都是有背后的理论基础作为支撑的，因为这些理论基础都是抽象和归纳，比如不管是 Java 还是其它的一些开发语言，只要只用 TCP/IP 协议，用的都是一样的原理，不同的只是技术实现形式上的差异，你只要打牢基础理论知识，抓住本质原理，不管它技术实现形式上如何变化，都能很快掌握它。 计算机基础理论分类这些知识绝大部分都是一个科班学生本科的专业课讲到的原理知识，但是大部分人在学校可能都没有静下心来认真学习钻研，有句话说得好：“出来混，迟早要还的~”，一个好的学习方法就是一定要看一些经典的书和世界顶级学校的课程，最后自己归纳总结输出。这些知识总的来说可以分为以下几类， 系统知识类：计算机系统、网络协议、数据库等 算法和数据结构类：算法和数据结构、分布式系统等 中间件类：消息队列、任务调度、网关代理等 程序语言类：类库实现、设计模式、编程技术（多线程、异步等）、语言原理等 计算机发展的这几十年来，核心的基础知识就是上面列举的这些，虽然我们的直观感受技术是在不断更替的，实际上本质的东西并没有改变，其理论基础还是这些内容，变化的只是技术形式，我想说的一点是对这些基础理论知识的掌握程能直接决定的成长天花板。万丈高楼平地起，勿在浮沙筑高台。]]></content>
      <categories>
        <category>基础知识</category>
        <category>思考</category>
      </categories>
      <tags>
        <tag>思考</tag>
        <tag>基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个简易版的 Spring - 如何实现 AOP（终结篇）]]></title>
    <url>%2Fpost%2Fbd7ad750.html</url>
    <content type="text"><![CDATA[前言在 上篇 实现了 判断一个类的方式是符合配置的 pointcut 表达式、根据一个 Bean 的名称和方法名，获取 Method 对象、实现了 BeforeAdvice、AfterReturningAdvice 以及 AfterThrowingAdvice并按照指定次序调用 等功能，这篇再来看看剩下的 代理对象如何生成、根据 XML 配置文件生成 BeanDefintion以及如何将生成的代理对象放入到容器中 等功能，话不多说，下面进入主题。 代理对象生成代理对象的生成策略和 Spring 框架一致，当被代理类实现了接口时采用 JDK 动态代理的方式生成代理对象，被代理对象未实现接口时使用 CGLIB 来生成代理对象，为了简单起见这里不支持手动指定生成代理对象的策略，JDK 动态代理的实现这里不在介绍，感兴趣可以自己实现一下，这里主要讨论 CGLIB 的生成方式。 基于面向接口编程的思想，这里的生成代理对象需要定义一个统一的接口，不管是 CGLIB 生成方式还是JDK 动态代理生成方式都要实现该接口。生成代理对象是根据一些配置去生成的，同样，这里生成代理的配置也可以抽取一个统一的接口，在实现类中定义拦截器（也就是 Advice）以及实现的接口等，CGLIB 的基本使用可以到官网自行查找。代理对象生成的整体的类图如下： 其中代理创建的工厂接口 AopProxyFactory 如下，提供了不指定 ClassLoader（使用默认的 ClassLoader）和指定 ClassLoader 两种方式创建代理对象，源码如下： 1234567891011/** * @author mghio * @since 2021-06-13 */public interface AopProxyFactory &#123; Object getProxy(); Object getProxy(ClassLoader classLoader);&#125; 使用 CGLIB 创建代理的工厂接口实现类如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * @author mghio * @since 2021-06-13 */public class CglibProxyFactory implements AopProxyFactory &#123; /* * Constants for CGLIB callback array indices */ private static final int AOP_PROXY = 0; protected final Advised advised; public CglibProxyFactory(Advised config) &#123; Assert.notNull(config, "AdvisedSupport must not be null"); if (config.getAdvices().size() == 0) &#123; throw new AopConfigException("No advisors and no TargetSource specified"); &#125; this.advised = config; &#125; @Override public Object getProxy() &#123; return getProxy(null); &#125; @Override public Object getProxy(ClassLoader classLoader) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating CGLIB proxy: target class is " + this.advised.getTargetClass()); &#125; try &#123; Class&lt;?&gt; rootClass = this.advised.getTargetClass(); // Configure CGLIB Enhancer... Enhancer enhancer = new Enhancer(); if (classLoader != null) &#123; enhancer.setClassLoader(classLoader); &#125; enhancer.setSuperclass(rootClass); enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); // BySpringCGLIB enhancer.setInterceptDuringConstruction(false); Callback[] callbacks = getCallbacks(rootClass); Class&lt;?&gt;[] types = new Class&lt;?&gt;[callbacks.length]; for (int i = 0; i &lt; types.length; i++) &#123; types[i] = callbacks[i].getClass(); &#125; enhancer.setCallbackFilter(new ProxyCallbackFilter(this.advised)); enhancer.setCallbackTypes(types); enhancer.setCallbacks(callbacks); // Generate the proxy class and create a proxy instance. return enhancer.create(); &#125; catch (CodeGenerationException | IllegalArgumentException ex) &#123; throw new AopConfigException("Could not generate CGLIB subclass of class [" + this.advised.getTargetClass() + "]: " + "Common causes of this problem include using a final class or a non-visible class", ex); &#125; catch (Exception ex) &#123; // TargetSource.getTarget() failed throw new AopConfigException("Unexpected AOP exception", ex); &#125; &#125; // omit other methods ...&#125; 整体来看还是比较简单的，主要是 CGLIB 第三方字节码生成库的基本用法，当然，前提是你已经了解了 CGLIB 的基本使用。AOP 的相关配置接口 Advised 相对来说就比较简单了，主要是一些相关属性的增、删、改等操作，主要部分代码如下： 123456789101112131415161718192021/** * @author mghio * @since 2021-06-13 */public interface Advised &#123; Class&lt;?&gt; getTargetClass(); boolean isInterfaceProxied(Class&lt;?&gt; intf); List&lt;Advice&gt; getAdvices(); void addAdvice(Advice advice); List&lt;Advice&gt; getAdvices(Method method); void addInterface(Class&lt;?&gt; clazz); // omit other methods ...&#125; 实现类也比较简单，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * @author mghio * @since 2021-06-13 */public class AdvisedSupport implements Advised &#123; private boolean proxyTargetClass = false; private Object targetObject = null; private final List&lt;Advice&gt; advices = new ArrayList&lt;&gt;(); private final List&lt;Class&lt;?&gt;&gt; interfaces = new ArrayList&lt;&gt;(); public AdvisedSupport() &#123; &#125; @Override public Class&lt;?&gt; getTargetClass() &#123; return this.targetObject.getClass(); &#125; @Override public boolean isInterfaceProxied(Class&lt;?&gt; intf) &#123; return interfaces.contains(intf); &#125; @Override public List&lt;Advice&gt; getAdvices() &#123; return this.advices; &#125; @Override public void addAdvice(Advice advice) &#123; this.advices.add(advice); &#125; @Override public List&lt;Advice&gt; getAdvices(Method method) &#123; List&lt;Advice&gt; result = new ArrayList&lt;&gt;(); for (Advice advice : this.getAdvices()) &#123; Pointcut pc = advice.getPointcut(); if (pc.getMethodMatcher().matches(method)) &#123; result.add(advice); &#125; &#125; return result; &#125; @Override public void addInterface(Class&lt;?&gt; clazz) &#123; this.interfaces.add(clazz); &#125; // omit other methods ...&#125; 到这里，代理对象使用 CGLIB 生成的方式就已经实现了，核心代码其实比较简单，主要是需要多考虑考虑代码后期的扩展性。 创建 BeanDefinition我们先来看看一般 AOP 在 XML 配置文件中是如何定义的，一个包含 BeforeAdvice、AfterReturningAdvice以及AfterThrowingAdvice 的 XML 配置文件如下： 12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.e3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/beans/spring-context.xsd"&gt; &lt;context:scann-package base-package="cn.mghio.service.version5,cn.mghio.dao.version5" /&gt; &lt;bean id="tx" class="cn.mghio.tx.TransactionManager"/&gt; &lt;aop:config&gt; &lt;aop:aspect ref="tx"&gt; &lt;aop:pointcut id="placeOrder" expression="execution(* cn.mghio.service.version5.*.placeOrder(..))"/&gt; &lt;aop:before pointcut-ref="placeOrder" method="start"/&gt; &lt;aop:after-returning pointcut-ref="placeOrder" method="commit"/&gt; &lt;aop:after-throwing pointcut-ref="placeOrder" method="rollback"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 有了之前解析 XML 的 Bean 定义的经验后，很显然这里我们需要一个数据结构去表示这个 AOP 配置，如果你阅读过 上篇 的话，类 AspectJExpressionPointcut 表示的是 &lt;aop:pointcut id=”placeOrder” expression=”execution(* cn.mghio.service.version5.*.placeOrder(..))”/&gt;，另外几个 Advice 配置分别对应 AspectJBeforeAdvice、AspectJAfterReturningAdvice以及 AspectJAfterThrowingAdvice 等几个类。这里只要解析 XML 配置文件，然后使用对应的 Advice 的构造器创建对应的对象即可，解析 XML 使用的是 dom4j，主要部分代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * @author mghio * @since 2021-06-13 */public class ConfigBeanDefinitionParser &#123; private static final String ASPECT = "aspect"; private static final String EXPRESSION = "expression"; private static final String ID = "id"; private static final String REF = "ref"; private static final String BEFORE = "before"; private static final String AFTER = "after"; private static final String AFTER_RETURNING_ELEMENT = "after-returning"; private static final String AFTER_THROWING_ELEMENT = "after-throwing"; private static final String AROUND = "around"; private static final String POINTCUT = "pointcut"; private static final String POINTCUT_REF = "pointcut-ref"; private static final String ASPECT_NAME_PROPERTY = "aspectName"; public void parse(Element element, BeanDefinitionRegistry registry) &#123; List&lt;Element&gt; childElements = element.elements(); for (Element el : childElements) &#123; String localName = el.getName(); if (ASPECT.equals(localName)) &#123; parseAspect(el, registry); &#125; &#125; &#125; private void parseAspect(Element aspectElement, BeanDefinitionRegistry registry) &#123; String aspectName = aspectElement.attributeValue(REF); List&lt;BeanDefinition&gt; beanDefinitions = new ArrayList&lt;&gt;(); List&lt;RuntimeBeanReference&gt; beanReferences = new ArrayList&lt;&gt;(); // parse advice List&lt;Element&gt; elements = aspectElement.elements(); boolean adviceFoundAlready = false; for (Element element : elements) &#123; if (isAdviceNode(element)) &#123; if (!adviceFoundAlready) &#123; adviceFoundAlready = true; if (!StringUtils.hasText(aspectName)) &#123; return; &#125; beanReferences.add(new RuntimeBeanReference(aspectName)); &#125; GenericBeanDefinition advisorDefinition = parseAdvice(aspectName, element, registry, beanDefinitions, beanReferences); beanDefinitions.add(advisorDefinition); &#125; &#125; // parse pointcut List&lt;Element&gt; pointcuts = aspectElement.elements(POINTCUT); for (Element pointcut : pointcuts) &#123; parsePointcut(pointcut, registry); &#125; &#125; private void parsePointcut(Element pointcutElement, BeanDefinitionRegistry registry) &#123; String id = pointcutElement.attributeValue(ID); String expression = pointcutElement.attributeValue(EXPRESSION); GenericBeanDefinition pointcutDefinition = createPointcutDefinition(expression); if (StringUtils.hasText(id)) &#123; registry.registerBeanDefinition(id, pointcutDefinition); &#125; else &#123; BeanDefinitionReaderUtils.registerWithGeneratedName(pointcutDefinition, registry); &#125; &#125; private GenericBeanDefinition parseAdvice(String aspectName, Element adviceElement, BeanDefinitionRegistry registry, List&lt;BeanDefinition&gt; beanDefinitions, List&lt;RuntimeBeanReference&gt; beanReferences) &#123; GenericBeanDefinition methodDefinition = new GenericBeanDefinition(MethodLocatingFactory.class); methodDefinition.getPropertyValues().add(new PropertyValue("targetBeanName", aspectName)); methodDefinition.getPropertyValues().add(new PropertyValue("methodName", adviceElement.attributeValue("method"))); methodDefinition.setSynthetic(true); // create instance definition factory GenericBeanDefinition aspectFactoryDef = new GenericBeanDefinition(AopInstanceFactory.class); aspectFactoryDef.getPropertyValues().add(new PropertyValue("aspectBeanName", aspectName)); aspectFactoryDef.setSynthetic(true); // register the pointcut GenericBeanDefinition adviceDef = createAdviceDefinition(adviceElement, aspectName, methodDefinition, aspectFactoryDef, beanDefinitions, beanReferences); adviceDef.setSynthetic(true); // register the final advisor BeanDefinitionReaderUtils.registerWithGeneratedName(adviceDef, registry); return adviceDef; &#125; // omit other methods ...&#125; 创建 BeanDefinition 已经完成了，现在可根据 XML 配置文件解析出对应的 BeanDefintion 了，下面只需要在合适的时机将这些 BeanDefinition 放到容器中就完成了全部流程了。 如何放到容器中该如何把解析出来的 BeanDefintion 放到容器当中去呢？我们知道在 Spring 框架当中提供了很多的“钩子函数”，可以从这里入手，Bean 的生命周期如下： 选择在 Bean 实例化完成之后 BeanPostProcessor 的 postProcessAfterInitialization() 方法创建代理对象，AOP 使用的是 AspectJ，将创建代理对象的类命名为 AspectJAutoProxyCreator，实现 BeanPostProcessor 接口，处理代理对象的创建，AspectJAutoProxyCreator 类的核心源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * @author mghio * @since 2021-06-13 */public class AspectJAutoProxyCreator implements BeanPostProcessor &#123; private ConfigurableBeanFactory beanFactory; @Override public Object beforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Override public Object afterInitialization(Object bean, String beanName) throws BeansException &#123; // 如果这个 bean 本身就是 Advice 及其子类，则不生成动态代理 if (isInfrastructureClass(bean.getClass())) &#123; return bean; &#125; List&lt;Advice&gt; advices = getCandidateAdvices(bean); if (advices.isEmpty()) &#123; return bean; &#125; return createProxy(advices, bean); &#125; protected Object createProxy(List&lt;Advice&gt; advices, Object bean) &#123; Advised config = new AdvisedSupport(); for (Advice advice : advices) &#123; config.addAdvice(advice); &#125; Set&lt;Class&gt; targetInterfaces = ClassUtils.getAllInterfacesForClassAsSet(bean.getClass()); for (Class targetInterface : targetInterfaces) &#123; config.addInterface(targetInterface); &#125; config.setTargetObject(bean); AopProxyFactory proxyFactory = null; if (config.getProxiedInterfaces().length == 0) &#123; // CGLIB 代理 proxyFactory = new CglibProxyFactory(config); &#125; else &#123; // TODO(mghio): JDK dynamic proxy ... &#125; return proxyFactory.getProxy(); &#125; public void setBeanFactory(ConfigurableBeanFactory beanFactory) &#123; this.beanFactory = beanFactory; &#125; private List&lt;Advice&gt; getCandidateAdvices(Object bean) &#123; List&lt;Object&gt; advices = this.beanFactory.getBeansByType(Advice.class); List&lt;Advice&gt; result = new ArrayList&lt;&gt;(); for (Object advice : advices) &#123; Pointcut pointcut = ((Advice) advice).getPointcut(); if (canApply(pointcut, bean.getClass())) &#123; result.add((Advice) advice); &#125; &#125; return result; &#125; private boolean canApply(Pointcut pointcut, Class&lt;?&gt; targetClass) &#123; MethodMatcher methodMatcher = pointcut.getMethodMatcher(); Set&lt;Class&gt; classes = new LinkedHashSet&lt;&gt;(ClassUtils.getAllInterfacesForClassAsSet(targetClass)); classes.add(targetClass); for (Class&lt;?&gt; clazz : classes) &#123; Method[] methods = clazz.getDeclaredMethods(); for (Method m : methods) &#123; if (methodMatcher.matches(m)) &#123; return true; &#125; &#125; &#125; return false; &#125; private boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; return Advice.class.isAssignableFrom(beanClass); &#125;&#125; 最后别忘了，这里的 BeanPostProcessor 接口是我们新加的，需要到之前定义的 DefaultFactoryBean 中加上对 BeanPostProcessor 的处理逻辑，主要修改如下： 1234567891011121314151617181920212223242526272829303132333435363738public class DefaultBeanFactory extends AbstractBeanFactory implements BeanDefinitionRegistry &#123; @Override public Object createBean(BeanDefinition bd) throws BeanCreationException &#123; // 1. instantiate bean Object bean = instantiateBean(bd); // 2. populate bean populateBean(bd, bean); // 3. initialize bean bean = initializeBean(bd, bean); return bean; &#125; protected Object initializeBean(BeanDefinition bd, Object bean) &#123; ... // 非合成类型则创建代理 if (!bd.isSynthetic()) &#123; return applyBeanPostProcessorAfterInitialization(bean, bd.getId()); &#125; return bean; &#125; private Object applyBeanPostProcessorAfterInitialization(Object existingBean, String beanName) &#123; Object result = existingBean; for (BeanPostProcessor postProcessor : getBeanPostProcessors()) &#123; result = postProcessor.afterInitialization(result, beanName); if (result == null) &#123; return null; &#125; &#125; return result; &#125; // omit other field and methods ...&#125; 最后运行事先测试用例，正常通过符合预期。 总结本文主要介绍了 AOP 代理对象生成、解析 XML 配置文件并创建对应的 BeanDefinition 以及最后注入到容器中，只是介绍了大体实现思路，具体代码实现已上传 mghio-spring，感兴趣的朋友可以参考，到这里，AOP 实现部分已经全部介绍完毕。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>AOP</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个简易版的 Spring - 如何实现 AOP（下）]]></title>
    <url>%2Fpost%2F2a28641b.html</url>
    <content type="text"><![CDATA[前言前面两篇 如何实现 AOP（上）、如何实现 AOP（中） 做了一些 AOP 的核心基础知识简要介绍，本文进入到了实战环节了，去实现一个基于 XML 配置的简易版 AOP，虽然是简易版的但是麻雀虽小五脏俱全，一些核心的功能都会实现，通过实现这个简易版的 AOP，相信你会对 AOP 有深入的理解，不止知其然，还能知其所以然。AOP 的顶层接口规范和底层依赖基础组件都是由一个叫 AOP Alliance 的组织制定的，我们经常听到的 AspectJ、ASM、CGLIB 就是其中被管理的一些项目，需要明确的一点是，在 Spring 中只是使用了 AspectJ 的核心概念和核心类，并不是像 AspectJ 那样在编译期实现的 AOP，而是在运行期。话不多说，下面开始进入主题。 解析 XML 中的 pointcut 定义及方法解析假设有一个 OrderService 类(P.S. 这里的 @Component 是我自定义的注解，详见 这篇)，其中有一个下单的方法 placeOrder()，我们想实现的效果是想给这个 placeOrder() 方法加上 数据库事务，即执行方法之前开启事务，执行过程中发生异常回滚事务，正常执行完成提交事务。OrderService 类的代码如下： 123456789101112/** * @author mghio * @since 2021-06-06 */@Component(value = "orderService")public class OrderService &#123; public void placeOrder() &#123; System.out.println("place order"); &#125;&#125; 很明显，这里的 pointcut 就是 placeOrder() 方法，在 XML 配置文件中的配置如下： 1&lt;aop:pointcut id="placeOrder" expression="execution(* cn.mghio.service.version5.*.placeOrder(..))"/&gt; 我们需要一个类去表达这个概念，pointcut 要实现的功能是给定一个类的方法，判断是否匹配配置文件中给定的表达式。总的来看 pointcut 由方法匹配器和匹配表达式两部分组成，方法匹配器可以有各种不同的实现，所以是一个接口，pointcut 同样也可以基于多种不同技术实现，故也是一个接口，默认是基于 AspectJ 实现的，类图结构如下： 实现类 AspectJExpressionPointcut 是基于 AspectJ 实现的，方法的匹配过程是委托给 AspectJ 中的 PointcutExpression 来判断给定的方法是否匹配表达式，该类的核心实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * @author mghio * @since 2021-06-06 */public class AspectJExpressionPointcut implements Pointcut, MethodMatcher &#123; private static final Set&lt;PointcutPrimitive&gt; SUPPORTED_PRIMITIVES = new HashSet&lt;&gt;(); static &#123; SUPPORTED_PRIMITIVES.add(PointcutPrimitive.EXECUTION); &#125; private String expression; private ClassLoader pointcutClassLoader; private PointcutExpression pointcutExpression; @Override public MethodMatcher getMethodMatcher() &#123; return this; &#125; @Override public String getExpression() &#123; return expression; &#125; @Override public boolean matches(Method method) &#123; checkReadyToMatch(); ShadowMatch shadowMatch = getShadowMatch(method); return shadowMatch.alwaysMatches(); &#125; private void checkReadyToMatch() &#123; if (Objects.isNull(getExpression())) &#123; throw new IllegalArgumentException("Must set property 'expression' before attempting to match"); &#125; if (Objects.isNull(this.pointcutExpression)) &#123; this.pointcutClassLoader = ClassUtils.getDefaultClassLoader(); this.pointcutExpression = buildPointcutExpression(this.pointcutClassLoader); &#125; &#125; private PointcutExpression buildPointcutExpression(ClassLoader classLoader) &#123; PointcutParser pointcutParser = PointcutParser .getPointcutParserSupportingSpecifiedPrimitivesAndUsingSpecifiedClassLoaderForResolution(SUPPORTED_PRIMITIVES, classLoader); return pointcutParser.parsePointcutExpression(replaceBooleanOperators(getExpression())); &#125; private String replaceBooleanOperators(String pcExpr) &#123; String result = StringUtils.replace(pcExpr, " and ", " &amp;&amp; "); result = StringUtils.replace(result, " or ", " || "); result = StringUtils.replace(result, " not ", " ! "); return result; &#125; private ShadowMatch getShadowMatch(Method method) &#123; ShadowMatch shadowMatch; try &#123; shadowMatch = this.pointcutExpression.matchesMethodExecution(method); &#125; catch (Exception e) &#123; throw new RuntimeException("not implemented yet"); &#125; return shadowMatch; &#125; // omit other setter、getter ...&#125; 到这里就完成了给定一个类的方法，判断是否匹配配置文件中给定的表达式的功能。再来看如下的一个完整的 AOP 配置： 12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.e3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/beans/spring-context.xsd"&gt; &lt;context:scann-package base-package="cn.mghio.service.version5,cn.mghio.dao.version5" /&gt; &lt;bean id="tx" class="cn.mghio.tx.TransactionManager"/&gt; &lt;aop:config&gt; &lt;aop:aspect ref="tx"&gt; &lt;aop:pointcut id="placeOrder" expression="execution(* cn.mghio.service.version5.*.placeOrder(..))"/&gt; &lt;aop:before pointcut-ref="placeOrder" method="start"/&gt; &lt;aop:after-returning pointcut-ref="placeOrder" method="commit"/&gt; &lt;aop:after-throwing pointcut-ref="placeOrder" method="rollback"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 在实现各种 XXXAdvice 之前需要定位到这个 Method，比如以上配置文件中的 start、commit、rollback 等方法，为了达到这个目标我们还需要实现的功能就是根据一个 Bean 名称（比如这里的 tx）定位到指定的 Method，然后通过反射调用这个定位到的方法。实际上也比较简单，这个类命名为 MethodLocatingFactory，根据其功能可以定义出目标 Bean 的名称 targetBeanName、需要定位的方法名称 methodName 以及定位完成后得到的方法 method 这三个属性，整体类图结构如下所示： 根据名称和类型定位到方法主要是在 setBeanFactory() 方法中完成的，前提是对应的目标 Bean 名称和方法名称要设置完成，方法定位的类 MethodLocatingFactory 类的代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @author mghio * @since 2021-06-06 */public class MethodLocatingFactory implements FactoryBean&lt;Method&gt;, BeanFactoryAware &#123; private String targetBeanName; private String methodName; private Method method; public void setTargetBeanName(String targetBeanName) &#123; this.targetBeanName = targetBeanName; &#125; public void setMethodName(String methodName) &#123; this.methodName = methodName; &#125; @Override public void setBeanFactory(BeanFactory beanFactory) &#123; if (!StringUtils.hasText(this.targetBeanName)) &#123; throw new IllegalArgumentException("Property 'targetBeanName' is required"); &#125; if (!StringUtils.hasText(this.methodName)) &#123; throw new IllegalArgumentException("Property 'methodName' is required"); &#125; Class&lt;?&gt; beanClass = beanFactory.getType(this.targetBeanName); if (Objects.isNull(beanClass)) &#123; throw new IllegalArgumentException("Can't determine type of bean with name '" + this.targetBeanName); &#125; this.method = BeanUtils.resolveSignature(this.methodName, beanClass); if (Objects.isNull(this.method)) &#123; throw new IllegalArgumentException("Unable to locate method [" + this.methodName + "] on bean [" + this.targetBeanName + "]"); &#125; &#125; @Override public Method getObject() &#123; return this.method; &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return Method.class; &#125;&#125; 实现各种不同类型的 Advice各种不同类型的 Advice（BeforeAdvice、AfterAdvice 等）目标都是需要在指定对象的指定方法执行前后按指定次序执行一些操作（称之为 拦截器），比如以上示例中的一种执行次序为：BeforeAdvice -&gt; placeOrder -&gt; AfterAdvice。这里的一个关键问题就是如何去实现按照指定次序的链式调用？，这里先卖个关子，这个问题先放一放等下再介绍具体实现，先来看看要如何定义各种不同类型的 Advice，我们的 Advice 定义都是扩展自 AOP Alliance 定义的 MethodInterceptor 接口，Advice 部分的核心类图如下： 其实到这里如果有了前面两篇文章（如何实现 AOP（上）、如何实现 AOP（中））的基础了，实现起来就相对比较简单了，就是在方法执行之前、之后以及发生异常时调用一些特定的方法即可，AbstractAspectJAdvice 类定义了一下公共的属性和方法，核心实现源码如下： 1234567891011121314151617181920212223242526272829303132/** * @author mghio * @since 2021-06-06 */public abstract class AbstractAspectJAdvice implements Advice &#123; protected Method adviceMethod; protected AspectJExpressionPointcut pc; protected AopInstanceFactory adviceObjectFactory; public AbstractAspectJAdvice(Method adviceMethod, AspectJExpressionPointcut pc, AopInstanceFactory adviceObjectFactory) &#123; this.adviceMethod = adviceMethod; this.pc = pc; this.adviceObjectFactory = adviceObjectFactory; &#125; @Override public Pointcut getPointcut() &#123; return pc; &#125; protected void invokeAdviceMethod() throws Throwable &#123; adviceMethod.invoke(adviceObjectFactory.getAspectInstance()); &#125; public Object getAdviceInstance() throws Exception &#123; return adviceObjectFactory.getAspectInstance(); &#125; // omit getter ...&#125; 有了这个公共抽象父类之后其它几个 Advice 的实现就很简单了，AspectJBeforeAdvice 就是在执行拦截方法之前调用，核心源码如下： 1234567891011121314/** * @author mghio * @since 2021-06-06 */public class AspectJBeforeAdvice extends AbstractAspectJAdvice &#123; // omit constructor ... @Override public Object invoke(MethodInvocation mi) throws Throwable &#123; this.invokeAdviceMethod(); return mi.proceed(); &#125;&#125; 同理，AspectJAfterReturningAdvice 就是在方法正常执行结束后调用，核心源码如下： 123456789101112131415/** * @author mghio * @since 2021-06-06 */public class AspectJAfterReturningAdvice extends AbstractAspectJAdvice &#123; // omit constructor ... @Override public Object invoke(MethodInvocation mi) throws Throwable &#123; Object result = mi.proceed(); this.invokeAdviceMethod(); return result; &#125;&#125; 剩下的 AspectJAfterThrowingAdvice 想必你已经猜到了，没错，就是在方法执行过程中发生异常时调用，对应 Java 的异常机制也就是在 try{...}catch{...} 的 catch 中调用，核心源码如下： 123456789101112131415161718/** * @author mghio * @since 2021-06-06 */public class AspectJAfterThrowingAdvice extends AbstractAspectJAdvice &#123; // omit constructor ... @Override public Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; return mi.proceed(); &#125; catch (Throwable t) &#123; this.invokeAdviceMethod(); throw t; &#125; &#125;&#125; 我们支持的三种不同的 Advice 已经定义好了，接下来就是如何组装调用的问题了，同时也处理了如何去实现按照指定次序的链式调用？的问题，这里的方法调用我们也是扩展 AOP Alliance 定义的规范，即方法调用 MethodInvocation 接口。 由于这里的方法调用是基于反射完成的，将该类命名为 ReflectiveMethodInvocation，要使用反射来调用方法，很显然需要知道目标对象 targetObject、targetMethod 以及方法参数列表 arguments 等参数，当然还有我们的拦截器列表（也就是上文定义的 Advice）interceptors，因为这个是一个类似自调用的过程，为了判断是否已经执行完成所有拦截器，还需要记录当前调用拦截器的下标位置 currentInterceptorIndex，当 currentInterceptorIndex 等于 interceptors.size() - 1 时表示所有拦截器都已调用完成，再调用我们的实际方法即可。核心的类图如下： 其中类 ReflectiveMethodInvocation 的核心源码实现如下，强烈建议大家将 proceed() 方法结合上问定义的几个 Advice 类一起看： 123456789101112131415161718192021222324252627282930313233343536373839/** * @author mghio * @since 2021-04-05 */public class ReflectiveMethodInvocation implements MethodInvocation &#123; protected final Object targetObject; protected final Method targetMethod; protected Object[] arguments; protected final List&lt;MethodInterceptor&gt; interceptors; private int currentInterceptorIndex = -1; public ReflectiveMethodInvocation(Object targetObject, Method targetMethod, Object[] arguments, List&lt;MethodInterceptor&gt; interceptors) &#123; this.targetObject = targetObject; this.targetMethod = targetMethod; this.arguments = arguments; this.interceptors = interceptors; &#125; @Override public Object proceed() throws Throwable &#123; // all interceptors have been called. if (this.currentInterceptorIndex == interceptors.size() - 1) &#123; return invokeJoinpoint(); &#125; this.currentInterceptorIndex++; MethodInterceptor methodInterceptor = this.interceptors.get(this.currentInterceptorIndex); return methodInterceptor.invoke(this); &#125; private Object invokeJoinpoint() throws Throwable &#123; return this.targetMethod.invoke(this.targetObject, this.arguments); &#125; // omit other method ...&#125; 至此，各种不同类型的 Advice 的核心实现已经介绍完毕，本来打算在这边介绍完 AOP 剩下部分的实现的，但是鉴于文章长度太长，还是放到下一次再开一篇来介绍吧。 总结本文主要介绍了 AOP 在 XML 配置的 pointcut 解析实现、方法匹配定位以及各种不同类型的 Advice 的实现，特别是 Advice 的实现部分，建议自己动手实现一版，这样印象会更加深刻，另源码已上传至 GitHub，可自行下载参考，有任何问题请留言交流讨论。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>AOP</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个简易版的 Spring - 如何实现 AOP（中）]]></title>
    <url>%2Fpost%2Faf7194f9.html</url>
    <content type="text"><![CDATA[前言在上篇 如何实现 AOP（上） 介绍了 AOP 技术出现的原因和一些重要的概念，在我们自己实现之前有必要先了解一下 AOP 底层到底是如何运作的，所以这篇再来看看 AOP 实现所依赖的一些核心基础技术。AOP 是使用动态代理和字节码生成技术来实现的，在运行期（注意：不是编译期！）为目标对象生成代理对象，然后将横切逻辑织入到生成的代理对象中，最后系统使用的是带有横切逻辑的代理对象，而不是被代理对象，由代理对象转发到被代理对象。 代理模式动态代理的根源是设计模式中的代理模式，代理模式在 GoF 中的描述如下： Provide a surrogate or placeholder for another object to control access to it. 从其定义可以看出，代理模式主要是为了控制对象的访问，通常也会拥有被代理者的所有功能。通过代理模式我们可以在不改变被代理类的情况下，通过引入代理类来给被代理类添加一些功能，此时脑海里飘过计算机科学界中一句著名的话(P.S. 基础知识很重要啊，可以参见 这篇)： 计算机科学的任何一个问题，都可以通过增加一个中间层来解决。 代理模式其实在现实生活中也经常会接触到，比如在一线城市租房时大部分都是找的租房中介去看的房子、谈价格以及签合同，是因为房子的房东已经把房子全权托管给了中介处理了，这里的租房中介其实就是充当了代理模式中的代理对象的解决，而真正的被代理对象(目标对象)其实是房子的房东，而和我们打交道都是租房中介(代理对象)。代理模式类图结构如下图所示： 图中各个部分的含义如下： ISubject 是被代理对象所能提供能力的抽象。 SubjectImpl 是被代理的具体实现类。 SubjectProxy 是代理的实现类，通常该类持有 ISubject 接口的实例。 Client 是访问者的抽象角色，要访问 ISubject 类型的资源。 可以看到 SubjectImpl 和 SubjectProxy 都实现了相同的接口 ISubject，在代理对象 SubjectProxy 内持有 ISubject 的引用，当 Client 访问 doOperation() 时，代理对象将请求转发给被代理对象，单单从这个过程来看，代理对象如果只是为了转发请求，是不是有点多此一举了？再结合代理模式的定义思考一下，在转发之前（后者之后）不就可以添加一些访问控制了吗。 在代理对象(SubjectProxy)将请求转发给被代理对象(SubejctImpl)之前或者之后都是根据需要添加一些处理逻辑，而不需要修改被代理对象的具体实现逻辑，假设 SubjectImpl 是我们系统中 Joinpoint 所在的对象，此时 SubjectImpl 就是我们的目标对象了，只需要为这个目标对象创建一个代理对象，然后将横切逻辑添加到代理对象中，对外暴露出创建出来的代理对象就可以将将横切逻辑和原来的逻辑融合在一起了。 动态代理到目前为止，一切都是那么美好，当只为同一个目标对象类型添加横切逻辑时，只需要创建一个代理对象即可，但是在 Joinpoint 相同而目标对象类型不同时，需要为每个不同的目标对象类型都单独创建一个代理对象，而这些代理对象的横切逻辑其实都是一样的，根据 DRY原则，需要寻找另一种技术来解决这个问题。在 JDK 1.3 引入的 动态代理机制 可以为指定的接口在运行期动态的去生成代理对象，使用这个动态代理机制可以解决上述问题，这样我们就可以不事先为每个原始类创建代理类，而是在运行时动态生成代理类。在 Java 中，使用动态代理是比较简单的，它本身就已经使用反射实现了动态代理的语法，主要是由一个类 Proxy 和一个接口 InvocationHandler 组成，使用动态代理机制实现前文示例如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * @author mghio * @since 2021-05-29 */public interface Subject &#123; void doOperation();&#125;public class SubjectImpl implements Subject &#123; @Override public void doOperation() &#123; System.out.println("SubjectImpl doOperation..."); &#125;&#125;public class JDKInvocationHandler implements InvocationHandler &#123; private final Subject target; public JDKInvocationHandler(Subject target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // add pre process logic if necessary System.out.println("Proxy before JDKInvocationHandler doOperation..."); Object result = method.invoke(target, args); System.out.println("Proxy after JDKInvocationHandler doOperation..."); // add post process logic if necessary return result; &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; // 将生成的代理类保存在根目录下（com/sun/proxy/XXX.class） System.setProperty("sun.misc.ProxyGenerator.saveGeneratedFiles", "true"); Subject target = new SubjectImpl(); Subject proxy = (Subject) Proxy.newProxyInstance(SubjectImpl.class.getClassLoader(), new Class[]&#123;Subject.class&#125;, new JDKInvocationHandler(target)); proxy.doOperation(); &#125;&#125; 由以上代码可知，使用 JDK 的动态代理只要 3 步： 定义公共接口 Subject，创建被代理对象 SubjectImpl 创建被代理对象的处理对象 JDKInvocationHandler，持有目标对象 Subject 的引用 使用 JDK 的 Proxy 类的静态方法 newProxyInstance 创建代理对象 通过设置 sun.misc.ProxyGenerator.saveGeneratedFiles 属性，可以将动态生成的代理类保存在项目根目录下，运行上面的示例代码生成的代理类如下： 123456789101112131415161718192021222324252627282930313233343536public final class $Proxy0 extends Proxy implements Subject &#123; private static Method m1; private static Method m2; private static Method m3; private static Method m0; static &#123; try &#123; m1 = Class.forName("java.lang.Object").getMethod("equals", Class.forName("java.lang.Object")); m2 = Class.forName("java.lang.Object").getMethod("toString"); m3 = Class.forName("cn.mghio.designpattern.proxy.dynamicproxy.Subject").getMethod("doOperation"); m0 = Class.forName("java.lang.Object").getMethod("hashCode"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final void doOperation() throws &#123; try &#123; super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; // omit toString、equals、hashCode method...&#125; 从动态生成的代理类的代码可以看出，JDK 动态代理生成的代理类是继承 JDK 中提供的 Proxy 和实现被代理类所实现的接口。进一步可以从这个实现方式得出两点：1. 使用 JDK 动态代理时为什么只能使用接口引用指向代理，而不能使用被代理的具体类引用指向代理；2. 被代理类必须实现接口，因为 JDK 动态代理生成的代理类必须继承自 Proxy，而 Java 不支持多重继承，所以只能通过实现接口的方式。 在默认情况下，Spring AOP 发现了目标对象实现了接口，会使用 JDK 动态代理机制为其动态生成代理对象，虽然提倡面向接口编程，但是也有目标对象没有实现接口的场景，当被代理的目标对象没有实现接口时就无法使用 JDK 动态代理了，那么这种情况下就需要使用第三方工具来帮忙了。 字节码生成技术当目标对象没有实现接口时，可以通过动态字节码生成来继承目标对象来动态生成相应的子类，在生成的子类中重写父类目标对象的行为，然后将横切逻辑放在子类，在系统中使用目标对象的子类，最终的效果是代理模式是一样的，CGLIB 动态字节码生成类库（它本身其实也是一个抽象层，更底层是 ASM）可以动态生成和修改一个类的字节码。当以上示例代码目标对象未实现接口时修改为 CGLIB 动态生成字节码方式实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @author mghio * @since 2021-05-29 */public class RealSubject &#123; public void doOperation() &#123; System.out.println("RealSubject doOperation..."); &#125;&#125;public class CglibMethodInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; // add pre process logic if necessary System.out.println("Cglib before RealSubject doOperation..."); Object result = methodProxy.invokeSuper(o, args); System.out.println("Cglib after RealSubject doOperation..."); // add post process logic if necessary return result; &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; // 将生成的动态代理类保存到文件中 System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, "/Users/mghio/IdeaProjects/designpattern/cglib/proxy/"); // 1. 创建 Enhancer 对象 Enhancer enhancer = new Enhancer(); // 2. 设置被代理类 enhancer.setSuperclass(RealSubject.class); // 3. 设置回调对象(实现 MethodInterceptor 接口) enhancer.setCallback(new CglibMethodInterceptor()); // 4. 创建代理对象 RealSubject proxy = (RealSubject) enhancer.create(); proxy.doOperation(); &#125;&#125; 使用 CGLIB 生成代理对象需要 4 步： 创建 Enhancer 对象，动态生成字节码的绝大部分逻辑都是在这个类中完成的。 设置被代理类(目标对象)，生成的代理类会继承自这个接口，也就意味着这个类不能是 final 类型的。 设置回调对象(实现 MethodInterceptor 接口)，在这里根据需要添加横切逻辑。 调用 Enhaner 的 create() 方法创建代理对象。 在设置 DebuggingClassWriter.DEBUG_LOCATION_PROPERTY 属性后，反编译已保存的动态生成代理类如下： 从反编译后的代码可以看出 CGLIB 生成的代理类是通过继承被代理类 RealSubject 实现 Factory 接口实现的，要能被继承也就要求被代理类不能是 final 类型的。看到这里你可能会问：既然 JDK 动态代理要求被代理类实现接口，而 CGLIB 动态字节码生成要求不能是 final 类，那对于那些没有实现接口同时还是 final 类，要怎么动态代理呢？好问题，这个就留给你自己去思考了。 总结本文简要介绍了 Spring AOP 实现所依赖的核心基础技术，从动态代理的根源代理模式到动态代理和动态字节码生成技术，为下篇动手实现简易版的 AOP 打下基础，在了解了所依赖的基础技术后，在具体实现时就会更加丝滑，动态代理和动态字节码生成对比如下： 对比项 JDK 动态代理 CGLIB 生成代理类的方式 继承 JDK 中 Proxy，实现被代理类的所有接口 继承被代理类，实现 CGLIB 的 Factory 接口 被代理对象的要求 必须实现接口，可以是 final 类 非 final 类，方法也要是非 final 类型的 集成方式 JDK 内置 第三方动态字节码生成类库]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>AOP</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个简易版的 Spring - 如何实现 AOP（上）]]></title>
    <url>%2Fpost%2F9294037e.html</url>
    <content type="text"><![CDATA[前言本文是「如何实现一个简易版的 Spring 系列」的第五篇，在之前介绍了 Spring 中的核心技术之一 IoC，从这篇开始我们再来看看 Spring 的另一个重要的技术——AOP。用过 Spring 框架进行开发的朋友们相信或多或少应该接触过 AOP，用中文描述就是面向切面编程。学习一个新技术了解其产生的背景是至关重要的，在刚开始接触 AOP 时不知道你有没有想过这个问题，既然在面向对象的语言中已经有了 OOP 了，为什么还需要 AOP 呢？换个问法也就是说在 OOP 中有哪些场景其实处理得并不优雅，需要重新寻找一种新的技术去解决处理？（P.S. 这里建议暂停十秒钟，自己先想一想…） 为什么需要 AOP我们做软件开发的最终目的是为了解决公司的各种需求，为业务赋能，注意，这里的需求包含了业务需求和系统需求，对于绝大部分的业务需求的普通关注点，都可以通过面向对象（OOP）的方式对其进行很好的抽象、封装以及模块化，但是对于系统需求使用面向对象的方式虽然很好的对其进行分解并对其模块化，但是却不能很好的避免这些类似的系统需求在系统的各个模块中到处散落的问题。 因此，需要去重新寻找一种更好的办法，可以在基于 OOP 的基础上提供一套全新的方法来处理上面的问题，或者说是对 OOP 面向对象的开发模式做一个补充，使其可以更优雅的处理上面的问题，迄今为止 Spring 提供一个的解决方案就是面向切面编程——AOP。有了 AOP 后，我们可以将这些事务管理、系统日志以及安全检查等系统需求（横切关注点：cross-cutting concern）进行模块化的组织，使得整个系统更加的模块化方便后续的管理和维护。细心的你应该发现在 AOP 里面引入了一个关键的抽象就是切面（Aspect），用于对于系统中的一些横切关注点进行封装，要明确的一点是 AOP 和 OOP 不是非此即彼的对立关系，AOP 是对 OOP 的一种补充和完善，可以相互协作来完成需求，Aspect 对于 AOP 的重要程度就像 Class 对 OOP 一样。 几个重要的概念我们最终的目的是要模仿 Spring 框架自己去实现一个简易版的 AOP 出来，虽然是简易版但是会涉及到 Spring AOP 中的核心思想和主要实现步骤，不过在此之前先来看看 AOP 中的重要概念，同时也是为以后的实现打下理论基础，这里需要说明一点是我不会使用中文翻译去描述这些 AOP 定义的术语（另外，业界 AOP 术语本来就不太统一），你需要重点理解的是术语在 AOP 中代表的含义，就像我们不会把 Spring 给翻译成春天一样，在软件开发交流你知道它表示一个 开发框架就可以了。下面对其关键术语进行逐个介绍：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950### Joinpoint&gt; A point during the execution of a program, such as the execution of a method or the handling of an exception. In Spring AOP, a join point always represents a method execution. -- Spring Docs通过之前的介绍可知，在我们的系统运行之前，需要将 AOP 定义的一些横切关注点（功能模块）**织入**（可以简单理解为嵌入）到系统的一些业务模块当中去，想要完成织入的前提是我们需要知道可以在哪些**执行点**上进行操作，这些执行点就是 Joinpoint。下面看个简单示例：```Java/** * @author mghio * @since 2021-05-22 */public class Developer &#123; private String name; private Integer age; private String siteUrl; private String position; public Developer(String name, String siteUrl) &#123; this.name = name; this.siteUrl = siteUrl; &#125; public void setSiteUrl(String siteUrl) &#123; this.siteUrl = siteUrl; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public void setName(String name) &#123; this.name = name; &#125; public void setPosition(String position) &#123; this.position = position; &#125; public void showMainIntro() &#123; System.out.printf(&quot;name:[%s], siteUrl:[%s]\n&quot;, this.name, this.siteUrl); &#125; public void showAllIntro() &#123; System.out.printf(&quot;name:[%s], age:[%s], siteUrl:[%s], position:[%s]\n&quot;, this.name, this.age, this.siteUrl, this.position); &#125;&#125; 12345678910111213141516/** * @author mghio * @since 2021-05-22 */public class DeveloperTest &#123; @Test public void test() &#123; Developer developer = new Developer("mghio", "https://www.mghio.cn"); developer.showMainIntro(); developer.setAge(18); developer.setPosition("中国·上海"); developer.showAllIntro(); &#125;&#125; 理论上，在上面示例的这个 test() 方法调用中，我们可以选择在 Developer 的构造方法执行时进行织入，也可以在 showMainIntro() 方法的执行点上进行织入（被调用的地方或者在方法内部执行的地方），或者在 setAge() 方法设置 sge 字段时织入，实际上，只要你想可以在 test() 方法的任何一个执行点上执行织入，这些可以织入的执行点就是 Joinpoint。这么说可能比较抽象，下面通过 test() 方法调用的时序图来直观的看看： 从方法执行的时序来看不难发现，会有如下的一些常见的 Joinpoint 类型： 构造方法调用（Constructor Call）。对某个对象调用其构造方法进行初始化的执行点，比如以上代码中的 Developer developer = new Developer(“mghio”, “https://www.mghio.cn&quot;);。 方法调用（Method call）。调用某个对象的方法时所在的执行点，实际上构造方法调用也是方法调用的一种特殊情况，只是这里的方法是构造方法而已，比如示例中的 developer.showMainIntro(); 和 developer.showAllIntro(); 都是这种类型。 方法执行（Method execution）。当某个方法被调用时方法内部所处的程序的执行点，这是被调用方法内部的执行点，与方法调用不同，方法执行入以上方法时序图中标注所示。 字段设置（Field set）。调用对象 setter 方法设置对象字段的代码执行点，触发点是对象的属性被设置，和设置的方式无关。以上示例中的 developer.setAge(18); 和 developer.setPosition(“中国.上海”); 都是这种类型。 类初始化（Class initialization）。类中的一些静态字段或者静态代码块的初始化执行点，在以上示例中没有体现。 异常执行（Exception execution）。类的某些方法抛出异常后对应的异常处理逻辑的执行点，在以上示例中没有这种类型。 虽然理论上，在程序执行中的任何执行点都可以作为 Joinpoint，但是在某些类型的执行点上进行织入操作，付出的代价比较大，所以在 Spring 中的 Joinpoint 只支持方法执行（Method execution）这一种类型（这一点从 Spring 的官方文档上也有说明），实际上这种类型就可以满足绝大部分的场景了。 Pointcut A predicate that matches join points. Advice is associated with a pointcut expression and runs at any join point matched by the pointcut (for example, the execution of a method with a certain name). The concept of join points as matched by pointcut expressions is central to AOP, and Spring uses the AspectJ pointcut expression language by default.– by Spring Docs Pointcut 表示的是一类 Jointpoint 的表述方式，在进行织入时需要根据 Pointcut 的配置，然后往那些匹配的 Joinpoint 织入横切的逻辑。这里面临的第一个问题：用人类的自然语言可以很快速的表述哪些我们需要织入的 Joinpoint，但是在代码里要如何去表述这些 Joinpoint 呢？目前有如下的一些表述 Joinpoint 定义的方式： 直接指定织入的方法名。显而易见，这种表述方式虽然简单，但是所支持的功能比较单一，只适用于方法类型的 Joinpoint，而且当我们系统中需要织入的方法比较多时，一个一个的去定义织入的 Pointjoint 时过于麻烦。 正则表达式方式。正则表达式相信大家都有一些了解，功能很强大，可以匹配表示多个不同方法类型的 Jointpoint，Spring 框架的 AOP 也支持这种表述方式。 Pointcut 特定语言方式。这个因为是一种特定领域语言（DSL），所以其提供的功能也是最为灵活和丰富的，这也导致了不管其使用和实现复杂度都比较高，像 AspectJ 就是使用的这种表述方式，当然 Spring 也支持。 另外 Pointcut 也支持进行一些简单的逻辑运算，这时我们就可以将多个简单的 Pointcut 通过逻辑运算组合为一个比较复杂的 Pointcut 了，比如在 Spring 配置中的 and 和 or 等逻辑运算标识符以及 AspectJ 中的 &amp;&amp; 和 || 等逻辑运算符。 Advice Action taken by an aspect at a particular join point. Different types of advice include “around”, “before” and “after” advice. (Advice types are discussed later.) Many AOP frameworks, including Spring, model an advice as an interceptor and maintain a chain of interceptors around the join point.– by Spring Docs Advice 表示的是一个注入到 Joinpoint 的横切逻辑，是一个横切关注点逻辑的抽象载体。按照 Advice 的执行点的位置和功能的不同，分为如下几种主要的类型： Before Advice。Before Advice 表示是在匹配的 Joinpoint 位置之前执行的类型。如果被成功织入到方法类型的 Joinpoint 中，那么 Beofre Advice 就会在这个方法执行之前执行，还有一点需要注意的是，如果需要在 Before Advice 中结束方法的执行，我们可以通过在 Advice 中抛出异常的方式来结束方法的执行。 After Advice。显而易见，After Advice 表示在配置的 Joinpoint 位置之后执行的类型。可以在细分为 After returning Advice、After throwing Advice 和 After finally Advice 三种类型。其中 After returning Advice 表示的是匹配的 Joinpoint 方法正常执行完成（没有抛出异常）后执行；After throwing Advice 表示匹配的 Joinpoint 方法执行过程中抛出异常没有正常返回后执行；After finally Advice 表示方法类型的 Joinpoint 的不管是正常执行还是抛出异常都会执行。这几种 Advice 类型在方法类型的 Joinpoint 中执行顺序如下图所示： Around Advice。这种类型是功能最为强大的 Advice，可以匹配的 Joinpoint 之前、之后甚至终端原来 Joinpoint 的执行流程，正常情况下，会先执行 Joinpoint 之前的执行逻辑，然后是 Joinpoint 自己的执行流程，最后是执行 Joinpoint 之后的执行逻辑。细心的你应该发现了，这不就是上面介绍的 Before Advice 和 After Advice 类型的组合吗，是的，它可以完成这两个类型的功能，不过还是要根据具体的场景选择合适的 Advice 类型。 Aspect A modularization of a concern that cuts across multiple classes. Transaction management is a good example of a crosscutting concern in enterprise Java applications. In Spring AOP, aspects are implemented by using regular classes (the schema-based approach) or regular classes annotated with the @Aspect annotation (the @AspectJ style). – Spring Docs Aspect 是对我们系统里的横切关注点（crosscutting concern）包装后的一个抽象概念，可以包含多个 Joinpoint 以及多个 Advice 的定义。Spring 集成了 AspectJ 后，也可以使用 @AspectJ 风格的声明式指定一个 Aspect，只要添加 @Aspect 注解即可。 Target object An object being advised by one or more aspects. Also referred to as the “advised object”. Since Spring AOP is implemented by using runtime proxies, this object is always a proxied object. – by Spring Docs 目标对象一般是指那些可以匹配上 Pointcut 声明条件，被织入横切逻辑的对象，正常情况下是由 Pointcut 来确定的，会根据 Pointcut 设置条件的不同而不同。有了 AOP 这些概念后就可以把上文的例子再次进行整理，各个概念所在的位置如下图所示： 总结本文首先对 AOP 技术的诞生背景做了简要介绍，后面介绍了 AOP 的几个重要概念为后面我们自己实现简易版 AOP 打下基础，AOP 是对 OOP 的一种补充和完善，文中列出的几个概念只是 AOP 中涉及的概念中的冰山一角，想要深入了解更多的相关概念的朋友们可以看 官方文档 学习，下篇是介绍 AOP 实现依赖的一些基础技术，敬请期待。转发、分享都是对我的支持，我将更有动力坚持原创分享！]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
        <category>AOP</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个简易版的 Spring - 如何实现 @Autowired 注解]]></title>
    <url>%2Fpost%2F80982e71.html</url>
    <content type="text"><![CDATA[前言本文是 如何实现一个简易版的 Spring 系列第四篇，在 上篇 介绍了 @Component 注解的实现，这篇再来看看在使用 Spring 框架开发中常用的 @Autowired 注入要如何实现，大家用过 Spring 都知道，该注解可以用在字段、构造函数以及setter 方法上，限于篇幅原因我们主要讨论用在字段的方式实现，其它的使用方式大体思路是相同的，不同的只是解析和注入方式有所区别，话不多说，下面进入我们今天的正题—如何实现一个简易版的 Spring - 如何实现 @Autowired 注解。 实现步骤拆分实现步骤总的来说分为三大步： 分析总结要做的事情，抽象出数据结构 利用这些数据结构来做一些事情 在某个时机注入到 Spring 容器中 细心的朋友可以发现，其实前面几篇文章的实现也是套路，其中最为关键也是比较困难的点就是如何抽象出数据结构。这里我们要做的是当某个 Bean 上的字段有 @Autowired 注解时，从容器中获取该类型的 Bean 然后调用该字段对应的 setter 方法设置到对象的属性中。下面就跟着这个思路去实现 @Autowired 注解。 数据结构抽象要想根据字段的类型注入在容器中对应的实例，首先需要提供这个从一个类型获取对应 Bean 实例的能力，这需要 BeanFactory 接口提供一个这样的能力，等等，像这样容器内部使用的接口直接定义在 BeanFactory 好吗？像这种内部的操作应该尽量做到对使用者透明，所以这里新加一个接口 AutowireCapableBeanFactory 继承自 BeanFactory，这样在内部就可以直接使用新接口接口。需要注意的是新接口的方法参数并不能直接使用 Class 类型去容器中查找对应的 Bean，为了后期的灵活扩展（比如：是否必须依赖等），需要使用一个类来描述这种依赖，命名为 DependencyDescriptor，其部分源码如下所示： 12345678910111213141516171819202122232425/** * @author mghio * @since 2021-03-07 */public class DependencyDescriptor &#123; private Field field; private boolean required; public DependencyDescriptor(Field field, boolean required) &#123; Assert.notNull(field, "Field must not be null"); this.field = field; this.required = required; &#125; public Class&lt;?&gt; getDependencyType() &#123; if (this.field != null) &#123; return field.getType(); &#125; throw new RuntimeException("only support field dependency"); &#125; public boolean isRequired() &#123; return this.required; &#125; &#125; 接口 AutowireCapableBeanFactory 声明如下： 1234567/** * @author mghio * @since 2021-03-07 */public interface AutowireCapableBeanFactory extends BeanFactory &#123; Object resolveDependency(DependencyDescriptor descriptor);&#125; 查找解析依赖的功能我们抽象完成了，下面来看看核心步骤如何抽象封装注入的过程，抽象总结后不难发现，注入可以分为两大部分：注入的目标对象 和 需要被注入的元素列表，这些对于注入来说是一些元数据，命名为 InjectionMetadata，其包含两个字段，一个是注入的目标对象，另一个是被注入的元素列表，还有一个重要的方法将元素列表注入到方法参数传入的目标对象中去。 每个注入元素都要提供一个注入到指定目标对象的能力，所以抽取出公共抽象父类 InjectionElement，使用上文的 AutowireCapableBeanFactory 接口解析出当前字段类型对应 Bean，然后注入到指定的目标对象中。抽象父类 InjectinElement 的主要代码如下： 123456789101112131415/** * @author mghio * @since 2021-03-07 */public abstract class InjectionElement &#123; protected Member member; protected AutowireCapableBeanFactory factory; public InjectionElement(Member member, AutowireCapableBeanFactory factory) &#123; this.member = member; this.factory = factory; &#125; abstract void inject(Object target);&#125; 注入元数据类 InjectionMetadata 的主要代码如下： 12345678910111213141516171819202122232425/** * @author mghio * @since 2021-03-07 */public class InjectionMetadata &#123; private final Class&lt;?&gt; targetClass; private List&lt;InjectionElement&gt; injectionElements; public InjectionMetadata(Class&lt;?&gt; targetClass, List&lt;InjectedElement&gt; injectionElements) &#123; this.targetClass = targetClass; this.injectionElements = injectionElements; &#125; public void inject(Object target) &#123; if (injectionElements == null || injectionElements.isEmpty()) &#123; return; &#125; for (InjectionElement element : injectionElements) &#123; element.inject(target); &#125; &#125; ... &#125; 把一个 Class 转换为 InjectionMetadata 的部分实现我们留到下文实现部分介绍，抽象后总的流程就是把一个 Class 转换为 InjectionMedata ，然后调用 InjectionMedata 提供的 inject(Object) 方法来完成注入（依赖 AutowireCapableBeanFactory 接口提供的 resolveDependency(DependencyDescriptor) 能力），下面是抽象后的字段注入部分的相关类图关系如下： 解析构造出定义的数据结构在上文我们还没实现将一个类转换为 InjectionMetadata 的操作，也就是需要实现这样的一个方法 InjectionMetadata buildAutowiringMetadata(Class&lt;?&gt; clz)，实现过程也比较简单，扫描类中声明的属性找到有 @Autowried 注解解析构造出 InjectinMetadata 实例，核心实现代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @author mghio * @since 2021-03-07 */public class AutowiredAnnotationProcessor &#123; private final String requiredParameterName = "required"; private boolean requiredParameterValue = true; private final Set&lt;Class&lt;? extends Annotation&gt;&gt; autowiredAnnotationTypes = new LinkedHashSet&lt;&gt;(); public AutowiredAnnotationProcessor() &#123; this.autowiredAnnotationTypes.add(Autowired.class); &#125; public InjectionMetadata buildAutowiringMetadata(Class&lt;?&gt; clz) &#123; LinkedList&lt;InjectionElement&gt; elements = new LinkedList&lt;&gt;(); Class&lt;?&gt; targetClass = clz; do &#123; LinkedList&lt;InjectionElement&gt; currElements = new LinkedList&lt;&gt;(); for (Field field : targetClass.getDeclaredFields()) &#123; Annotation ann = findAutowiredAnnotation(field); if (ann != null) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; continue; &#125; boolean required = determineRequiredStatus(ann); elements.add(new AutowiredFieldElement(field, required, beanFactory)); &#125; &#125; elements.addAll(0, currElements); targetClass = targetClass.getSuperclass(); &#125; while (targetClass != null &amp;&amp; targetClass != Object.class); return new InjectionMetadata(clz, elements); &#125; protected boolean determineRequiredStatus(Annotation ann) &#123; try &#123; Method method = ReflectionUtils.findMethod(ann.annotationType(), this.requiredParameterName); if (method == null) &#123; return true; &#125; return (this.requiredParameterValue == (Boolean) ReflectionUtils.invokeMethod(method, ann)); &#125; catch (Exception e) &#123; return true; &#125; &#125; private Annotation findAutowiredAnnotation(AccessibleObject ao) &#123; for (Class&lt;? extends Annotation&gt; annotationType : this.autowiredAnnotationTypes) &#123; Annotation ann = AnnotationUtils.getAnnotation(ao, annotationType); if (ann != null) &#123; return ann; &#125; &#125; return null; &#125; ... &#125; 上面在做数据结构抽象时定义好了注入元素的抽象父类 InjectionElement，这里需要定义一个子类表示字段注入类型，命名为 AutowiredFieldElement，依赖 AutowireCapableBeanFactory 接口的能力解析出字段所属类型的 Bean，然后调用属性的 setter 方法完成注入，在基于我们上面定义好的数据结构后实现比较简单，主要代码如下： 12345678910111213141516171819202122232425262728293031/** * @author mghio * @since 2021-03-07 */public class AutowiredFieldElement extends InjectionElement &#123; private final boolean required; public AutowiredFieldElement(Field field, boolean required, AutowireCapableBeanFactory factory) &#123; super(field, factory); this.required = required; &#125; public Field getField() &#123; return (Field) this.member; &#125; @Override void inject(Object target) &#123; Field field = this.getField(); try &#123; DependencyDescriptor descriptor = new DependencyDescriptor(field, this.required); Object value = factory.resolveDependency(descriptor); if (value != null) &#123; ReflectionUtils.makeAccessible(field); field.set(target, value); &#125; &#125; catch (Throwable e) &#123; throw new BeanCreationException("Could not autowire field:" + field, e); &#125; &#125;&#125; 注入到 Spring 中接下来面临的问题是：要在什么时候调用上面这些类和方法呢？在这里我们回顾一下 Spring 中 Bean 的生命周期，其中几个钩子入口如下图所示： 通过生命周期开放的钩子方法可以看出我们需要在 InstantiationAwareBeanPostProcessor 接口的 postProcessPropertyValues 方法中实现 Autowired 注入，将前面的 AutowiredAnnotationProcessor 类实现该接口然后在 postProcessPropertyValues 方法处理注入即可。这部分的整体类图如下所示： AutowiredAnnotationProcessor 处理器实现的 postProcessPropertyValues() 方法如下： 123456789101112131415161718/** * @author mghio * @since 2021-03-07 */public class AutowiredAnnotationProcessor implements InstantiationAwareBeanProcessor &#123; ... @Override public void postProcessPropertyValues(Object bean, String beanName) throws BeansException &#123; InjectionMetadata metadata = this.buildAutowiringMetadata(bean.getClass()); try &#123; metadata.inject(bean); &#125; catch (Throwable e) &#123; throw new BeanCreationException(beanName, "Injection of autowired dependencies failed"); &#125; &#125; &#125; 然后只需要在抽象父类 AbstractApplicationContext 构造函数注册那些我们定义的 processor，然后在 Bean 注入的时候(DefaultBeanFactory.populateBean())调用 processor 的 postProcessPropertyValues 方法完成属性注入，抽象类 AbstractApplicationContext 改动部分的代码如下： 12345678910111213141516171819202122/** * @author mghio * @since 2021-03-07 */public abstract class AbstractApplicationContext implements ApplicationContext &#123; ... public AbstractApplicationContext(String configFilePath) &#123; ... registerBeanPostProcessor(beanFactory); &#125; protected void registerBeanPostProcessor(ConfigurableBeanFactory beanFactory) &#123; AutowiredAnnotationProcessor postProcessor = new AutowiredAnnotationProcessor(); postProcessor.setBeanFactory(beanFactory); beanFactory.addBeanPostProcessor(postProcessor); &#125; ... &#125; BeanFactory 接口的默认实现类 DefaultBeanFactory 注入 Bean 属性的方法 populateBean(BeanDefinition, Object) 改动如下： 12345678910111213141516171819202122232425/** * @author mghio * @since 2021-03-07 */public class DefaultBeanFactory extends DefaultSingletonBeanRegistry implements ConfigurableBeanFactory, BeanDefinitionRegistry &#123; ... private final List&lt;BeanPostProcessor&gt; beanPostProcessors = new ArrayList&lt;&gt;(); private void populateBean(BeanDefinition bd, Object bean) &#123; for (BeanPostProcessor postProcessor : this.getBeanPostProcessors()) &#123; if (postProcessor instanceof InstantiationAwareBeanProcessor) &#123; ((InstantiationAwareBeanProcessor) postProcessor).postProcessPropertyValues(bean, bd.getId()); &#125; &#125; ... &#125; ... &#125; 总的来说整个使用 processor 的过程分为两步，首先在 AbstractApplicationContext 构造方法中注册我们自定义的 processor，然后再 DefaultBeanFactory 中调用其 postProcessPropertyValues 方法进行注入，至此使用在类字段上的 @Autowired 注解实现完成。 总结本文简要介绍了实现 Spring 的 @Autowired 注解（使用在类字段上的方式），其中比较麻烦的步骤是数据结构抽象部分，需要考虑到后期的扩展性和内部操作对使用者尽量透明，限于篇幅，只列出了部分核心实现代码，完整代码已上传至 GitHub ，感兴趣的朋友可以查看完整代码。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个简易版的 Spring - 如何实现 @Component 注解]]></title>
    <url>%2Fpost%2F6775e26e.html</url>
    <content type="text"><![CDATA[前言前面两篇文章（如何实现一个简易版的 Spring - 如何实现 Setter 注入、如何实现一个简易版的 Spring - 如何实现 Constructor 注入）介绍的都是基于 XML 配置文件方式的实现，从 JDK 5 版本开始 Java 引入了注解支持，带来了极大的便利，Sprinng 也从 2.5 版本开始支持注解方式，使用注解方式我们只需加上相应的注解即可，不再需要去编写繁琐的 XML 配置文件，深受广大 Java 编程人员的喜爱。接下来一起看看如何实现 Spring 框架中最常用的两个注解（@Component、@Autowired），由于涉及到的内容比较多，会分为两篇文章进行介绍，本文先来介绍上半部分 — 如何实现 @Component 注解。 实现步骤拆分本文实现的注解虽然说不用再配置 XML 文件，但是有点需要明确的是指定扫描 Bean 的包还使用 XML 文件的方式配置的，只是指定 Bean 不再使用配置文件的方式。有前面两篇文章的基础后实现 @Component 注解主要分成以下几个步骤： 读取 XML 配置文件，解析出需要扫描的包路径 对解析后的包路径进行扫描然后读取标有 @Component 注解的类，创建出对应的 BeanDefinition 根据创建出来的 BeanDefinition 创建对应的 Bean 实例 下面我们一步步来实现这几个步骤，最后去实现 @Component 注解： 读取 XML 配置文件，解析出需要扫描的包路径假设有如下的 XML 配置文件： 123456789101112&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.e3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/beans/spring-context.xsd"&gt; &lt;context:scann-package base-package="cn.mghio.service.version4,cn.mghio.dao.version4" /&gt;&lt;/beans&gt; 我们期望的结果是解析出来的扫描包路径为： cn.mghio.service.version4、cn.mghio.dao.version4 。如果有仔细有了前面的文章后，这个其实就比较简单了，只需要修改读取 XML 配置文件的类 XmlBeanDefinitionReader 中的 loadBeanDefinition(Resource resource) 方法，判断当前的 namespace 是否为 context 即可，修改该方法如下： 12345678910111213141516171819202122232425262728293031323334353637public void loadBeanDefinition(Resource resource) &#123; try (InputStream is = resource.getInputStream()) &#123; SAXReader saxReader = new SAXReader(); Document document = saxReader.read(is); Element root = document.getRootElement(); // &lt;beans&gt; Iterator&lt;Element&gt; iterator = root.elementIterator(); while (iterator.hasNext()) &#123; Element element = iterator.next(); String namespaceUri = element.getNamespaceURI(); if (this.isDefaultNamespace(namespaceUri)) &#123; // beans parseDefaultElement(element); &#125; else if (this.isContextNamespace(namespaceUri)) &#123; // context parseComponentElement(element); &#125; &#125; &#125; catch (DocumentException | IOException e) &#123; throw new BeanDefinitionException("IOException parsing XML document:" + resource, e); &#125;&#125;private void parseComponentElement(Element element) &#123; // 1. 从 XML 配置文件中获取需要的扫描的包路径 String basePackages = element.attributeValue(BASE_PACKAGE_ATTRIBUTE); // TODO 2. 对包路径进行扫描然后读取标有 `@Component` 注解的类，创建出对应的 `BeanDefinition` ... &#125;private boolean isContextNamespace(String namespaceUri) &#123; // CONTEXT_NAMESPACE_URI = http://www.springframework.org/schema/context return (StringUtils.hasLength(namespaceUri) &amp;&amp; CONTEXT_NAMESPACE_URI.equals(namespaceUri));&#125;private boolean isDefaultNamespace(String namespaceUri) &#123; // BEAN_NAMESPACE_URI = http://www.springframework.org/schema/beans return (StringUtils.hasLength(namespaceUri) &amp;&amp; BEAN_NAMESPACE_URI.equals(namespaceUri));&#125; 第一个步骤就已经完成了，其实相对来说还是比较简单的，接下来看看第二步要如何实现。 对解析后的包路径进行扫描然后读取标有 @Component 注解的类，创建出对应的 BeanDefinition第二步是整个实现步骤中最为复杂和比较麻烦的一步，当面对一个任务比较复杂而且比较大时，可以对其进行适当的拆分为几个小步骤分别去实现，这里可以其再次拆分为如下几个小步骤： 扫描包路径下的字节码（.class ）文件并转换为一个个 Resource 对象（其对于 Spring 框架来说是一种资源，在 Spring 中资源统一抽象为 Resource ，这里的字节码文件具体为 FileSystemResource） 读取转换好的 Resource 中的 @Component 注解 根据读取到的 @Component 注解信息创建出对应的 BeanDefintion ① 扫描包路径下的字节码（.class ）文件并转换为一个个 Resource 对象（其对于 Spring 框架来说是一种资源，在 Spring 中资源统一抽象为 Resource ，这里的字节码文件具体为 FileSystemResource）第一小步主要是实现从一个指定的包路径下获取该包路径下对应的字节码文件并将其转化为 Resource 对象，将该类命名为 PackageResourceLoader，其提供一个主要方法是 Resource[] getResources(String basePackage) 用来将一个给定的包路径下的字节码文件转换为 Resource 数组，实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class PackageResourceLoader &#123; ... public Resource[] getResources(String basePackage) &#123; Assert.notNull(basePackage, "basePackage must not be null"); String location = ClassUtils.convertClassNameToResourcePath(basePackage); ClassLoader classLoader = getClassLoader(); URL url = classLoader.getResource(location); Assert.notNull(url, "URL must not be null"); File rootDir = new File(url.getFile()); Set&lt;File&gt; matchingFile = retrieveMatchingFiles(rootDir); Resource[] result = new Resource[matchingFile.size()]; int i = 0; for (File file : matchingFile) &#123; result[i++] = new FileSystemResource(file); &#125; return result; &#125; private Set&lt;File&gt; retrieveMatchingFiles(File rootDir) &#123; if (!rootDir.exists() || !rootDir.isDirectory() || !rootDir.canRead()) &#123; return Collections.emptySet(); &#125; Set&lt;File&gt; result = new LinkedHashSet&lt;&gt;(8); doRetrieveMatchingFiles(rootDir, result); return result; &#125; private void doRetrieveMatchingFiles(File dir, Set&lt;File&gt; result) &#123; File[] dirContents = dir.listFiles(); if (dirContents == null) &#123; return; &#125; for (File content : dirContents) &#123; if (!content.isDirectory()) &#123; result.add(content); continue; &#125; if (content.canRead()) &#123; doRetrieveMatchingFiles(content, result); &#125; &#125; &#125; ...&#125; 上面的第一小步至此已经完成了，下面继续看第二小步。 ② 读取转换好的 Resource 中的 @Component 注解要实现第二小步（读取转换好的 Resource 中的 @Component 注解），首先面临的第一个问题是：如何读取字节码？，熟悉字节结构的朋友可以字节解析读取，但是难度相对比较大，而且也比较容易出错，这里读取字节码的操作我们使用著名的字节码操作框架 ASM 来完成底层的操作，官网对其的描述入下： ASM is an all purpose Java bytecode manipulation and analysis framework. 其描述就是：ASM 是一个通用的 Java 字节码操作和分析框架。其实不管是在工作或者日常学习中，我们对于一些比较基础的库和框架，如果有成熟的开源框架使用其实没有从零开发（当然，本身就是想要研究其源码的除外），这样可以减少不必要的开发成本和精力。ASM 基于 Visitor 模式可以方便的读取和修改字节码，目前我们只需要使用其读取字节码的功能。 ASM 框架中分别提供了 ClassVisitor 和 AnnotationVisitor 两个抽象类来访问类和注解的字节码，我们可以使用这两个类来获取类和注解的相关信息。很明显我们需要继承这两个类然后覆盖其中的方法增加自己的逻辑去完成信息的获取，要如何去描述一个类呢？其实比较简单无非就是 类名、是否是接口、是否是抽象类、父类的类名、实现的接口列表 等这几项。 但是一个注解要如何去描述它呢？注解其实我们主要关注注解的类型和其所包含的属性，类型就是一个 包名 + 注解名 的字符串表达式，而属性本质上是一种 K-V 的映射，值类型可能为 数字、布尔、字符串 以及 数组 等，为了方便使用可以继承自 LinkedHashMap&lt;String, Object&gt; 封装一些方便的获取属性值的方法，读取注解部分的相关类图设计如下： 其中绿色背景的 ClassVisitor 和 AnnotationVisitor 是 ASM 框架提供的类，ClassMetadata 是类相关的元数据接口，AnnotationMetadata 是注解相关的元数据接口继承自 ClassMetadata，AnnotationAttributes 是对注解属性的描述，继承自 LinkedHashMap 主要是封装了获取指定类型 value 的方法，还有三个自定义的 Visitor 类是本次实现的关键，第一个类 ClassMetadataReadingVisitor 实现了 ClassVisitor 抽象类，用来获取字节码文件中类相关属性的提取，其代码实现如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @author mghio * @since 2021-02-14 */public class ClassMetadataReadingVisitor extends ClassVisitor implements ClassMetadata &#123; private String className; private Boolean isInterface; private Boolean isAbstract; ... public ClassMetadataReadingVisitor() &#123; super(Opcodes.ASM7); &#125; @Override public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) &#123; this.className = ClassUtils.convertResourcePathToClassName(name); this.isInterface = ((access &amp; Opcodes.ACC_INTERFACE) != 0); this.isAbstract = ((access &amp; Opcodes.ACC_ABSTRACT) != 0); ... &#125; @Override public String getClassName() &#123; return this.className; &#125; @Override public boolean isInterface() &#123; return this.isInterface; &#125; @Override public boolean isAbstract() &#123; return this.isAbstract; &#125; ... &#125; 第二个类 AnnotationMetadataReadingVisitor 用来获取注解的类型，然后通过构造方法传给 AnnotataionAttributesVisitor，为获取注解属性做准备，代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637/** * @author mghio * @since 2021-02-14 */public class AnnotationMetadataReadingVisitor extends ClassMetadataReadingVisitor implements AnnotationMetadata &#123; private final Set&lt;String&gt; annotationSet = new LinkedHashSet&lt;&gt;(8); private final Map&lt;String, AnnotationAttributes&gt; attributesMap = new LinkedHashMap&lt;&gt;(8); @Override public AnnotationVisitor visitAnnotation(String descriptor, boolean visible) &#123; String className = Type.getType(descriptor).getClassName(); this.annotationSet.add(className); return new AnnotationAttributesReadingVisitor(className, this.attributesMap); &#125; @Override public boolean hasSuperClass() &#123; return StringUtils.hasText(getSuperClassName()); &#125; @Override public Set&lt;String&gt; getAnnotationTypes() &#123; return this.annotationSet; &#125; @Override public boolean hasAnnotation(String annotationType) &#123; return this.annotationSet.contains(annotationType); &#125; @Override public AnnotationAttributes getAnnotationAttributes(String annotationType) &#123; return this.attributesMap.get(annotationType); &#125;&#125; 第三个类 AnnotationAttributesReadingVisitor 根据类 AnnotationMetadataReadingVisitor 传入的注解类型和属性集合，获取并填充注解对应的属性，代码实现如下： 123456789101112131415161718192021222324252627282930/** * @author mghio * @since 2021-02-14 */public class AnnotationAttributesReadingVisitor extends AnnotationVisitor &#123; private final String annotationType; private final Map&lt;String, AnnotationAttributes&gt; attributesMap; private AnnotationAttributes attributes = new AnnotationAttributes(); public AnnotationAttributesReadingVisitor(String annotationType, Map&lt;String, AnnotationAttributes&gt; attributesMap) &#123; super(Opcodes.ASM7); this.annotationType = annotationType; this.attributesMap = attributesMap; &#125; @Override public void visit(String attributeName, Object attributeValue) &#123; this.attributes.put(attributeName, attributeValue); &#125; @Override public void visitEnd() &#123; this.attributesMap.put(this.annotationType, this.attributes); &#125;&#125; 该类做的使用比较简单，就是当每访问当前注解的一个属性时，将其保存下来，最后当访问完成时以 K-V （key 为注解类型全名称，value 为注解对应的属性集合）的形式存入到 Map 中，比如，当我访问如下的类时： 12345678910/** * @author mghio * @since 2021-02-14 */@Component(value = "orderService")public class OrderService &#123; ...&#125; 此时 AnnotationAttributesReadingVisitor 类的 visit(String, Object) 方法的参数即为当前注解的属性和属性的取值如下： 至此我们已经完成了第二步中的前半部分的扫描指定包路径下的类并读取注解，虽然功能已经实现了，但是对应使用者来说还是不够友好，还需要关心一大堆相关的 Visitor 类，这里能不能再做一些封装呢？此时相信爱思考的你脑海里应该已经浮现了一句计算机科学界的名言： 计算机科学的任何一个问题，都可以通过增加一个中间层来解决。 仔细观察可以发现，以上读取类和注解相关信息的本质是元数据的读取，上文提到的 Resource 其实也是一中元数据，提供信息读取来源，将该接口命名为 MetadataReader，如下所示： 123456789101112/** * @author mghio * @since 2021-02-14 */public interface MetadataReader &#123; Resource getResource(); ClassMetadata getClassMetadata(); AnnotationMetadata getAnnotationMetadata();&#125; 还需要提供该接口的实现，我们期望的最终结果是只要面向 MetadataReader 接口编程即可，只要传入 Resource 就可以获取 ClassMetadata 和 AnnotationMetadata 等信息，无需关心那些 visitor，将该实现类命名为 SimpleMetadataReader，其代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940/** * @author mghio * @since 2021-02-14 */public class SimpleMetadataReader implements MetadataReader &#123; private final Resource resource; private final ClassMetadata classMetadata; private final AnnotationMetadata annotationMetadata; public SimpleMetadataReader(Resource resource) throws IOException &#123; ClassReader classReader; try (InputStream is = new BufferedInputStream(resource.getInputStream())) &#123; classReader = new ClassReader(is); &#125; AnnotationMetadataReadingVisitor visitor = new AnnotationMetadataReadingVisitor(); classReader.accept(visitor, ClassReader.SKIP_DEBUG); this.resource = resource; this.classMetadata = visitor; this.annotationMetadata = visitor; &#125; @Override public Resource getResource() &#123; return this.resource; &#125; @Override public ClassMetadata getClassMetadata() &#123; return this.classMetadata; &#125; @Override public AnnotationMetadata getAnnotationMetadata() &#123; return this.annotationMetadata; &#125;&#125; 在使用时只需要在构造 SimpleMetadataReader 传入对应的 Resource 即可，如下所示： 到这里第二小步从字节码中读取注解的步骤已经完成了。 ③ 根据读取到的 @Component 注解信息创建出对应的 BeanDefintion为了使之前定义好的 BeanDefinition 结构保持纯粹不被破坏，这里我们再增加一个针对注解的 AnnotatedBeanDefinition 接口继承自 BeanDefinition 接口，接口比较简单只有一个获取注解元数据的方法，定义如下所示： 12345678/** * @author mghio * @since 2021-02-14 */public interface AnnotatedBeanDefinition extends BeanDefinition &#123; AnnotationMetadata getMetadata();&#125; 同时增加一个该接口的实现类，表示从扫描注解生成的 BeanDefinition，将其命名为 ScannedGenericBeanDefinition，代码实现如下： 12345678910111213141516171819/** * @author mghio * @since 2021-02-14 */public class ScannedGenericBeanDefinition extends GenericBeanDefinition implements AnnotatedBeanDefinition &#123; private AnnotationMetadata metadata; public ScannedGenericBeanDefinition(AnnotationMetadata metadata) &#123; super(); this.metadata = metadata; setBeanClassName(this.metadata.getClassName()); &#125; @Override public AnnotationMetadata getMetadata() &#123; return this.metadata; &#125;&#125; 还有一个问题就是使用注解的方式时该如何生成 Bean 的名字，这里我们采用和 Spring 一样的策略，当在注解指定 Bean 的名字时使用指定的值为 Bean 的名字，否则使用类名的首字母小写为生成 Bean 的名字， 很明显这只是其中的一种默认实现策略，因此需要提供一个生成 Baen 名称的接口供后续灵活替换生成策略，接口命名为 BeanNameGenerator ，接口只有一个生成 Bean 名称的方法，其定义如下： 12345678/** * @author mghio * @since 2021-02-14 */public interface BeanNameGenerator &#123; String generateBeanName(BeanDefinition bd, BeanDefinitionRegistry registry);&#125; 其默认的生成策略实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * @author mghio * @since 2021-02-14 */public class AnnotationBeanNameGenerator implements BeanNameGenerator &#123; @Override public String generateBeanName(BeanDefinition definition, BeanDefinitionRegistry registry) &#123; if (definition instanceof AnnotatedBeanDefinition) &#123; String beanName = determineBeanNameFromAnnotation((AnnotatedBeanDefinition) definition); if (StringUtils.hasText(beanName)) &#123; return beanName; &#125; &#125; return buildDefaultBeanName(definition); &#125; private String buildDefaultBeanName(BeanDefinition definition) &#123; String shortClassName = ClassUtils.getShortName(definition.getBeanClassName()); return Introspector.decapitalize(shortClassName); &#125; private String determineBeanNameFromAnnotation(AnnotatedBeanDefinition definition) &#123; AnnotationMetadata metadata = definition.getMetadata(); Set&lt;String&gt; types = metadata.getAnnotationTypes(); String beanName = null; for (String type : types) &#123; AnnotationAttributes attributes = metadata.getAnnotationAttributes(type); if (attributes.get("value") != null) &#123; Object value = attributes.get("value"); if (value instanceof String) &#123; String stringVal = (String) value; if (StringUtils.hasLength(stringVal)) &#123; beanName = stringVal; &#125; &#125; &#125; &#125; return beanName; &#125; &#125; 最后我们再定义一个扫描器类组合以上的功能提供一个将包路径下的类读取并转换为对应的 BeanDefinition 方法，将该类命名为 ClassPathBeanDefinitionScanner，其代码实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @author mghio * @since 2021-02-14 */public class ClassPathBeanDefinitionScanner &#123; public static final String SEMICOLON_SEPARATOR = ","; private final BeanDefinitionRegistry registry; private final PackageResourceLoader resourceLoader = new PackageResourceLoader(); private final BeanNameGenerator beanNameGenerator = new AnnotationBeanNameGenerator(); public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry) &#123; this.registry = registry; &#125; public Set&lt;BeanDefinition&gt; doScanAndRegistry(String packageToScan) &#123; String[] basePackages = StringUtils.tokenizeToStringArray(packageToScan, SEMICOLON_SEPARATOR); Set&lt;BeanDefinition&gt; beanDefinitions = new HashSet&lt;&gt;(); for (String basePackage : basePackages) &#123; Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) &#123; beanDefinitions.add(candidate); registry.registerBeanDefinition(candidate.getId(), candidate); &#125; &#125; return beanDefinitions; &#125; private Set&lt;BeanDefinition&gt; findCandidateComponents(String basePackage) &#123; Set&lt;BeanDefinition&gt; candidates = new HashSet&lt;&gt;(); try &#123; Resource[] resources = this.resourceLoader.getResources(basePackage); for (Resource resource : resources) &#123; MetadataReader metadataReader = new SimpleMetadataReader(resource); if (metadataReader.getAnnotationMetadata().hasAnnotation(Component.class.getName())) &#123; ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader.getAnnotationMetadata()); String beanName = this.beanNameGenerator.generateBeanName(sbd, registry); sbd.setId(beanName); candidates.add(sbd); &#125; &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException("I/O failure during classpath scanning", ex); &#125; return candidates; &#125;&#125; 到这里就已经把读取到的 @Component 注解信息转换为 BeanDefinition 了。 根据创建出来的 BeanDefinition 创建对应的 Bean 实例这一步其实并不需要再修改创建 Bean 的代码了，创建的逻辑都是一样的，只需要将之前读取 XML 配置文件那里使用上文提到的扫描器 ClassPathBeanDefinitionScanner 扫描并注册到 BeanFactory 中即可，读取配置文件的 XmlBeanDefinitionReader 类的读取解析配置文件的方法修改如下： 1234567891011121314151617181920212223242526public void loadBeanDefinition(Resource resource) &#123; try (InputStream is = resource.getInputStream()) &#123; SAXReader saxReader = new SAXReader(); Document document = saxReader.read(is); Element root = document.getRootElement(); // &lt;beans&gt; Iterator&lt;Element&gt; iterator = root.elementIterator(); while (iterator.hasNext()) &#123; Element element = iterator.next(); String namespaceUri = element.getNamespaceURI(); if (this.isDefaultNamespace(namespaceUri)) &#123; parseDefaultElement(element); &#125; else if (this.isContextNamespace(namespaceUri)) &#123; parseComponentElement(element); &#125; &#125; &#125; catch (DocumentException | IOException e) &#123; throw new BeanDefinitionException("IOException parsing XML document:" + resource, e); &#125;&#125;private void parseComponentElement(Element element) &#123; String basePackages = element.attributeValue(BASE_PACKAGE_ATTRIBUTE); // 读取指定包路径下的类转换为 BeanDefinition 并注册到 BeanFactory 中 ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(registry); scanner.doScanAndRegistry(basePackages);&#125; 到这里实现 @Component 注解的主要流程已经介绍完毕，完整代码已上传至仓库 GitHub 。 总结本文主要介绍了实现 @Component 注解的主要流程，以上只是实现的最简单的功能，但是基本原理都是类似的，有问题欢迎留言讨论。下篇预告：如何实现 @Autowried 注解。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个简易版的 Spring - 如何实现 Constructor 注入]]></title>
    <url>%2Fpost%2F315ff4dc.html</url>
    <content type="text"><![CDATA[前言本文是「如何实现一个简易版的 Spring」系列的第二篇，在 第一篇 介绍了如何实现一个基于 XML 的简单 Setter 注入，这篇来看看要如何去实现一个简单的 Constructor 注入功能，实现步骤和 Setter 注入是一样的“套路”，先设计一个数据结构去解析表达 XML 配置文件里的信息，然后再使用这些解析好的数据结构做一些事情，比如这里的 Constructor 注入。话不多说，下面我们直接进入正题。 数据结构设计使用 Constructor 注入方式的 XML 的一种配置如下所示： 12345&lt;bean id="orderService" class="cn.mghio.service.version3.OrderService"&gt; &lt;constructor-arg ref="stockService"/&gt; &lt;constructor-arg ref="tradeService"/&gt; &lt;constructor-arg type="java.lang.String" value="mghio"/&gt;&lt;/bean&gt; 以上 OrderService 类如下： 12345678910111213141516/** * @author mghio * @since 2021-01-16 */public class OrderService &#123; private StockDao stockDao; private TradeDao tradeDao; private String owner; public OrderService(StockDao stockDao, TradeDao tradeDao, String owner) &#123; this.stockDao = stockDao; this.tradeDao = tradeDao; this.owner = owner; &#125;&#125; 从 XML 的配置结构上看和 Setter 注入类似，都是 Key-Value 类的格式，可以将每个 constructor-arg 节点抽象为 ValueHolder，包含实际解析后的值类型 value、类型 type 以及参数名称 name，如下所示： 1234567891011/** * @author mghio * @since 2021-01-16 */public class ValueHolder &#123; private Object value; private String type; private String name; // omit setter and getter &#125; 同样一个 Bean 可以包含多个 ValueHolder，为了封装实现以及方便提供一些判断方法（比如是否配置有构造器注入等），将进一步封装为 ConstructorArgument，并提供一些 CRUD 接口，而 ValueHolder 作为内部类，如下所示： 12345678910111213141516171819202122232425262728293031323334353637/** * @author mghio * @since 2021-01-16 */public class ConstructorArgument &#123; private final List&lt;ValueHolder&gt; argumentsValues = new LinkedList&lt;&gt;(); public void addArgumentValue(Object value) &#123; this.argumentsValues.add(new ValueHolder(value)); &#125; public List&lt;ValueHolder&gt; getArgumentsValues() &#123; return this.argumentsValues; &#125; public int getArgumentCount() &#123; return this.argumentsValues.size(); &#125; public boolean isEmpty() &#123; return this.argumentsValues.isEmpty(); &#125; public void clear() &#123; this.argumentsValues.clear(); &#125; // some other methods... public static class ValueHolder &#123; private Object value; private String type; private String name; &#125;&#125; 然后在 BeanDefinition 接口中增加获取 ConstructorArgument 方法和判断是否配置 ConstructorArgument 方法。结构如下图所示： 解析 XML 配置文件有了 上篇文章 的基础，解析 XML 也比较简单，这里我们解析的是 constructor-arg 节点，组装数据添加到 BeanDefinition 的 ConstructorArgument 属性中，修改 XmlBeanDefinitionReader 类的 loadBeanDefinition(Resource resource) 方法如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * @author mghio * @since 2021-01-16 */public class XmlBeanDefinitionReader &#123; private static final String CONSTRUCTOR_ARG_ELEMENT = "constructor-arg"; private static final String NAME_ATTRIBUTE = "name"; private static final String TYPE_ATTRIBUTE = "type"; // other fields and methods ... public void loadBeanDefinition(Resource resource) &#123; try (InputStream is = resource.getInputStream()) &#123; SAXReader saxReader = new SAXReader(); Document document = saxReader.read(is); Element root = document.getRootElement(); // &lt;beans&gt; Iterator&lt;Element&gt; iterator = root.elementIterator(); while (iterator.hasNext()) &#123; Element element = iterator.next(); String beanId = element.attributeValue(BEAN_ID_ATTRIBUTE); String beanClassName = element.attributeValue(BEAN_CLASS_ATTRIBUTE); BeanDefinition bd = new GenericBeanDefinition(beanId, beanClassName); if (null != element.attributeValue(BEAN_SCOPE_ATTRIBUTE)) &#123; bd.setScope(element.attributeValue(BEAN_SCOPE_ATTRIBUTE)); &#125; // parse &lt;constructor-arg&gt; node parseConstructorArgElements(element, bd); parsePropertyElementValues(element, bd); this.registry.registerBeanDefinition(beanId, bd); &#125; &#125; catch (DocumentException | IOException e) &#123; throw new BeanDefinitionException("IOException parsing XML document:" + resource, e); &#125; &#125; private void parseConstructorArgElements(Element rootEle, BeanDefinition bd) &#123; Iterator&lt;Element&gt; iterator = rootEle.elementIterator(CONSTRUCTOR_ARG_ELEMENT); while (iterator.hasNext()) &#123; Element element = iterator.next(); parseConstructorArgElement(element, bd); &#125; &#125; private void parseConstructorArgElement(Element element, BeanDefinition bd) &#123; String typeAttr = element.attributeValue(TYPE_ATTRIBUTE); String nameAttr = element.attributeValue(NAME_ATTRIBUTE); Object value = parsePropertyElementValue(element, null); ConstructorArgument.ValueHolder valueHolder = new ConstructorArgument.ValueHolder(value); if (StringUtils.hasLength(typeAttr)) &#123; valueHolder.setType(typeAttr); &#125; if (StringUtils.hasLength(nameAttr)) &#123; valueHolder.setName(nameAttr); &#125; bd.getConstructorArgument().addArgumentValue(valueHolder); &#125; // other fields and methods ...&#125; 解析 XML 的过程整体上分为两步，第一步在遍历每个 &lt;bean&gt; 节点时判断 &lt;constructor-arg&gt; 节点是否存在，存在则解析 &lt;constructor-arg&gt; 节点；第二步将解析拼装好的 ValueHolder 添加到 BeanDefinition 中，这样我们就把 XML 配置的 Constructor 注入解析到 BeanDefinition 中了，下面看看如何在创建 Bean 的过程中如何使用该数据结构进行构造器注入。 如何选择 Constructor很明显，使用构造器注入需要放在实例化 Bean的阶段，通过判断当前待实例化的 Bean 是否有配置构造器注入，有则使用构造器实例化。判断 XML 是否有配置构造器注入可以直接使用 BeanDefinition 提供的 hasConstructorArguments() 方法即可，实际上最终是通过判断 ConstructorArgument.ValueHolder 集合是否有值来判断的。这里还有个问题 当存在多个构造器时如何选择，比如 OrderService 类有如下三个构造函数： 1234567891011121314151617181920212223242526272829/** * @author mghio * @since 2021-01-16 */public class OrderService &#123; private StockDao stockDao; private TradeDao tradeDao; private String owner; public OrderService(StockDao stockDao, TradeDao tradeDao) &#123; this.stockDao = stockDao; this.tradeDao = tradeDao; this.owner = "nobody"; &#125; public OrderService(StockDao stockDao, String owner) &#123; this.stockDao = stockDao; this.owner = owner; &#125; public OrderService(StockDao stockDao, TradeDao tradeDao, String owner) &#123; this.stockDao = stockDao; this.tradeDao = tradeDao; this.owner = owner; &#125;&#125; 其 XML 构造器注入的配置如下： 12345&lt;bean id="orderService" class="cn.mghio.service.version3.OrderService"&gt; &lt;constructor-arg ref="stockService"/&gt; &lt;constructor-arg ref="tradeService"/&gt; &lt;constructor-arg type="java.lang.String" value="mghio"/&gt;&lt;/bean&gt; 这时该如何选择最适合的构造器进行注入呢？这里使用的匹配方法是 1. 先判断构造函数参数个数，如果不匹配直接跳过，进行下一次循环；2. 当构造器参数个数匹配时再判断参数类型，如果和当前参数类型一致或者是当前参数类型的父类型则使用该构造器进行实例化。这个使用的判断方法比较简单直接，实际上 Spring 的判断方式考虑到的情况比较全面同时代码实现也更加复杂，感兴趣的朋友可以查看 org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(...) 方法。这里需要注意的是，在解析 XML 配置的构造器注入参数时要进行类型转换为目标类型，将该类命名为 ConstructorResolver，实现代码比较多这里就不贴出来了，可以到 GitHub 查看完整代码。然后只需要在实例化 Bean 的时候判断是否存在构造器注入配置，存在则使用构造器注入即可，修改 DefaultBeanFactory 的实例化方法如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @author mghio * @since 2021-01-16 */public class DefaultBeanFactory extends DefaultSingletonBeanRegistry implements ConfigurableBeanFactory, BeanDefinitionRegistry &#123; // other fields and methods ... private Object doCreateBean(BeanDefinition bd) &#123; // 1. instantiate bean Object bean = instantiateBean(bd); // 2. populate bean populateBean(bd, bean); return bean; &#125; private Object instantiateBean(BeanDefinition bd) &#123; // 判断当前 Bean 的 `XML` 配置是否配置为构造器注入方式 if (bd.hasConstructorArguments()) &#123; ConstructorResolver constructorResolver = new ConstructorResolver(this); return constructorResolver.autowireConstructor(bd); &#125; else &#123; ClassLoader classLoader = this.getClassLoader(); String beanClassName = bd.getBeanClassName(); try &#123; Class&lt;?&gt; beanClass = null; Class&lt;?&gt; cacheBeanClass = bd.getBeanClass(); if (cacheBeanClass == null) &#123; beanClass = classLoader.loadClass(beanClassName); bd.setBeanClass(beanClass); &#125; else &#123; beanClass = cacheBeanClass; &#125; return beanClass.getDeclaredConstructor().newInstance(); &#125; catch (Exception e) &#123; throw new BeanCreationException("Created bean for " + beanClassName + " fail.", e); &#125; &#125; &#125; // other fields and methods ...&#125; 到这里就已经实现了一个简易版的基于 XML 配置的 Constructor 注入了。 总结本文简要介绍了 Spring 基于 XML 配置的 Constructor 注入，其实有了第一篇的 Setter 注入的基础，实现 Constructor 注入相对来说难度要小很多，这里的实现相对来说比较简单，但是其思想和大体流程是类似的，想要深入了解 Spring 实现的具体细节可以查看源码。完整代码已上传至 GitHub，感兴趣的朋友可以到这里 mghio-spring 查看完整代码，下篇预告：「如何实现一个简易版的 Spring - 实现字段注解方式注入」。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个简易版的 Spring - 如何实现 Setter 注入]]></title>
    <url>%2Fpost%2F5731122e.html</url>
    <content type="text"><![CDATA[前言之前在 上篇 提到过会实现一个简易版的 IoC 和 AOP，今天它终于来了。。。相信对于使用 Java 开发语言的朋友们都使用过或者听说过 Spring 这个开发框架，绝大部分的企业级开发中都离不开它，通过 官网 可以了解到其生态非常庞大，针对不同方面的开发提供了一些解决方案，可以说 Spring 框架的诞生是对 Java 开发人员的一大福利，自 2004 年发布以来，Spring 为了解决一些企业开发中的痛点先后引入了很多的特性和功能，其中最重要的就是我们经常听到的 IoC 和 AOP 特性，由于涉及到的知识和细节比较多，会分为几篇文章来介绍，今天这篇（也是第一篇）我们来看看如何实现基于 XML 配置方式的 Setter 注入。 预备知识既然是通过 XML 配置文件的方式，首先第一件事就是要读取 XML 文件然后转换为我们需要的数据结构，解析 XML 文件有但不限于这些方式（JDOM、XOM、dom4j），这里使用的是简单易上手的 dom4j，所你得对其基础知识有一些简单了解，其实都是一些很简单的方法基础使用而已，第二个就是你要有一些 Spring 框架的使用经验，这里实现的简易版本质上是对 Spring 的一个精简后的核心部分的简单实现，是的，没错，你只需要有了这些基础预备知识就可以了。 基础数据结构抽象在开始编码实现前先要做一些简单的构思和设计，首先在 Spring 中把一个被其管理的对象称之为 Bean，然后其它的操作都是围绕这个 Bean 来展开设计的，所以为了能在程序中统一并且规范的表示一个 Bean 的定义，于是第一个接口 BeanDefinition 就出来了，本次需要的一些基本信息包含 Bean 的名称、所属类名称、是否单例、作用域等，如下所示： 现在 BeanDefinition 有了，接下来就是要根据这个 BeanDefinition 去创建出对应的 Bean 实例了，很显然这需要一个 Factory 工厂接口去完成这个创建的工作，这个创建 Bean 的接口命名为 BeanFactory，其提供根据不同条件去创建相对应的 Bean 实例功能（比如 beanId），但是创建的前提是需要先注册这个 BeanDefinition，然后根据一定条件再从中去获取 BeanDefinition，根据 单一职责 原则，这个功能应该由一个新的接口去完成，主要是做注册和获取 BeanDefinition 的工作，故将其命名为 BeanDefinitionRegistry，我们需要的 BeanDefinition 要从哪里获取呢？很显然我们是基于 XML 配置的方式，当然是从 XML 配置文件中获取到的，同样根据单一职责原则，也需要一个类去完成这个事情，将其命名为 XMLBeanDefinitionReader，这部分的整体结构如下所示： 接下来面临的一个问题就是，像 XML 这种配置文件资源要如何表示呢，这些配置对于程序来说是一种资源，可以统一抽象为 Resource，然后提供一个返回资源对应流（InputStream）对象接口，这种资源可以从项目中获取、本地文件获取甚至是从远程获取，它们都是一种 Resource，结构如下： 最后就是要一个提供去组合调用上面的那些类去完成 XML 配置文件解析为 BeanDefinition 并注入到容器中了的功能，担任这程序上下文的职责，将其命名为 ApplicationContext，这里同样也可以根据 Resource 的类型分为多种不同的类，比如：FileSystmXmlApplicationContext、ClassPathXmlApplicationContext 等，这些内部都有一个将配置文件转换为 Resource 的过程，可以使用 模板方法 抽象出一个公共父类抽象类，如下所示: 总结以上分析结果，得出初步类图设计如下： 最终要实现 Setter 注入这个目标，可以将其分解为以下两个步骤： 将 XML 配置文件中的 &lt;bean&gt; 标签解析为 BeanDefinition 并注入到容器中 实现 Setter 注入 下面我们分为这两个部分来分别讲述如何实现。 配置文件解析假设有如下内容的配置文件 applicationcontext-config1.xml: 123456789&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.e3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="orderService" class="cn.mghio.service.version1.OrderService" /&gt;&lt;/beans&gt; 最终需要解析出一个 id 为 orderService 类型为 cn.mghio.service.version1.OrderService 的 BeanDefinition，翻译成测试类的话也就是需要让如下测试类可以运行通过： 1234567891011121314151617181920212223242526272829303132333435363738/** * @author mghio */public class BeanFactoryTest &#123; private Resource resource; private DefaultBeanFactory beanFactory; private XmlBeanDefinitionReader reader; @BeforeEach public void beforeEach() &#123; resource = new ClassPathResource("applicationcontext-config1.xml"); beanFactory = new DefaultBeanFactory(); reader = new XmlBeanDefinitionReader(beanFactory); &#125; @Test public void testGetBeanFromXmlFile() &#123; reader.loadBeanDefinition(resource); BeanDefinition bd = beanFactory.getBeanDefinition("orderService"); assertEquals("cn.mghio.service.version1.OrderService", bd.getBeanClassNam()); OrderService orderService = (OrderService) beanFactory.getBean("orderService"); assertNotNull(orderService); &#125; @Test public void testGetBeanFromXmlFileWithInvalidBeanId() &#123; assertThrows(BeanCreationException.class, () -&gt; beanFactory.getBean("notExistsBeanId")); &#125; @Test public void testGetFromXmlFilWithFileNotExists() &#123; resource = new ClassPathResource("notExists.xml"); assertThrows(BeanDefinitionException.class, () -&gt; reader.loadBeanDefinition(resource)); &#125;&#125; 可以看到这里面的关键就是如何去实现 XmlBeanDefinitionReader 类的 loadBeanDefinition 从配置中加载和注入 BeanDefinition，思考分析后不然发现这里主要是两步，第一步是解析 XML 配置转换为 BeanDefinition，这就需要上文提到的 dom4j 提供的能力了，第二步将解析出来的 BeanDefinition 注入到容器中，通过组合使用 BeanDefinitionRegistry 接口提供注册 BeanDefinition 的能力来完成。读取 XML 配置的类 XmlBeanDefinitionReader 的代码实现很快就可以写出来了，该类部分代码如下所示： 123456789101112131415161718192021222324252627282930313233/** * @author mghio */public class XmlBeanDefinitionReader &#123; private static final String BEAN_ID_ATTRIBUTE = "id"; private static final String BEAN_CLASS_ATTRIBUTE = "class"; private BeanDefinitionRegistry registry; public XmlBeanDefinitionReader(BeanDefinitionRegistry registry) &#123; this.registry = registry; &#125; @SuppressWarnings("unchecked") public void loadBeanDefinition(Resource resource) &#123; try (InputStream is = resource.getInputStream()) &#123; SAXReader saxReader = new SAXReader(); Document document = saxReader.read(is); Element root = document.getRootElement(); // &lt;beans&gt; Iterator&lt;Element&gt; iterator = root.elementIterator(); while (iterator.hasNext()) &#123; Element element = iterator.next(); String beanId = element.attributeValue(BEAN_ID_ATTRIBUTE); String beanClassName = element.attributeValue(BEAN_CLASS_ATTRIBUTE); BeanDefinition bd = new GenericBeanDefinition(beanId, beanClassName); this.registry.registerBeanDefinition(beanId, bd); &#125; &#125; catch (DocumentException | IOException e) &#123; throw new BeanDefinitionException("IOException parsing XML document:" + configurationFile, e); &#125; &#125;&#125; 然后当调用 BeanFactory 的 getBean 方法时就可以根据 Bean 的全限定名创建一个实例出来了(PS：暂时不考虑实例缓存)，方法实现主要代码如下： 1234567891011121314public Object getBean(String beanId) &#123; BeanDefinition bd = getBeanDefinition(beanId); if (null == bd) &#123; throw new BeanCreationException("BeanDefinition does not exists, beanId:" + beanId); &#125; ClassLoader classLoader = this.getClassLoader(); String beanClassName = bd.getBeanClassNam(); try &#123; Class&lt;?&gt; clazz = classLoader.loadClass(beanClassName); return clazz.newInstance(); &#125; catch (ClassNotFoundException | IllegalAccessException | InstantiationException e) &#123; throw new BeanCreationException("Created bean for " + beanClassName + " fail.", e); &#125;&#125; 到这里配置文件解析方面的工作已完成，接下来看看要如何实现 Setter 注入。 如何实现 Setter 注入首先实现基于 XML 配置文件的 Setter 注入本质上也是解析 XML 配置文件，然后再调用对象属性的 setXXX 方法将配置的值设置进去，配置文件 applicationcontext-config2.xml 如下所示： 12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.e3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="stockDao" class="cn.mghio.dao.version2.StockDao"/&gt; &lt;bean id="tradeDao" class="cn.mghio.dao.version2.TradeDao"/&gt; &lt;bean id="orderService" class="cn.mghio.service.version2.OrderService"&gt; &lt;property name="stockDao" ref="stockDao"/&gt; &lt;property name="tradeDao" ref="tradeDao"/&gt; &lt;property name="num" value="2"/&gt; &lt;property name="owner" value="mghio"/&gt; &lt;property name="orderTime" value="2020-11-24 18:42:32"/&gt; &lt;/bean&gt;&lt;/beans&gt; 我们之前使用了 BeanDefinition 去抽象了 &lt;bean&gt; 标签，这里面临的第一个问题就是要如何去表达配置文件中的 &lt;property&gt; 标签，其中 ref 属性表示一个 beanId、value 属性表示一个值（值类型为：Integer、String、Date 等）。观察后可以发现，&lt;property&gt; 标签本质上是一个 K-V 格式的数据（name 作为 Key，ref 和 value 作为 Value），将这个类命名为 PropertyValue，很明显一个 BeanDefinition 会有多个 PropertyValue，结构如下： 这里的 value 有两种不同的类型，一种是表示 Bean 的 id 值，运行时会解析为一个 Bean 的引用，将其命名为 RuntimeBeanReference，还有一种是 String 类型，运行时会解析为不同的类型，将其命名为 TypeStringValue。第二个问题就是要如何将一个类型转换为另一个类型呢？比如将上面配置中的字符串 2 转换为整型的 2、字符串 2020-11-24 18:42:32 转换为日期，这类通用的问题前辈们已经开发好了类库处理了，这里我们使用 commons-beanutils 库提供的 BeanUtils.copyProperty(final Object bean, final String name, final Object value) 方法即可。然后只需在之前 XmlBeanDefinitionReader 类的 loadBeanDefinition 方法解析 XML 配置文件的时解析 &lt;bean&gt; 标签下的 &lt;property&gt; 标签并设置到 BeanDefinition 的 propertyValues 属性中；DefaultBeanFactory 中的 getBean 方法分为实例化 Bean 和读取向实例化完成的 Bean 使用 Setter 注入配置文件中配置属性对应的值。XmlBeanDefinitionReader 的 loadBeanDefinition() 方法代码修改为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public void loadBeanDefinition(Resource resource) &#123; try (InputStream is = resource.getInputStream()) &#123; SAXReader saxReader = new SAXReader(); Document document = saxReader.read(is); Element root = document.getRootElement(); // &lt;beans&gt; Iterator&lt;Element&gt; iterator = root.elementIterator(); while (iterator.hasNext()) &#123; Element element = iterator.next(); String beanId = element.attributeValue(BEAN_ID_ATTRIBUTE); String beanClassName = element.attributeValue(BEAN_CLASS_ATTRIBUTE); BeanDefinition bd = new GenericBeanDefinition(beanId, beanClassName); parsePropertyElementValue(element, bd); // parse &lt;property&gt; this.registry.registerBeanDefinition(beanId, bd); &#125; &#125; catch (DocumentException | IOException e) &#123; throw new BeanDefinitionException("IOException parsing XML document:" + resource, e); &#125;&#125;private void parsePropertyElementValue(Element element, BeanDefinition bd) &#123; Iterator&lt;Element&gt; iterator = element.elementIterator(PROPERTY_ATTRIBUTE); while (iterator.hasNext()) &#123; Element propertyElement = iterator.next(); String propertyName = propertyElement.attributeValue(NAME_ATTRIBUTE); if (!StringUtils.hasText(propertyName)) &#123; return; &#125; Object value = parsePropertyElementValue(propertyElement, propertyName); PropertyValue propertyValue = new PropertyValue(propertyName, value); bd.getPropertyValues().add(propertyValue); &#125;&#125;private Object parsePropertyElementValue(Element propertyElement, String propertyName) &#123; String elementName = (propertyName != null) ? "&lt;property&gt; element for property '" + propertyName + "' " : "&lt;constructor-arg&gt; element"; boolean hasRefAttribute = propertyElement.attribute(REF_ATTRIBUTE) != null; boolean hasValueAttribute = propertyElement.attribute(VALUE_ATTRIBUTE) != null; if (hasRefAttribute) &#123; String refName = propertyElement.attributeValue(REF_ATTRIBUTE); RuntimeBeanReference ref = new RuntimeBeanReference(refName); return ref; &#125; else if (hasValueAttribute) &#123; String value = propertyElement.attributeValue(VALUE_ATTRIBUTE); TypedStringValue valueHolder = new TypedStringValue(value); return valueHolder; &#125; else &#123; throw new RuntimeException(elementName + " must specify a ref or value"); &#125;&#125; DefaultBeanFactory 的 getBean 方法也增加 Bean 属性注入操作，部分代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940public Object getBean(String beanId) &#123; BeanDefinition bd = getBeanDefinition(beanId); // 1. instantiate bean Object bean = instantiateBean(bd); // 2. populate bean populateBean(bd, bean); return bean;&#125;private Object instantiateBean(BeanDefinition bd) &#123; ClassLoader classLoader = this.getClassLoader(); String beanClassName = bd.getBeanClassName(); try &#123; Class&lt;?&gt; clazz = classLoader.loadClass(beanClassName); return clazz.newInstance(); &#125; catch (ClassNotFoundException | IllegalAccessException | InstantiationException e) &#123; throw new BeanCreationException("Created bean for " + beanClassName + " fail.", e); &#125;&#125;private void populateBean(BeanDefinition bd, Object bean) &#123; List&lt;PropertyValue&gt; propertyValues = bd.getPropertyValues(); if (propertyValues == null || propertyValues.isEmpty()) &#123; return; &#125; BeanDefinitionResolver resolver = new BeanDefinitionResolver(this); SimpleTypeConverted converter = new SimpleTypeConverted(); try &#123; for (PropertyValue propertyValue : propertyValues) &#123; String propertyName = propertyValue.getName(); Object originalValue = propertyValue.getValue(); Object resolvedValue = resolver.resolveValueIfNecessary(originalValue); BeanUtils.copyProperty(bean, propertyName, resolvedValue); &#125; &#125; catch (Exception e) &#123; throw new BeanCreationException("Failed to obtain BeanInfo for class [" + bd.getBeanClassName() + "]"); &#125;&#125; 至此，简单的 Setter 注入功能已完成。 总结本文简单概述了基于 XML 配置文件方式的 Setter 注入简单实现过程，整体实现 Setter 注入的思路就是先设计一个数据结构去表达 XML 配置文件中的标签数据（比如上面的 PropertyValue），然后再解析配置文件填充数据并利用这个数据结构完成一些功能（比如 Setter 注入等）。感兴趣的朋友可以到这里 mghio-spring 查看完整代码。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 是如何造出一个 Bean 的]]></title>
    <url>%2Fpost%2F558ca0bd.html</url>
    <content type="text"><![CDATA[前言使用 Java 作为第一开发语言的朋友们，相信大家或多或少的都使用过 Spring 这个开发框架，可以说 Spring 框架真是我们 Java 程序员的春天，在 Spring 中 Bean 是其中最重要的概念之一，是学习其它高级知识的基础，Bean 说白了其实就是一个被 Spring 框架管理的对象，今天我们来看看 Bean 在 Spring 中是如何被造出来的。 1. Bean 要如何定义假如你有如下这样的一个 Programmer 类，这个程序员类有三个属性： 姓名(name)、年龄(age)、是否有女朋友(hasGirlFriend)（P.S. 正常情况下 hasGirlFriend 属性应该都是 false），还有一个显示个人资料的方法 showMaterial。 1234567891011121314151617/** * @Author: mghio * @Date: 2020-10-05 * @Description: Programmer. */public class Programmer &#123; private String name; private Integer age; private Boolean hasGirlFriend; public void showMaterial() &#123; System.out.println("name: " + name + ", age: " + age + ", hasGirlFriend: " + hasGirlFriend); &#125;&#125; 现在请你思考一下，如果让你来设计该如何在一个 Spring 容器中描述这样的一个 Programmer 对象呢？ 无非就是需要如下这些信息： 1.1 类名首先类名肯定是需要的，这样到时候才能通过类名加载到这个类。 1.2 实例别名当我们在一个容器中如果一个类有多个实例或者不想通过一个类名来描述一个实例时，这时通过设置一个别名就可以很方便的描述该实例了。 1.3 构造函数我们知道 Java 中创建一个类的实例首先就会调用该类的构造函数，当有多个构造函数时，需要明确的描述要使用哪个构造函数来创建对象，比如通过传入不同的参数类型来选择不同的构造函数。 1.4 类的属性设置当我们没有在构造函数中传入属性，比如上面的 Programmer 可以直接通过无参构造函数就可以创建出来了，后面如果需要设置实例的属性则需要调用其设置属性的方式来进行设置，所以属性方法也是必要的。 1.5 初始化方法有时候我们需要在一个实例化完成之后做一些我们自定义的业务逻辑，比如想让上面例子中的 Programmer 在实例化完成之后就显示个人资料（调用 showMaterial() 方法），这种场景使用初始化方法就很合适了。 1.6 销毁方法说到销毁，大家可能都会想到和资源有关，比如一个共识就是大家一般都把资源释放类的工作放在 finally 代码块中确保资源可以得到释放，同样当一个 Bean 之后连接使用了某些资源时，当销毁后想要对这些资源进行释放，这时候就可以通过其 销毁方法 来释放资源。 1.7 作用域有些 Bean 可能需要在整个容器中只有一个，也就是单例，而有些可能要求每一次请求对应的 Bean 都不一样，这时可以通过一个 作用域 的概念，来区分不同要求的 Bean，当容器发现这个类是 单例 的，就会复用已存在的 Bean，否则才重新创建。 当然这里只是列举一些个人觉得比较重要的属性，还有其它的一些属性需要增加。在 Spring 框架中 Bean 的定义是通过一个 BeanDefinition 类来描述的。 在没有使用 SpringBoot 之前我们都是通过 XML 配置然后 Spring 来解析生成 Bean 的，同时我们也可以通过代码方式使用 BeanDefinitionBuilder 生成 Bean，具体代码如下所示： 1234567891011121314151617181920212223/** * @Author: mghio * @Date: 2020-10-05 * @Description: */public class ProgrammerTest &#123; public static void main(String[] args) &#123; new Programmer().showMaterial(); BeanDefinitionBuilder beanDefinitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(Programmer.class); beanDefinitionBuilder.addPropertyValue("name", "mghio"); beanDefinitionBuilder.addPropertyValue("age", 18); beanDefinitionBuilder.addPropertyValue("hasGirlFriend", false); DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory(); beanFactory.registerBeanDefinition("programmer", beanDefinitionBuilder.getBeanDefinition()); Programmer programmer = (Programmer) beanFactory.getBean("programmer"); programmer.showMaterial(); &#125;&#125; 运行结果如下： 在使用 XML 方式时一般是通过调用 ClassPathXmlApplicationContext 来注册 Bean 的，其构造函数可以传入具体的 XMl配置文件的路径，可以是一个或者多个，甚至还可以是通配符。在构造函数内部就会调用熟悉的 refresh 方法了。 深入 refresh 方法可以发现，在该方法中调用了 obtainFreshBeanFactory 方法来获取生成的 Bean，这个方法实际上是调用了抽象实现类 AbstractRefreshableApplicationContext 的 refreshBeanFactory 方法，该方法首先会先判断此时是否还有 beanFactory ，如果有的话会先销毁 beanFactory，然后再重新创建一个 BeanFactory（实际上是 DefaultListableBeanFactory 类型)，最后会调用 loadBeanDefinitions 加载我们定义的 XMl 配置，方法使用的是 XmlBeanDefinitionReader 来读取的 XMl 配置，下面一起来深入的了解一下 Spring 生成 Bean 的过程。 2. 创建 Bean 的过程首先我们看看 BeanFactory 类图，如下所示： Bean 的整体创建流程如下所示： 3. 总结本文简要的讲述了 Spring 创建 Bean 的主要流程，还有许多细节的地方需要深入研读源码才能了解，在这里先给自己一个小目标，后续会自己实现一个简易版本的 Spring（IOC、AOP），预知后事如何，请看下篇博文。。。]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从 CPU 缓存看缓存的套路]]></title>
    <url>%2Fpost%2Ffa75f5d7.html</url>
    <content type="text"><![CDATA[一、前言不同存储技术的访问时间差异很大，从 计算机层次结构 可知，通常情况下，从高层往底层走，存储设备变得更慢、更便宜同时体积也会更大，CPU 和内存之间的速度存在着巨大的差异，此时就会想到计算机科学界中一句著名的话：计算机科学的任何一个问题，都可以通过增加一个中间层来解决。 二、引入缓存层为了解决速度不匹配问题，可以通过引入一个缓存中间层来解决问题，但是也会引入一些新的问题。现代计算机系统中，从硬件到操作系统、再到一些应用程序，绝大部分的设计都用到了著名的局部性原理，局部性通常有如下两种不同的形式： 时间局部性：在一个具有良好的时间局部性的程序当中，被引用过一次的内存位置，在将来一个不久的时间内很可能会被再次引用到。 空间局部性：在一个具有良好的空间局部性的程序当中，一个内存位置被引用了一次，那么在不久的时间内很可能会引用附近的位置。 有上面这个局部性原理为理论指导，为了解决二者速度不匹配问题就可以在 CPU 和内存之间加一个缓存层，于是就有了如下的结构： 三、何时更新缓存在 CPU 中引入缓存中间层后，虽然可以解决和内存速度不一致的问题，但是同时也面临着一个问题：当 CPU 更新了其缓存中的数据之后，要什么时候去写入到内存中呢？，比较容易想到的一个解决方案就是，CPU 更新了缓存的数据之后就立即更新到内存中，也就是说当 CPU 更新了缓存的数据之后就会从上到下更新，直到内存为止，英文称之为write through，这种方式的优点是比较简单，但是缺点也很明显，由于每次都需要访问内存，所以速度会比较慢。还有一种方法就是，当 CPU 更新了缓存之后并不马上更新到内存中去，在适当的时候再执行写入内存的操作，因为有很多的缓存只是存储一些中间结果，没必要每次都更新到内存中去，英文称之为write back，这种方式的优点是 CPU 执行更新的效率比较高，缺点就是实现起来会比较复杂。 上面说的在适当的时候写入内存，如果是单核 CPU 的话，可以在缓存要被新进入的数据取代时，才更新内存，但是在多核 CPU 的情况下就比较复杂了，由于 CPU 的运算速度超越了 1 级缓存的数据 I\O 能力，CPU 厂商又引入了多级的缓存结构，比如常见的 L1、L2、L3 三级缓存结构，L1 和 L2 为 CPU 核心独有，L3 为 CPU 共享缓存。 如果现在分别有两个线程运行在两个不同的核 Core 1 和 Core 2 上，内存中 i 的值为 1，这两个分别运行在两个不同核上的线程要对 i 进行加 1 操作，如果不加一些限制，两个核心同时从内存中读取 i 的值，然后进行加 1 操作后再分别写入内存中，可能会出现相互覆盖的情况，解决的方法相信大家都能想得到，第一种是只要有一个核心修改了缓存的数据之后，就立即把内存和其它核心更新。第二种是当一个核心修改了缓存的数据之后，就把其它同样复制了该数据的 CPU 核心失效掉这些数据，等到合适的时机再更新，通常是下一次读取该缓存的时候发现已经无效，才从内存中加载最新的值。 四、缓存一致性协议不难看出第一种需要频繁访问内存更新数据，执行效率比较低，而第二种会把更新数据推迟到最后一刻才会更新，读取内存，效率高（类似于懒加载）。 缓存一致性协议(MESI) 就是使用第二种方案，该协议主要是保证缓存内部数据的一致，不让系统数据混乱。MESI 是指 4 种状态的首字母。每个缓存存储数据单元（Cache line）有 4 种不同的状态，用 2 个 bit 表示，状态和对应的描述如下： 状态 描述 监听任务 M 修改 (Modified) 该 Cache line 有效，数据被修改了，和内存中的数据不一致，数据只存在于本 Cache 中 Cache line 必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成 S（共享）状态之前被延迟执行 E 独享、互斥 (Exclusive) 该 Cache line 有效，数据和内存中的数据一致，数据只存在于本 Cache 中 Cache line 必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成 S（共享）状态 S 共享 (Shared) 该 Cache line 有效，数据和内存中的数据一致，数据存在于很多 Cache 中 Cache line 必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该 Cache line 变成无效 I 无效 (Invalid) 该 Cache line 无效 无监听任务 下面看看基于缓存一致性协议是如何进行读取和写入操作的， 假设现在有一个双核的 CPU，为了描述方便，简化一下只看其逻辑结构： 单核读取步骤：Core 0 发出一条从内存中读取 a 的指令，从内存通过 BUS 读取 a 到 Core 0 的缓存中，因为此时数据只在 Core 0 的缓存中，所以将 Cache line 修改为 E 状态（独享），该过程用示意图表示如下： 双核读取步骤：首先 Core 0 发出一条从内存中读取 a 的指令，从内存通过 BUS 读取 a 到 Core 0 的缓存中，然后将 Cache line 置为 E 状态，此时 Core 1 发出一条指令，也是要从内存中读取 a，当 Core 1 试图从内存读取 a 的时候， Core 0 检测到了发生地址冲突（其它缓存读主存中该缓存行的操作），然后 Core 0 对相关数据做出响应，a 存储于这两个核心 Core 0 和 Core 1 的缓存行中，然后设置其状态为 S 状态（共享），该过程示意图如下： 假设此时 Core 0 核心需要对 a 进行修改了，首先 Core 0 会将其缓存的 a 设置为 M（修改）状态，然后通知其它缓存了 a 的其它核 CPU（比如这里的 Core 1）将内部缓存的 a 的状态置为 I（无效）状态，最后才对 a 进行赋值操作。该过程如下所示： 细心的朋友们可能已经注意到了，上图中内存中 a 的值（值为 1）并不等于 Core 0 核心中缓存的最新值（值为 2），那么要什么时候才会把该值更新到内存中去呢？就是当 Core 1 需要读取 a 的值的时候，此时会通知 Core 0 将 a 的修改后的最新值同步到内存（Memory）中去，在这个同步的过程中 Core 0 中缓存的 a 的状态会置为 E（独享）状态，同步完成后将 Core 0 和 Core 1 中缓存的 a 置为 S（共享）状态，示意图描述该过程如下所示： 至此，变量 a 在 CPU 的两个核 Core 0 和 Core 1 中回到了 S（共享）状态了，以上只是简单的描述了一下大概的过程，实际上这些都是在 CPU 的硬件层面上去保证的，而且操作比较复杂。 五、总结现在很多一些实现缓存功能的应用程序都是基于这些思想设计的，缓存把数据库中的数据进行缓存到速度更快的内存中，可以加快我们应用程序的响应速度，比如我们使用常见的 Redis 数据库可能是采用下面这些策略：① 首先应用程序从缓存中查询数据，如果有就直接使用该数据进行相应操作后返回，如果没有则查询数据库，更新缓存并且返回。② 当我们需要更新数据时，先更新数据库，然后再让缓存失效，这样下次就会先查询数据库再回填到缓存中去，可以发现，实际上底层的一些思想都是相通的，不同的只是对于特定的场景可能需要增加一些额外的约束。基础知识才是技术这颗大树的根，我们先把根栽好了，剩下的那些枝和叶都是比较容易得到的东西了。]]></content>
      <categories>
        <category>缓存</category>
        <category>基础</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 集合类 List 的那些坑]]></title>
    <url>%2Fpost%2Fd7d0fc76.html</url>
    <content type="text"><![CDATA[现在的一些高级编程语言都会提供各种开箱即用的数据结构的实现，像 Java 编程语言的集合框架中就提供了各种实现，集合类包含 Map 和 Collection 两个大类，其中 Collection 下面的 List 列表是我们经常使用的集合类之一，很多的业务代码都离不开它，今天就来看看 List 列表的一些坑。 第一个坑：Arrays.asList 方法返回的 List 不支持增加、删除操作例如我们执行以下代码： 12List&lt;String&gt; strings = Arrays.asList("m", "g");strings.add("h"); 会抛出 java.lang.UnsupportedOperationException 异常，此时你内心 OS what？明明返回的 ArrayList 为啥不能往里面增加元素，这以后还能好好的增加元素吗？，然后果断开启 Debug 大法： 发现返回的 ArrayList 并不是我们常用的 java.util.ArrayList，而是 Arrays 的内部类 java.util.Arrays.ArrayList。进入方法 Arrays.asList 源码如下： 123public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; 方法返回的是 Arrays 的静态内部类 java.util.Arrays.ArrayList，该类虽然和 java.util.ArrayList 也继承自抽象类 java.util.AbstractList ，但是通过该类的源码发现它并没有对抽象父类AbstractList的 add 方法默认就是抛出 java.lang.UnsupportedOperationException 异常。 这个坑的根本原因是我们调用返回的 strings 的 add 方法是继承自抽象父类的 add 方法，而抽象父类的方法默认就是抛出 java.lang.UnsupportedOperationException 这个异常。 第二个坑，Arrays.asList 方法返回的新 List 和该方法原始入参数组修改会相互影响Arrays.asList 方法除了上面这个 不支持增加、删除元素 这个坑之外，还有另外一个坑： 从以上代码可以发现，对原始数组的修改会影响我们通过 Arrays.asList方法获得的新 List，深入 java.util.Arrays.ArrayList 的源码： 12345678910111213private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable &#123; private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) &#123; a = Objects.requireNonNull(array); &#125; ... &#125; 可以发现是直接使用了原始的数组，所有当我们使用 Arrays.asList 方式获得的 List 时要特别注意，因为共享了数组，相互修改时可能产生一些意想不到的 Bug。标准的姿势之一是将其作为 ArrayList 构造方法的参数重新 new 一个 List 出来即可（e.g. List&lt;String&gt; stringList = new ArrayList&lt;&gt;(Arrays.asList(arrays))）或者通过 Guava 库中的 Lists.newArrayList ，将返回的新 List 和原始的数组解耦，就不会再互相影响了。 第三个坑，直接遍历 List 集合删除元素会报错在直接遍历集合元素时增加、删除元素会报错，比如执行如下代码： 123456List&lt;String&gt; stringList = Lists.newArrayList("m", "g", "h");for (String s : stringList) &#123; if (Arrays.asList("m", "h").contains(s)) &#123; stringList.remove(s); &#125;&#125; 以上代码可以正常编译通过，但是执行时会抛出 java.util.ConcurrentModificationException 异常，查看其源码可以发现，删除元素方法 remove 会使集合结构发生修改，也就是 modCount（集合实际修改的次数）会修改，在循环过程中，会比较当前 List 的集合实际修改的次数 modCount 与迭代器修改的次数 expectedModCount ，而 expectedModCount 是初始化时的 modCount， 二者不相等，就会报 ConcurrentModificationException 异常。解决方法主要有两种方式，1.使用 ArrayList 的迭代器方式遍历，然后调用其中的方法。2.在 JDK 1.8+ 可以使用 removeIf 方法进行删除操作。 最后扎心一问：调用 ArrayList 的 remove 方法传入 int 基本类型的数字和 Integer 包装类型的数字，执行结果是不是一样的？]]></content>
      <categories>
        <category>Java</category>
        <category>List</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 基础概念进阶]]></title>
    <url>%2Fpost%2Ff92758d8.html</url>
    <content type="text"><![CDATA[上一篇 RabbitMQ 入门之基础概念 介绍了 RabbitMQ 的一些基础概念，本文再来介绍其中的一些细节和其它的进阶的概念。 一、消息生产者发送的消息不可达时如何处理RabbitMQ 提供了消息在传递过程中无法发送到一个队列（比如根据自己的类型和路由键没有找到匹配的队列）时将消息回传给消息发送方的功能，使用 RabbitMQ 的客户端提供 channel.basicPublish 方法的两个参数 mandatory 和 immediate (RabbitMQ 3.0 以下版本)，除此之外还提供了一个备份交换器可以将无法发送的消息存储起来处理，不用重新传回给发送方。 1.1 mandatory 参数mandatory 被定义在 RabbitMQ 提供的客户端的 channel.basicPublish 方法中，如下所示： 当把方法的 mandatory 参数设置为 true 时，那么会在交换器无法根据自身的类型和路由键找到一个符合要求的队列时，RabbitMQ 会自动调用 Basic.Return 把该消息回传给发送方也就是我们的消息生产者。反之，如果设置为 false 的话，消息就会被直接丢弃掉。那么问题来了，我们要如何去获取这些没有被发送出去的消息呢？RabbitMQ 给我们提供了事件监听机制来获取这种消息，可以通过 addReturnListener 方法添加一个 ReturnListener 来获取这种未发送到队列的消息，如下所示： 通过查看 ReturnListener 接口的源码可以看到，该接口只有一个方法，如果是 JDK8+ 的版本的话可以使用 Lambda 表达式来简化一些代码。 可以看出，当设置了 mandatory 参数时，还必须为生产者同时添加 ReturnListener 监听器的编程逻辑，这样就会使得生产者的代码变得更加复杂了，为了处理这种情况，RabbitMQ 提供了 `备份交换器` 来将没有成功路由出去的消息存储起来，当我们需要的时候再去处理即可。 1.2 immediate 参数该的参数同样也是在channel.basicPublish 方法中定义的，其官方描述如下： This flag tells the server how to react if the message cannot be routed to a queue consumer immediately. If this flag is set, the server will return an undeliverable message with a Return method. If this flag is zero, the server will queue the message, but with no guarantee that it will ever be consumed. 当把 immediate 参数设置为 true 时，如果交换器根据其类型和路由键找到符合要求的队列时，发现所有队列上没有任何消费者，则该消息并不会存入到队列中，会通过 Basic.Return 命令把消息回传给生产者。简而言之也就是说，当设置了 immediate 参数时，该消息关联的队列上存在消费者时，会立即发送消息到该队列中，反之如果匹配的队列上不存在任何消费者，则直接把消息回传给生产者。这里有一点需要注意的是：从 RabbitMQ 3.0 + 已经去除了该参数。 二、如何对消息和队列设置过期时间 （TTL）TTL 是 time to live 首字母的简称，RabbitMQ 中可以设置消息和队列的过期时间，我们先来看看要如何设置消息的过期时间。 1.1 消息 TTL 设置RabbitMQ 提供了两种设置消息的过期时间，第一种是通过队列的属性设置，该方式的特点就是队列中所有消息的过期时间都一致。还有一种是更小粒度的设置，就是对每条消息单独设置过期时间，这种方式更加灵活，每条消息的过期时间都可以不一样。这是你可能会问，如果同时设置了队列的过期属性和消息本身的过期属性，最终以哪个为准呢？结果是 RabbitMQ 会比较这两个 TTL 的值大小，以较小的那个为准。很容易想到，通过队列的属性的方式设置过期时间的话是在声明队列的时候指定，对应到客户端就是其提供的 channel.queueDeclare 方法的参数 arguments 指定，示例代码如下： 需要注意的是 x-message-ttl 参数的单位是毫秒。如果不设置 TLL，则表示该消息不会过期，如果将 TTL 设置为 0，表示除非此时可以把消息直接发送投递到消费者端去，否则就会直接丢弃该消息。 准对每条消息设置 TTL 的方法是在发送消息的时候设置的，对应到客户端方法是 channel.basicPublish 的 expiration 属性参数，具体设置代码如下： 这种设置方式，即使队列过期也不会立即从队列中移除，因为每条消息是否过期的判定是在发送到消费者是才进行的，如果此时发现已经过期才会删除消息。而对于第一种方式则会把已经过期的消息移到队列头部，然后 RabbitMQ 只要定期的从头开始扫描是否存在过期的消息即可。 1.2 队列 TTL 设置设置队列的过期时间使用的是客户端的 channel.queueDeclare 方法参数中的 x-expires 参数，其单位同样也是毫秒，不过需要注意的是它不能设置为 0。设置队列过期的代码如下所示： 上面代码创建了一个过期时间为 15 分钟的队列。 三、死信队列介绍死信交换器（DLX）的全称是 Dead-Letter-Exchange ，也称之为死信邮箱。简单来说就是当一个消息由于 消息被拒绝 、 消息过期 、 队列达到最大长度 时，变成死信（dead message）之后，会被重新发送到一个交换器中，这个交换器就是死信交换器，绑定在这个交换器上的队列就称之为死信队列。死信交换器实际上就是平常的交换器，可以在任何队列上指定，当在一个队列上设置死信交换器后，如果该队列出现死信时就会被 RabbitMQ 把死信消息重新发送到死信交换器上去，然后路由到死信队列中，我们可以监听这个队列来处理那些死信消息。为一个队列设置死信交换器是在生产者的声明队列的方法中设置 x-dead-letter-message 参数来实现的，如下所示： 同时也可以通过 x-dead-letter-routing-key 参数设置死信交互器的路由键，不设置默认使用原始度列的路由键。可以到 RabbitMQ 的后台管理界面，有 DLX 标志的就是死信队列。 RabbitMQ 提供的 DLX 是个比较实用的功能特性，它可以在我们消息不能被消费者正确消费的情况下放入到死信队列，后续我们可以通过这个死信队列的内容来查看异常情况来改造和优化系统。 四、延迟队列介绍顾名思义，延迟队列存储的是哪些需要等待指定时间后才能拿到的延迟消息，一个比较典型的场景就是订单 30 分钟后未支付取消订单。这里需要注意的是，在 RabbitMQ 中并没有直接提供延迟队列的功能，而是需要通过上面介绍的过期时间（TTL）和死信队列一起来实现，比如超时取消订单这个场景，我们可以让消费者订阅死信队列，设置正常的那个队列的超时时间为 30 分钟并绑定到该死信队列上，当消息超过 30 分钟未被处理后消息就会把发送到死信队列中，然后死信队列的消费者就可以在 30 分钟后成功的消费到该消息了。 同时当我们有其它的超时配置需求时也很方便扩展，比如可以在生产者发送消息的时候通过设置不同的路由键，通过路由键来将消息发送到与交换器绑定的不同队列中，然后这些队列分别设置不同的过期时间和与之相对应的死信队列，当消息过期时就会被 RabbitMQ 转发到相应的死信队列中，这样就可以去订阅相应的死信队列即可。 五、交换器、消息和队列持久化持久化可以提高可靠性，可以防止宕机或者重启等异常下数据的丢失，RabbitMQ 的持久化从组成结构上可以分为三个部分，即交换器持久化、消息持久化和队列持久化。 1.1 交换器持久化交换器持久化是在声明交换器时将 durable 参数设置为 true 来实现的。如果不设置持久化属性的话，当 RabbitMQ 服务重启后交换器的数据就会丢失，需要注意的是，是交换器的数据丢失，消息不会丢失，只是不能将消息发送到这个交换器中了，一般生产环境使用都会把该属性设置为持久化。 1.2 消息持久化交换器的持久化仅仅只是保证了交换器本身的元数据不会丢失，无法保证其存储的消息不会丢失，如果需要其内部存储的消息不丢失，则需要设置消息的持久化，通过将消息的投递模式(deliveryMode)设置为 2 即可实现消息的持久化，如下所示： 需要消息持久化的前提是其所在的队列也要设置持久化，假如仅仅只设置消息的持久化的话，RabbitMQ 重启之后队列消失，然后消息也会丢失。这里有点需要注意一下，虽然持久化可以提高可靠性，但是持久化是将数据存储到硬盘上，比直接操作内存要慢很多，所以对于哪些可靠性要求不高的业务不需要进行持久化。 1.3 队列持久化队列的持久化的设置和交换器持久化类似，同样也是在声明的时候通过 durable 参数设置为 true 实现的，如果不设置，当 RabbitMQ 重启后，相关的队列元数据也会丢失，相应的其存储的消息也会随之丢失掉。 将交换器、队列、消息都设置了持久化之后就能百分之百保证数据不丢失了吗？其实无法保证百分之百数据不丢失。比如消费者在订阅消费队列时将自动应答（autoAck）参数设置为 true 的话，在接收到消息后还没来得及处理就挂了，这时需要把自动应答设置 false，进行手动 ack 应答即可。还有一个就是由于不是实时持久化存盘，当消息存盘的过程中 RabbitMQ 宕机了，此时也会发生数据丢失，此时需要通过 RabbitMQ 的 镜像队列机制 来处理了。 六、总结本文主要介绍了一些参数具体使用时的设置细节和死信队列、延迟队列以及持久化等，还有一些比较重要的点没有涉及到，比如消息确认机制。“纸上得来终觉浅，绝知此事要躬行”，在了解一些基础的概念之后还是需要通过具体编码实践才能对其更加理解深刻。]]></content>
      <categories>
        <category>Java</category>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 入门之基础概念]]></title>
    <url>%2Fpost%2Ff3f86c01.html</url>
    <content type="text"><![CDATA[什么是消息队列（MQ）消息是在不同应用间传递的数据。这里的消息可以非常简单，比如只包含字符串，也可以非常复杂，包含多个嵌套的对象。消息队列（Message Queue）简单来说就是一种应用程序间的通讯方式，消息发送后立即返回，然后由消息系统保证消息的可靠性传输，消息生产者只需要把消息发到 MQ 中就可以了，不需要关心消息的消费，同样，消息消费者只管从 MQ 中拉取消息而不管是谁生产的消息，通过这样的一个“互相不知道对象存在”模式，将消息的生产者和消息的消费者解耦了。 什么场景下考虑使用消息队列从上面可以知道，消息队列是一种应用间的异步协作机制，那么我们什么时候需要用到 MQ 呢？以常见的订单系统为例，当用户点击「下单」后的业务逻辑可能包括：扣减库存、生成相应订单数据、发短信通知等。在项目和业务发展初期上面这些逻辑可能放在一起执行，随着业务的发展订单量的增加，需要提升系统服务的性能，此时就可以将一些不需要立即生效的操作拆分出来异步执行，比如发送短信通知等。这种场景下就可以使用 MQ ，在下单主流程（比如扣减库存、生成订单数据等）完成之后发送一条消息到 MQ 让主流程快速走完，然后由另外一个线程拉取 MQ 的消息，执行相应的业务逻辑。这里的例子主要是用消息队列来解耦。 RabbitMQ 的特点RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。AMQP（Advanced Message Queue：高级消息队列协议）它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。RabbitMQ 最初起源于消息系统，用于在分布式系统中存储转发消息，具体有如下一些特点： 可靠性： RabbitMQ 使用一些机制来保证可靠性，比如持久化、传输确认机制（ack）和发布确认等。 灵活的路由策略： 在消息进入队列之前，通过 Exchange 来路由消息，对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对复杂的路由功能，可以将多个 Exchange 绑在一起，也通过插件机制实现自己的 Exchange。 消息集群： 多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker。 高可用： 队列可以在集群中的集群上进行镜像，使得在部分节点出问题的情况下队列仍然可用。 多种协议： RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等。 多语言客户端： RabbitMQ 几乎支持多有常用的语言，比如：Java、.NET 等 管理界面： RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方面。 RabbitMQ 安装（mac）和运行1、安装因为 RabbitMQ 依赖于 Erlang 语言，所以在安装 RabbitMQ 之前需要先安装 Erlang 环境，但是由于是 Mac 环境，可以使用 HomeBrew 安装，安装前先更新 brew： 1brew update 接着安装 RabbitMQ 即可，安装过程中会自动安装其所依赖的 Erlang。 2、运行RabbitMQ 的启动运行很简单，找到其安装目录后（使用 Homwbrew 安装的默认目录为：/usr/local/Cellar/rabbitmq），进入到目录的 sbin 目录下，可以看到有 6 个以 rabbitmq 开头的可执行文件，直接执行 rabbitmq-server 即可。 启动正常的话可以看到启动过程的日志信息和最后的 completed with 6 plugins，这也说明启动的时候默认加载了 6 个插件。 此时通过浏览器访问 http://localhost:15672 可以看到其管理界面（默认用户名和密码都是 guest），可以在 admin 选项卡页面新增用户，管理界面如下： PS： 以上方式不是后台启动，如果想让 RabbitMQ 后台守护进程的方式启动的话，可以在启动的时候加上 -detached 参数。 3、查询服务器状态在安装目录的 sbin 下面有个可执行文件 rabbitmqctl ，它提供了 RabbitMQ 管理需要的几乎一站式解决方案，绝大部分的运维命令它都可以提供。查询 RabbitMQ 服务器的状态信息可以用参数 status。 RabbitMQ 中的基础概念1、消息模型 几乎所有的 MQ 抽象来说都是一样的过程：消费者订阅某个队列，生产者生产消息，然后发布到队列中，最后将消息发送到监听该队列的消费者那里。如下图所示： 2、基本概念 上面上一个消息队列的抽象概述，具体到 RabbitMQ 有一些特有的概念，RabbitMQ 是 AMQP 协议的一个开源实现，其内部概念大都是 AMQP 协议的一些概念。 名称 描述 Message 消息 消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则是由一系列的可选属性组成，这些属性包括 routing-key（路由键）、priority（相对于其它消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。 Publisher 消息生产者 一个向交换机发送消息的客户端应用程序。 Exchange 交换器 用来接收生产者发送过来的消息，并将这些消息发送给服务器中的队列。 Binding 绑定 用于消息队列和交换器之间的关联，一个绑定就是一个基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue 消息队列 用来保存消息直到发送给消费者，它是消息的容器，也是消息的终点，一个消息可投入一个或多个队列，消息一直在队列里面，等待消费者连接到这个队列并将其取走。 Connection 网络连接 比如一个 TCP 连接。 Channel 信道 多路复用连接中的一条独立双向数据流通道，信道是建立在真实 TCP 连接内的虚拟连接，AMQP 命令都是通过信道发送出去的，不管是发布消息、订阅消息还是接收消息，这些动作都是通过信道完成的。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。 Consumer 消息的消费者 一个从消息队列中获取消息的客户端应用程序。 Virtual Host 虚拟主机 表示一批交换器、消息队列和相关对象。虚拟主机是共享相同身份认证和加密环境的对服务器域。每个 vhost 本质上是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。 3、AMQP 中的消息路由 AMQP 中消息路由过程和 Java 开发者熟悉的 JMS 存在一些差别，AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发送到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发到哪个队列。 4、Exchange 类型 Exchange 分发消息时根据类型的不同分发策略略有区别，目前共有四种类型：direct、fanout、topic、headers。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型即可。 4.1、direct 类型 消息中的路由键（routing key）如果和 Binding 中的 binding key 一致，交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为 “dog”，则只转发 routing key 标记为 “dog” 的消息，不会转发 “dog.puppy”，也不会转发 “dog.guard” 等等。它是完全匹配、单播的模式。 4.2、fanout 类型 每个发到 fanout 类型交换机的消息都会发到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得一份复制的消息。fanout 类型转发消息是最快的。 3、topic 类型 topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上，它将路由键和绑定的字符串切分成单词，这些单词之间用点隔开。它同样也识别两个通配符：符号 “#” 和符号 “*”。# 符号匹配 0 个或多个单词，* 符号匹配不多不少一个单词。 总结本文主要讲了关于 RabbitMQ 的安装以及基础概念的相关介绍，由于它是基于 Erlang 语言开发，可能对于部分 Java 开发者想了解其底层实现细节以及排查比较复杂的问题时不是很友好。]]></content>
      <categories>
        <category>Java</category>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中队列同步器 AQS（AbstractQueuedSynchronizer）实现原理]]></title>
    <url>%2Fpost%2F4b00e13c.html</url>
    <content type="text"><![CDATA[前言在 Java 中通过 锁 来控制多个线程对共享资源的访问，使用 Java 编程语言开发的朋友都知道，可以通过 synchronized 关键字来实现锁的功能，它可以隐式的获取锁，也就是说我们使用该关键字并不需要去关心锁的获取和释放过程，但是在提供方便的同时也意味着其灵活性的下降。例如，有这样的一个场景，先获取锁 A，然后再获取锁 B，当锁 B 获取到之后，释放锁 A 同时获取锁 C，当获取锁 C 后，再释放锁 B 同时获取锁 D，依次类推，像这种比较复杂的场景，使用 synchronized 关键字就比较难实现了。在 Java SE 5 之后，新增加了 Lock 接口和一系列的实现类来提供和 synchronized 关键字一样的功能，它需要我们显示的进行锁的获取和释放，除此之外还提供了可响应中断的锁获取操作以及超时获取锁等同步特性。JDK 中提供的 Lock 接口实现类大部分都是聚合一个同步器 AQS 的子类来实现多线程的访问控制的，下面我们看看这个构建锁和其它同步组件的基础框架——队列同步器 AQS（AbstractQueuedSynchronizer）。 AQS 基础数据结构同步队列队列同步器 AQS（下文简称为同步器）主要是依赖于内部的一个 FIFO（first-in-first-out）双向队列来对同步状态进行管理的，当线程获取同步状态失败时，同步器会将当前线程和当前等待状态等信息封装成一个内部定义的节点 Node，然后将其加入队列，同时阻塞当前线程；当同步状态释放时，会将同步队列中首节点唤醒，让其再次尝试去获取同步状态。同步队列的基本结构如下： 队列节点 Node同步队列使用同步器中的静态内部类 Node 用来保存获取同步状态的线程的引用、线程的等待状态、前驱节点和后继节点。 同步队列中 Node 节点的属性名称和具体含义如下表所示： 属性类型和名称 描述 volatile int waitStatus 当前节点在队列中的等待状态 volatile Node prev 前驱节点，当节点加入同步队列时被赋值(使用尾部添加方式) volatile Node next 后继节点 volatile Thread thread 获取同步状态的线程 Node nextWaiter 等待队列中的后继节点，如果当前节点是共享的，则该字段是一个 SHARED 常量 每个节点线程都有两种锁模式，分别为 SHARED 表示线程以共享的模式等待锁，EXCLUSIVE 表示线程以独占的方式等待锁。同时每个节点的等待状态 waitStatus 只能取以下表中的枚举值： 枚举值 描述 SIGNAL 值为 -1，表示该节点的线程已经准备完毕，等待资源释放 CANCELLED 值为 1，表示该节点线程获取锁的请求已经取消了 CONDITION 值为 -2，表示该节点线程等待在 Condition 上，等待被其它线程唤醒 PROPAGATE 值为 -3，表示下一次共享同步状态获取会无限进行下去，只在 SHARED 情况下使用 0 值为 0，初始状态，初始化的默认值 同步状态 state同步器内部使用了一个名为 state 的 int 类型的变量表示同步状态，同步器的主要使用方式是通过继承，子类通过继承并实现它的抽象方法来管理同步状态，同步器给我们提供了如下三个方法来对同步状态进行更改。 方法签名 描述 protected final int getState() 获取当前同步状态 protected final void setState(int newState) 设置当前同步状态 protected final boolean compareAndSetState(int expect, int update) 使用 CAS 设置当前状态，该方法能够保证状态设置的原子性 在独享锁中同步状态 state 这个值通常是 0 或者 1（如果是重入锁的话 state 值就是重入的次数），在共享锁中 state 就是持有锁的数量。 独占式同步状态获取与释放同步器中提供了 acquire(int arg) 方法来进行独占式同步状态的获取，获取到了同步状态也就是获取到了锁，该方法源码如下所示： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 方法首先会调用 tryAcquire 方法尝试去获取锁，查看方法的源码可以发现，同步器并未对该方法进行实现（只是抛出一个不支持操作异常 UnsupportedOperationException），这个方法是需要后续同步组件的开发人员自己去实现的，如果方法返回 true 则表示当前线程成功获取到锁，调用 selfInterrupt() 中断当前线程（PS：这里留给大家一个问题：为什么获取了锁以后还要中断线程呢？），方法结束返回，如果方法返回 false 则表示当前线程获取锁失败，也就是说有其它线程先前已经获取到了锁，此时就需要把当前线程以及等待状态等信息添加到同步队列中，下面来看看同步器在线程未获取到锁时具体是如何实现。通过源码发现，当获取锁失败时，会执行判断条件与操作的后半部分 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，首先指定锁模式为 Node.EXCLUSIVE 调用 addWaiter 方法，该方法源码如下： 1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 通过方法参数指定的锁模式（共享锁 or 独占锁）和当前线程构造出一个 Node 节点，如果同步队列已经初始化，那么首先会进行一次从尾部加入队列的尝试，使用 compareAndSetTail 方法保证原子性，进入该方法源码可以发现是基于 sun.misc 包下提供的 Unsafe 类来实现的。如果首次尝试加入同步队列失败，会再次调用 enq 方法进行入队操作，继续跟进 enq 方法源码如下： 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 通过其源码可以发现和第一次尝试加入队列的代码类似，只是该方法里面加了同步队列初始化判断，使用 compareAndSetHead 方法保证设置头节点的原子性，同样它底层也是基于 Unsafe 类，然后外层套了一个 for (;;) 死循环，循环唯一的退出条件是从队尾入队成功，也就是说如果从该方法成功返回了就表示已经入队成功了，至此，addWaiter 执行完毕返回当前 Node 节点。然后以该节点作为 acquireQueued 方法的入参继续进行其它步骤，该方法如下所示： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 可以看到，该方法本质上也是通过一个死循环（自旋）去获取锁并且支持中断，在循环体外面定义两个标记变量，failed 标记是否成功获取到锁，interrupted 标记在等待的过程中是否被中断过。方法首先通过 predecessor 获取当前节点的前驱节点，当当前节点的前驱节点是 head 头节点时就调用 tryAcquire 尝试获取锁，也就是第二个节点则尝试获取锁，这里为什么要从第二个节点才尝试获取锁呢？是因为同步队列本质上是一个双向链表，在双向链表中，第一个节点并不存储任何数据是虚节点，只是起到一个占位的作用，真正存储数据的节点是从第二个节点开始的。如果成功获取锁，也就是 tryAcquire 方法返回 true 后，将 head 指向当前节点并把之前找到的头节点 p 从队列中移除，修改是否成功获取到锁标记，结束方法返回中断标记。如果当前节点的前驱节点 p 不是头节点或者前驱节点 p 是头节点但是获取锁操作失败，那么会调用 shouldParkAfterFailedAcquire 方法判断当前 node 节点是否需要被阻塞，这里的阻塞判断主要是为了防止长时间自旋给 CPU 带来非常大的执行开销，浪费资源。该方法源码如下： 123456789101112131415161718192021222324252627private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 方法参数为当前节点的前驱节点以及当前节点，主要是靠前驱节点来判断是否需要进行阻塞，首先获取到前驱节点的等待状态 ws，如果节点状态 ws 为 SIGNAL，表示前驱节点的线程已经准备完毕，等待资源释放，方法返回 true 表示可以阻塞，如果 ws &gt; 0，通过上文可以知道节点只有一个状态 CANCELLED（值为 1） 满足该条件，表示该节点线程获取锁的请求已经取消了，会通过一个 do-while 循环向前查找 CANCELLED 状态的节点并将其从同步队列中移除，否则进入 else 分支，使用 compareAndSetWaitStatus 原子操作将前驱节点的等待状态修改为 SIGNAL，以上这两种情况都不需要进行阻塞方法返回 false。当经过判断后需要阻塞的话，也就是 compareAndSetWaitStatus 方法返回 true 时，会通过 parkAndCheckInterrupt 方法阻塞挂起当前线程，并返回当前线程的中断标识。方法如下： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 线程阻塞是通过 LockSupport 这个工具类实现的，深入其源码可以发现它底层也是基于 Unsafe 类实现的。如果以上两个方法都返回 true 的话就更新中断标记。这里还有一个问题就是什么时候会将一个节点的等待状态 waitStatus 修改为 CANCELLED 节点线程获取锁的请求取消状态呢？细心的朋友可能已经发现了，在上文贴出的 acquireQueued 方法源码中的 finally 块中会根据 failed 标记来决定是否调用 cancelAcquire 方法，这个方法就是用来将节点状态修改为 CANCELLED 的，方法的具体实现留给大家去探索。至此 AQS 独占式同步状态获取锁的流程就完成了，下面通过一个流程图来看看整体流程： 下面再看看独占式锁释放的过程，同步器使用 release 方法来让我们进行独占式锁的释放，其方法源码如下： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 首先调用 tryRelease 方法尝试进行锁释放操作，继续跟进该方法发现同步器只是抛出了一个不支持操作异常 UnsupportedOperationException，这里和上文独占锁获取中 tryAcquire 方法是一样的套路，需要开发者自己定义锁释放操作。 通过其 JavaDoc 可以得知，如果返回 false，则表示释放锁失败，方法结束。该方法如果返回 true，则表示当前线程释放锁成功，需要通知队列中等待获取锁的线程进行锁获取操作。首先获取头节点 head，如果当前头节点不为 null，并且其等待状态不是初始状态（0），则解除线程阻塞挂起状态，通过 unparkSuccessor 方法实现，该方法源码如下： 1234567891011121314151617181920212223242526private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 首先获取头节点的等待状态 ws，如果状态值为负数（Node.SIGNAL or Node.PROPAGATE），则通过 CAS 操作将其改为初始状态（0），然后获取头节点的后继节点，如果后继节点为 null 或者后继节点状态为 CANCELLED（获取锁请求已取消），就从队列尾部开始寻找第一个状态为非 CANCELLED 的节点，如果该节点不为空则使用 LockSupport 的 unpark 方法将其唤醒，该方法底层是通过 Unsafe 类的 unpark 实现的。这里需要从队尾查找非 CANCELLED 状态的节点的原因是，在之前的获取独占锁失败时的入队 addWaiter 方法实现中，该方法如下： 假设一个线程执行到了上图中的 ① 处，② 处还没有执行，此时另一个线程恰好执行了 unparkSuccessor 方法，那么就无法通过从前向后查找了，因为节点的后继指针 next 还没赋值呢，所以需要从后往前进行查找。至此，独占式锁释放操作就结束了，同样的，最后我们也通过一个流程图来看看整个锁释放的过程： 独占式可中断同步状态获取同步器提供了 acquireInterruptibly 方法来进行可响应中断的获取锁操作，方法实现源码如下： 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; 方法首先检查当前线程的中断状态，如果已中断，则直接抛出中断异常 InterruptedException 即响应中断，否则调用 tryAcquire 方法尝试获取锁，如果获取成功则方法结束返回，获取失败调用 doAcquireInterruptibly 方法，跟进该方法如下： 12345678910111213141516171819202122private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 仔细观察可以发现该方法实现源码和上文中 acquireQueued 方法的实现基本上类似，只是这里把入队操作 addWaiter 放到了方法里面了，还有一个区别就是当在循环体内判断需要进行中断时会直接抛出异常来响应中断，两个方法的对比如下： 其它步骤和独占式锁获取一致，流程图大体上和不响应中断的锁获取差不多，只是在最开始多了一步线程中断状态检查和循环是会抛出中断异常而已。 独占式超时获取同步状态同步器提供了 tryAcquireNanos 方法可以超时获取同步状态（也就是锁），该方法提供了之前 synchronized 关键字不支持的超时获取的特性，通过该方法我们可以在指定时间段 nanosTimeout 内获取锁，如果获取到锁则返回 true，否则，返回 false。方法源码如下： 1234567public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; 首先会调用 tryAcquire 方法尝试获取一次锁，如果获取锁成功则立即返回，否则调用 doAcquireNanos 方法进入超时获取锁流程。通过上文可以得知，同步器的 acquireInterruptibly 方法在等待获取同步状态时，如果当前线程被中断了，会抛出中断异常 InterruptedException 并立刻返回。超时获取锁的流程其实是在响应中断的基础上增加了超时获取的特性，doAcquireNanos 方法的源码如下： 123456789101112131415161718192021222324252627282930private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 由以上方法实现源码可以看出，针对超时获取这里主要实现思路是：先使用当前时间加上参数传入的超时时间间隔 deadline 计算出超时的时间点，然后每次进行循环的时候使用超时时间点 deadline 减去当前时间得到剩余的时间 nanosTimeout，如果剩余时间小于 0 则证明当前获取锁操作已经超时，方法结束返回 false，反如果剩余时间大于 0。可以看到在里面执行自旋的时候和上面独占式同步获取锁状态 acquireQueued 方法那里是一样的套路，即当当前节点的前驱节点为头节点时调用 tryAcquire 尝试获取锁，如果获取成功则返回。 除了超时时间计算那里不同外，还有个不同的地方就是在超时获取锁失败之后的操作，如果当前线程获取锁失败，则判断剩余超时时间 nanosTimeout 是否小于 0，如果小于 0 则表示已经超时方法立即返回，反之则会判断是否需要进行阻塞挂起当前线程，如果通过 shouldParkAfterFailedAcquire 方法判断需要挂起阻塞当前线程，还要进一步比较超时剩余时间 nanosTimeout 和 spinForTimeoutThreshold 的大小，如果小于等于 spinForTimeoutThreshold 值（1000 纳秒）的话，将不会使当前线程进行超时等待，而是再次进行自旋过程。加后面这个判断的主要原因在于，在非常短（小于 1000 纳秒）的时间内的等待无法做到十分精确，如果这时还进行超时等待的话，反而会让我们指定 nanosTimeout 的超时从整体上给人感觉反而不太精确，因此，在剩余超时时间非常短的情况下，同步器会再次自旋进行超时获取锁的过程，独占式超时获取锁整个过程如下所示： 共享式同步状态获取与释放共享锁顾名思义就是可以多个线程共用一个锁，在同步器中使用 acquireShared 来获取共享锁（同步状态），方法源码如下： 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 首先通过 tryAcquireShared 尝试获取共享锁，该方法是一个模板方法在同步器中只是抛出一个不支持操作异常，需要开发人员自己去实现，同时方法的返回值有三种不同的类型分别代表三种不同的状态，其含义如下： 小于 0 表示当前线程获取锁失败 等于 0 表示当前线程获取锁成功，但是之后的线程在没有锁释放的情况下获取锁将失败，也就是说这个锁是共享模式下的最后一把锁了 大于 0 表示当前线程获取锁成功，并且还有剩余的锁可以获取 当方法 tryAcquireShared 返回值小于 0 时，也就是获取锁失败，将会执行方法 doAcquireShared，继续跟进该方法： 123456789101112131415161718192021222324252627private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 方法首先调用 addWaiter 方法封装当前线程和等待状态为共享模块的节点并将其添加到等待同步队列中，可以发现在共享模式下节点的 nextWaiter 属性是固定值 Node.SHARED。然后循环获取当前节点的前驱节点，如果前驱节点是头节点的话就尝试获取共享锁，如果返回值大于等于 0 表示获取共享锁成功，则调用 setHeadAndPropagate 方法，更新头节点同时如果有可用资源，则向后传播，唤醒后继节点，接下来会检查一下中断标识，如果已经中断则中断当前线程，方法结束返回。如果返回值小于 0，则表示获取锁失败，需要挂起阻塞当前线程或者继续自旋获取共享锁。下面看看 setHeadAndPropagate 方法的具体实现： 1234567891011121314151617181920212223242526private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 首先将当前获取到锁的节点设置为头节点，然后方法参数 propagate &gt; 0 时表示之前 tryAcquireShared 方法的返回值大于 0，也就是说当前还有剩余的共享锁可以获取，则获取当前节点的后继节点并且后继节点是共享节点时唤醒节点去尝试获取锁，doReleaseShared 方法是同步器共享锁释放的主要逻辑。 同步器提供了 releaseShared 方法来进行共享锁的释放，方法源码如下所示： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 首先调用 tryReleaseShared 方法尝试释放共享锁，方法返回 false 代表锁释放失败，方法结束返回 false，否则就表示成功释放锁，然后执行 doReleaseShared 方法，进行唤醒后继节点并检查它是否可以向后传播等操作。继续跟进该方法如下： 1234567891011121314151617181920212223242526272829private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 可以看到和独占式锁释放不同的是，在共享模式下，状态同步和释放可以同时执行，其原子性由 CAS 来保证，如果头节点改变了也会继续循环。每次共享节点在共享模式下唤醒时，头节点都会指向它，这样就可以保证可以获取到共享锁的所有后续节点都可以唤醒了。 如何自定义同步组件在 JDK 中基于同步器实现的一些类绝大部分都是聚合了一个或多个继承了同步器的类，使用同步器提供的模板方法自定义内部同步状态的管理，然后通过这个内部类去实现同步状态管理的功能，其实这从某种程度上来说使用了 模板模式。比如 JDK 中可重入锁 ReentrantLock、读写锁 ReentrantReadWriteLock、信号量 Semaphore 以及同步工具类 CountDownLatch 等，其源码部分截图如下： 通过上文可以知道，我们基于同步器可以分别自定义独占锁同步组件和共享锁同步组件，下面以实现一个在同一个时刻最多只允许 3 个线程访问，其它线程的访问将被阻塞的同步工具 TripletsLock 为例，很显然这个工具是共享锁模式，主要思路就是去实现一个 JDk 中的 Lock 接口来提供面向使用者的方法，比如，调用 lock 方法获取锁，使用 unlock 来对锁进行释放等，在 TripletsLock 类内部有一个自定义同步器 Sync 继承自同步器 AQS，用来对线程的访问和同步状态进行控制，当线程调用 lock 方法获取锁时，自定义同步器 Sync 先计算出获取到锁后的同步状态，然后使用 Unsafe 类操作来保证同步状态更新的原子性，由于同一时刻只能 3 个线程访问，这里我们可以将同步状态 state 的初始值设置为 3，表示当前可用的同步资源数量，当有线程成功获取到锁时将同步状态 state 减 1，有线程成功释放锁时将同步状态加 1，同步状态的取值范围为 0、1、2、3，同步状态为 0 时表示没有可用同步资源，这个时候如果有线程访问将被阻塞。下面来看看这个自定义同步组件的实现代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * @author mghio * @date: 2020-06-13 * @version: 1.0 * @description: * @since JDK 1.8 */public class TripletsLock implements Lock &#123; private final Sync sync = new Sync(3); private static final class Sync extends AbstractQueuedSynchronizer &#123; public Sync(int state) &#123; setState(state); &#125; Condition newCondition() &#123; return new ConditionObject(); &#125; @Override protected int tryAcquireShared(int reduceCount) &#123; for (; ;) &#123; int currentState = getState(); int newState = currentState - reduceCount; if (newState &lt; 0 || compareAndSetState(currentState, newState)) &#123; return newState; &#125; &#125; &#125; @Override protected boolean tryReleaseShared(int count) &#123; for (; ;) &#123; int currentState = getState(); int newState = currentState + count; if (compareAndSetState(currentState, newState)) &#123; return true; &#125; &#125; &#125; &#125; @Override public void lock() &#123; sync.acquireShared(1); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override public boolean tryLock() &#123; return sync.tryAcquireShared(1) &gt; 0; &#125; @Override public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; @Override public void unlock() &#123; sync.releaseShared(1); &#125; @Override public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125; 下面启动 20 个线程测试看看自定义同步同步工具类 TripletsLock 是否达到我们的预期。测试代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @author mghio * @date: 2020-06-13 * @version: 1.0 * @description: * @since JDK 1.8 */public class TripletsLockTest &#123; private final Lock lock = new TripletsLock(); private final DateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS"); @Test public void testTripletsLock() &#123; // 启动 20 个线程 for (int i = 0; i &lt; 20; i++) &#123; Thread worker = new Runner(); worker.setDaemon(true); worker.start(); &#125; for (int i = 0; i &lt; 20; i++) &#123; second(2); System.out.println(); &#125; &#125; private class Runner extends Thread &#123; @Override public void run() &#123; for (; ;) &#123; lock.lock(); try &#123; second(1); System.out.println(dateFormat.format(new Date()) + " ----&gt; " + Thread.currentThread().getName()); second(1); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; &#125; private static void second(long seconds) &#123; try &#123; TimeUnit.SECONDS.sleep(seconds); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 测试结果如下： 从以上测试结果可以发现，同一时刻只有三个线程可以获取到锁，符合预期，这里需要明确的是这个锁获取过程是非公平的。 总结本文主要是对同步器中的基础数据结构、独占式与共享式同步状态获取与释放过程做了简要分析，由于水平有限如有错误之处还请留言讨论。队列同步器 AbstractQueuedSynchronizer 是 JDK 中很多的一些多线程并发工具类的实现基础框架，对其深入学习理解有助于我们更好的去使用其特性和相关工具类。 参考文章 Java Synchronizer - AQS Learning从 ReentrantLock 的实现看 AQS 的原理及应用The java.util.concurrent Synchronizer Framework]]></content>
      <categories>
        <category>Java</category>
        <category>并发</category>
        <category>进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文让你快速上手 Mockito 单元测试框架]]></title>
    <url>%2Fpost%2F24042edf.html</url>
    <content type="text"><![CDATA[前言在计算机编程中，单元测试是一种软件测试方法，通过该方法可以测试源代码的各个单元功能是否适合使用。为代码编写单元测试有很多好处，包括可以及早的发现代码错误，促进更改，简化集成，方便代码重构以及许多其它功能。使用 Java 语言的朋友应该用过或者听过 Junit 就是用来做单元测试的，那么为什么我们还需要 Mockito 测试框架呢？想象一下这样的一个常见的场景，当前要测试的类依赖于其它一些类对象时，如果用 Junit 来进行单元测试的话，我们就必须手动创建出这些依赖的对象，这其实是个比较麻烦的工作，此时就可以使用 Mockito 测试框架来模拟那些依赖的类，这些被模拟的对象在测试中充当真实对象的虚拟对象或克隆对象，而且 Mockito 同时也提供了方便的测试行为验证。这样就可以让我们更多地去关注当前测试类的逻辑，而不是它所依赖的对象。 生成 Mock 对象方式要使用 Mockito，首先需要在我们的项目中引入 Mockito 测试框架依赖，基于 Maven 构建的项目引入如下依赖即可： 123456&lt;dependency&gt; &lt;groupId&gt;org.mockito&lt;/groupId&gt; &lt;artifactId&gt;mockito-core&lt;/artifactId&gt; &lt;version&gt;3.3.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 如果是基于 Gradle 构建的项目，则引入如下依赖： 1testCompile group: 'org.mockito', name: 'mockito-core', version: '3.3.3' 使用 Mockito 通常有两种常见的方式来创建 Mock 对象。 1、使用 Mockito.mock(clazz) 方式通过 Mockito 类的静态方法 mock 来创建 Mock 对象，例如以下创建了一个 List 类型的 Mock 对象： 1List&lt;String&gt; mockList = Mockito.mock(ArrayList.class); 由于 mock 方法是一个静态方法，所以通常会写成静态导入方法的方式，即 List&lt;String&gt; mockList = mock(ArrayList.class)。 2、使用 @Mock 注解方式第二种方式就是使用 @Mock 注解方式来创建 Mock 对象，使用该方式创需要注意的是要在运行测试方法前使用 MockitoAnnotations.initMocks(this) 或者单元测试类上加上 @ExtendWith(MockitoExtension.class) 注解，如下所示代码创建了一个 List 类型的 Mock 对象(PS: @BeforeEach 是 Junit 5 的注解，功能类似于 Junit 4 的 @Before 注解。)： 123456789101112131415161718/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 *///@ExtendWith(MockitoExtension.class)public class MockitoTest &#123; @Mock private List&lt;String&gt; mockList; @BeforeEach public void beforeEach() &#123; MockitoAnnotations.initMocks(this); &#125;&#125; 验证性测试Mockito 测试框架中提供了 Mockito.verify 静态方法让我们可以方便的进行验证性测试，比如方法调用验证、方法调用次数验证、方法调用顺序验证等，下面看看具体的代码。 验证方法单次调用验证方法单次调用的话直接 verify 方法后加上待验证调用方法即可，以下代码的功能就是验证 mockList 对象的 size 方法被调用一次。 12345678910111213141516171819/** * @author mghio * @date: 2020-05-28 * @version: 1.0 * @description: * @since JDK 1.8 */@ExtendWith(MockitoExtension.class)public class MockitoVerifyTest &#123; @Mock List&lt;String&gt; mockList; @Test void verify_SimpleInvocationOnMock() &#123; mockList.size(); verify(mockList).size(); &#125;&#125; 验证方法调用指定次数除了验证单次调用，我们有时候还需要验证一些方法被调用多次或者指定的次数，那么此时就可以使用 verify + times 方法来验证方法调用指定次数，同时还可以结合 atLeast + atMost 方法来提供调用次数范围，同时还有 never 等方法验证不被调用等。 1234567891011121314151617181920212223/** * @author mghio * @date: 2020-05-28 * @version: 1.0 * @description: * @since JDK 1.8 */@ExtendWith(MockitoExtension.class)public class MockitoVerifyTest &#123; @Mock List&lt;String&gt; mockList; @Test void verify_NumberOfInteractionsWithMock() &#123; mockList.size(); mockList.size(); verify(mockList, times(2)).size(); verify(mockList, atLeast(1)).size(); verify(mockList, atMost(10)).size(); &#125;&#125; 验证方法调用顺序同时还可以使用 inOrder 方法来验证方法的调用顺序，下面示例验证 mockList 对象的 size、add 和 clear 方法的调用顺序。 1234567891011121314151617181920212223242526/** * @author mghio * @date: 2020-05-28 * @version: 1.0 * @description: * @since JDK 1.8 */@ExtendWith(MockitoExtension.class)public class MockitoVerifyTest &#123; @Mock List&lt;String&gt; mockList; @Test void verify_OrderedInvocationsOnMock() &#123; mockList.size(); mockList.add("add a parameter"); mockList.clear(); InOrder inOrder = inOrder(mockList); inOrder.verify(mockList).size(); inOrder.verify(mockList).add("add a parameter"); inOrder.verify(mockList).clear(); &#125;&#125; 以上只是列举了一些简单的验证性测试，还有验证测试方法调用超时以及更多的验证测试可以通过相关官方文档探索学习。 验证方法异常异常测试我们需要使用 Mockito 框架提供的一些调用行为定义，Mockito 提供了 when(...).thenXXX(...) 来让我们定义方法调用行为，以下代码定义了当调用 mockMap 的 get 方法无论传入任何参数都会抛出一个空指针 NullPointerException 异常，然后通过 Assertions.assertThrows 来验证调用结果。 1234567891011121314151617181920/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */@ExtendWith(MockitoExtension.class)public class MockitoExceptionTest &#123; @Mock public Map&lt;String, Integer&gt; mockMap; @Test public void whenConfigNonVoidReturnMethodToThrowEx_thenExIsThrown() &#123; when(mockMap.get(anyString())).thenThrow(NullPointerException.class); assertThrows(NullPointerException.class, () -&gt; mockMap.get("mghio")); &#125;&#125; 同时 when(...).thenXXX(...) 不仅可以定义方法调用抛出异常，还可以定义调用方法后的返回结果，比如 when(mockMap.get(&quot;mghio&quot;)).thenReturn(21); 定义了当我们调用 mockMap 的 get 方法并传入参数 mghio 时的返回结果是 21。这里有一点需要注意，使用以上这种方式定义的 mock 对象测试实际并不会影响到对象的内部状态，如下图所示： 虽然我们已经在 mockList 对象上调用了 add 方法，但是实际上 mockList 集合中并没有加入 mghio，这时候如果需要对 mock 对象有影响，那么需要使用 spy 方式来生成 mock 对象。 1234567891011public class MockitoTest &#123; private List&lt;String&gt; mockList = spy(ArrayList.class); @Test public void add_spyMockList_thenAffect() &#123; mockList.add("mghio"); assertEquals(0, mockList.size()); &#125;&#125; 断点后可以发现当使用 spy 方法创建出来的 mock 对象调用 add 方法后，mghio 被成功的加入到 mockList 集合当中。 与 Spring 框架集成Mockito 框架提供了 @MockBean 注解用来将 mock 对象注入到 Spring 容器中，该对象会替换容器中任何现有的相同类型的 bean，该注解在需要模拟特定bean（例如外部服务）的测试场景中很有用。如果使用的是 Spring Boot 2.0+ 并且当前容器中已有相同类型的 bean 的时候，需要设置 spring.main.allow-bean-definition-overriding 为 true（默认为 false）允许 bean 定义覆盖。下面假设要测试通过用户编码查询用户的信息，有一个数据库操作层的 UserRepository，也就是我们等下要 mock 的对象，定义如下： 12345678910111213/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */@Repositorypublic interface UserRepository &#123; User findUserById(Long id);&#125; 还有用户操作的相关服务 UserService 类，其定义如下所示: 1234567891011121314151617181920/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */@Servicepublic class UserService &#123; private UserRepository userRepository; public UserService(UserRepository userRepository) &#123; this.userRepository = userRepository; &#125; public User findUserById(Long id) &#123; return userRepository.findUserById(id); &#125;&#125; 在测试类中使用 @MockBean 来标注 UserRepository 属性表示这个类型的 bean 使用的是 mock 对象，使用 @Autowired 标注表示 UserService 属性使用的是 Spring 容器中的对象，然后使用 @SpringBootTest 启用 Spring 环境即可。 123456789101112131415161718192021222324/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */@SpringBootTestpublic class UserServiceUnitTest &#123; @Autowired private UserService userService; @MockBean private UserRepository userRepository; @Test public void whenUserIdIsProvided_thenRetrievedNameIsCorrect() &#123; User expectedUser = new User(9527L, "mghio", "18288888880"); when(userRepository.findUserById(9527L)).thenReturn(expectedUser); User actualUser = userService.findUserById(9527L); assertEquals(expectedUser, actualUser); &#125;&#125; Mockito 框架的工作原理通过以上介绍可以发现， Mockito 非常容易使用并且可以方便的验证一些方法的行为，相信你已经看出来了，使用的步骤是先创建一个需要 mock 的对象 Target ，该对象如下： 1234567public class Target &#123; public String foo(String name) &#123; return String.format("Hello, %s", name); &#125;&#125; 然后我们直接使用 Mockito.mock 方法和 when(...).thenReturn(...) 来生成 mock 对象并指定方法调用时的行为，代码如下： 1234567@Testpublic void test_foo() &#123; String expectedResult = "Mocked mghio"; when(mockTarget.foo("mghio")).thenReturn(expectedResult); String actualResult = mockTarget.foo("mghio"); assertEquals(expectedResult, actualResult);&#125; 仔细观察以上 when(mockTarget.foo(&quot;mghio&quot;)).thenReturn(expectedResult) 这行代码，首次使用我也觉得很奇怪，when 方法的入参竟然是方法的返回值 mockTarget.foo(&quot;mghio&quot;)，觉得正确的代码应该是这样 when(mockTarget).foo(&quot;mghio&quot;)，但是这个写法实际上无法进行编译。既然 Target.foo 方法的返回值是 String 类型，那是不是可以使用如下方式呢？ 1Mockito.when("Hello, I am mghio").thenReturn("Mocked mghio"); 结果是编译通过，但是在运行时报错： 从错误提示可以看出，when 方法需要一个方法调用的参数，实际上它只需要 mock 对象方法调用在 when 方法之前就行，我们看看下面这个测试代码： 12345678@Testpublic void test_mockitoWhenMethod() &#123; String expectedResult = "Mocked mghio"; mockTarget.foo("mghio"); when("Hello, I am mghio").thenReturn(expectedResult); String actualResult = mockTarget.foo("mghio"); assertEquals(expectedResult, actualResult);&#125; 以上代码可以正常测试通过，结果如下： 为什么这样就可以正常测试通过？是因为当我们调用 mock 对象的 foo 方法时，Mockito 会拦截方法的调用然后将方法调用的详细信息保存到 mock 对象的上下文中，当调用到 Mockito.when 方法时，实际上是从该上下文中获取最后一个注册的方法调用，然后把 thenReturn 的参数作为其返回值保存，然后当我们的再次调用 mock 对象的该方法时，之前已经记录的方法行为将被再次回放，该方法触发拦截器重新调用并且返回我们在 thenReturn 方法指定的返回值。以下是 Mockito.when 方法的源码： 该方法里面直接使用了 MockitoCore.when 方法，继续跟进，该方法源码如下： 仔细观察可以发现，在源码中并没有用到参数 methodCall，而是从 MockingProgress 实例中获取 OngoingStubbing 对象，这个 OngoingStubbing 对象就是前文所提到的上下文对象。个人感觉是 Mockito 为了提供简洁易用的 API 然后才制造了 when 方法调用的这种“幻象”，简而言之，Mockito 框架通过方法拦截在上下文中存储和检索方法调用详细信息来工作的。 如何实现一个微型的 Mock 框架知道了 Mockito 的运行原理之后，接下来看看要如何自己去实现一个类似功能的 mock 框架出来，看到方法拦截这里我相信你已经知道了，其实这就是 AOP 啊，但是通过阅读其源码发现 Mockito 其实并没有使用我们熟悉的 Spring AOP 或者 AspectJ 做的方法拦截，而是通过运行时增强库 Byte Buddy 和反射工具库 Objenesis 生成和初始化 mock 对象的。现在，通过以上分析和源码阅读可以定义出一个简单版本的 mock 框架了，将自定义的 mock 框架命名为 imock。这里有一点需要注意的是，Mockito 有一个好处是，它不需要进行初始化，可以直接通过其提供的静态方法来立即使用它。在这里我们也使用相同名称的静态方法，通过 Mockito 源码： 很容易看出 Mockito 类最终都是委托给 MockitoCore 去实现的功能，而其只提供了一些面向使用者易用的静态方法，在这里我们也定义一个这样的代理对象 IMockCore，这个类中需要一个创建 mock 对象的方法 mock 和一个给方法设定返回值的 thenReturn 方法，同时该类中持有一个方法调用详情 InvocationDetail 集合列表，这个类是用来记录方法调用详细信息的，然后 when 方法仅返回列表中的最后一个 InvocationDetail，这里列表可以直接使用 Java 中常用的 ArrayList 即可，这里的 ArrayList 集合列表就实现了 Mockito 中的 OngoingStubbing 的功能。根据方法的三要素方法名、方法参数和方法返回值很容易就可以写出 InvocationDetail 类的代码，为了对方法在不同类有同名的情况区分，还需要加上类全称字段和重写该类的 equals 和 hashCode 方法（判断是否在调用方法集合列表时需要根据该方法判断），代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class InvocationDetail&lt;T&gt; &#123; private String attachedClassName; private String methodName; private Object[] arguments; private T result; public InvocationDetail(String attachedClassName, String methodName, Object[] arguments) &#123; this.attachedClassName = attachedClassName; this.methodName = methodName; this.arguments = arguments; &#125; public void thenReturn(T t) &#123; this.result = t; &#125; public T getResult() &#123; return result; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; InvocationDetail&lt;?&gt; behaviour = (InvocationDetail&lt;?&gt;) o; return Objects.equals(attachedClassName, behaviour.attachedClassName) &amp;&amp; Objects.equals(methodName, behaviour.methodName) &amp;&amp; Arrays.equals(arguments, behaviour.arguments); &#125; @Override public int hashCode() &#123; int result = Objects.hash(attachedClassName, methodName); result = 31 * result + Arrays.hashCode(arguments); return result; &#125;&#125; 接下来就是如何去创建我们的 mock 对象了，在这里我们也使用 Byte Buddy 和 Objenesis 库来创建 mock 对象，IMockCreator 接口定义如下： 123456789101112/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public interface IMockCreator &#123; &lt;T&gt; T createMock(Class&lt;T&gt; mockTargetClass, List&lt;InvocationDetail&gt; behaviorList);&#125; 实现类 ByteBuddyIMockCreator 使用 Byte Buddy 库在运行时动态生成 mock 类对象代码然后使用 Objenesis 去实例化该对象。代码如下： 123456789101112131415161718192021222324252627282930/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class ByteBuddyIMockCreator implements IMockCreator &#123; private final ObjenesisStd objenesisStd = new ObjenesisStd(); @Override public &lt;T&gt; T createMock(Class&lt;T&gt; mockTargetClass, List&lt;InvocationDetail&gt; behaviorList) &#123; ByteBuddy byteBuddy = new ByteBuddy(); Class&lt;? extends T&gt; classWithInterceptor = byteBuddy.subclass(mockTargetClass) .method(ElementMatchers.any()) .intercept(MethodDelegation.to(InterceptorDelegate.class)) .defineField("interceptor", IMockInterceptor.class, Modifier.PRIVATE) .implement(IMockIntercepable.class) .intercept(FieldAccessor.ofBeanProperty()) .make() .load(getClass().getClassLoader(), Default.WRAPPER).getLoaded(); T mockTargetInstance = objenesisStd.newInstance(classWithInterceptor); ((IMockIntercepable) mockTargetInstance).setInterceptor(new IMockInterceptor(behaviorList)); return mockTargetInstance; &#125;&#125; 基于以上分析我们可以很容易写出创建 mock 对象的 IMockCore 类的代码如下： 123456789101112131415161718192021222324/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class IMockCore &#123; private final List&lt;InvocationDetail&gt; invocationDetailList = new ArrayList&lt;&gt;(8); private final IMockCreator mockCreator = new ByteBuddyIMockCreator(); public &lt;T&gt; T mock(Class&lt;T&gt; mockTargetClass) &#123; T result = mockCreator.createMock(mockTargetClass, invocationDetailList); return result; &#125; @SuppressWarnings("unchecked") public &lt;T&gt; InvocationDetail&lt;T&gt; when(T methodCall) &#123; int currentSize = invocationDetailList.size(); return (InvocationDetail&lt;T&gt;) invocationDetailList.get(currentSize - 1); &#125;&#125; 提供给使用者的类 IMock 只是对 IMockCore 进行的简单调用而已，代码如下： 12345678910111213141516171819/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class IMock &#123; private static final IMockCore IMOCK_CORE = new IMockCore(); public static &lt;T&gt; T mock(Class&lt;T&gt; clazz) &#123; return IMOCK_CORE.mock(clazz); &#125; public static &lt;T&gt; InvocationDetail when(T methodCall) &#123; return IMOCK_CORE.when(methodCall); &#125;&#125; 通过以上步骤，我们就已经实现了一个微型的 mock 框架了，下面来个实际例子测试一下，首先创建一个 Target 对象： 1234567891011121314/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class Target &#123; public String foo(String name) &#123; return String.format("Hello, %s", name); &#125;&#125; 然后编写其对应的测试类 IMockTest 类如下： 12345678910111213141516171819202122/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class IMockTest &#123; @Test public void test_foo_method() &#123; String exceptedResult = "Mocked mghio"; Target mockTarget = IMock.mock(Target.class); IMock.when(mockTarget.foo("mghio")).thenReturn(exceptedResult); String actualResult = mockTarget.foo("mghio"); assertEquals(exceptedResult, actualResult); &#125;&#125; 以上测试的可以正常运行，达到了和 Mockito 测试框架一样的效果，运行结果如下： 上面只是列出了一些关键类的源码，自定义 IMock 框架的所有代码已上传至 Github 仓库 imock，感兴趣的朋友可以去看看。 总结本文只是介绍了 Mockito 的一些使用方法，这只是该框架提供的最基础功能，更多高级的用法可以去官网阅读相关的文档，然后介绍了框架中 when(...).thenReturn(...) 定义行为方法的实现方式并按照其源码思路实现了一个相同功能的简易版的 imock 。虽然进行单元测试有很多优点，但是也不可盲目的进行单元测试，在大部分情况下只要做好对项目中逻辑比较复杂、不容易理解的核心业务模块以及项目中公共依赖的模块的单元测试就可以了。 参考文章 MockitoObjenesisByte Buddy]]></content>
      <categories>
        <category>Java</category>
        <category>unit test</category>
        <category>mockito</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>test</tag>
        <tag>mockito</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在一台计算机上安装多个 JDK 版本]]></title>
    <url>%2Fpost%2F51e5bd99.html</url>
    <content type="text"><![CDATA[前言对于使用 Java 语言开发的朋友可能会遇到这种情况，有时想学习和探索 Java 的最新版本提供的一些新特性，比如 Java 11，但你无法将其安装在自己的计算机上，因为你的团队正在使用比这个旧的版本（我们目前用的 Java 8)，你并不想影响目前的项目。或者你目前是在维护和开发多个项目，而这些不同的项目使用的 JDK 版本不一样，比如那些维护的老项目使用的是 JDK 8，而新项目你打算使用比较新的版本 JDK 11，以上这些情况都需要在计算机上安装多个 JDK，并且应该能够在多个版本之间方便快速的切换。今天要介绍的主角 SDKMAN 可以很好的解决上面这种问题，它提供了在同一台计算机上对多个版本的开发工具包管理。需要注意的是：这个工具只适用于类 Unix 的系统（比如：Mac OSX、Linux、Cygwin、Solaris、FreeBSD 等）。 SDKMan 简介直接引用 SDKMan 官网上的介绍如下： SDKMAN! is a tool for managing parallel versions of multiple Software Development Kits on most Unix based systems. It provides a convenient Command Line Interface (CLI) and API for installing, switching, removing and listing Candidates. 简单来说就是其提供了管理多个版本开发工具包的能力，同时也提供了一些命令行接口让我们方便安装、版本切换、版本移除和显示版本列表。关于 SDKMan 还有几个要点如下： SDKMan 是由开源社区开发的，免费使用，。 SDKMan 是用 bash 编写的，它只需要您的系统上安装了 curl 和 zip / unzip 命令即可。 SDKMan 可以为 JVM 安装大约 29 个软件开发包，比如 Java、Groovy、Scala、Kotlin、Gradle、Maven、Spark、Spring Boot 等。 SDKMan 可以自动处理帮我们配置 *_HOME(e.g.:JAVA_HOME) 和 PATH 环境变量，因此我们不需要担心切换版本后这些环境变量的设置。 安装 SDKManSDKMan 可以运行在任何类 Unix 系统上，我们只需要在命令行输入以下命令即可安装： 1curl -s "https://get.sdkman.io" | bash 然后执行以下命令，加载文件 sdkman-init.sh 到当前环境，执行完该命令之后我们可以通过 sdk version 来验证是否安装成功，同时还可以通过 sdk help 命令显示有关 sdk 命令用法和帮助（PS: 对于使用 Windows 环境的朋友可以安装 Cygwin 或 Git Bash 运行以上命令）。 1source "$HOME/.sdkman/bin/sdkman-init.sh" 使用 SDKMan 安装 JDK前面已经介绍过，SDKMan 支持多达大约 29 个软件开发包管理，我们也可以使用 sdk list 命令来查看支持的完整列表，本文主要介绍 Java 相关的内容，可以通过命令 sdk list java 来查看支持安装的 Java 版本。 使用以下命令安装 Java 11 ： 1sdk install java 11.0.7.hs-adpt 该命令会花费一些时间，因为它会在我们的计算机上下载对应版本的 JDK，执行完成之后 SDKman 会自动给我们配置好 JAVA_HOME 和 PATH 等环境变量，可以通过 Java -version 命令验证。 现在，如果检查 Java 版本和 JAVA_HOME 环境变量，可以看到当前 Java 的版本已更新为 11.0.7。 可以使用以下命令来设置默认使用的 JDK 版本。 1sdk default java 11.0.7.hs-adpt 将 SDKMan 指向已安装 Java 版本如果在你安装 SDKMan 之前本地电脑已经安装了 JDK 版本，默认是无法识别到的，那么你需要进行以下配置才能让 SDKMan 识别已安装的版本，首先，第一步你要先找到你的 Java 安装目录，我本地 Mac 的安装目录是 /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk，然后使用命令 ln -s 来为 Java 安装目录建立符号链接。 多个 JDK 版本切换示例SDKMan 提供了命令 sdk use java &lt;version_want_to_use&gt; 在多个版本之间进行切换，使用 sdk use java jdk1.8.0_181.jdk 命令来使用之前本地安装的 Java 8。 使用命令 sdk use java 11.0.7.hs-adpt 来设置版本为 Java 11。 需要注意的是：使用命令 sdk use java &lt;version&gt; 只在当前会话有效，如果你关闭终端并再次打开它，则将使用以前安装的版本，不会改变你本地使用的版本，此时可以使用 sdk default java &lt;version&gt; 来设置永久生效。 如何卸载指定的 JDK 版本如果你想要卸载任何已安装的 JDK 版本，比如： 11.0.7.hs-adpt，可以使用以下命令卸载： 1sdk uninstall java 11.0.7.hs-adpt 此时，如果你想再次安装之前通过 SDKMan 卸载的版本，此时不会再次重新下载，会提示 Found a previously downloaded java 11.0.7.hs-adpt archive. Not downloading it again...，因为之前删除操作并没有真正的从你计算机上删除源压缩包文件。 IntelliJ IDEA 使用 SDMan 安装 JDKSDKMan 所有安装的 JDK 都放在目录 .sdkman/candidates/java/，你可以在你当前用户的 home 文件夹下面看到该文件夹（注意是隐藏文件夹）。 在 IntelliJ IDEA 中打开任何一个 Java 项目后，您可以按 Command + : 快捷键打开项目结构窗口，在 Project SDK 模块选择新建一个 JDK 后输入你需要的 JDK 版本在 SDKMan 中的路径即可。 因为 .sdkman 是隐藏文件夹不太方便查找，可以使用以下命令创建一个非隐藏文件夹指向它。 1ln -s ~/.sdkman ~/sdkman]]></content>
      <categories>
        <category>JDK</category>
        <category>Java</category>
        <category>版本管理工具</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>版本管理工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看了你就懂的同步与异步、阻塞与非阻塞]]></title>
    <url>%2Fpost%2F34755d6c.html</url>
    <content type="text"><![CDATA[前言在网上看到过很多讲有关同步与异步、阻塞与非阻塞的文章，但是很多都是抛出一堆相关定义，看了之后还是云里雾里的，对这几个概念还是不能很好的去区分它们。本文通过通俗易懂的语言和相关例子让你深入理解其本质。 同步与异步首先我们要明确的是，同步和异步都是针对两个或者两个以上的事物来说的。比如当我们在网上购物看中一件物品，然后去浏览该商品详情的时候，首先页面会先发送一个请求，后台服务器查询对应商品的相关数据，然后前端详情页面才根据返回数据展示该商品的详细信息。而此时你的网速比较差，一个详情页面等了将近一分钟才全部展示完成，这时候你问这个请求是同步还是异步？答案显然是同步请求，它给我们最直观的表现形式就是页面一直显示在加载中，商品的详情页面渲染必须要等待后台服务器返回商品详情数据后才能进行。也就是说下一个操作必须要等待上一个操作完成才能进行，它依赖于上一个操作的返回结果。 你可能会问，在同步的情况下，当一个事物正在进行操作的时候，其它的事物此时在干嘛呢？这个实际上并没有明确的规定，其实同步更多的是关注事物一个一个的串行执行的过程，保证不会交叉执行，至于某个时刻处于什么状态并不关心。这在计算机中大部分时候其它事物都是处于一个等待的状态，而我们人则要灵活得多，在我们日常生活中常用的同步手段就是排队，比如我们上下班坐地铁进行安检的时候，需要依次排队安检进站乘车，但是你在排队的过程是在看手机、聊天还是什么也不做都可以，安检人员并不会在意你在做什么，这种就是由于安检资源有限导致的同步。 对于同步这里有两个点需要注意，一是同步的范围，有时候并不需要全局的大范围的去同步，只需要在特定的操作同步即可，这样可以提升执行效率，比如 Java 语言中的同步方法和同步代码块。另一个是同步的粒度，并不是在一些大的操作粒度上才需要同步操作，小的粒度操作也需要同步操作，只是有的小粒度操作天然就已经是同步操作，并不需要我们人为的去添加同步操作控制。比如 Java 语言中的同步都是针对有两个或者两个以上线程的程序来说的，因为单线程的程序里它天然就是同步的。而异步则完全相反，在异步情况下多个事务可以同时进行，互不影响，你进行你的，我进行我的，谁都不用关心谁。总的来说就是: 同步 两个事物相互依赖，并且一个事物必须以依赖于另一事物的执行结果。比如在事物 A-&gt;B 事件模型中，你需要先完成事物 A 才能执行事物 B。也就是说，同步调用在被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。 异步 两个事物完全独立，一个事物的执行不需要等待另外一个事物的执行。也就是说，异步调用可以返回结果不需要等待结果返回，当结果返回的时候通过回调函数或者其他方式带着调用结果再做相关事情。 可以看出同步与异步是从行为角度描述事物的，你品，你细品。（PS：这里的多个事务可以指代不同的操作、不同的方法或者不同的代码语句等等） 阻塞与非阻塞所谓阻塞，简单来说就是发出一个请求不能立刻返回响应，要等所有的逻辑全处理完才能返回响应。非阻塞反之，发出一个请求立刻返回应答，不用等处理完所有逻辑。阻塞与非阻塞指的是单个线程内遇到同步等待时，是否在原地不做任何操作。堵车就是阻塞与非阻塞最好的例子，在一线城市生活过的朋友应该都有体会，在交通正常的时候汽车可以正常通行，就是非阻塞，上下班高峰的时候经常发生堵车，交通正常的时候半个小时车程，高峰期可能需要二、三个小时才能到。。。而且一旦发生交通堵塞，所有马路上的车子都一动不动，只能在车子里等待，就是阻塞，当然大多数人不会选择干等，他们会玩手机或者和朋友聊天等等，同样的在计算机里，阻塞就意味着停止执行停下来等待，非阻塞表明操作可以继续向下执行，但是在发生阻塞的时候计算机可就没有像人这么灵活了，通常计算机的处理方式就是挂起当前线程，然后干等着，阻塞结束后才继续执行该线程。可以看出阻塞和非阻塞描述的当前事物的状态（等待调用结果时的状态）。 结合前面介绍的同步与异步，两两组合就会有四种情况，分别是同步阻塞、同步非阻塞、异步阻塞和异步非阻塞。下面通过车道的例子来形象的解释这几种状态： 同步阻塞 只有一个车道，不能超车，所有车子依次行使，一次只能通过一辆车，尴尬的是这个车道还堵车了。 同步非阻塞 只有一个车道，不能超车，所有车子依次行使，一次只能通过一辆车，不过比较幸运这个车道没有堵车，可以正常通行。 异步阻塞 有两个或两个以上车道，每条马路都可以通行，不同车道上的车子可以并行行使，尴尬的是所有的车道都堵车了。 异步非阻塞 有两个或两个以上车道，每条马路都可以通行，不同车道上的车子可以并行行使，不过比较幸运的是没有一个车道堵车，都可以正常通行。 对应到我们计算机里也是一样的，同步阻塞相当于只有一个线程，而且该线程处于阻塞（Blocked）状态，同步非阻塞相当于只有一个线程，而且该线程处于运行（Running）状态。异步阻塞相当于有多个线程，而且所有线程都处于阻塞（Blocked）状态，异步非阻塞相当于有多个线程，而且所有线程都在正常运行。 总结很多程序思想都来源于生活，需要我们自己去寻找身边的场景多类比思考、总结归纳，这样才会理解得更深刻。]]></content>
      <categories>
        <category>Java</category>
        <category>IO模型</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在亿级数据中判断一个元素是否存在？]]></title>
    <url>%2Fpost%2Ffe76043.html</url>
    <content type="text"><![CDATA[前言在日常工作中，经常要判断一个元素是否在一个集合中。假设你要向浏览器添加一项功能，该功能可以通知用户输入的网址是否是恶意网址，此时你手上有大约 1000 万个恶意 URL 的数据集，你该如何实现该功能。按我之前的思维，要判断一个元素在不在当前的数据集中，首先想到的就是使用 hash table，通过哈希函数运行所有的恶意网址以获取其哈希值，然后创建出一个哈希表（数组）。这个方案有个明显的缺点，就是需要存储原始元素本身，内存占用大，而我们其实主要是关注 当前输入的网址在不在我们的恶意 URL 数据集中，也就是之前的恶意 URL 数据集的具体值是什么并不重要，通过吴军老师的《数学之美》了解到，对于这种场景大数据领域有个用于在海量数据情况下判断某个元素是否已经存在的算法很适合，关键的一点是该算法并不存储元素本身，这个算法就是 — 布隆过滤器(Bloom filter)。 原理布隆过滤器是由巴顿.布隆于一九七零年提出的，在 维基百科 中的描述如下： A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. 布隆过滤器是一个数据结构，它可以用来判断某个元素是否在集合内，具有运行快速，内存占用小的特点，它由一个很长的二进制向量和一系列随机映射函数组成。而高效插入和查询的代价就是，它是一个基于概率的数据结构，只能告诉我们一个元素绝对不在集合内，布隆过滤器的好处在于快速，省空间，但是有一定的误判率。布隆过滤器的基础数据结构是一个比特向量，假设有一个长度为 16 的比特向量，下面我们通过一个简单的示例来看看其工作原理，： 上图比特向量中的每一个空格表示一个比特, 空格下面的数字表示当前位置的索引。只需要简单的对输入进行多次哈希操作，并把对应于其结果的比特置为 1，就完成了向 Bloom filter 添加一个元素的操作。下图表示向布隆过滤器中添加元素 https://www.mghio.cn 和 https://www.abc.com 的过程，它使用了 func1 和 func2 两个简单的哈希函数。 当我们往集合里添加一个元素的时候, 可以检查该元素在应用对应哈希函数后的哈希值对比特向量的长度取余后的位置是否为 1，图中用 1 表示最新添加的元素对应位置。然后当我们要判断添加元素是否存在集合中的话，只需要简单的通过对该元素应用同样的哈希函数，然后看比特向量里对应的位置是否为 1 的方式来判断一个元素是否在集合里。如果不是，则该元素一定不再集合中，但是需要注意的是，如果是，你只知道元素可能在里面, 因为这些对应位置有可能恰巧是由其它元素或者其它元素的组合所引起的。以上就是布隆过滤器的实现原理。 如何自己实现布隆过滤器的思想比较简单，首先在构造方法中初始化了一个指定长度的 int 数组，在添加元素的时候通过哈希函数 func1 和 func2 计算出对应的哈希值，对数组长度取余后将对应位置置为 1，判断元素是否存在于集合中时，同样也是对元素用同样的哈希函数进行两次计算，取到对应位置的哈希值，只要存在位置的值为 0，则认为元素不存在。下面使用 Java 语言实现了上面示例中简单版的布隆过滤器： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class BloomFilter &#123; /** * 数组长度 */ private int size; /** * 数组 */ private int[] array; public BloomFilter(int size) &#123; this.size = size; this.array = new int[size]; &#125; /** * 添加数据 */ public void add(String item) &#123; int firstIndex = func1(item); int secondIndex = func2(item); array[firstIndex % size] = 1; array[secondIndex % size] = 1; &#125; /** * 判断数据 item 是否存在集合中 */ public boolean contains(String item) &#123; int firstIndex = func1(item); int secondIndex = func2(item); int firstValue = array[firstIndex % size]; int secondValue = array[secondIndex % size]; return firstValue != 0 &amp;&amp; secondValue != 0; &#125; /** * hash 算法 func1 */ private int func1(String key) &#123; int hash = 7; hash += 61 * hash + key.hashCode(); hash ^= hash &gt;&gt; 15; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 11; return Math.abs(hash); &#125; /** * hash 算法 func2 */ private int func2(String key) &#123; int hash = 7; for (int i = 0, len = key.length(); i &lt; len; i++) &#123; hash += key.charAt(i); hash += (hash &lt;&lt; 7); hash ^= (hash &gt;&gt; 17); hash += (hash &lt;&lt; 5); hash ^= (hash &gt;&gt; 13); &#125; return Math.abs(hash); &#125;&#125; 自己实现虽然简单但是有一个问题就是检测的误判率比较高，通过其原理可以知道，可我们可以提高数组长度以及 hash 计算次数来降低误报率，但是相应的 CPU、内存的消耗也会相应的提高，这需要我们根据自己的业务需要去权衡选择。 扎心一问哈希函数该如何设计？布隆过滤器里的哈希函数最理想的情况就是需要尽量的彼此独立且均匀分布，同时，它们也需要尽可能的快 (虽然 sha1 之类的加密哈希算法被广泛应用，但是在这一点上考虑并不是一个很好的选择)。 布隆过滤器应该设计为多大？个人认为布隆过滤器的一个比较好特性就是我们可以修改过滤器的错误率。一个大的过滤器会拥有比一个小的过滤器更低的错误率。假设在布隆过滤器里面有 k 个哈希函数，m 个比特位（也就是位数组长度），以及 n 个已插入元素，错误率会近似于 (1-ekn/m)k，所以你只需要先确定可能插入的数据集的容量大小 n，然后再调整 k 和 m 来为你的应用配置过滤器。 应该使用多少个哈希函数?显然，布隆过滤器使用的哈希函数越多其运行速度就会越慢，但是如果哈希函数过少，又会遇到误判率高的问题。所以这个问题上需要认真考虑，在创建一个布隆过滤器的时候需要确定哈希函数的个数，也就是说你需要提前预估集合中元素的变动范围。然而你这样做了之后，你依然需要确定比特位个数和哈希函数的个数的值。看起来这似乎这是一个十分困难的优化问题，但幸运的是，对于给定的 m（比特位个数）和 n（集合元素个数），最优的 k（哈希函数个数）值为: (m/n)ln(2)（PS：需要了解具体的推导过程的朋友可以参考维基百科）。也就是我们可以通过以下步骤来确定布隆过滤器的哈希函数个数： 确定 n（集合元素个数）的变动范围。 选定 m（比特位个数）的值。 计算 k（哈希函数个数）的最优值 对于给定的 n、m 和 k 计算错误率，如果这个错误率不能接受的话，可以继续回到第二步。 布隆过滤器的时间复杂度和空间复杂度?对于一个 m（比特位个数）和 k（哈希函数个数）值确定的布隆过滤器，添加和判断操作的时间复杂度都是 O(k)，这意味着每次你想要插入一个元素或者查询一个元素是否在集合中，只需要使用 k 个哈希函数对该元素求值，然后将对应的比特位标记或者检查对应的比特位即可。 总结布隆过滤器的实际应用很广泛，特别是那些要在大量数据中判断一个元素是否存在的场景。可以看到，布隆过滤器的算法原理比较简单，但要实际做一个生产级别的布隆过滤器还是很复杂的，谷歌的开源库 Guava 的 BloomFilter 提供了 Java 版的实现，用法很简单。最后留给大家一个问题：布隆过滤器支持元素删除吗？]]></content>
      <categories>
        <category>Java</category>
        <category>Bloom filter</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Bloom filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串操作 — Google Guava]]></title>
    <url>%2Fpost%2F3ae0ff4e.html</url>
    <content type="text"><![CDATA[前言Java 里字符串表示字符的不可变序列，创建后就不能更改。在我们日常的工作中，字符串的使用非常频繁，熟练的对其操作可以极大的提升我们的工作效率，今天要介绍的主角是 Google 开源的一个核心 Java 库 Guava，它提供了集合类型、不可变的集合、并发、I / O、缓存、字符串等许多实用功能。在本文中，我们将学习使用 Guava 中的 Strings 和 Splitter 字符串操作工具类。 如何使用Google Guava 会同步到 Maven Central 中，所以，如果你是 Maven 项目的话只需要在 pom.xml 文件中引入如下依赖即可： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;28.2-jre&lt;/version&gt;&lt;/dependency&gt; 对于 Gradle 项目在 build.gradle 中引入如下依赖即可： 1compile group: 'com.google.guava', name: 'guava', version: '28.2-jre' PS：28.2-jre 是编写本文时的最新版本，你可以从 Maven Central 中查看当前的最新版本。 为什么需要引入类库Google Guava 提供了很多实用的静态方法，这些可以解决开发人员在开发中所要完成的一些重复任务。当然，这个工作我们也可以自己做，但是引入类库它会降低错误发生的可能性，毕竟这些类库都是已经经过多年的生产验证。比如类库中 Strings 提供的一个方法 commonPrefix，它接受两个字符串并返回两个字符串之间的公共前缀（eg: abcd 和 abef 返回 ab）。你可以在脑子里想象一下在应用程序代码中面临这样的要求时，自己要如何编写代码来完成该操作，要自己实现这个功能，还是需要花费一些时间的，同时还需要考虑到各种边界异常情况。这就是类库提供给我们的最大价值之一，所以当我们需要的某种功能可以作为一种工具方法使用时，首先应该去寻找一些已存在的类库并去熟练使用的它们，而不是自己去实现。总结起来使用类库有如下几个原因： Google Guava 类库有人已经对其进行了彻底的测试，bug 出现的概率会比我们自己实现的小很多。 作为 Google Guava 的一部分，已经存在各种测试用例，用于测试实用程序的实现。如果我们自己编写代码实现的话，可能还要去编写和维护它们的测试。 StringsGoogle Guava 有许多实用的工具类和方法，不可能在一篇文章中都有介绍完，在本文中，只会介绍和字符串操作相关的两个工具类。首先第一个是 Strings 类，该类提供了操作 String 和 CharSequence 的实用方法。 nullToEmpty、emptyToNull 和 isNullOrEmptynullToEmpty 方法功能为：如果传入的字符串为 null，则返回一个空字符串 &quot;&quot;，否则按原样返回传入的字符串。 1234567@Testpublic void testStringsOfNullToEmpty() &#123; System.out.println(Strings.nullToEmpty("mghio")); // mghio System.out.println(Strings.nullToEmpty("")); // "" System.out.println(Strings.nullToEmpty(null)); // "" System.out.println(Strings.nullToEmpty(null).isEmpty()); // true&#125; emptyToNull 方法功能为：它与 nullToEmpty 相反，如果传入了空字符串，则返回 null，否则返回原始字符串。 123456@Testpublic void testStringsOfEmptyToNull() &#123; System.out.println(Strings.emptyToNull("mghio")); // mghio System.out.println(Strings.emptyToNull(null)); // null System.out.println(Strings.emptyToNull("")); // null&#125; isNullOrEmpty 方法功能为：如果传入的字符串为 null 或为空，则返回 true，否则返回 false。 123456@Testpublic void testStringsOfIsNullOrEmpty() &#123; System.out.println(Strings.isNullOrEmpty("mghio")); // false System.out.println(Strings.isNullOrEmpty("")); // true System.out.println(Strings.isNullOrEmpty(null)); // true&#125; padStart 和 padEnd这两个方法有三个参数，分别为：输入字符串、最小长度和要填充的字符，它将字符根据需要多次插入到输入字符串的开头，以使输入字符串的长度等于传入的最小长度。 12345@Testpublic void testStringsOfPadStart() &#123; System.out.println(Strings.padStart("9527", 6, '0')); // 009527 System.out.println(Strings.padStart("123456", 6, '0')); // 123456&#125; 在第一行代码中，将两次填充 0 以使最终的字符串长度等于我们传入的最小长度（6）。在第二行代码中，输入字符串长度本身具有所需的最小长度，因此未进行填充padEnd 方法和上面这个方法类似，只不过它是在字符的末尾而不是在开始处进行填充。 12345@Testpublic void testStringsOfPadEnd() &#123; System.out.println(Strings.padEnd("9527", 6, '0')); // 952700 System.out.println(Strings.padEnd("123456", 6, '0')); // 123456&#125; repeat该方法需要传入一个字符串和一个重复次数 count，它返回一个由原始字符串组成的字符串，该字符串重复了 count 次。 1234@Testpublic void testStringsRepeat() &#123; System.out.println(Strings.repeat("mghio", 3)); // mghiomghiomghio&#125; commonPrefix 和 commonSuffixcommonPrefix 方法返回传入的两个字符串之间最大的公共前缀，而 commonSuffix 方法返回传入两个字符串之间最大的公共后缀。 12345@Testpublic void testStrings() &#123; System.out.println(Strings.commonPrefix("mghio9527", "mghio666")); // mghio System.out.println(Strings.commonSuffix("iammghio", "nicemghio")); // mghio&#125; SplitterSplitter 类提供的功能正如其名（PS:一个好的命名很重要），它用于根据提供的分割符将字符串拆分为多个子字符串。我们可以通过传入一个分割符来获一个 Splitter 的实例，有了分割器之后，我们可以根据分割器的配置方式对字符串进行分割。 12345@Testpublic void testSplitterOfSplit() &#123; Iterable&lt;String&gt; result = Splitter.on(",").split("m,g,h,i,o"); System.out.println(result); // [m, g, h, i, o]&#125; 上面的例子中使用逗号进行分割，因此，它将传入的字符串 m,g,h,i,o 拆分为一个 Iterable &lt;String&gt;，然后当我们对其进行迭代遍历时会输出 [m, g, h, i, o]。 获取 Splitter 实例on 和 onPattern现在，我们来看看获得一个分割器 Splitter 的各种方法。on 方法有各种不同的重载版本，它们以字符、字符串或正则表达式作为分隔符，我们还可以将 Pattern 实例作为字符串传递给 onPattern 方法中。 123456789@Testpublic void testSplitterOfOn() &#123; Splitter wordSplitter = Splitter.on(":;"); // 下面这行输出结果 [the, text, is, separated, by, colon, semicolon] System.out.println(wordSplitter.split("the:;text:;is:;separated:;by:;colon:;semicolon")); Splitter patternBasedSplitter = Splitter.on(Pattern.compile("\\s+")); System.out.println(patternBasedSplitter.split("abc dmg hio")); // [abc, dmg, hio] System.out.println(Splitter.onPattern("\\s+").split("www mghio cn")); // [www, mghio, cn]&#125; fixedLengthfixedLength 也是最有用的方法之一，它可以将字符串分成给定长度的相等部分，需要注意的是，最后一个部分可能会小于给定的长度。 123456@Testpublic void testSplitterOfFixedLength() &#123; Splitter fixedLengthSplitter = Splitter.fixedLength(3); System.out.println(fixedLengthSplitter.split("iammghiojava")); // [iam, mgh, ioj, ava] System.out.println(fixedLengthSplitter.split("https://www.mghio.cn")); // [htt, ps:, //w, ww., mgh, io., cn]&#125; Splitter 修饰符方法Splitter 还提供了可以在更改或修改 Splitter 行为的常用方法。 trimResults这个方法可以从生成的分割器的结果字符串中删除前面和末尾的空格。 1234567@Testpublic void testSplitterOfTrimResult() &#123; Splitter commaSplitter = Splitter.on(","); System.out.println(commaSplitter.split("m, g, h, i, o")); // [m, g, h, i, o] Splitter commaSplitterWithTrim = commaSplitter.trimResults(); System.out.println(commaSplitterWithTrim.split("m, g, h, i, o")); // [m, g, h, i, o]&#125; 注意，第一个分割的结果在字符串 g、 h、i、o 之前有一个空格，使用 trimResults 方法后，将去除这些前导空格。 omitEmptyStrings这个方法会从结果中忽略所有空字符串。 1234567@Testpublic void testSplitterOfOmitEmptyStrings() &#123; Splitter commaSplitter = Splitter.on(","); System.out.println(commaSplitter.split("m,,g,h,i,o")); // [m, , g, h, i, o] Splitter commaSplitterWithNoEmptyString = commaSplitter.omitEmptyStrings(); System.out.println(commaSplitterWithNoEmptyString.split("m,,g,h,i,o")); // [m, g, h, i, o]&#125; 上面的 commaSplitterWithNoEmptyString 会从输出中删除空字符串的结果。 limit这个方法返回与原始分割器等效的分割器，但它会在达到指定的输入限制后将停止拆分，将后续剩余结果字符串作为一项输出，也就是说，我们可以通过的传入的参数指定结果中存在的最大项目数。需要注意的是：该方法在省略空字符串时，省略的字符串不计算在内。。 123456@Testpublic void testSplitterOfLimit() &#123; Splitter commaSplitter = Splitter.on(","); Splitter limitingCommaSplitter = commaSplitter.limit(3); System.out.println(limitingCommaSplitter.split("i,m,g,h,i,o")); // [i, m, g,h,i,o]&#125; 有一点需要注意，Splitter 是不可变的（这一点和 String 类似），因此，调用它的任何修饰符方法都将返回新的 Splitter，并且不会修改原始的 Splitter。 123456789@Testpublic void testSplitterImmutable() &#123; Splitter splitter = Splitter.on('/'); System.out.println("Before: " + splitter); // Before: com.google.common.base.Splitter@33b37288 splitter.trimResults(); // do nothing System.out.println("First: " + splitter); // First: com.google.common.base.Splitter@33b37288 splitter = splitter.trimResults(); // the returned splitter to be assigned System.out.println("Second: " + splitter); // Second: com.google.common.base.Splitter@77a57272&#125; splitToList我们前面已经使用的 split 方法，它返回的是一个 Iterable&lt;String&gt; 对象。而这里的 splitToList 方法返回一个 List&lt;String&gt;。由于分割方法返回的是 Iterable，因此它是惰性的。 123456@Testpublic void testSplitterOfSplitToList() &#123; Splitter commaSplitter = Splitter.on(","); List&lt;String&gt; result = commaSplitter.splitToList("m,g,h,i,o"); System.out.println(result); // [m, g, h, i, o]&#125; MapSplitterMapSplitter 顾名思义就是用来将一个将字符串拆分为 Map 对象的。我们可以使用 withKeyValueSeparator 方法从 Splitter 中获取 MapSplitter 对象，该方法接收一个字符、字符串或者 Splitter 对象作为参数。首先，根据原始的分割器将字符串分割为多个项，然后，使用传给 withKeyValueSeparator 方法的分割符将各个项分为 Map 键-值对。 1234567@Testpublic void testSplitterOfWithKeyValueSeparator() &#123; Splitter commaSplitter = Splitter.on(','); Splitter.MapSplitter keyValueSplitter = commaSplitter.withKeyValueSeparator('='); Map&lt;String, String&gt; map = keyValueSplitter.split("name=mghio,blog=mghio.cn"); System.out.println(map); // &#123;name=mghio, blog=mghio.cn&#125;&#125; 从结果可以看到，它分割为两个 entry （name=mghio 与 blog=mghio.cn）项，还有一个点需要注意的是：如果我们在原始的分割器上指定了任何修改器，则它们仅适用于该分割器，而不适用于 MapSplitter。 1234567@Testpublic void testSplitterOfWithKeyValueSeparatorAndModifiers() &#123; Splitter originalSplitter = Splitter.on(",").trimResults(); Splitter.MapSplitter keyValueSplitter = originalSplitter.withKeyValueSeparator('='); // 输出结果：&#123;name =mghio, blog= mghio.cn&#125; System.out.println(keyValueSplitter.split("name =mghio, blog= mghio.cn")); &#125; 由以上结果可以看出 trimResults 修饰方法仅适用于原始拆分器。因此，blog 开头的空格已被移除（使用 , 分割原始字符串时），但是，mghio.cn 开头的空格不会被移除（使用 = 分割成键值时）。 最后需要注意的是：MapSplitter 类被标记为 @Beta，这意味着类库中与 MapSplitter 相关的类和方法是实验性的，可以更改（以中断的方式），甚至将来版本可能删除。 总结在本文中，介绍了 Google Guava 库以及在项目或应用程序中使用它的好处，如何将其导入到我们的应用程序中使用。然后，介绍了 Guava 库中对字符串操作工具类（Strings 和 Splitter ）的一些基本用法，当然，这只是冰山一角，Guava 库还提供了其它很多有用的基础功能，需要我们自己去查询相关文档学习了解，感兴趣的朋友可以去看看它的实现源码，这个库的代码写得很优雅。 参考 StringsExplained Guava’s Strings Class]]></content>
      <categories>
        <category>Java</category>
        <category>Guava</category>
        <category>String</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何编写优雅的异步代码 — CompletableFuture]]></title>
    <url>%2Fpost%2F7b9ead86.html</url>
    <content type="text"><![CDATA[前言在我们的意识里，同步执行的程序都比较符合人们的思维方式，而异步的东西通常都不好处理。在异步计算的情况下，以回调表示的动作往往会分散在代码中，也可能相互嵌套在内部，如果需要处理其中一个步骤中可能发生的错误时，情况变得更加糟糕。Java 8 引入了很多的新特性，其中就包含了 CompletableFuture 类的引入，这让我们编写清晰可读的异步代码变得更加容易，该类功能非常强大，包含了超过 50 多个方法。。。 什么是 CompletableFutureCompletableFuture 类的设计灵感来自于 Google Guava 的 ListenableFuture 类，它实现了 Future 和 CompletionStage 接口并且新增了许多方法，它支持 lambda，通过回调利用非阻塞方法，提升了异步编程模型。它允许我们通过在与主应用程序线程不同的线程上（也就是异步）运行任务，并向主线程通知任务的进度、完成或失败，来编写非阻塞代码。 为什么要引入 CompletableFutureJava 的 1.5 版本引入了 Future，你可以把它简单的理解为运算结果的占位符，它提供了两个方法来获取运算结果。 get()：调用该方法线程将会无限期等待运算结果。 get(long timeout, TimeUnit unit)：调用该方法线程将仅在指定时间 timeout 内等待结果，如果等待超时就会抛出 TimeoutException 异常。 Future 可以使用 Runnable 或 Callable 实例来完成提交的任务，通过其源码可以看出，它存在如下几个问题： 阻塞 调用 get() 方法会一直阻塞，直到等待直到计算完成，它没有提供任何方法可以在完成时通知，同时也不具有附加回调函数的功能。 链式调用和结果聚合处理 在很多时候我们想链接多个 Future 来完成耗时较长的计算，此时需要合并结果并将结果发送到另一个任务中，该接口很难完成这种处理。 异常处理 Future 没有提供任何异常处理的方式。 以上这些问题在 CompletableFuture 中都已经解决了，接下来让我们看看如何去使用 CompletableFuture。 如何创建 CompletableFuture最简单的创建方式就是调用 CompletableFuture.completedFuture(U value) 方法来获取一个已经完成的 CompletableFuture 对象。 12345678910@Testpublic void testSimpleCompletableFuture() &#123; CompletableFuture&lt;String&gt; completableFuture = CompletableFuture.completedFuture("Hello mghio"); assertTrue(completableFuture.isDone()); try &#123; assertEquals("Hello mghio", completableFuture.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125;&#125; 需要注意的是当我们对不完整的 CompleteableFuture调用 get 方法的话，会由于 Future 未完成，因此 get 调用将永远阻塞，此时可以使用 CompletableFuture.complete 方法手动完成 Future。 任务异步处理当我们想让程序在后台异步执行任务而不关心任务的处理结果时，可以使用 runAsync 方法，该方法接收一个 Runnable 类型的参数返回 CompletableFuture&lt;Void&gt;。 123456789101112@Testpublic void testCompletableFutureRunAsync() &#123; AtomicInteger variable = new AtomicInteger(0); CompletableFuture&lt;Void&gt; runAsync = CompletableFuture.runAsync(() -&gt; process(variable)); runAsync.join(); assertEquals(100, variable.get());&#125;public void process(AtomicInteger variable) &#123; System.out.println(Thread.currentThread() + " Process..."); variable.set(100);&#125; 如果我们想让任务在后台异步执行而且需要获取任务的处理结果时，可以使用 supplyAsync 方法，该方法接收一个 Supplier&lt;T&gt; 类型的参数返回一个 CompletableFuture&lt;T&gt;。 12345678910111213@Testpublic void testCompletableFutureSupplyAsync() &#123; CompletableFuture&lt;String&gt; supplyAsync = CompletableFuture.supplyAsync(this::process); try &#123; assertEquals("Hello mghio", supplyAsync.get()); // Blocking &#125; catch (ExecutionException | InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;public String process() &#123; return "Hello mghio";&#125; 看到这里你可能会有个问题，上面执行 runAsync 和 supplyAsync 任务的线程是从哪里来的、谁创建的呢？实际上它和 Java 8 中的 parallelStream 类似， CompletableFuture 也是从全局 ForkJoinPool.commonPool() 获得的线程中执行这些任务的。同时，上面的两个方法也提供了自定义线程池去执行任务，其实你如果去了解过 CompletableFuture 的源码的话，你会发现其 API 中的所有方法都有个重载的版本，有或没有自定义 Executor 执行器。 1234567891011121314@Testpublic void testCompletableFutureSupplyAsyncWithExecutor() &#123; ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(2); CompletableFuture&lt;String&gt; supplyAsync = CompletableFuture.supplyAsync(this::process, newFixedThreadPool); try &#123; assertEquals("Hello mghio", supplyAsync.get()); // Blocking &#125; catch (ExecutionException | InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;public String process() &#123; return "Hello mghio";&#125; 链式调用和结果聚合处理我们知道 CompletableFuture 的 get() 方法会一直阻塞直到获取到结果，CompletableFuture 提供了 thenApply、thenAccept 和 thenRun 等方法来避免这种情况，而且我们还可以添加任务完成后的回调通知。这几个方法的使用场景如下： thenApply 当我们如果要在从 Future 接收值后任务之前运行自定义的业务代码，然后要为此任务返回一些值时，则可以使用该方法 thenAccept 如果我们希望在从 Future 接收到一些值后执行任务之前运行自定义的业务代码而不关心返回结果值时，则可以使用该方法 thenRun 如果我们想在Future完成后运行自定义的业务代码，并且不想为此返回任何值时，则可以使用该方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Testpublic void testCompletableFutureThenApply() &#123; Integer notificationId = CompletableFuture.supplyAsync(this::thenApplyProcess) .thenApply(this::thenApplyNotify) // Non Blocking .join(); assertEquals(new Integer(1), notificationId);&#125;@Testpublic void testCompletableFutureThenAccept() &#123; CompletableFuture.supplyAsync(this::processVariable) .thenAccept(this::thenAcceptNotify) // Non Blocking .join(); assertEquals(100, variable.get());&#125;@Testpublic void testCompletableFutureThenRun() &#123; CompletableFuture.supplyAsync(this::processVariable) .thenRun(this::thenRunNotify) .join(); assertEquals(100, variable.get());&#125;private String processVariable() &#123; variable.set(100); return "success";&#125;private void thenRunNotify() &#123; System.out.println("thenRun completed notify ....");&#125;private Integer thenApplyNotify(Integer integer) &#123; return integer;&#125;private void thenAcceptNotify(String s) &#123; System.out.println( String.format("Thread %s completed notify ....", Thread.currentThread().getName()));&#125;public Integer thenApplyProcess() &#123; return 1;&#125; 如果有大量的异步计算，那么我们可以继续将值从一个回调传递到另一个回调中去，也就是使用链式调用方式，使用方式很简单。 12345678910111213141516171819202122232425262728@Testpublic void testCompletableFutureThenApplyAccept() &#123; CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .thenAccept((i) -&gt; notifyByEmail()).join();&#125;private void notifyByEmail() &#123; // business code System.out.println("send notify by email ...");&#125;private Double notifyBalance(Double d) &#123; // business code System.out.println(String.format("your balance is $%s", d)); return 9527D;&#125;private Double calculateBalance(Object o) &#123; // business code return 9527D;&#125;private Double findAccountNumber() &#123; // business code return 9527D;&#125; 比较细心的朋友可能注意到在所有前面的几个方法示例中，所有方法都是在同一线程上执行的。如果我们希望这些任务在单独的线程上运行时，那么我们可以使用这些方法对应的异步版本。 123456789101112131415@Testpublic void testCompletableFutureApplyAsync() &#123; ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(2); ScheduledExecutorService newSingleThreadScheduledExecutor = Executors .newSingleThreadScheduledExecutor(); CompletableFuture&lt;Double&gt; completableFuture = CompletableFuture .supplyAsync(this::findAccountNumber, newFixedThreadPool) // 从线程池 newFixedThreadPool 获取线程执行任务 .thenApplyAsync(this::calculateBalance, newSingleThreadScheduledExecutor) .thenApplyAsync(this::notifyBalance); Double balance = completableFuture.join(); assertEquals(9527D, balance);&#125; 执行结果处理thenCompose 方法适合有依赖性的任务处理，比如一个计算账户余额的业务：首先我们要先找到帐号，然后为该帐户计算余额，然后计算完成后再发送通知。所有这些任务都是依赖前一个任务的返回 CompletableFuture 结果，此时我们需要使用 thenCompose 方法，其实有点类似于 Java 8 流的 flatMap 操作。 123456789101112131415161718192021222324252627282930313233343536@Testpublic void testCompletableFutureThenCompose() &#123; Double balance = this.doFindAccountNumber() .thenCompose(this::doCalculateBalance) .thenCompose(this::doSendNotifyBalance).join(); assertEquals(9527D, balance);&#125;private CompletableFuture&lt;Double&gt; doSendNotifyBalance(Double aDouble) &#123; sleepSeconds(2); // business code System.out.println(String.format("%s doSendNotifyBalance ....", Thread.currentThread().getName())); return CompletableFuture.completedFuture(9527D);&#125;private CompletableFuture&lt;Double&gt; doCalculateBalance(Double d) &#123; sleepSeconds(2); // business code System.out.println(String.format("%s doCalculateBalance ....", Thread.currentThread().getName())); return CompletableFuture.completedFuture(9527D);&#125;private CompletableFuture&lt;Double&gt; doFindAccountNumber() &#123; sleepSeconds(2); // business code System.out.println(String.format("%s doFindAccountNumber ....", Thread.currentThread().getName())); return CompletableFuture.completedFuture(9527D);&#125;private void sleepSeconds(int timeout) &#123; try &#123; TimeUnit.SECONDS.sleep(timeout); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; thenCombine 方法主要是用于合并多个独立任务的处理结果。假设我们需要查找一个人的姓名和住址，则可以使用不同的任务来分别获取，然后要获得这个人的完整信息（姓名 + 住址），则需要合并这两种方法的结果，那么我们可以使用 thenCombine 方法。 12345678910111213141516171819202122@Testpublic void testCompletableFutureThenCombine() &#123; CompletableFuture&lt;String&gt; thenCombine = this.findName().thenCombine(this.findAddress(), (name, address) -&gt; name + address); String personInfo = thenCombine.join(); assertEquals("mghio Shanghai, China", personInfo);&#125;private CompletableFuture&lt;String&gt; findAddress() &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleepSeconds(2); // business code return "Shanghai, China"; &#125;);&#125;private CompletableFuture&lt;String&gt; findName() &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleepSeconds(2); // business code return "mghio "; &#125;);&#125; 等待多个任务执行完成在许多情况下，我们希望并行运行多个任务，并在所有任务完成后再进行一些处理。假设我们要查找 3 个不同用户的姓名并将结果合并。此时就可以使用 CompletableFuture 的静态方法 allOf，该方法会等待所有任务完成，需要注意的是该方法它不会返回所有任务的合并结果，因此我们必须手动组合任务的执行结果。 12345678910111213141516171819202122232425@Testpublic void testCompletableFutureAllof() &#123; List&lt;CompletableFuture&lt;String&gt;&gt; list = Lists.newArrayListWithCapacity(4); IntStream.range(0, 3).forEach(num -&gt; list.add(findName(num))); CompletableFuture&lt;Void&gt; allFuture = CompletableFuture .allOf(list.toArray(new CompletableFuture[0])); CompletableFuture&lt;List&lt;String&gt;&gt; allFutureList = allFuture .thenApply(val -&gt; list.stream().map(CompletableFuture::join).collect(Collectors.toList())); CompletableFuture&lt;String&gt; futureHavingAllValues = allFutureList .thenApply(fn -&gt; String.join("", fn)); String result = futureHavingAllValues.join(); assertEquals("mghio0mghio1mghio2", result);&#125;private CompletableFuture&lt;String&gt; findName(int num) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleepSeconds(2); // business code return "mghio" + num; &#125;);&#125; 异常处理在多线程中程序异常其实不太好处理，但是幸运的是在 CompletableFuture 中给我们提供了很方便的异常处理方式，在我们上面的例子代码中： 123456@Testpublic void testCompletableFutureThenCompose() &#123; Double balance = this.doFindAccountNumber() .thenCompose(this::doCalculateBalance) .thenCompose(this::doSendNotifyBalance).join();&#125; 在上面的代码中，三个方法 doFindAccountNumber、doCalculateBalance 和 doSendNotifyBalance 只要任意一个发生异常了，则之后调用的方法将不会运行。CompletableFuture 提供了三种处理异常的方式，分别是 exceptionally、handle 和 whenComplete 方法。第一种方式是使用 exceptionally 方法处理异常，如果前面的方法失败并发生异常，则会调用异常回调。 123456789101112@Testpublic void testCompletableFutureExceptionally() &#123; CompletableFuture&lt;Double&gt; thenApply = CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .exceptionally(ex -&gt; &#123; System.out.println("Exception " + ex.getMessage()); return 0D; &#125;); Double join = thenApply.join(); assertEquals(9527D, join);&#125; 第二种方式是使用 handle 方法处理异常，使用该方式处理异常比上面的 exceptionally 方式更为灵活，我们可以同时获取到异常对象和当前的处理结果。 12345678910111213141516@Testpublic void testCompletableFutureHandle() &#123; CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .handle((ok, ex) -&gt; &#123; System.out.println("最终要运行的代码..."); if (ok != null) &#123; System.out.println("No Exception !!"); &#125; else &#123; System.out.println("Exception " + ex.getMessage()); return -1D; &#125; return ok; &#125;);&#125; 第三种是使用 whenComplete 方法处理异常。 12345678910@Testpublic void testCompletableFutureWhenComplete() &#123; CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .whenComplete((result, ex) -&gt; &#123; System.out.println("result = " + result + ", ex = " + ex); System.out.println("最终要运行的代码..."); &#125;);&#125; 总结在本文中，介绍了 CompletableFuture 类的部分方法和使用方式，这个类的方法很多同时提供的功能也非常强大，在异步编程中使用的比较多，熟悉了基本的使用方法之后要深入了解还是要深入源码分析其实现原理。]]></content>
      <categories>
        <category>Java</category>
        <category>异步</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码中的坏味道]]></title>
    <url>%2Fpost%2Fa38c0645.html</url>
    <content type="text"><![CDATA[前言在日常生活中，当我们买的水果放久了之后会发出一种难闻的气味（“坏味道”），这个时候我们就应该把它扔掉。同样，代码也有“坏味道”，当然确定什么是和不是代码“坏味道”是主观的，它会随语言、开发人员和开发方法的不同而不同。在工作当中，很多时候都是在维护之前的项目和在此基础上增加一些新功能，为了能让项目代码易于理解和维护，要时刻注意代码中的“坏味道”，当发现代码如果有坏味道了，要及时去重构它使其变成优秀的整洁的代码。本文列举代码中一些常见的“坏味道”和相应的重构方案。 过长方法 (Long Method)这种“坏味道”表现为方法代码行数过长，方法行数越长，就越难以理解和维护它。一个比较有用的方案就是当你觉得需要对方法中的内容加注释的时候，你应该将这个代码段作为一个新方法提取出来，哪怕有时候仅仅是一行代码也可以这么做，而且方法的命名要尽量做到见名知意，如果局部变量和参数干扰到方法的提取，则可以使用引入参数对象来进行提取。一般情况下，方法中条件运算符和循环是可以将代码移至单独方法的一个很好的代码段，对于条件运算符，可以尝试分解条件，如果方法出现循环，可以尝试提取方法。 过大的类 (Large Class)这种“坏味道”表现为一个定义了很多的变量、方法代码行数很长的大类，刚开始的时候类通常都不“大”，一段时间之后，随着业务的发展新功能的增加，类通常都会就会变得越来越“大”，通常程序员都喜欢在原有的类上添加属性或者添加新的方法的方式来完成功能的开发，当一个类的代码行数过多或者功能职责过多的时候，就意味着我们应该将其拆分了，常用有以下三种不同的拆分方式： 提取新类，当大类的部分行为可以分解为一​​个单独的组件，则可以使用提取类的方式拆分。 提取子类，当大类的部分行为可以以不同的方式实现或在极少数情况下使用，则可以使用提取子类方式拆分。 提取接口，当有必要列出客户端可以使用的操作和行为的列表的时候，则可以提取接口的方式拆分。 通过重构大类，可以使开发人员无需记住一个类的大量属性，在许多情况下，将大类分成多个部分可以避免代码和功能的重复。 过长参数列表 (Long Parameter List)这种“坏味道”表现为一个方法超过三个以上的参数，当一个方法合并了几个算法之后就会可能出现过多参数的情况，这些参数用来控制方法将要运行哪种算法以及如何运行的。长参数列表也可能是由于我们将类的对象创建过程拆分产生的，想象这么一个场景，当我们把用于创建方法所需对象的代码片段从方法内部移至用于调用方法的代码，然后创建的对象作为参数传入方法，这样，原始类就不再了解对象之间的关系，依赖性降低了。当有多个这种对象需要创建之后，每个对象将需要自己的参数，这意味着参数列表会更长。随着时间的流逝，我们就会越来越难于理解这种方法的长参数列表的具体含义了，清除这种“坏味道”的方式就是将方法的参数列表封装成一个对象的属性。通过重构之后，可以使代码的可读性更高，代码更简短，同时可能还会让你看到以前未被注意的重复代码。 过多注释 (Too Many Comments)这种“坏味道”表现为一种方法充满解释性的注释，当开发者意识到自己的代码不直观或不明显时一般都会给代码加上相应的注释。写代码注释的意图通常都是好的，是为了可以有更好的可读性让后面易于维护，在这种情况下，代码注释就会掩盖了可以改进的可疑代码的“坏味道”，好的方法名或者类名就是最好的注释。 The best comment is a good name for a method or class. 当我们遇到没有注释就无法理解代码片段时，首先应该尝试以无需注释的方式更改代码结构，解决过多注释通常有以下几种方式： 提取变量，当如果要使用注释来解释复杂的表达式的时候，则可以使用“提取变量”的方式将表达式拆分为可理解的子表达式。 提取方法，当如果注释解释了一段代码片段，则可以通过提取方法的方式来将这一部分变成一个单独的方法，这个时候往往方法的名称就是注释的内容。 通过提取变量或者提取方法的方式可以使代码变得更加直观和明显。 Switch 滥用（Switch Abuse）这种“坏味道”表现为代码中存在一个复杂的 switch 运算符，通常，if 条件语句的代码可以分散在程序中的不同位置，当需要添加新条件后，就必须找到所有开关代码并进行修改。根据经验，当看到 switch 时，你第一时间应该想到要用多态性去重构代码。如果 switch 是基于类型判断的，可以使用“用子类替换”或“用状态/策略替换”。但是当运算符中没有太多条件，并且它们都使用不同的参数调用相同的方法，那么多态其实是多余的。在这种情况下，则可以使用“将参数替换为方法”，然后将该方法分解为多个较小的方法，并相应地更改 switch ，代码经过重构之后改进其的组织方式。当然如果 switch 操作只是执行简单的判断时，则没有必要进行代码重构。还有就是，在工厂设计模式（工厂方法和抽象工厂）使用开关运算符来选择创建的类时，也没有必要对其进行重构。 异曲同工类（Alternative Classes with Different Interfaces）这种“坏味道”表现为两个类有着相同的功能，但方法名称不同，产生这种代码的原因通常是创建其中一个类的程序员可能并不知道功能上等效的类已经存在。清除这种“坏味道”有以下几种方式： 方法重命名，重命名相同功能的方法，使它们在所有替代类中相同。 移动方法、添加参数和泛型方法使得方法的签名和实现相同。 如果仅仅是重复了方法的部分功能，可以使用提取相同父类的方式重构，在这种情况下，现有的类将成为该父类的子类。 通过重构异曲同工类后，可以去除掉不必要的重复代码，从而减少代码的行数，同时代码也会有更好的可读更易于理解。 临时变量滥用（Temporary Field）这种“坏味道”表现为一些临时变量仅在某些情况下才获得其值，在这些情况之外，它们都为空，通常，当我们在创建一个算法后需要定义一些临时变量以供该算法输入使用。此时，程序员往往会决定在类中为此算法去创建变量，而不是在方法中创建大量参数，导致这些变量仅在算法当中才会使用，其它地方都不会使用这些变量。一个应对的方式就是将这些临时变量和对其进行操作的所有代码都提取出来放到单独的类中。 重复代码（Duplicate Code）这种“坏味道”表现为两个或者多个代码片段看起来几乎相同，当我们多个人同时在同一项目中的不同部分上工作时，通常就会发生复制，产生重复的代码。因为正在实现不同的功能，因此可能并不知道其他人已经编写了类似的代码，这些代码其实是可以根据自己的需要进行复用的。当代码中的一些特定部分看起来不同但实际上实现相同的功能时，这样的代码有着更多细微的重复，这种情况下的代码重复可能很难找到和修复。如果重复代码在两个处于相同层次结构的子类出现时，我们可以通过以下方式进行重构： 提取方法，将重复的代码片段提取为方法然后放到共同的父类当中。 如果重复的代码在构造方法内部，则将其提取到父类的构造方法当中去，然后再在当前类的构造方法中使用 super 的方式调用父类构造方法。 如果重复的代码结构上相似但又不完全相同，那么则使用模板方法方式重构。 如果重复代码在两个或者多个不同的类出现时，我们可以通过以下方式进行重构： 如果这些类不是层次结构的一部分，可以使用提取共同父类的方式来为这些类创建一个保留所有之前的功能的单个父类。 当很难或者不可能创建父类，那么可以在其中的任意一个类中使用提取类的方式来重构，然后在其它类中使用刚刚创建出来的类。 通过重构合并重复的代码可以简化代码的结构并使其更加简短和易于后期维护。 总结本文总结了一些代码中常见的“坏味道”并给出了一些解决方法，重构是需要我们开发人员时刻都要去做的，要将重构始终贯穿在整个开发过程中，不断去发现代码中的“坏味道”，不断的持续的渐进重构。最后不管我们是如何去重构代码的，其背后的指导思想都是 Solid 原则。]]></content>
      <categories>
        <category>Java</category>
        <category>重构</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>重构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 垃圾收集技术]]></title>
    <url>%2Fpost%2F4615256d.html</url>
    <content type="text"><![CDATA[前言在计算机科学中，垃圾回收（GC: garbage collection）是内存自动管理的一种方式，它并不是同 Java 语言一起诞生的，实际上，早在 1959 年为了简化 Lisp 语言的手动内存管理，该语言的作者就开始使用了内存自动管理技术。 垃圾收集和手动内存管理刚好相反，后者需要编程人员自己去指定需要释放的对象然后将内存归还给操作系统，而前者不需要关心给对象分配的内存回收问题。Java 语言使用自动垃圾收集器来管理对象生命周期中的内存，要进行垃圾收集首先需要明确三个问题：1. 哪些内存需要回收、2. 什么时候进行回收、3. 怎么进行内存回收。接下来让我们一起看看 Java 语言对这些问题是如何处理的。 哪些内存需要回收为了方便管理和跨平台，Java 虚拟机规范规定在执行 Java 程序的时候把它所管理的内存划分为若干个不同的数据区域。这些区域都有着各自不同的用途以及创建和销毁的时间，有的数据区域随着用户线程的启动和结束而建立和销毁，有的区域会随着虚拟机进程的启动和停止而存在和销毁。更多有关运行时数据区域的内容请看 Java 运行时数据区域。由于 Java 运行时数据区域中的 程序计数器、虚拟机栈和本地方法栈和线程的生命周期一致，随线程的启动和结束而建立和销毁。而且当我们的类结构确定了之后，在编译期间，一个栈帧需要分配内存的大小基本上也就确定下来了，这三个区域的内存分配和收回都是具备确定性的，不需要我们过多的去考虑内存回收问题。主要考虑Java 堆和方法区的内存回收的问题。 什么时候进行回收在 Java 语言中，一个对象的生命周期分为以下三个阶段： 对象创建阶段 通常我们使用 new 关键字进行对象创建 e.g. Object obj = new Object();，当我们创建对象时，Java 虚拟机将分配一定大小的内存来存储该对象，分配的内存量可能会根据虚拟机厂商的不同而有所不同。 对象使用阶段 在这个阶段，对象被应用程序的其它对象使用（其它活动对象拥有指向它的引用）。在使用期间，该对象会一直驻留在内存当中，并且可能包含对其它对象的引用。 对象销毁阶段 垃圾收集系统监视对象，如果发现对象不被任何对象引用了，则进行该对象内存回收操作。 那么问题来了，该如何去判断一个对象有没有被引用呢？目前，主要有两种判断对象是否存活的算法，分别是 引用计数算法（Reference counting algorithm）和可达性分析算法（Accessibility analysis algorithm）。 引用计数算法首先我们看看引用计数算法是如何判断的，该算法的主要思想就是给每个对象都添加一个引用计数器，当该对象被变量或者另一个对象引用时该计数器值就会加 1，同时当对象的一个引用无效时，对象计数器的值会相应的减 1。当对象引用计数器的值为 0 时，说明该对象已经不再被引用了，那么就可以销毁对象进行内存回收操作了。这个算法的实现比较简单，对象是否“存活”的判断效率也比较高，这个算法看起来确实不错，但是它有个致命的缺点就是：无法解决对象间相互引用的问题。相互引用简单来说就是，有两个对象 object1 和 object2 都有一个引用类型字段 ref，并且做了如下赋值操作： 12object1.ref = object2;object2.ref = object1; 这两个对象除了上面这个赋值之外，不被其它任何对象引用，实际上这两个对象都不可能再被访问了，但是因为它们俩都互相引用了对方，导致引用计数器不为 0，导致使用引用计数器算法的 垃圾收集器 无法收集它们，它们就会一直存在于内存之中直到虚拟机进程结束。正是因为这个原因，市场上主流的 Java 虚拟机大部分都没有选用这个算法来管理内存，下面介绍的 可达性分析算法 就可以很好的避免了对象间相互引用的问题。 可达性分析算法Java 虚拟机是通过可达性分析算法来判断对象是否存活的，该算法的主要思想是将一系列称为 GC Root 的对象作为起点，向下进行搜索，搜索经过的路径称为引用链（Reference chain），当一个对象到 GC Root 对象没有任何引用链的时候，则表示该对象是不可达的，可以对其进行内存回收。 在 Java 虚拟机中，规定以下几种情况可以作为 GC Root 对象： 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中 Native 方法引用的对象 怎么进行内存回收当我们创建的对象不可达之后，Java 虚拟机会在后台自动去收集回收不可达对象的内存，自 Java 语言诞生以来，在垃圾收集算法上进行了许多更新，主要有标记-清除算法（Mark and sweep algorithm）、复制算法（Copying algorithm）、标记—整理算法（Mark and compact algorithm）和分代收集算法（Generational collection algorithm），根据这些算法实现的垃圾收集器在后台默默运行以释放内存，下面让我们看看它们是如何工作的。 标记-清除算法（mark and sweep algorithm）标记—清除算法是初始且非常基本的算法，主要分为以下两个阶段： 标记需要回收对象，找出程序中所有需要回收的对象并标记。 清除所有标记对象，在标记完成后统一回收被标记对象。 首先标记出需要回收的对象，标记完成后再统一回收被标记对象。这个算法是最基础的垃圾收集算法，后面将要介绍的几个算法都是在它的基础上优化改进的，算法主要有两个不足的地方：① 效率不高，标记和清除过程的效率都不高。② 空间利用率不高，标记清除之后会产生大量不连续的内存碎片，后面如果要分配大对象的时候由于连续内存不足可能会再次触发垃圾收集操作。 复制算法（copying algorithm）复制算法就是为了解决标记—清除算法的效率问题的，主要思想就是将可用的内存分为大小相等的两个部分，每一次都只使用其中的一块，当这块内存使用完了之后，就将依然存活的对象复制到另一块内存上去，然后再把这块含有可回收对象的内存清理掉，这样每次都是清理一半的连续内存了，就不会存在内存碎片的情况。但是这个算法的缺点也很明显，它把可用内存的大小缩小到了一半。 标记-整理算法（mark and compact algorithm）如果对象的存活率比较低的情况下，上面介绍的复制算法效率还是很高的，毕竟只要复制少部分存活对象到另一块内存中即可，但是当对象的存活率比较高时就会进行多次复制操作。比如老年代，老年代的对象是经过多次垃圾回收依然存活的对象，对象的存活率相对来说比较高，根据老年代的这个特点，于是针对这种情况就有了另一个算法称之为标记-整理算法，主要思想和其名字一样也是分为标记和整理两个阶段，第一个标记阶段依然和标记—清除算法一样，后面的第二个整理阶段就不是直接对可回收对象进行清理了，而是让所有存活的对象都向内存的同一侧移动，然后就直接清除掉另一侧的内存。 分代收集算法（generational collection algorithm）根据不同分代的特点，现在商业上的虚拟机针对不同的分代采取适合的垃圾收集，一般是把 Java 堆分为新生代和老年代。在新生代中，对象大部分存活时间都很短每次垃圾收集都会有很多的对象被清除，只有少部分对象可以存活下来，那么此时就可以使用复制算法，只需要复制出少部分存活的对象即可效率高。然而在老年代中大部分对象的存活时间比较长，则需采用标记-清除算法或者标记-整理算法来进行垃圾收集。垃圾收集算法对于垃圾回收来说类似于我们程序中的接口，是一套垃圾回收的指导算法，算法的具体实现我们称之为垃圾收集器。但是 Java 虚拟机规范中并没有对垃圾收集器的实现有任何规定。所以不同的厂商和不同版本的虚拟机实现的垃圾收集器也不一样，不过一般都会提供一些配置参数来让用户根据自身情况来设置所需的垃圾收集器。 JVM 相关 GC 配置Java 虚拟机部分垃圾收集（Garbage Collection，GC）相关配置如下 参数 描述 -Xms2048m 设置初始堆大小（新生代 + 老年代） -XX:InitialHeapSize=3g 设置初始堆大小（新生代 + 老年代） -Xmx3g 设置最大堆大小（新生代 + 老年代） -XX:MaxHeapSize=3g 设置最大堆大小（新生代 + 老年代） -XX:NewSize=128m 设置堆初始新生代大小 -XX:MaxNewSize=128m 设置堆最大新生代大小 -XX:PermSize=512m（JDK 1.7） 设置初始永久代（元空间）大小 -XX:MetaspaceSize=512m（JDK 1.8+） 设置初始永久代（元空间）大小 -XX:MaxPermSize=1g（JDK 1.7） 设置最大永久代（元空间）大小 -XX:MaxMetaspaceSize=1g（JDK 1.8+） 设置最大永久代（元空间）大小 -XX:+DisableExplicitGC 忽略应用程序对 System.gc() 方法的任何调用 -XX:+PrintGCDetails 打印输出 GC 收集相关信息 参考文章 深入理解Java虚拟机（第2版） Garbage collection (computer science) The Java® Virtual Machine Specification（Java SE 8 Edition）]]></content>
      <categories>
        <category>Java</category>
        <category>GC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务发现组件之 — Eureka]]></title>
    <url>%2Fpost%2F710bd10b.html</url>
    <content type="text"><![CDATA[前言现在流行的微服务体系结构正在改变我们构建应用程序的方式，从单一的单体服务转变为越来越小的可单独部署的服务（称为微服务），共同构成了我们的应用程序。当进行一个业务时不可避免就会存在多个服务之间调用，假如一个服务 A 要访问在另一台服务器部署的服务 B，那么前提是服务 A 要知道服务 B 所在机器的 IP 地址和服务对应的端口，最简单的方式就是让服务 A 自己去维护一份服务 B 的配置（包含 IP 地址和端口等信息），但是这种方式有几个明显的缺点：随着我们调用服务数量的增加，配置文件该如何维护；缺乏灵活性，如果服务 B 改变 IP 地址或者端口，服务 A 也要修改相应的文件配置；还有一个就是进行服务的动态扩容或缩小不方便。一个比较好的解决方案就是 服务发现（Service Discovery）。它抽象出来了一个注册中心，当一个新的服务上线时，它会将自己的 IP 和端口注册到注册中心去，会对注册的服务进行定期的心跳检测，当发现服务状态异常时将其从注册中心剔除下线。服务 A 只要从注册中心中获取服务 B 的信息即可，即使当服务 B 的 IP 或者端口变更了，服务 A 也无需修改，从一定程度上解耦了服务。服务发现目前业界有很多开源的实现，比如 apache 的 zookeeper、 Netflix 的 eureka、hashicorp 的 consul、 CoreOS 的 etcd。 Eureka 是什么Eureka 在 github 上对其的定义为 Eureka is a REST (Representational State Transfer) based service that is primarily used in the AWS cloud for locating services for the purpose of load balancing and failover of middle-tier servers.At Netflix, Eureka is used for the following purposes apart from playing a critical part in mid-tier load balancing. Eureka 是由 Netflix 公司开源，采用的是 Client / Server 模式进行设计，基于 http 协议和使用 Restful Api 开发的服务注册与发现组件，提供了完整的服务注册和服务发现，可以和 Spring Cloud 无缝集成。其中 Server 端扮演着服务注册中心的角色，主要是为 Client 端提供服务注册和发现等功能，维护着 Client 端的服务注册信息，同时定期心跳检测已注册的服务当不可用时将服务剔除下线，Client 端可以通过 Server 端获取自身所依赖服务的注册信息，从而完成服务间的调用。遗憾的是从其官方的 github wiki 可以发现，2.0 版本已经不再开源。但是不影响我们对其进行深入了解，毕竟服务注册、服务发现相对来说还是比较基础和通用的，其它开源实现框架的思想也是想通的。 服务注册中心（Eureka Server）我们在项目中引入 Eureka Server 的相关依赖，然后在启动类加上注解 @EnableEurekaServer，就可以将其作为注册中心，启动服务后访问页面如下： 我们继续添加两个模块 service-provider，service-consumer，然后在启动类加上注解 @EnableEurekaClient 并指定注册中心地址为我们刚刚启动的 Eureka Server，再次访问可以看到两个服务都已经注册进来了。 Demo 仓库地址：https://github.com/mghio/depth-in-springcloud 可以看到 Eureka 的使用非常简单，只需要添加几个注解和配置就实现了服务注册和服务发现，接下来我们看看它是如何实现这些功能的。 服务注册（Register）注册中心提供了服务注册接口，用于当有新的服务启动后进行调用来实现服务注册，或者心跳检测到服务状态异常时，变更对应服务的状态。服务注册就是发送一个 POST 请求带上当前实例信息到类 ApplicationResource 的 addInstance 方法进行服务注册。 可以看到方法调用了类 PeerAwareInstanceRegistryImpl 的 register 方法，该方法主要分为两步： 调用父类 AbstractInstanceRegistry 的 register 方法把当前服务注册到注册中心 调用 replicateToPeers 方法使用异步的方式向其它的 Eureka Server 节点同步服务注册信息 服务注册信息保存在一个嵌套的 map 中，它的结构如下： 第一层 map 的 key 是应用名称（对应 Demo 里的 SERVICE-PROVIDER），第二层 map 的 key 是应用对应的实例名称（对应 Demo 里的 mghio-mbp:service-provider:9999），一个应用可以有多个实例，主要调用流程如下图所示： 服务续约（Renew）服务续约会由服务提供者（比如 Demo 中的 service-provider）定期调用，类似于心跳，用来告知注册中心 Eureka Server 自己的状态，避免被 Eureka Server 认为服务时效将其剔除下线。服务续约就是发送一个 PUT 请求带上当前实例信息到类 InstanceResource 的 renewLease 方法进行服务续约操作。 进入到 PeerAwareInstanceRegistryImpl 的 renew 方法可以看到，服务续约步骤大体上和服务注册一致，先更新当前 Eureka Server 节点的状态，服务续约成功后再用异步的方式同步状态到其它 Eureka Server 节上，主要调用流程如下图所示： 服务下线（Cancel）当服务提供者（比如 Demo 中的 service-provider）停止服务时，会发送请求告知注册中心 Eureka Server 进行服务剔除下线操作，防止服务消费者从注册中心调用到不存在的服务。服务下线就是发送一个 DELETE 请求带上当前实例信息到类 InstanceResource 的 cancelLease 方法进行服务剔除下线操作。 进入到 PeerAwareInstanceRegistryImpl 的 cancel 方法可以看到，服务续约步骤大体上和服务注册一致，先在当前 Eureka Server 节点剔除下线该服务，服务下线成功后再用异步的方式同步状态到其它 Eureka Server 节上，主要调用流程如下图所示： 服务剔除（Eviction）服务剔除是注册中心 Eureka Server 在启动时就启动一个守护线程 evictionTimer 来定期（默认为 60 秒）执行检测服务的，判断标准就是超过一定时间没有进行 Renew 的服务，默认的失效时间是 90 秒，也就是说当一个已注册的服务在 90 秒内没有向注册中心 Eureka Server 进行服务续约（Renew），就会被从注册中心剔除下线。失效时间可以通过配置 eureka.instance.leaseExpirationDurationInSeconds 进行修改，定期执行检测服务可以通过配置 eureka.server.evictionIntervalTimerInMs 进行修改，主要调用流程如下图所示： 服务提供者（Service Provider）对于服务提供方（比如 Demo 中的 service-provider 服务）来说，主要有三大类操作，分别为 服务注册（Register）、服务续约（Renew）、服务下线（Cancel），接下来看看这三个操作是如何实现的。 服务注册（Register）一个服务要对外提供服务，首先要在注册中心 Eureka Server 进行服务相关信息注册，能进行这一步的前提是你要配置 eureka.client.register-with-eureka=true，这个默认值为 true，注册中心不需要把自己注册到注册中心去，把这个配置设为 false，这个调用比较简单，主要调用流程如下图所示： 服务续约（Renew）服务续约是由服务提供者方定期（默认为 30 秒）发起心跳的，主要是用来告知注册中心 Eureka Server 自己状态是正常的还活着，可以通过配置 eureka.instance.lease-renewal-interval-in-seconds 来修改，当然服务续约的前提是要配置 eureka.client.register-with-eureka=true，将该服务注册到注册中心中去，主要调用流程如下图所示： 服务下线（Cancel）当服务提供者方服务停止时，要发送 DELETE 请求告知注册中心 Eureka Server 自己已经下线，好让注册中心将自己剔除下线，防止服务消费方从注册中心获取到不可用的服务。这个过程实现比较简单，在类 DiscoveryClient 的 shutdown 方法加上注解 @PreDestroy，当服务停止时会自动触发服务剔除下线，执行服务下线逻辑，主要调用流程如下图所示： 服务消费者（Service Consumer）这里的服务消费者如果不需要被其它服务调用的话，其实只会涉及到两个操作，分别是从注册中心 获取服务列表（Fetch） 和 更新服务列表（Update）。如果同时也需要注册到注册中心对外提供服务的话，那么剩下的过程和上文提到的服务提供者是一致的，这里不再阐述，接下来看看这两个操作是如何实现的。 获取服务列表（Fetch）服务消费者方启动之后首先肯定是要先从注册中心 Eureka Server 获取到可用的服务列表同时本地也会缓存一份。这个获取服务列表的操作是在服务启动后 DiscoverClient 类实例化的时候执行的。 可以看出，能发生这个获取服务列表的操作前提是要保证配置了 eureka.client.fetch-registry=true，该配置的默认值为 true，主要调用流程如下图所示： 更新服务列表（Update）由上面的 获取服务列表（Fetch） 操作过程可知，本地也会缓存一份，所以这里需要定期的去到注册中心 Eureka Server 获取服务的最新配置，然后比较更新本地缓存，这个更新的间隔时间可以通过配置 eureka.client.registry-fetch-interval-seconds 修改，默认为 30 秒，能进行这一步更新服务列表的前提是你要配置 eureka.client.register-with-eureka=true，这个默认值为 true。主要调用流程如下图所示： 总结工作中项目使用的是 Spring Cloud 技术栈，它有一套非常完善的开源代码来整合 Eureka，使用起来非常方便。之前都是直接加注解和修改几个配置属性一气呵成的，没有深入了解过源码实现，本文主要是阐述了服务注册、服务发现等相关过程和实现方式，对 Eureka 服务发现组件有了更近一步的了解。 参考文章Netflix EurekaService Discovery in a Microservices Architecture]]></content>
      <categories>
        <category>Java</category>
        <category>服务发现</category>
        <category>Eureka</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>服务发现</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020 年 JVM 生态报告解读]]></title>
    <url>%2Fpost%2Fe09f0428.html</url>
    <content type="text"><![CDATA[前言做过 Java 开发的同学都知道，JVM（Java 虚拟机） 是 Java 实现的基础，虽然在平时工作中真正运用到的时候可能并不多，但是一个程序员想要上升到高级层次，那就必须知道 Java 到底是怎么运行的，这就有必要去学习了解 JVM 的相关知识了。学习 JVM 可以能更深入的理解 Java 这门语言，可以清楚知道Java程序是如何执行的以及为未来排查线上问题打下坚实的基础。接下来我们看看 2020 年的 JVM 生态报告和最新趋势，值得我们每个 Java 开发者去关注了解。 JDK 厂商占比Oracle JDK 和 Open JDK 加起来占比将近 60%，其中 Oracle JDK 占比略多一些，Oracle JDK 和 Open JDK 都是市场上的热门选择，我们看看二者之间的一些差异。Oracle JDK 更多的关注稳定性，更适合企业级用户，而 Open JDK 相对而言没有那么稳定，它会经常发布一些新特性。Oracle JDK 支持长期发布的更改，而 Open JDK 仅支持计划和完成下一个发行版，还有一个就是 Oracle JDK 是根据 二进制代码许可协议 获得许可，而 Open JDK 是根据 GPL v2 许可获得许可。使用 Oracle 平台时会产生一些许可影响。如 Oracle 宣布的那样，在没有商业许可的情况下，在 2019 年 1 月之后发布的 Oracle Java SE 8 的公开更新将无法用于商业，商业或生产用途。但是，Open JDK 是完全开源的，可以自由使用。 愿意付费用户占比很少只有 9% 的用户表示愿意为 JDK 支付费用，还有 86% 的用户表示并不想为 JDK 支付费用，可以看出大部分用户其实对 JDK 的付费使用还是不赞同的，目前来看，如果要真正实行付费模式还是有点难。不过人们选择为 JDK 支付费用时，Oracle 还是当之无愧的大赢家的。自从 JDK9 发布之后，以后每年的 3 月和 9 月都会发布一个新的版本，这个发布节奏的改变，这个对许多用户的版本更新策略还是有一定的影响。调查结果显示这个发布节奏的变更影响了三分之一的开发者们是否决定为其支付费用。 Java 8 仍然是主流版本从 Java 9 之后对 JDK 的结构做了很大的调整，这也是影响人们升级的原因之一，根据报告结果来看 Java 8 仍然是大家使用最多的版本，但是在 2018 年 9 月发布了第一个 LTS(长期支持) 版的 Java 11 之后，有四分之一的开发者在生产环境中使用了 Java 11。因为发布节奏的原因，大部分开发者还是不愿意每 6 个月就对版本进行一次更新，版本迁移成本其实也不低，还有新版本在生产环境的稳定性也是其中的一个考虑因素。 Kotlin 在 JVM 类语言中占比第二在 JVM 类语言语言中 Java 占比 86.9% 稳居第一，除了 Java 语言之外，Kotlin 语言在 JVM 类语言占比第二占比 5.5%，Kotlin 从去年的 2.4% 增加到今年的 5.5%，JVM 类语言的用户中 Kotlin 使用率的增长，因为它可以与 Java 无缝集成也不足为奇，像在 Spring Boot 框架中使用 Kotlin 进行开发也很容易。Kotlin 也一直在创新，积极拥抱 Java 的大腿，在 Java 的新版本中也在试图整合一些 Kotlin 的概念。 Spring 依然是 Java 框架中的王者有十分之六的开发者依赖 Spring 框架来构建他们的程序，这对于众多的第三方开源框架来说，这是一个很高的占比，Spring Framework 依然是 Java 开发框架中的王者，Spring 框架已经发布了很长一段时间了，通过长时间的改进和创新，无疑 Spring 现在已经成为 Java 生态系统中的最重要的框架。在众多的使用者中有将近三分之二的用户使用 Spring 5，可见大家对 Spring 框架的新版使用率还是很高的。 Spring Boot 是主流的服务器端 Web 框架服务器端依然是 Spring 的天下，其中有一半的人使用的是 Spring Boot 框架，还有将近的三分之一的人使用的是 Spring MVC 框架，前几年比较火的 Struts 框架已经开始没落了，这个占比和现在市场上比较流行微服务架构是分不开，因为 Spring Boot 框架天生就是为微服务而生的，它可以快速实现微服务。使用基于 Spring Boot 的 Spring Cloud 框架可以快速搭建一个分布式的服务或应用。 IntelliJ IDEA 是主流的开发工具IntelliJ IDEA 是 Java 开发者们使用最广泛的开发工具，调查结果显示有 62% 的开发人员使用社区免费版和付费终极版。Apache NetBeans 以 10% 的市场份额保持在第三位，和去年的调查结果一致。可以发现被业界广泛称赞的 VS Code 神级编辑器在 Java 开发人员中并没有想象的那么受欢迎。 Maven 是主流的项目构建管理工具Maven 是一个软件项目管理和自动构建的工具，由 Apache 基金会 维护。它基于项目对象模型(POM)概念，Maven 利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。调查结果显示它在排名仍是第一，一直都是主流的项目构建工具，排名第二的 Gradle 一直保持着增长的趋势，在 2019 年占比达到四分之一，而在 2012 年占比高达 40% 的老牌的构建工具 Ant 将逐渐退出舞台，到 2019 年占比不到 10%。可以明确的是，构建工具之间的竞争从不会停止，能否及时更新发布一些可以解决使用者痛点的工具是大家选择的因素之一。 Jenkins 仍然是持续集成工具中的王者和我们大多数 Java 开发人员的期望一致，Jenkins 以高达 58% 的占比排名稳居第一，排名第二的 GitLab 占比仅为 6%，有趣的是没有使用工具的也高达 12%，虽然不适用工具的人数占比比去年低了很多，但是这个占比还是让人有点儿惊讶。 生态报告来源：https://snyk.io/blog/jvm-ecosystem-report-2020 PS：关注公众号「mghio」，回复关键字 JVM 获取 2020 年 JVM 生态报告 PDF 版原文。]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统之 — CAP 定理]]></title>
    <url>%2Fpost%2F11cb7677.html</url>
    <content type="text"><![CDATA[前言在互联网时代，我们的应用都是分布式系统，部署在 N 台机器上。说到分布式系统我们就不得不说分布式系统的祖先——集中式系统。它和分布式系统是两个完全相反的概念，集中式系统就是把所有的程序和功能都放到一台主机上，从而对外提供服务。集中式系统的优点就是容易理解、维护方便，它的的弊端也很明显，如果这个主机出故障了那么整个系统就崩溃了。著名投资家巴菲特有个关于投资的名言： 不要把鸡蛋放在一个篮子里 对于我们的系统而言也是如此，我们不可能保证主机永远不坏、也无法保证自己的程序永远不会出 bug，所以问题是无法避免的，我们只能把“鸡蛋”分散到不同的“篮子”里，降低系统出故障的风险，这就是我们为什么需要分布式系统的原因之一。使用分布式系统的另一个理由就是扩展性，毕竟单台主机都会有性能的极限，分布式系统可以通过增加主机数量来实现横向水平性能的扩展。接下来我们看看分布式系统中的一个基本定理——CAP定理。 什么是 CAP 定理CAP 定理指出对于一个分布式系统来说，不可能同时满足以下三点： 一致性（Consistency） 可用性（Availability） 分区容错性（Partition tolerance） 定理看起来很简单，但是一致性、可用性、分区容错性究竟是代表什么意思呢？理解定理的最简单的方式就是想象一个有两个节点分别处在不同的分区（PS：可以简单的把分区理解为不同的子网络）的分布式系统。 场景假设我们假定一个很简单的分布式系统，系统由两个系统 S1 和 S2 组成。两个系统上面有两个相同的变量 K，该变量在两个系统对应的初始值为 V0。系统 S1 和 S2 可以进行通信同时也对外提供服务。我们假定的分布式系统如下所示： 客户端 client 可以向 S1 和 S2 任何一个系统发起读和写请求。当一个服务接收到发过来的请求后进行一些相关业务操作，然后返回给客户端 client，发起写请求的过程如下图所示： 客户端发起读请求的过程如下所示： 我们的分布式系统模型建立好了，接下来我们通过这个模型来分析CAP 定理中的一致性、可用性和分区容错性的具体含义。 一致性（Consistency）一致性要求在一个写操作完成之后的任何读操作都必须返回该值或者以后进行写操作的结果。在满足一致性的分布式系统中，客户端发起一个写请求到分布式系统的任何一个子系统中，然后再向该系统中任何一个子系统发起读请求查询该变量对应的值，都会返回上次更新的最新结果。客户端向一个不满足一致性的分布式系统发起写-读请求的过程如下所示： 当客户端向系统 S1 发送写请求(write V1)，得到成功返回响应后，再向系统 S2 发送读请求读取该变量的值，系统 S2 还是返回旧值 V0。另一方面，我们看看客户端向一个满足一致性的分布式系统发起写-读请求的过程： 在这个满足一致性的系统中，在上述过程中系统 S1 在返回客户端请求结果之前会先把最新值 V1 发送到系统 S2，然后才返回客户端的写请求结果。因此，当客户端再去请求系统 S2 的时候就会返回最新值 V1。 可用性（Availability）可用性要求在分布式系统中非故障节点收到的每一个请求都必须返回响应。在一个满足可用性的分布式系统中，如果客户端向系统中任意一个节点发送请求并且服务器没有崩溃的情况下，则该节点必须响应客户端，不管是哪个节点，只要收到请求，就必须告诉用户，到底是 V0 还是 V1，否则就不满足可用性，不允许服务器忽略客户端的请求。 分区容错性（Partition tolerance）分区容错表明当消息从一个节点向另一个节点发送消息的过程中，消息可能会丢失。以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在一致性和可用性之间做出选择。如果所有消息都无法发送的话，分布式系统的各个节点将无法同步消息。如下所示： 一般来说，分区容错无法避免，因此可以认为CAP定理的分区容错性总是成立。CAP 定理告诉我们，剩下的一致性和可用性无法同时做到。通常我们为了分区容错，我们的系统必须保证能够在任意网络分区下正常运行。 为何不能同时满足一致性和可用性我们现在知道了一致性、可用性、分区容错性所表示的具体含义，接下来看看为什么在一个分布式系统中不能同时满足一致性和可用性。我们假定存在一个同时满足这三个特性的系统。首先要做的就是对该系统进行分区，分区后系统如下所示： 下一步，客户端向分布式系统的节点 S1 发送一个写请求(write V1)，系统只要是可用的，该节点总是会返回响应。但是系统存在网络分区，因此节点 S1 无法将最新值 V1 通知节点 S2 去更新。如下所示： 接下来，客户端向分布式系统的节点 S2 发送一个读请求（read K）查询变量 K 的值，同样的，系统只要是可用的，该节点总是会返回响应，但是系统存在网络分区，因此节点 S2 无法从节点 S1 获取到最新值 V1 进行更新。如下所示： 客户端已经向节点 S1 发送写请求（write V1）成功后，再向节点 S2 发起读请求，得到的返回值是旧值 V0。这和我们假设的一致性冲突。如果要保证节点 S1 的一致性，那么节点 S1 必须在写操作时，锁定节点 S2 的读操作和写操作。只有当数据同步后，才能重新开放节点 S2 的读写操作。那么在锁定期间，S2不能读写，它就没有可用性了。再来看看，我们如果保证节点 S2 的可用性，那么就不能锁定节点 S2 的读写操作，所以一致性不成立。所以，节点 S2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性，如果追求所有节点的可用性，那就没法做到一致性了。 总结CAP定理指明了分布式系统的三大指标一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）不能同时满足，该定理是分布式系统的基本定理，也是理解分布式系统的起点。(PS: 像我们常用的注册中心 Eureka，因为节点之间的状态同步采用的异步方式，所以不能保证任意时刻各个节点间的状态一定是一致的，只能保证节点间最终状态是一致的。所以按照CAP理论，Eureka 的选择就是放弃了一致性，选择可用性和分区容错性。)]]></content>
      <categories>
        <category>分布式系统</category>
        <category>CAP定理</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>CAP定理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA 最新版（2019.3）激活教程]]></title>
    <url>%2Fpost%2Ff440d00b.html</url>
    <content type="text"><![CDATA[前言相信做 Java 开发的朋友们绝大部分人应该都是用 IntelliJ IDEA 作为开发工具，没用过的朋友们建议将你的开发工具换成这个，关于它的优点可以去 Google 一下，我之前都是用 Eclipse 作为开发工具，自从用过一次 IDEA 之后就再也回不去了。。。今天早上更新（作死）了一下 IDEA 到最新版（2019.3.1），安装完毕之后进入就提示说之前的激活码失效了，经过一顿搜索之后终于成功激活了，在此记录一下激活过程。 Step 1 升级 IDEA 到 2019.3 版本如果之前电脑安装过 IDEA，依次选择菜单项 IntelliJ IDEA -&gt; About IntelliJ IDEA 查看 IDEA 的版本（PS: windows 系统菜单项可能不同），如果不是 2019.3 版本，则要到 官网 下载 2019.3.1 版本，具体安装过程比较简单，安装过程有问题的朋友们请自行 Google。 Step 2 下载补丁包扫码关注微信公众号 mghio 后回复「idea」获取激活补丁包。 Step 3 编辑 IDEA 的 idea.vmoptions 文件经过 Step 1 安装完成之后，打开 IDEA 开发工具，然后它会提示要激活，这里我们先选择 试用 30 天。 然后将 Step 2 我们下载好的激活补丁包 jetbrains-agent.jar 拷贝到 IDEA 安装目录的 bin 目录下。 编辑 IDEA 的 idea.vmoptions（PS:推荐直接从IDEA中编辑），依次选择菜单项 Help -&gt; Edit Custom VM Optons...。 点击打开编辑，在其内容最后追加如下代码： 1-javaagent:你的 IDEA 的安装目录/bin/jetbrains-agent.jar Step 4 重启后输入激活码激活退出 IDEA 重新启动进入，依次选择菜单项 Help -&gt; Register...。 进入后选择 Activation code 以输入激活码方式激活，在第二步 Step 2 下载补丁包 中下载的 txt 文件（文件名：激活码.txt）为激活码，这里也贴一下，激活码如下（PS: 鼠标移至激活码区域，点击右侧 「复制」 按钮即可复制）： 1KNBB2QUUR1-eyJsaWNlbnNlSWQiOiJLTkJCMlFVVVIxIiwibGljZW5zZWVOYW1lIjoiZ2hib2tlIiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IiIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiQUMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiRFBOIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlBTIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkdPIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRNIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkNMIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJTMCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSRCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJQQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSTSIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJXUyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQiIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSU1UiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In1dLCJoYXNoIjoiMTI3OTY4NzcvMCIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-1iV7BA/baNqv0Q5yUnAphUmh66QhkDRX+qPL09ICuEicBqiPOBxmVLLCVUpkxhrNyfmOtat2LcHwcX/NHkYXdoW+6aS0S388xe1PV2oodiPBhFlEaOac42UQLgP4EidfGQSvKwC9tR1zL5b2CJPQKZ7iiHh/iKBQxP6OBMUP1T7j3Fe1rlxfYPc92HRZf6cO+C0+buJP5ERZkyIn5ZrVM4TEnWrRHbpL8SVNq4yqfc+NwoRzRSNC++81VDS3AXv9c91YeZJz6JXO7AokIk54wltr42FLNuKbozvB/HCxV9PA5vIiM+kZY1K0w5ytgxEYKqA87adA7R5xL/crpaMxHQ==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG/PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg/nYV31HLF7fJUAplI/1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4/G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd/GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt/wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59/THOT7NJQhr6AyLkhhJCdkzE2cob/KouVp4ivV7Q3Fc6HX7eepHAAF/DpxwgOrg9smX6coXLgfp0b1RU2u/tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB/40BjpMUrDRCeKuiBahC0DCoU/4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV/g== 部分朋友输入以上激活码后点击激活可能会出现如下报错提示：Your activation code could not be validated（error 1653219），未出现此错误提示的朋友可以跳过以下步骤。 出现此错误是因为没有屏蔽 account.jetbrains.com 的 443 端口，因此修改本地 hosts 文件在其内容追加以下内容即可。 10.0.0.0 https://account.jetbrains.com:443 修改保存 hosts 文件后，再次激活即可激活。 Step 5 验证是否激活重启 IDEA 后，依次选择菜单项 IntelliJ IDEA -&gt; About IntelliJ IDEA，可以看到激活到期日期为：2089-07-08。 至此， IntelliJ IDEA 激活完成。 总结以上激活步骤只针对 IntelliJ IDEA 的 2019.3.1 版本，不同的版本可能无法激活，在激活前请确认好你所使用的 IDEA 版本。激活码和激活补丁包要一起使用，单独使用无效，在激活过程中有问题请在文末留言区留言讨论。]]></content>
      <categories>
        <category>Java</category>
        <category>IDEA</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 反射机制（二）]]></title>
    <url>%2Fpost%2F7528c810.html</url>
    <content type="text"><![CDATA[前言在上篇 Java 反射机制（一） 介绍了一些 Java 反射相关的常用 API ，在知道了如何去使用反射之后，作为一个合格的工程师，下一步肯定是要去了解它的如何实现的，我们今天就来看看在 JDK 源码中是如何去实现反射的(PS:以下源码分析基于 JDK1.8)。 Field 类 set 方法的实现Field 类的 set 方法是在运行时用来动态修改一个类的属性的值，进入到 Field 类的 set 方法的源码如下： 1234567891011public void set(Object obj, Object value) throws IllegalArgumentException, IllegalAccessException&#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; getFieldAccessor(obj).set(obj, value);&#125; 首先根据 override 判断是否需要检查字段的访问权限，然后通过 getFieldAccessor 方法获得一个 FieldAccessor 字段访问者对象，最后调用的是 FieldAccessor 类的 set 方法进行下一步操作的，FieldAccessor 是一个接口，定义了对字段的一些操作，该接口有如下一些实现类： 要看 set 到底调用的是哪个实现类的方法，那么我们需要看看 getFieldAccessor() 返回的是哪个类的对象，下面是 getFieldAccessor 方法的源码实现： 12345678// security check is done before calling this methodprivate FieldAccessor getFieldAccessor(Object obj) throws IllegalAccessException&#123; boolean ov = override; FieldAccessor a = (ov) ? overrideFieldAccessor : fieldAccessor; return (a != null) ? a : acquireFieldAccessor(ov);&#125; 这里先通过 override 来获取不同的缓存的 FieldAccessor，其中 overrideFieldAccessor 代表本类覆盖父类的字段访问者对象缓存，fieldAccessor 是本类的字段访问器对象缓存。如果缓存存在的话就直接复用之前的对象，否则就调用 Field 类的 acquireFieldAccessor 方法获取。我们进入到 acquireFieldAccessor 方法中看看，方法源码如下： 123456789101112131415161718private FieldAccessor acquireFieldAccessor(boolean overrideFinalCheck) &#123; // First check to see if one has been created yet, and take it // if so FieldAccessor tmp = null; if (root != null) tmp = root.getFieldAccessor(overrideFinalCheck); if (tmp != null) &#123; if (overrideFinalCheck) overrideFieldAccessor = tmp; else fieldAccessor = tmp; &#125; else &#123; // Otherwise fabricate one and propagate it up to the root tmp = reflectionFactory.newFieldAccessor(this, overrideFinalCheck); setFieldAccessor(tmp, overrideFinalCheck); &#125; return tmp;&#125; 从 acquireFieldAccessor 的源码中我们可以看到，先判断是否已存在 FieldAccessor 对象，如果存在的话那么就会复用之前的 FieldAccessor 对象，否则就使用 reflectionFactory 工厂的 newFieldAccessor 方法生成一个新的 FieldAccessor 对象出来。所以我们就要进到 newFieldAccessor 方法里面看看是如何生成的，方法源码如下： 1234public FieldAccessor newFieldAccessor(Field var1, boolean var2) &#123; checkInitted(); return UnsafeFieldAccessorFactory.newFieldAccessor(var1, var2);&#125; 从 newFieldAccessor 方法代码可以得知，在方法里面是通过 UnsafeFieldAccessorFactory 类的 static 方法 newFieldAccessor 来生产 FieldAccessor 的，那么我们继续进入到 UnsafeFieldAccessorFactory 类的 newFieldAccessor 方法里面看看，方法源码如下： 123456789101112131415161718192021222324252627282930313233static FieldAccessor newFieldAccessor(Field var0, boolean var1) &#123; Class var2 = var0.getType(); boolean var3 = Modifier.isStatic(var0.getModifiers()); boolean var4 = Modifier.isFinal(var0.getModifiers()); boolean var5 = Modifier.isVolatile(var0.getModifiers()); boolean var6 = var4 || var5; boolean var7 = var4 &amp;&amp; (var3 || !var1); if (var3) &#123; UnsafeFieldAccessorImpl.unsafe.ensureClassInitialized(var0.getDeclaringClass()); if (!var6) &#123; if (var2 == Boolean.TYPE) &#123; return new UnsafeStaticBooleanFieldAccessorImpl(var0); &#125; else if (var2 == Byte.TYPE) &#123; return new UnsafeStaticByteFieldAccessorImpl(var0); &#125; else if (var2 == Short.TYPE) &#123; return new UnsafeStaticShortFieldAccessorImpl(var0); &#125; else if (var2 == Character.TYPE) &#123; return new UnsafeStaticCharacterFieldAccessorImpl(var0); &#125; else if (var2 == Integer.TYPE) &#123; return new UnsafeStaticIntegerFieldAccessorImpl(var0); &#125; else if (var2 == Long.TYPE) &#123; return new UnsafeStaticLongFieldAccessorImpl(var0); &#125; else if (var2 == Float.TYPE) &#123; return new UnsafeStaticFloatFieldAccessorImpl(var0); &#125; else &#123; return (FieldAccessor)(var2 == Double.TYPE ? new UnsafeStaticDoubleFieldAccessorImpl(var0) : new UnsafeStaticObjectFieldAccessorImpl(var0)); &#125; &#125; // 剩下的部分省略... &#125; &#125; 从以上 UnsafeFieldAccessorFactory 类的 newFieldAccessor 方法代码可以看出，方法里面通过类的字段修饰符类型和字段的类类型共同决定返回的 FieldAccessor 实现类，这里要注意一下方法里面这几个变量的含义： var3（isStatic）：静态属性，也就是 static 关键字修饰的属性。 var4（isFinal）：final 关键字修饰的属性。 var5（isVolatile）：valatile 关键字修饰的属性。 var6（isQualified）：valatile 关键字或者 final 关键字修饰的属性。 var7 (isReadOnly)：是否只读属性，final 关键字修饰的属性或者 static 关键字修饰并且不能覆盖（override = false）的属性 举一个例子，假设在一个类中的字段声明为 public static String name，那么返回的字段访问器为 UnsafeStaticCharacterFieldAccessorImpl，我们看看这个类的 set 方法是如何实现的，方法源码如下： 123456789101112131415public void set(Object var1, Object var2) throws IllegalArgumentException, IllegalAccessException &#123; if (this.isFinal) &#123; this.throwFinalFieldIllegalAccessException(var2); &#125; if (var2 == null) &#123; this.throwSetIllegalArgumentException(var2); &#125; if (var2 instanceof Character) &#123; unsafe.putChar(this.base, this.fieldOffset, (Character)var2); &#125; else &#123; this.throwSetIllegalArgumentException(var2); &#125;&#125; 从上面方法的代码得知，方法最终还是通过 Unsafe 类的 native 方法 putChar(Object var1, long var2, char var4) 来实现的，有关 Unsafe 类的介绍请看这篇文章（Java魔法类：Unsafe应用解析）。 Method 类 invoke 方法的实现Method 类的 invoke 方法用来在运行时动态调用对象的方法，我们进入到 Method 类的 invoke 方法中看看在 JDK 中到底是怎么做的，方法源码如下： 123456789101112131415public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; MethodAccessor ma = methodAccessor; // read volatile if (ma == null) &#123; ma = acquireMethodAccessor(); &#125; return ma.invoke(obj, args);&#125; 从以上方法代码我们可以看到，和上文说的的 Field 类一样，首先也是先根据 override 进行了一些权限检查，最后调用的是 MethodAccessor 的 invoke 方法进行处理，这个方法访问器 MethodAccessor 是一个接口，它只有一个操作方法调用的 invoke 方法，它有如下三个实现类： 要想知道 ma.invoke 具体调用的是哪个类的方法，我们需要看看方法 acquireMethodAccessor 返回的对象是哪个，该方法的源码如下： 123456789101112131415private MethodAccessor acquireMethodAccessor() &#123; // First check to see if one has been created yet, and take it // if so MethodAccessor tmp = null; if (root != null) tmp = root.getMethodAccessor(); if (tmp != null) &#123; methodAccessor = tmp; &#125; else &#123; // Otherwise fabricate one and propagate it up to the root tmp = reflectionFactory.newMethodAccessor(this); setMethodAccessor(tmp); &#125; return tmp;&#125; 从以上方法 acquireMethodAccessor 的源码可以看出，首先会先先判断是否已经存在了对应的 MethodAccessor 对象，如果有就会复用这个对象，否则就调用工厂 reflectionFactory 的 newMethodAccessor 方法生成一个 MethodAccessor 对象出来。那么我们就需要进入到方法 newMethodAccessor 中，方法源码如下： 1234567891011public MethodAccessor newMethodAccessor(Method var1) &#123; checkInitted(); if (noInflation &amp;&amp; !ReflectUtil.isVMAnonymousClass(var1.getDeclaringClass())) &#123; return (new MethodAccessorGenerator()).generateMethod(var1.getDeclaringClass(), var1.getName(), var1.getParameterTypes(), var1.getReturnType(), var1.getExceptionTypes(), var1.getModifiers()); &#125; else &#123; NativeMethodAccessorImpl var2 = new NativeMethodAccessorImpl(var1); DelegatingMethodAccessorImpl var3 = new DelegatingMethodAccessorImpl(var2); var2.setParent(var3); return var3; &#125;&#125; 从方法 newMethodAccessor 的代码可以看到，方法首先是使用 Method 对象作为入参生成了 NativeMethodAccessorImpl 对象，然后再使用 NativeMethodAccessorImpl 对象作为入参生成了 DelegatingMethodAccessorImpl 对象。这个使用了代理模式，将 NativeMethodAccessorImpl 交给了 DelegatingMethodAccessorImpl 类进行了代理，进入到代理类 DelegatingMethodAccessorImpl 中可以看到： 从上面的红色方框可以看到，在类 DelegatingMethodAccessorImpl 的构造方法中将参数赋值给类中的 delegate 属性，所有上所说的 ma.invoke 最终会进入到 DelegatingMethodAccessorImpl 代理类的 invoke，方法里调用的是 delegate 属性的 invoke 方法，该属性声明的类型为抽象类 MethodAccessorImpl，它有如下两个实现类： 按照上文所说的，这里的 delegate 属性是 NativeMethodAccessorImpl 对象，那么就进入到 NativeMethodAccessorImpl 的 invoke 方法中，方法源码如下： 12345678public Object invoke(Object var1, Object[] var2) throws IllegalArgumentException, InvocationTargetException &#123; if (++this.numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(this.method.getDeclaringClass())) &#123; MethodAccessorImpl var3 = (MethodAccessorImpl)(new MethodAccessorGenerator()).generateMethod(this.method.getDeclaringClass(), this.method.getName(), this.method.getParameterTypes(), this.method.getReturnType(), this.method.getExceptionTypes(), this.method.getModifiers()); this.parent.setDelegate(var3); &#125; return invoke0(this.method, var1, var2);&#125; 类 NativeMethodAccessorImpl 的 invoke 方法会先判断此次调用是否超过 ReflectionFactory.inflationThreshold() 方法返回的阈值（PS：默认的阈值大小为 15），如果超过了该阈值，则使用方法访问生成器重新生成一个 MethodAccessorImpl，并将 DelegatingMethodAccessorImpl 的 delegate 属性指向这个新生成的 MethodAccessorImpl 对象。从 Reflectionfactory 工厂类的一下注释： 可以得知 JVM 初次加载字节码实现反射的时候，使用 Method.invoke 和 Constructor.newInstance 方式加载所花费的时间是使用原生代码加载所花费的时间的 3 - 4 倍。这也就是我们平常说为什么频繁使用反射的应用需要花费更多的时间。JVM 作者们为了避免这种花费较长的加载时间，我们在第一次加载的时候重用了 JVM 的入口，之后切换到字节码实现的实现。正如注释所述，在 MethodAccessor 接口的实现中，有两个不同的版本，一个 Java 实现的，一个是 Native 实现的。Java 版本实现的版本在初始化的时需要比较多的时间，但长久来说性能会更好一些；而 Native 版本则正好相反，在初始化时相对较快，但是在运行一段时间之后性能就不如 Java 版本的了。为了权衡两种版本的特性，sun 公司的 JDK 使用了 inflation 机制，让 Java 方法在被反射调用时，开头的几次调用使用 native 版，等反射调用次数超过阈值时则生成一个专用的 MethodAccessor 实现类，生成其中的 invoke 方法的字节码，以后对该 Java 方法的反射调用就会使用 Java 版。 总结本文主要介绍反射调用 set(Object obj, Object value) 方法和 invoke(Object obj, Object... args) 方法的底层实现，由于水平有限本人暂时还没有能力分析 JVM 的实现，这里只分析到最终 native 方法的调用。底层会依赖到 Unsafe 类来执行一些低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升 Java 运行效率、增强 Java 语言底层资源操作能力方面起到了很大的作用。对于属性反射的方法 setXXX 和 getXXX 的实现分别对应 Unsafe 类的 putXXX 和 getXXX 方法，也就是说完全依赖 Unsafe 类中的 native 方法来实现的；对于方法反射的方法 invoke 底层调用的是 NativeMethodAccessorImpl 类的 invoke0 的 native 方法来实现的。对于反射构造器调用的实现，读者可以自己进入其源码进行分析，大体上和反射方法调用的实现类似。 参考文章 JAVA深入研究——Method的Invoke方法。]]></content>
      <categories>
        <category>Java</category>
        <category>反射</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 反射机制（一）]]></title>
    <url>%2Fpost%2F102cd3d9.html</url>
    <content type="text"><![CDATA[前言在 Java 中有两种方式可以让我们在运行时识别对象和类的信息。一种是 RTTI（运行时类型识别：Run-Time Type Identification），它假定了我们在编译时已经知道了所有的类型；另一种是我们本文要说的反射机制，它允许我们在运行时获取和使用类的信息。无论是 RTTI 还是反射，其本质都是一样的，都是去动态的获取类的信息。它们唯一不同的是，RTTI 在编译时期知道要解析的类型，而反射是在运行时才知道要解析的类型。 反射概述反射就是把 Java 类中的各个部分（属性、方法、构造方法等）映射成一个个对象。Class 类与 java.lang.reflect 类库一起对反射的概念提供了支持，类库中包含了 Field、Method 及 Constructor 类，每个类都实现了 Member 接口。这些类型的对象都是由 JVM 运行时创建的，用来表示未知类里对应的成员。这样我们就可以使用 Constructor 创建新的对象，用 get 和 set 方法读取和修改类中与 Field 对象关联的字段，用 invoke 方法调用类中与 Method 对象关联的方法等。Java 反射机制是在运行状态中的，对于任意一个类我们可以通过反射获取这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。重要的是，要认识到反射机制并没有什么特别之处，当我们通过反射和一个未知类型的对象打交道时，JVM 只是简单的对这个对象做检查，看它属于哪个类，在用它做其它事情之前必须先加载那个类 Class 对象。所以那个类的字节码文件对象对于 JVM 来说必须是可获取的，要么在本地机器上，要么通过网络获取。 反射 API 的使用想要通过反射获取一个类的信息之前，首先要先获取这个类的 Class 对象，在 Java 中所有类型都有与之关联的 Class 对象。 获取类的 Class 对象在 Java 中获取一个类的 Class 对象有三种方式：第 ① 种 使用 Class 类的 forName 静态方法，当我们知道一个类的全路径时，可以通过 Class.forName 方法获取类的 Class 对象。 12Class stringClass = Class.forName("java.lang.String");System.out.println(stringClass); 运行结果 1class java.lang.String 第 ② 种 使用 .class 获取，这种方式只适合在编译前就已经知道了要操作的 Class。 12Class stringClass = String.class;System.out.println(stringClass); 运行结果 1class java.lang.String 第 ③ 种 使用 getClass() 方法获取 12Class stringClass = "mghio".getClass();System.out.println(stringClass); 运行结果 1class java.lang.String 通过反射创建类对象通过反射创建类对象有两种方式： 第 ① 种 通过调用 Class 对象的 newInstance() 方法创建 12Class&lt;Person&gt; personClass = Person.class;Person person = personClass.newInstance(); 第 ② 种 通过调用 Constructor 对象的 newInstance() 方法创建 123Class&lt;Person&gt; personClass = Person.class;Constructor personConstructor = personClass.getConstructor();Person person = (Person) personConstructor.newInstance(); 两者的区别是，通过 Class 的 newInstance 方法只能通过无参构造方法创建，这就要求这个类必须有一个无参的构造方法，而通过 Constructor 的 newInstance 可以指定参数来选择特定的构造方法来创建对象。以下代码就是指定参数然后通过特定的构造方法创建对象的。 123Class&lt;Person&gt; personClass = Person.class;Constructor personConstructor = personClass.getConstructor();Person person = (Person) personConstructor.newInstance("mghio", "中国上海"); 通过反射获取类的属性Class 类提供了两种方式获取一个类的属性。第 ① 种 是通过 Class 对象的 getFields 方法获取类的属性，该方法只能获取类的 public 属性。 123Class&lt;Person&gt; personClass = Person.class;Field[] fields = personClass.getFields();System.out.println(Arrays.toString(fields)); 运行结果 12[public java.lang.String cn.mghio.blogmghiocode.reflect.Person.id, public java.lang.String cn.mghio.blogmghiocode.reflect.Person.name] 第 ② 种 是通过 Class 对象的 getDeclaredFields 方法获取类的属性，该方法可以获取类的所有属性（包括 private 修饰的属性）。 123Class&lt;Person&gt; personClass = Person.class;Field[] fields = personClass.getDeclaredFields();System.out.println(Arrays.toString(fields)); 运行结果 1234[public java.lang.String cn.mghio.blogmghiocode.reflect.Person.id, public java.lang.String cn.mghio.blogmghiocode.reflect.Person.name, protected java.lang.Integer cn.mghio.blogmghiocode.reflect.Person.age, private java.lang.String cn.mghio.blogmghiocode.reflect.Person.address] 通过反射获取类的方法Class 也提供了两种方式获取类的方法。第 ① 种 是通过 Class 对象的 getMethods 方法获取类的方法（包括继承而得的方法）。 123Class&lt;Person&gt; personClass = Person.class;Method[] methods = personClass.getMethods();System.out.println(Arrays.toString(methods)); 运行结果 12345[public java.lang.String cn.mghio.blogmghiocode.reflect.Person.toString(), public java.lang.String cn.mghio.blogmghiocode.reflect.Person.getAddress(), ...public final native java.lang.Class java.lang.Object.getClass(), public final native void java.lang.Object.notify()] 第 ② 种 是通过 Class 对象的 getDeclaredMethods 方法获取类的方法（只包含类中定义的方法，不包含继承而来的方法）。 123Class&lt;Person&gt; personClass = Person.class;Method[] methods = personClass.getDeclaredMethods();System.out.println(Arrays.toString(methods)); 运行结果 12345[public java.lang.String cn.mghio.blogmghiocode.reflect.Person.toString(), public java.lang.String cn.mghio.blogmghiocode.reflect.Person.getAddress(), ... protected void cn.mghio.blogmghiocode.reflect.Person.protectedMethod(), private void cn.mghio.blogmghiocode.reflect.Person.privateMethod()] 从以上结果可以看出这个方法只获取当前类中定义的方法，包含 private 方法，不会获取从父类中继承而来的方法。 通过反射获取类的构造方法Class 也提供了两种方式获取类的构造方法。第 ① 种 是通过 Class 对象的 getConstructors 方法获取类的构造方法（只能获取当前类的 public 构造方法）。 123Class&lt;Person&gt; personClass = Person.class;Constructor[] constructors = personClass.getConstructors();System.out.println(Arrays.toString(constructors)); 运行结果 1[public cn.mghio.blogmghiocode.reflect.Person(java.lang.String,java.lang.String,java.lang.Integer,java.lang.String)] 第 ② 种 是通过 Class 对象的 getDeclaredConstructors 方法获取类的构造方法（只包含类中定义的所有构造方法）。 123Class&lt;Person&gt; personClass = Person.class;Constructor[] constructors = personClass.getDeclaredConstructors();System.out.println(Arrays.toString(constructors)); 运行结果 123[public cn.mghio.blogmghiocode.reflect.Person(java.lang.String,java.lang.String,java.lang.Integer,java.lang.String), protected cn.mghio.blogmghiocode.reflect.Person(java.lang.String,java.lang.String), private cn.mghio.blogmghiocode.reflect.Person()] 通过反射获取类的类名Class 类提供了两种方式获取类的类名。第 ① 种 是通过 getName 方法获取类的全限定名（包含包名）。 123Class&lt;Person&gt; personClass = Person.class;String fullPersonClassName = personClass.getName();System.out.println(fullPersonClassName); 运行结果 1cn.mghio.blogmghiocode.reflect.Person 第 ② 种 是通过 Class 对象的 getSimpleName 方法获取类的类名（不包含包名）。 123 Class&lt;Person&gt; personClass = Person.class;String fullPersonClassName = personClass.getSimpleName();System.out.println(fullPersonClassName); 运行结果 1Person 通过反射获取类的修饰符可以通过 Class 类来获取一个类的修饰符，也就是我们熟知的 public、protected、private 等关键字，通过调用 getModifiers 方法来获取一个类的修饰符。 123Class&lt;Person&gt; personClass = Person.class;int modifyInt = personClass.getModifiers();System.out.println(modifyInt); 运行结果 11 返回 1 表示类 Person 的修饰符为 public，修饰符在 Modifier 类中都被包装成一个 int 类型的数字，部分修饰符定义如下 1234567891011121314151617/** * The &#123;@code int&#125; value representing the &#123;@code public&#125; * modifier. */public static final int PUBLIC = 0x00000001;/** * The &#123;@code int&#125; value representing the &#123;@code private&#125; * modifier. */public static final int PRIVATE = 0x00000002;/** * The &#123;@code int&#125; value representing the &#123;@code protected&#125; * modifier. */public static final int PROTECTED = 0x00000004; 通过反射获取类的包信息Class 对象通过 getPackage 方法获取类的包相关信息，可以使用 Class 对象通过如下的方式获取包信息 123Class&lt;Person&gt; personClass = Person.class;Package packageClazz = personClass.getPackage();System.out.println(packageClazz.getName()); 运行结果 1cn.mghio.blogmghiocode.reflect 通过反射获取类的父类可以通过 Class 类来获取一个类的父类，通过调用 getModifiers 方法来获取一个类的父类。 123Class&lt;Person&gt; personClass = Person.class;Class superclass = personClass.getSuperclass();System.out.println(superclass.getName()); 运行结果 1java.lang.Object 以上运行结果表示 Person 类的父类是 Object 类，可以看到 superclass 对象其实就是一个 Class 类的实例，所以也可以继续在这个对象上进行反射操作。 通过反射获取类的实现接口可以通过 Class 类来获取一个类的父类，通过调用 getInterfaces 方法来获取一个类实现的接口。 123Class&lt;Person&gt; personClass = Person.class;Class&lt;?&gt;[] interfaces = personClass.getInterfaces();System.out.println(Arrays.toString(interfaces)); 运行结果 1[interface cn.mghio.blogmghiocode.reflect.IPerson] 在 Java 中一个类可以实现多个接口，因此 getInterfaces 方法返回一个 Class 数组，在 Java 中接口也同样有对应的 Class 对象。这个方法需要注意的是，getInterfaces 方法仅仅只返回当前类所实现的接口。当前类的父类如果实现了接口，这些接口是不会在返回的 Class 集合中的，尽管实际上当前类其实已经实现了父类接口。 通过反射获取泛型信息当我们在声明一个类或者接口的时候可以指定它可以参数化，常用的 List 接口就是一个参数化接口的例子。比如想要检查 List 接口的参数化类型，我们是没有办法能知道它具体的参数化类型是什么。这个类型就可以是一个应用中所有的类型。但是，当你检查一个使用了被参数化的类型的变量或者方法，你可以获得这个被参数化类型的具体参数。第 ① 种 泛型方法返回类型 当你获得了 Method 对象，那么就可以获取到这个方法的泛型返回类型信息。如果方法是在一个被参数化类型之中（例如: T foo()），那么将无法获得它的具体类型，但是如果方法返回的是一个泛型类（例如：List foo()），那么就可以获得这个泛型类的具体参数化类型。下面这个例子中的类定义了一个返回类型是泛型的方法。 12345678910111213141516/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemo &#123; protected List&lt;Integer&gt; stringList = Arrays.asList(2, 55, 3, 90, 81); public List&lt;Integer&gt; getStringList()&#123; return this.stringList; &#125;&#125; 我们可以获取上面这个类 ReflectGenericDemo 的方法 getStringList 的泛型返回类型。 1234567891011121314151617181920212223242526/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemoTests &#123; @Test public void testMethodReturnGenericType() throws NoSuchMethodException &#123; Class&lt;ReflectGenericDemo&gt; reflectClass = ReflectGenericDemo.class; Method method = reflectClass.getMethod("getStringList", (Class&lt;?&gt;) null); Type returnType = method.getGenericReturnType(); if (returnType instanceof ParameterizedType) &#123; ParameterizedType type = (ParameterizedType) returnType; Type[] typeArguments = type.getActualTypeArguments(); for (Type typeArgument : typeArguments) &#123; Class typeArgumentClass = (Class) typeArgument; System.out.println("typeArgumentClass = " + typeArgumentClass); &#125; &#125; &#125;&#125; 运行结果 1typeArgumentClass = class java.lang.Integer typeArguments 数组只有一个值，这个数组中唯一的值是 Integer 的 Class 类的实例，同时 Class 类也实现了 Type 接口。 第 ② 种 泛型方法返回类型 泛型方法参数类型，我们也可以通过反射来获取方法参数的泛型类型。 12345678910111213141516/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemo &#123; protected List&lt;Integer&gt; stringList = Arrays.asList(2, 55, 3, 90, 81); public void setStringList(List&lt;Integer&gt; stringList) &#123; this.stringList = stringList; &#125;&#125; 可以通过以下方式获取方法参数的泛型类型。 12345678910111213141516171819202122232425262728/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemoTests &#123; @Test public void testMethodParameterGenericType() throws NoSuchMethodException &#123; Class&lt;ReflectGenericDemo&gt; reflectClass = ReflectGenericDemo.class; Method method = reflectClass.getMethod("setStringList", List.class); Type[] genericParameterTypes = method.getGenericParameterTypes(); for (Type genericParameterType : genericParameterTypes) &#123; if (genericParameterType instanceof ParameterizedType) &#123; ParameterizedType parameterizedType = (ParameterizedType) genericParameterType; Type[] parameterArgTypes = parameterizedType.getActualTypeArguments(); for (Type parameterArgType : parameterArgTypes) &#123; Class parameterArgClass = (Class) parameterArgType; System.out.println("parameterArgClass = " + parameterArgClass); &#125; &#125; &#125; &#125;&#125; 运行结果 1parameterArgClass = class java.lang.Integer 第 ③ 种 泛型变量类型 可以通过反射来访问类中定义变量的泛型类型，不管这个变量是一个类的静态成员变量或是实例成员变量。 123456789101112/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemo &#123; private List&lt;Integer&gt; stringList = Arrays.asList(2, 55, 3, 90, 81);&#125; 我们可以通过以下代码来获取类 ReflectGenericDemo 的私有变量 stringList 的泛型变量类型。 1234567891011121314151617181920212223242526/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemoTests &#123; @Test public void testFieldGenericType() throws NoSuchFieldException &#123; Class&lt;ReflectGenericDemo&gt; reflectClass = ReflectGenericDemo.class; Field field = reflectClass.getDeclaredField("stringList"); Type type = field.getGenericType(); if (type instanceof ParameterizedType) &#123; ParameterizedType fieldGenericType = (ParameterizedType) type; Type[] fieldGenericTypes = fieldGenericType.getActualTypeArguments(); for (Type genericType : fieldGenericTypes) &#123; Class fieldGenericTypeClass = (Class) genericType; System.out.println(fieldGenericTypeClass); &#125; &#125; &#125;&#125; 运行结果 1class java.lang.Integer 数组 fieldGenericTypes 只有一个元素，它代表类 Integer 的 Class 类的实例。我们可以得出通过反射获取泛型信息的套路都是先获取 Class 类对象，然后通过该对象获取相应的类，如果是要获取变量的泛型信息就先获取到 Field 类，如果是要获取方法的泛型信息就先获取到 Method 类，最后再通过是否是 ParameterizedType 的实例来判断是否是泛型类型。 总结我们介绍了 Java 泛型的基本使用，反射可能在我们日常的工作中不怎么接触到，但是，在很多框架中都有运用，比如，Spring 的 IOC/DI 也是反射；还有 JDBC 的 classForName 也是反射。所有深入了解 Java 反射机制很有必要。 方法 描述 Constructor getConstructor(Class[] params) 根据构造方法的参数，返回一个 public 类型的构造方法 Constructor getConstructors() 返回所有 public 类型的构造方法数组 Constructor getDeclaredConstructor(Class[] params) 根据构造方法的参数，返回一个具体的构造方法（所有的类型） Constructor getDeclaredConstructors() 返回该类中所有的构造方法数组（所有的类型） Method getMethod(String name, Class[] params) 根据方法名和参数，返回一个 public 类型的方法 Method[] getMethods() 返回所有 public 类型的方法数组 Method getDeclaredMethod(String name, Class[] params) 根据方法名和参数，返回一个具体的方法（所有的类型） Method[] getDeclaredMethods() 返回该类中的所有的方法数组（所有的类型） Field getField(String name) 根据变量名，返回一个 public 类型的成员变量 Field[] getFields() 返回 public 类型的成员变量的数组 Field getDeclaredField(String name) 根据变量名，返回一个成员变量（所有的类型） Field[] getDelcaredField() 返回所有成员变量组成的数组（所有的类型）]]></content>
      <categories>
        <category>Java</category>
        <category>反射</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用命令]]></title>
    <url>%2Fpost%2F817c7d82.html</url>
    <content type="text"><![CDATA[1.1 前言作为 Java 后端开发的我们，开发的项目绝大部分都是部署在 Linux 系统上的，因此熟练使用一些常用的 Linux 命令不管是对于日常开发、服务部署或者查找问题都非常有用。以下整理了一些常用的 Linux 常用命令。 1.2 文件管理1.2.1 ls 命令ls 命令是 Linux 最常用的命令之一，其功能是列出指定目录下的内容及其相关属性信息。默认状态下，ls 命令会列出当前目录的内容，它也可以带上一些参数来实现更多的功能。语法格式：ls [选项] [文件]常用参数 参数 描述 -a 显示所有文件及目录（包括以 . 开头的隐藏文件） -l 使用长格式列出文件及目录 -r 将文件以相反次序显示（默认按照英文字母次序） -t 根据最后的修改时间排序 -A 同 -a，但是不列出 .（当前目录）以及 ..（父级目录） -S 根据文件大小排序 -R 递归列出所有子目录 Examples 12345ls -a # 列出所有文件（包括隐藏文件）ls -l # 列出文件的详细信息ls / # 列出根目录（/）下的所有目录ls -ltr s* # 列出当前目录下所有名称是 s 开头的文件ls -AS # 列出当前目录下所有文件及目录并以文件大小进行排序 1.2.2 chown 命令Linux 是一种多用户多任务的操作系统，所有的文件都有一个拥有者。chown 命令就是用来将指定文件的拥有者改为指定的用户或者组（PS：用户和组都可以是名称或者其 ID），文件是以空格分开的要改变权限的文件列表，支持通配符。语法格式：chown [参数]常用参数 参数 描述 -R 对当前目录下的所有文件与子目录进行相同的拥有者变更 -c 若该文件拥有者确实已经更改，才显示其更改动作 -f 若该文件拥有者无法更改也不显示错误信息 -v 显示拥有者变更的详细信息 –version 显示版本 Examples 123456789101112131415# 将 change_usergroup_and_user_demo.txt 文件用户组与用户都改为 mghio[root@mghio ~]# ll change_usergroup_and_user_demo.txt-rw-r--r-- 1 root root 56 Dec 21 10:17 change_usergroup_and_user_demo.txt[root@mghio ~]# chown mghio:mghio change_usergroup_and_user_demo.txt[root@mghio ~]# ll change_usergroup_and_user_demo.txt-rw-r--r-- 1 mghio mghio 56 Dec 21 10:17 change_usergroup_and_user_demo.txt# 显示其更改动作[root@mghio ~]# ll change_usergroup_and_user_demo.txt-rw-r--r-- 1 root root 45 Dec 21 10:30 change_usergroup_and_user_demo.txt[root@mghio ~]# chown -c mghio:mghio change_usergroup_and_user_demo.txtchanged ownership of 'change_usergroup_and_user_demo.txt' to mghio:mghio 1.2.3 cp 命令cp 命令为英文单词 copy 的缩写，功能为复制文件或目录。cp 命令可以将多个文件复制到一个具体的文件名或者一个已经存在的目录下，也可以同时复制多个文件到一个指定的目录中。语法格式：cp [参数] [文件]常用参数 参数 描述 -f 若目标文件已经存在，则直接覆盖原文件 -i 若目标文件已经存在，则会询问是否覆盖 -p 保留原文件或者目录的属性 -r 递归复制文件和目录 -d 当复制符号链接时，把目标文件或者目录也建立符号链接，并指向和原文件或目录连接的原始文件或目录 -l 对原文件建立连接，而非复制文件 -s 对原文件建立符合连接，而非复制文件 -b 覆盖已经存在的文件目标前将目标文件备份 -v 详细显示 cp 命令的执行过程 Examples 12345678# 复制目录cp -R source_dir1 dest_dir2/# 将文件 demo1.txt 改名为 demo2.txtcp -f demo1.txt demo2.txt# 复制多个文件cp -r file1 file2 file3 dest_dir 1.2.4 mkdir 命令mkdir 命令是 make directories 的缩写，其功能是用来创建目录。默认状态下，如果要创建的目录如果已经存在，则提示已存在，而不会继续创建目录。所有我们在创建目录时，应该要保证新建的目录与它所在的目录下的文件没有重名，同时该命令还可以一次性创建多个目录。语法格式：mkdir [参数] [目录]常用参数 参数 描述 -p 递归创建多级目录 -m 建立目录的同时设置目录的权限 -v 显示目录的常见过程 Examples 1234567891011# 在当前目录下，创建一个名为 dir 的子目录mkdir dir# 在目录 /usr/mghio 下建立子目录 dir，并且设置文件属主有读（4）、写（2）和执行（1）权限，其它用户无法访问mkdir -m 700 /usr/mghio/dir# 一次性创建目录 dir1、dir2、dir3mkdir dir1 dir2 dir3# 递归创建目录mkdir -p /mghio/dir 1.2.5 mv 命令mv 命令为英文单词 move 的缩写，功能为移动文件或者对文件重新命名。mv 与 cp 命令的结果不同。mv 命令是将文件整个移走，文件名发生改变，但是个数没有增加。而 cp 命令是对文件进行复制操作，文件个数增加。语法格式：mv [参数]常用参数 参数 描述 -i 若存在同名文件，则会询问是否覆盖 -f 覆盖已经存在的文件时，不进行任何提示 -b 当文件存在时，覆盖前为其创建一个备份 -u 当原文件比目标文件新或者目标文件不存在时，才会执行 Examples 12345678# 将文件 file1 重命名为 file2mv file1 file2# 将文件 file 移动到目录 dest_dirmv file /dest_dir# 将目录 dir 下的所有文件移到当前目录mv /dir/* . 1.3 文档编辑1.3.1 cat 命令在 Linux 系统中有很多用于查看文件内容的命令，cat 命令就是用来查看内容较少的纯文本内容文件的。当文件内容较大时，文本内容会在屏幕上快速滚屏，我们通常都看不到所显示的内容。对于较长文件内容可以按 Ctrl+S 键来停止滚屏，以及 Ctrl+Q 键来恢复滚屏，按 Ctrl+C（中断）键则可以终止该命令的执行。对于大文件，推荐使用下文说的 more 命令。语法格式：cat [参数] [文件]常用参数 参数 描述 -n 显示行数（一个空行显示一个编号） -s 显示行数（多个空行只算一个编号） -b 显示行数（空行不编号） -E 每行结束显示 $ 符号 -T 将 TAB 字符显示为 ^| 符号 –version 显示版本信息 Examples 1234567891011121314151617# 查看文件内容 cat demo.txt# 查看文件内容，并显示行号cat -n demo.txt# 产查看文件的内容，并添加行数编号后输出到另外一个文件中cat -n mghio.log &gt; mghio_with_line_number.log# 清空文件内容cat /dev/null &gt; /mghio/demo.txt# 持续写入文件内容，直到碰到 `EOF` 符号后结束并保存cat &gt; demo.txt &lt;&lt; EOF&gt; Hello, World&gt; mghio&gt; EOF 1.3.2 more 命令more 命令用于将内容较长的文本文件内容（无法在一屏显示完）进行分屏显示，并且支持显示时定位关键字。对于内容比较少的文本内容推荐使用 cat 命令查看。语法格式：more [参数] [文件]常用参数 参数 描述 -num 指定每屏显示的内容行数 -l more 在通常情况下把 ^L 当遇到这个字符就会暂停，这个参数可以屏蔽这个特性 -f 计算实际的行数，而非自动换行的行数 -p 先清除屏幕在显示文本文件的剩余内容 -c 与 -p 相似，不滚屏，先显示内容在清除内容 -s 多个空行压缩成一行显示 -u 禁止下划线 +/pattern 在每个文档显示前搜寻该字（pattern），然后该字串之后开始显示 +num 从第 num 行开始显示 查看时的命令操作 命令 描述 Space 键 显示文本的下一屏内容 Enter 键 向下 n 行，需要定义，默认为 1 行 \ 键 接着输入一个模式，可以在文本中寻找下一个相匹配的模式 H 键 显示帮助屏 B 键 显示上一屏内容 Q 键 退出 more 命令 Ctrl + F、空格键 向下滚动一屏 Ctrl + B 返回上一屏 = 输出当前的行号 :f 输出文件名和当前的行号 V 调用 vi 编辑器 ! 调用 Shell， 并执行命令 Examples 1234567891011# 显示文件 demo.txt 的内容和已显示的百分比，显示之前先清屏more -dc demo.txt# 显示文件 demo.txt 的内容，每 10 行显示一次，而且在显示之前先清屏more -c -10 demo.txt# 显示文件 demo.txt 的内容，每 5 行显示一次，而且在显示之后再清屏more -p -5 demo.txt# 从第 20 行开始显示文件 demo.txt 的内容more +20 demo.txt 1.3.3 tail 命令tial 命令用于显示文件尾部的内容，默认在屏幕上显示指定文件的末尾 10 行。如果给定的文件不止一个，则在显示的每个文件前面加一个文件名标题，如果没有指定文件或者文件名为 -，则读取标准输入。语法格式：tail [参数]常用参数 命令 描述 –retry 即是在 tail 命令启动时，文件不可访问或者文件稍后变得不可访问，都始终尝试打开文件。使用此选项时需要与 —f 一起使用 -c 输出文件尾部的 N（N 为整数） 个字节内容 -f 显示文件最新追加的内容 -n 输出文件的尾部 N（N 为整数） 行内容 Examples 12345678# 显示文件 demo.txt 的最后 10 行tail demo.txt# 显示文件 demo.txt 的内容，从第 20 行至文件末尾tail +20 demo.txt# 显示文件 demo.txt 的最后 10 个字符tail -c 10 demo.txt 1.3.4 grep 命令grep 是英文 global search regular expression and print out the line 的简称。是全面搜索正则表达式，并将其打印出来。这个命令可以结合正则表达式使用，使用非常广泛。grep 命令的选项用于对搜索过程的补充，而其命令的模式十分灵活，可以是变量、字符串、正则表达式，需要注意的是，当我们的模式中包含了空格的话，要使用双引号将其引起来。语法格式：grep [参数]参数列表 命令 描述 -i 搜索时，忽略大小写 -c 只输出匹配行的数量 -l 只列出符合匹配的文件名，不列出具体匹配行 -n 列出所有匹配行，显示行号 -h 查询多文件时不显示文件名 -s 不显示不存在、没有匹配文本的错误信息 -v 显示不包含匹配文本的所有行 -w 匹配整词 -x 匹配整行 -r 递归搜索 -q 禁止输出任何结果，已退出状态表示搜索是否成功 -b 打印匹配行距文件头部的偏移量（以字节为单位） -o 与 -b 结合使用，打印匹配的词距文件头部的偏移量（以字节为单位） Examples 12345678910111213141516171819# 支持多文件查询并支持使用通配符[root@mghio ~]# grep mghio file_* /usr/demofile_1:mghiofile_1:mghioddkjflkdjfdlkfjlsdkjfile_2:mghiofile_4:dkfjlmghioejfkdsfile_4:mghio djftgffile_4:twetmghioedkfgj# 列出所有的匹配行，并显示行号[root@mghio ~]# grep mghio file_* /usr/demofile_1:1:mghiofile_1:3:mghioddkjflkdjfdlkfjlsdkjfile_2:4:mghiofile_4:8:dkfjlmghioejfkdsfile_4:11:mghio djftgffile_4:20:twetmghioedkfgj 1.3.5 echo 命令echo 命令用于在终端设备上输出字符串或者变量提取后的值，这是在 Linux 系统中最常用的几个命令之一，在 Linux 系统中，人们一般使用在变量前加上 $ 符号的方式提取出变量的值，例如：$PATH，然后再用 echo 命令予以输出。或者直接使用 echo 命令输出一段字符串到屏幕上，起到给用户提示的作用。语法格式：echo [参数] [字符串]常用参数 命令 描述 -n 不输出结尾的换行符 -e”\a” 发出警告音 -e”\b” 删除前面的一个字符 -e”\c” 结尾不加换行符 -e”\f” 换行，光标仍然停留在原来的坐标位置 -e”\n” 换行，光标移至行首 -e”\r” 光标移至首行，但是不换行 -E 禁止反斜杠转义，与 -e 参数功能相反 Examples 123456789101112131415# 输出一段字符串[root@mghio ~]# echo "mghio.cn" mghio.cn# 输出变量提取后的值[root@mghio ~]# echo $PATH/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin# 对内容进行转义，不让$符号的提取变量值功能生效[root@mghio ~]# echo \$PATH$PATH# 使用反引号符执行命令，并输出其结果到终端[root@mghio ~]# echo `date`Sat Dec 21 15:30:24 CST 2019 1.4 网络通讯1.4.1 ssh 命令ssh 命令是 openssh 套件中的客户端连接工具，可以给予 ssh 加密协议实现安全的远程登录服务器，实现对服务器的管理。语法格式：ssh [参数] [主机]常用参数 命令 描述 -1 强制使用 ssh 协议版本 1 -2 强制使用 ssh 协议版本 2 -4 强制使用 IPv4 地址 -6 强制使用 IPv6 地址 -A 开启认证代理连接转发功能 -a 关闭认证代理连接转发功能 -b&lt;IP地址&gt; 使用本机指定的地址作为对位连接的源 IP 地址 -C 请求压缩所有数据 -F&lt;配置文件&gt; 指定 ssh 指令的配置文件，默认的配置文件为 /etc/ssh/ssh_config -f 后台执行 ssh指令 -g 允许远程主机连接本机的转发端口 -i&lt;身份文件&gt; 指定身份文件（即私钥文件） -l&lt;登录名&gt; 指定连接远程服务器的登录用户名 -N 不执行远程指令 -o&lt;选项&gt; 指定配置选项 -p&lt;端口&gt; 指定远程服务器上的端口 -q 静默模式，所有的警告和诊断信息被禁止输出 Examples 12345# 登录远程服务器[root@mghio ~]# ssh 112.67.239.127# 用 mghio 用户连接远程服务器[root@linuxcool ~]# ssh -l mghio 112.67.239.127 1.4.2 sftp 命令sftp 命令全称是 Secure File Transfer Protocol。是一个交互式的文件传输程序，sftp 命令的运行和使用与 ftp 相似，但是 sftp 命令对传输的所有信息使用 ssh 加密 ，它还支持公钥认证和压缩等功能。语法格式：sftp [参数] [IP或主机名]常用参数 命令 描述 -B 指定传输文件缓冲区的大小 -l 使用 ssh 协议版本 1 -b 指定批处理文件 -C 使用压缩 -o 指定 ssh 选项 -F 指定 ssh 配置文件 -R 指定一次可以容忍多少请求数 Examples 12345678# 使用 sftp 命令连接到服务器[root@mghio ~]# sftp 112.67.239.127# 指定传输文件是缓冲区大小[root@mghio ~]# sftp -B 256 112.67.239.127# 在传输过程中使用压缩[root@linuxcool ~]# sftp -C 112.67.239.127 1.4.3 telnet 命令telnet 命令的功能是远端登入，执行 telnet 指令开启终端机阶段作业，并登入远端主机。telnet 命令可以帮助你从这台路由器远程登陆到远端开启了 telnet 服务的设备，包括路由器、交换机、Linux 服务器等，并且配置当前路由器的 telnet 服务。语法格式：telnet [参数]常用参数 命令 描述 -8 允许使用 8 位字符资料，包括输入与输出 -a 尝试自动登入远端系统 -b 使用别名指定远端主机名称 -c 不读取用户专属目录里的 .telnetrc 文件 -d 启动排错模式 -e 设置脱离字符 -E 滤除脱离字符 -f 此参数的效果和指定 -F 参数相同 -F 使用 Kerberos V5 认证时，加上此参数可把本地主机的认证数据上传到远端主机 -k 使用 Kerberos 认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名 -K 不自动登入远端主机 -l 指定要登入远端主机的用户名称 -L 允许输出8位字符资料 -n 指定文件记录相关信息 -r 使用类似 rlogin 指令的用户界面 -S 设置 telnet 连线所需的 IP TOS 信息 -x 假设主机有支持数据加密的功能，就使用它 -X 关闭指定的认证形态 Examples 12345# 登录远程主机[root@mghio ~]# telnet 112.67.239.127# 连接本地主机，端口号为 23[root@mghio ~]# telnet localhost 23 1.4.4 netstat 命令netstat 命令用于显示各种网络相关信息，如网络连接、路由表、接口状态、多播成员等。从整体上看，netstat 的输出结果为两部分：一个是 Active Internet connections 称为 有源 TCP 连接，其中 Recv-Q 和 Send-Q 指 %OA 的是接收队列和发送队列。另一个是 Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。语法格式：netstat [参数]常用参数 命令 描述 -a 显示所有连线中的 Socket -p 显示正在使用 Socket 的程序识别码和程序名称 -u 显示 UDP 传输协议的连线状况 -i 显示网络界面信息表单 -n 直接使用 IP 地址，不通过域名服务器 Examples 123456789101112# 显示详细的网络状况[root@mghio ~]# netstat -a# 显示当前 UDP 连接状况[root@mghio ~]# netstat -nu# 显示网卡列表[root@mghio ~]# netstat -iKernel Interface table Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 1500 0 181864 0 0 0 141278 0 0 0 BMRU lo 16436 0 3362 0 0 0 3362 0 0 0 LRU]]></content>
      <categories>
        <category>Linux笔记</category>
      </categories>
      <tags>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 多线程基础（二）]]></title>
    <url>%2Fpost%2F4ea48fa7.html</url>
    <content type="text"><![CDATA[简介在上篇 Java 多线程基础（一） 我们提到了一些线程的常用方法，这篇我们具体看看其中一些方法的使用以及方法的区别，让我们在工作中更好的使用。 wait 方法与 notify 方法在 Object 类中定义了 wait 方法和 notify 方法，wait 方法的作用是让当前线程进入等待状态，将当前线程置入 预执行队列，会在 wait 方法所在代码处停止执行，直到被通知或者被中断，在调用 wait 方法之前，线程必须获取该对象的锁，因此只能在同步方法或者同步代码块中调用 wait 方法，并且该方法会释放当前线程锁持有的锁。notify 方法是唤醒在当前对象上等待的单个线程，如果有多个线程等待，那么线程调度器会挑出一个 wait 的线程，对其发出 notify ，并使它等待获取该对象的对象锁，这意味着，即使收到了通知，线程也不会立即获取到对象锁，必须等待 notify 方法的线程释放锁才可以。和 wait 方法一样，notify 方法也只能在同步方法或者同步代码块中调用。它还有个相似的方法 notifyAll，它的作用是唤醒在当前对象上等待的所有线程。 下面通过一个生产者消费者来说明 wait 方法和 notify 方法的使用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * @author mghio * @date: 2019-12-14 * @version: 1.0 * @description: 线程 wait() 和 notify() 方法使用示例 * @since JDK 1.8 */public class ThreadWaitAndNotifyDemo &#123; public static void main(String[] args) &#123; Producer producer = new Producer(); producer.start(); new Consumer("Consumer One", producer).start(); new Consumer("Consumer Two", producer).start(); new Consumer("Consumer Three", producer).start(); new Consumer("Consumer Four", producer).start(); &#125; static class Producer extends Thread &#123; List&lt;String&gt; messageList = new ArrayList&lt;&gt;(2); @Override public void run() &#123; try &#123; while (true) &#123; Thread.sleep(2000); synchronized (messageList) &#123; String message = String.format("producer message [create time:%s]", LocalDateTime.now()); messageList.add(message); System.out.println("Producer " + getName() + " producer a msg: " + message); messageList.notify(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; String getMessage() &#123; synchronized (messageList) &#123; if (messageList.size() == 0) &#123; try &#123; messageList.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; return messageList.remove(0); &#125; &#125; &#125; static class Consumer extends Thread &#123; private Producer producer; public Consumer(String name, Producer producer) &#123; super(name); this.producer = producer; &#125; @Override public void run() &#123; while (true) &#123; String message = producer.getMessage(); System.out.println("Consumer " + getName() + " get a msg: " + message); &#125; &#125; &#125;&#125; 输出结果如下： 12345678Producer Thread-0 producer a msg: producer message [create time:2019-12-14T22:45:42.319]Consumer Consumer One get a msg: producer message [create time:2019-12-14T22:45:42.319]Producer Thread-0 producer a msg: producer message [create time:2019-12-14T22:45:44.324]Consumer Consumer Two get a msg: producer message [create time:2019-12-14T22:45:44.324]Producer Thread-0 producer a msg: producer message [create time:2019-12-14T22:45:46.325]Consumer Consumer Three get a msg: producer message [create time:2019-12-14T22:45:46.325]Producer Thread-0 producer a msg: producer message [create time:2019-12-14T22:45:48.328]Consumer Consumer Four get a msg: producer message [create time:2019-12-14T22:45:48.328] 消费者线程循环调用生产者的 getMessage 方法获取消息，如果消息列表 messageList 为空，则调用消息列表的 wait 方法让线程进入等待状态，生产者每隔 2 秒生成消息并放入消息列表 messageList 中，放入成功后调用 notify 方法唤醒一个处于 wait 状态的线程去消费消息，需要注意的是，在调用 wait 和 notify 方法时必须要先获得该对象的锁，上面的示例中是在 synchronized 代码块中调用的。 sleep 方法与 wait、notify 方法不同，sleep 方法定义在 Thread 类中，从方法名也可以知道，这个方法的作用就是让当前线程休眠，即调用该方法后当前线程会从运行状态(Running）状态进入到阻塞（休眠）状态（Blocked），同时该方法必须指定休眠的时间，当前线程的休眠时间会大于或者等于这个指定的休眠时间。当线程重新被唤醒时，线程会由阻塞状态（Blocked）变成就绪状态（Runnable），然后等待 CPU 的调度执行。sleep 方法的示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @author mghio * @date: 2019-12-14 * @version: 1.0 * @description: 线程 sleep() 方法使用示例 * @since JDK 1.8 */public class ThreadSleepDemo &#123; private static Object object = new Object(); public static void main(String[] args) &#123; MyThread myThreadOne = new MyThread("t1"); MyThread myThreadTwo = new MyThread("t2"); myThreadOne.start(); myThreadTwo.start(); &#125; static class MyThread extends Thread &#123; public MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; synchronized (object) &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(String.format("%s: %d", this.getName(), i)); if (i % 2 == 0) &#123; Thread.sleep(2000); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 输出结果如下： 12345678910t1: 0t1: 1t1: 2t1: 3t1: 4t2: 0t2: 1t2: 2t2: 3t2: 4 我们启动了两个线程 t1 和 t2，两个线程的 run 方法引用了同一个对象 object 的同步锁（synchronized (object)），虽然在第一个线程 t1 中当 i 被 2 整除时会调用 Thread.sleep(2000) 让当前线程休眠 2 s，但是此时线程 t2 也不会得到 cpu 的执行权去执行，因为 t1 线程调用 sleep 方法并没有释放object所持有的同步锁。如果我们注释掉 synchronized (object) 后再次执行该程序，线程 t1 和 t2 是可以交替执行的，注释之后的输出结果如下： 12345678910t2: 0t1: 0t1: 1t2: 1t1: 2t2: 2t2: 3t1: 3t2: 4t1: 4 yield 方法yield 方法定义在 Thread 类中，是线程特有的方法。此方法的主要作用是让步，它会使当前线程从运行状态（Running）变为就绪状态（Runnable），从而让其他具有同样优先级的处于就绪状态的线程获取到 CPU 执行权(PS: CPU 会从众多的处于就绪状态的线程里选择，也就是说，当前也就是刚刚的那个线程还是有可能会被再次执行到的，并不是说一定会执行其他线程而该线程在下一次中不会执行到)，但是，也并不能保证在当前线程调用 yield 之后，其它哪些具有相同优先级的线程就一定能获得执行权，也有可能是当前线程又进入到运行状态（Running）继续运行。yield 方法的示例代码如下： 123456789101112131415161718192021222324252627282930313233/** * @author mghio * @date: 2019-12-14 * @version: 1.0 * @description: 线程 yield() 方法使用示例 * @since JDK 1.8 */public class ThreadYieldDemo &#123; public static void main(String[] args) &#123; MyThread myThreadOne = new MyThread("t1"); MyThread myThreadTwo = new MyThread("t2"); myThreadOne.start(); myThreadTwo.start(); &#125; static class MyThread extends Thread &#123; MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(String.format("%s [%d] ---&gt; %d", this.getName(), this.getPriority(), i)); if (i % 2 == 0) &#123; yield(); &#125; &#125; &#125; &#125;&#125; 输出结果如下： 1234567891011121314151617181920t1 [5] ---&gt; 0t2 [5] ---&gt; 0t1 [5] ---&gt; 1t1 [5] ---&gt; 2t1 [5] ---&gt; 3t1 [5] ---&gt; 4t1 [5] ---&gt; 5t1 [5] ---&gt; 6t1 [5] ---&gt; 7t1 [5] ---&gt; 8t1 [5] ---&gt; 9t2 [5] ---&gt; 1t2 [5] ---&gt; 2t2 [5] ---&gt; 3t2 [5] ---&gt; 4t2 [5] ---&gt; 5t2 [5] ---&gt; 6t2 [5] ---&gt; 7t2 [5] ---&gt; 8t2 [5] ---&gt; 9 从以上输出结果可以看出，线程 t1 中的变量 i 在被 2 整除的时候，并没有切换到线程 t2 去执行，这也验证了我们上文说的，yield 方法虽然可以让线程由运行状态变成就绪状态，但是，它不一定会让其它线程获取 CPU 执行权从而进入到运行状态，即使这个其它线程和当前具有相同的优先级，yield 方法不会释放锁（证明方法只需将上面这个示例的 run 方法里面加上 synchronized (obj) 即可，此时 t2 线程会等到线程 t1 执行完毕后才会执行）。 join 方法在有些场景中我们需要在子线程去执行一些耗时的任务，但是我们的主线程又必须等待子线程执行完毕之后才能结束，那么此时就可以使用 join 方法了，该方法定义在 Thread 类中，方法的作用是：让主线程等待子线程执行结束之后才能继续执行，下面我们通过一个例子来看看： 123456789101112131415161718192021222324252627282930313233343536373839/** * @author mghio * @date: 2019-12-15 * @version: 1.0 * @description: 线程 join() 方法使用示例 * @since JDK 1.8 */public class ThreadJoinDemo &#123; public static void main(String[] args) &#123; try &#123; MyThread myThread = new MyThread("t1"); myThread.start(); myThread.join(); System.out.println(String.format("%s ---&gt; %s finish", LocalDateTime.now(), Thread.currentThread().getName())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; static class MyThread extends Thread &#123; MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; System.out.println(String.format("%s ---&gt; %s start", LocalDateTime.now(), this.getName())); // 模拟耗时操作 try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(String.format("%s ---&gt; %s finish", LocalDateTime.now(), this.getName())); &#125; &#125;&#125; 输出结果如下： 1232019-12-15T00:22:55.971 ---&gt; t1 start2019-12-15T00:22:57.984 ---&gt; t1 finish2019-12-15T00:22:57.985 ---&gt; main finish 在主线程 main 中通过 new MyThread(&quot;t1&quot;) 新建线程 t1。 接着，通过 t1.start() 启动线程 t1，在执行 t1.join()之后， 主线程会进入阻塞状态等待 t1 运行结束。子线程 t1 结束之后，会唤醒主线程，主线程重新获取 CPU 执行权，主线程继续往下运行。在使用了 join 方法之后主线程会等待子线程结束之后才会结束。 总结以上是线程一些常用的方法介绍和具体使用知识总结。]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 多线程基础（一）]]></title>
    <url>%2Fpost%2F7eb2637f.html</url>
    <content type="text"><![CDATA[简介在接触多线程之前，在我们程序中在任意时刻都只能执行一个步骤，称之为单线程。在单线程开发的程序中所有的程序路径都是顺序执行的，前面的必须先执行，后面的才会执行。单线程的优点也很明显，相对于多线程来说更加稳定、扩展性更强、程序开发相对比较容易。但是由于每次都要等上一个任务执行完成后才能开始新的任务，导致其效率比多线程低，甚至有时候应用程序会出现假死的现象。使用多线程有利于充分发挥多处理器的功能。通过创建多线程进程，每个线程在一个处理器上运行，从而实现应用程序的并发性，使每个处理器都得到充分运行。多线程是 Java 学习的非常重要的方面，是每个 Java 程序员必须掌握的基本技能。本文是有关 Java 多线程的一些基础知识总结。 进程与线程的区别进程进程是操作系统资源分配的基本单位，它是操作系统的基础，是一个程序及其数据在处理机上顺序执行时所发生的活动。一个程序进入内存运行，即变成一个进程。进程是处于运行过程中的程序，并且具有一定独立功能。进程的实质就是程序在操作系统中的一次执行过程，它是动态产生的、动态销毁的，拥有自己的生命周期和各种不同的运行状态。同时，进程还具有并发性，它可以同其他进程一起并发执行，按各自独立的、不可预知的速度向前推进（PS：并发性和并行性是不同的概念，并行指的是同一时刻，两个及两个以上的指令在多个处理器上同时执行。而并发指的是同一时刻只有一条指令执行，但是多个进程可以被 CPU 快速交换执行，给我们感觉好像是多个执行在同时执行一样）。 线程线程是任务调度和执行的基本单位，也被称为轻量级进程，线程由线程 ID，当前指令指针(PC），寄存器集合和堆栈组成。线程不拥有系统资源，它只会拥有一点儿在运行时必不可少的资源，但是它可以与同属于同一进程的线程共享该进程所拥有的所有资源。一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。 二者的区别 调度 线程作为调度和分配的基本单位，进程作为拥有资源的基本单位 并发性 不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行 拥有资源 进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源 系统开销 在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销 创建线程的方式在 Java 中使用 Thread 类代表线程，所有的线程对象都必须是 Thread 类或者其子类的实例，Java 中创建线程主要有以下三种方式： 方式一 继承 Thread 类step 1 定义一个类继承自 Thread 类，然后重写该类的 run 方法，这个方法的内容表示线程要完成的任务step 2 创建线程对象，即创建 Thread 类子类的实例step 3 调用步骤二中创建出来的对象的 start 方法来启动线程 12345678910111213141516171819202122232425/** * @author mghio * @date: 2019-12-07 * @version: 1.0 * @description: 通过继承 Thread 类的方式创建线程 * @since JDK 1.8 */public class CreateThreadByExtendsThread extends Thread &#123; @Override public void run() &#123; IntStream.rangeClosed(1, 10).forEach(i -&gt; System.out.println(Thread.currentThread().getName() + " " + i)); &#125; public static void main(String[] args) &#123; CreateThreadByExtendsThread threadOne = new CreateThreadByExtendsThread(); CreateThreadByExtendsThread threadTwo = new CreateThreadByExtendsThread(); CreateThreadByExtendsThread threadThree = new CreateThreadByExtendsThread(); threadOne.start(); threadTwo.start(); threadThree.start(); &#125;&#125; 方式二 实现 Runnable 接口step 1 定义一个类实现 Runnable 接口，然后实现该接口的 run 方法，这个方法的内容同样也表示线程要完成的任务step 2 创建 Runnable 接口实现类的实例，并使用该实例作为 Thraed 构造方法的参数创建 Thread 类的对象，该对象才是真正的线程对象step 3 调用线程对象的 start 方法来启动该线程 12345678910111213141516171819202122/** * @author mghio * @date: 2019-12-07 * @version: 1.0 * @description: 通过实现 Runnable 接口的方式创建线程 * @since JDK 1.8 */public class CreateThreadByImplementsRunnable implements Runnable &#123; @Override public void run() &#123; IntStream.rangeClosed(1, 10).forEach(i -&gt; System.out.println(Thread.currentThread().getName() + " " + i)); &#125; public static void main(String[] args) &#123; CreateThreadByImplementsRunnable target = new CreateThreadByImplementsRunnable(); new Thread(target, "thread-one").start(); new Thread(target, "thread-two").start(); new Thread(target, "thread-three").start(); &#125;&#125; 方式三 实现 Callable 接口step 1 定义一个类实现 Callable 接口，然后实现该接口的 call 方法，这个方法的内容同样也表示线程要完成的任务，并且有返回值step 2 创建 Callable 接口实现类的实例，使用 FutureTask 类来包装 Callable 对象，该 FutureTask 对象封装了 Callable 对象的 call 方法的返回值step 3 并使用 FutureTask 对象作为 Thraed 构造方法的参数创建 Thread 对象，并调用该对象的 start 方法启动线程step 4 调用 FutureTask 对象的 get 方法获取线程执行结束后的返回值 123456789101112131415161718192021222324252627282930313233343536373839/** * @author mghio * @date: 2019-12-07 * @version: 1.0 * @description: 通过实现 Callable 接口的方式创建线程 * @since JDK 1.8 */public class CreateThreadByImplementsCallable implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; AtomicInteger count = new AtomicInteger(); IntStream.rangeClosed(0, 10).forEach(i -&gt; &#123; System.out.println(Thread.currentThread().getName() + " " + i); count.getAndIncrement(); &#125;); return count.get(); &#125; public static void main(String[] args) &#123; CreateThreadByImplementsCallable target = new CreateThreadByImplementsCallable(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(target); IntStream.rangeClosed(0, 10).forEach(i -&gt; &#123; System.out.println(Thread.currentThread().getName() + " 的循环变量 i 的值" + i); if (i == 8) &#123; new Thread(futureTask, "有返回值的线程").start(); &#125; &#125;); try &#123; System.out.println("有返回值线程的返回值：" + futureTask.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 通过以上可以看出，其实通过实现 Runnable 接口和实现 Callable 接口这两种方式创建线程基本相同，采用实现 Runnable 和 Callable 接口的方式创建线程时，线程类只是实现接口，还可以继承其它类（PS：Java 单继承决定）。在这种方式下，多个线程可以共享同一个 target对象，所以非常适合多个相同线程来处理同一份资源的情况。还有一点就是，使用继承 Thread 类的方式创建多线程时，编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread() 方法，直接使用 this 即可获得当前线程。，在实际项目中如果使用这三种方式创建线程，如果创建关闭频繁会消耗系统资源影响性能，而使用线程池可以不用线程的时候放回线程池，用的时候再从线程池取，所以在我们项目开发中主要还是使用线程池，有关线程池的可以看看这两篇 Java 线程池（一）、Java 线程池（二）。 线程的几种状态线程是一个动态执行的过程，它也有一个从产生到死亡的过程，在 Java 中一个线程完整的生命周期一共包含以下五种状态：新建状态（New）当使用 new 关键字和 Thread 类或其子类创建一个线程对象后，那么线程就进入了新建状态，此时它和其它的 Java 对象一样，仅仅由 JVM 分配了内存，并初始化其成员变量值，它会一直保持这个状态直到调用该对象的 start 方法。 就绪状态（Runnable）当线程对象调用了 start 方法之后，该线程就进入了就绪状态。就绪状态的线程会放在一个就绪队列中，等待 JVM 里的调度器进行调度。处于就绪状态的线程，随时可能被 CPU 调度执行。 运行状态（Running）如果就绪状态的执行被 CPU 调度执行，就可以执行 run 方法，此时线程就处于线程状态。处于运行状态的线程最复杂，它可以变为阻塞状态、就绪状态和死亡状态。需要注意一点，线程变为运行状态之前的状态只能是就绪状态。 阻塞状态（Blocked）线程变为阻塞状态是因为某种原因放弃 CPU 的使用权，暂时停止运行，如果执行了 sleep、suspend 等方法，释放了所占用的资源之后，线程就从运行状态进入阻塞状态。等待睡眠时间结束或者获得设备资源之可以重新进入就绪状态。阻塞可以分为以下三种： 等待阻塞 处于运行状态的线程调用wait方法，会使线程进入等待阻塞状态 同步阻塞 当线程获取 synchronized 同步锁因为同步锁被其他线程占用而失败后，会使线程进入同步阻塞 其它阻塞 通过调用线程的sleep或join发出了 I/O 请求时，线程就会进入到阻塞状态。当sleep状态超时，join等待线程终止或超时，或者 I/O 处理完毕，线程重新回到就绪状态。 死亡状态（Dead）一个处于运行状态的线程执行完了 run 方法或者因为其它终止条件发生时，线程就会进入到死亡状态，该线程结束生命周期。以上线程各种状态的流转用一张图表示如下： 线程常用方法线程中常用的方法按照来源可以分为两类，一类是继承自 Object 类的方法，如下所示： 方法 描述 public final native void notify() 唤醒在此对象监视器上等待的单个线程，使其进入就绪状态 public final native void notifyAll() 唤醒在此对象监视器上等待的所有线程，使其进入就绪状态 public final void wait() 让当前线程处于·等待阻塞状态，直到其他线程调用此对象的notify方法或notifyAll方法，当前线程被唤醒，会释放它所持有的锁 public final native void wait(long timeout) 让当前线程处于·等待阻塞状态，直到其他线程调用此对象的notify方法或notifyAll方法，当前线程被唤醒 public final void wait(long timeout, int nanos) 让当前线程处于·等待阻塞状态，直到其他线程调用此对象的notify方法或notifyAll方法或者其他某个线程中断当前线程，或者已超过某个实际时间量，当前线程被唤醒 另一类是 Thread 类定义的方法，如下所示： 方法 描述 public static native void yield() 暂停当前正在执行的线程对象，并执行其他线程，yield 方法不会释放锁 public static native void sleep(long millis) 在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），sleep 方法不会释放锁 public final void join() 当某个程序执行流中调用其他线程的 join 方法时，调用线程将被阻塞，直到被 join 的线程执行完毕 public void interrupt() 用于中断本线程，这个方法被调用时，会立即将线程的中断标志设置为 true public static boolean interrupted() Thread 类的一个静态方法，它返回一个布尔类型指明当前线程是否已经被中断，interrupted 方法除了返回中断标记之外，它还会清除中断标记(即将中断标记设为 false) public boolean isInterrupted() Thread 类的一个实例方法，它返回一个布尔类型指明当前线程是否已经被中断，isInterrupted 方法仅仅返回中断标记，不会清楚终端标记 线程的优先级每一个 Java 线程都有一个优先级，这样有助于操作系统确定线程的调度顺序。Java 线程的优先级是一个整数，其取值范围是1（Thread.MIN_PRIORITY ）~ 10（Thread.MAX_PRIORITY ）。默认情况下，每一个线程都会分配一个优先级NORM_PRIORITY（5）。具有较高优先级的线程对程序更重要，并且应该在低优先级的线程之前分配处理器资源，Thread 类提供了 setPriority 和 getPriority 方法来更改和获取线程优先级（需要注意的是: 线程优先级不能保证线程执行的顺序，而且非常依赖于平台）。 参考文章 进程和线程的区别 Java多线程系列–“基础篇”05之 线程等待与唤醒]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 线程池（二）]]></title>
    <url>%2Fpost%2Fab706eb5.html</url>
    <content type="text"><![CDATA[简介在上篇 Java 线程池（一） 我们介绍了线程池中一些的重要参数和具体含义，这篇我们看一看在 Java 中是如何去实现线程池的，要想用好线程池，只知其然是远远不够的，我们需要深入实现源码去了解线程池的具体实现细节，这样才能更好的使用到我们的工作中，当出现问题时能快速找到问题根源所在。 线程池如何处理提交的任务我们向线程池提交任务有两种方式，分别是通过 submit 方法提交和通过 execute 方法提交，这两种方式的区别为 execute 只能提交 Runnable 类型的任务并且没有返回值，而 submit 既能提交 Runnable 类型的任务也能提交 Callable（JDK 1.5+）类型的任务并且会有一个类型 Future 的返回值，我们知道 Runnable 是没有返回值的，所以只有当提交 Callable 类型的任务时才会有返回值，而提交 Runnable 的返回值是 null。 execute 执行任务时，如果此时遇到异常会直接抛出，而 submit 不会直接抛出，只有在使用 Future 的 get 方法获取任务的返回结果时，才会抛出异常。通过查看 ThreadPoolExecutor 的源码我们发现，其 submit 方法是继承自其抽象父类 AbstractExecutorService 而来的，有三个重载的方法，分别可以提交 Runnable 类型和 Callable 类型的任务。无论是哪个 submit 方法最终还是调用了 execute 方法来实现的。方法源码如下： 1234567891011121314151617181920public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125;public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;&#125;public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125; 首先对提交的任务进行判非空指针后，三个方法都是调用 newTaskFor 方法把任务统一封装成 RunnableFuture 对象，然后把封装好的对象作为 execute 方法的入参去执行，而此时 execute 方法还未实现，这个方法是在 AbstractExecutorService 的继承类 ThreadPoolExecutor 中实现。下面看看 newTaskFor 方法是如何封装我们提交的任务的，两个重载方法的源码如下： 1234567protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable);&#125; 那么这个 FutureTask 是个什么东东呢，进入其源码发现它实现了 RunnableFuture 接口，而 RunnableFuture 接口的作用正如其名，它是 Runnable 和 Future 的结合体，表示一个能异步返回结果的线程。我们知道 Runnable 是不能返回结果的，所以上面第一个 newTaskFor(Runnable runnable, T value) 方法的第二个参数 value 的作用就是指定返回结果。其实最后也是通过 RunnableAdapter 把 Runnable 和 value 封装成 Callable 的。下面我们看看 execute 方法是怎么处理的，方法源码如下： 第 ① 步 获取当前的 ctl 值，在上篇 Java 线程池（一） 中说过，变量 ctl 存储了线程池的工作状态 runState 和线程池中正在运行的线程数 workerCount。第 ② 步 通过 workerCountOf 方法取出线程池中当前正在运行的线程数( ctl 低 29 位的值)，如果线程池当前工作线程数小于核心线程数 corePoolSize，则进行第 ③ 步。第 ③ 步 通过 addWorker 方法新建一个线程加到线程池中，addWorker 方法的第二个参数如果为 true 则限制添加线程的数量是根据 corePoolSize 来判断，反之则根据 maximumPoolSize 来判断，并把任务添加到该线程中。第 ④ 步 如果添加失败，则重新获取 ctl 的值。第 ⑤ 步 如果当前线程池的状态是运行状态（state &lt; SHUTDOWN）并且把任务成功添加到队列中。第 ⑥ 步 重新获取 ctl 的值，再次判断线程池的运行状态，如果不是运行状态，要从队列中移除任务，因为到这一步了，意味着之前已经把任务成功添加到队列中了，所以需要从队列移除。移除成功后调用拒绝策略对任务进行处理，整个 execute 方法结束（PS：为什么不在入队列之前就先判断线程池的状态呢？因为判断一个线程池工作处于运行状态到执行入队列操作这段时间，线程池可能已经被其它线程关闭了，所以提前判断其实毫无意义）。第 ⑦ 步 通过 workerCountOf 方法取出线程池中当前正在运行的线程数( ctl 低 29 位的值)，如果是 0 则执行 addWorker(null, false) 方法，第一个参数传 null 表示只是在线程池中创建一个线程出来，但是没有立即启动，因为我们创建线程池时可能要求核心线程数量为 0。第二个参数为 false 表示限制添加线程时根据 maximumPoolSize 来判断，如果当前线程池中正在运行线程数量大于 0 ，则直接返回，因为在上面第 ⑤ 步已经把任务成功添加到队列 workQueue 中，它会在将来的某个时刻执行到。第 ⑧ 步 如果执行到这个地方，只有两种情况，一种是线程池的状态已经不是运行状态了，另一种是线程池是运行状态，但是此时线程池的工作线程数大于等于核心线程数（workerCount &gt;= corePoolSize）并且队列 workQueue 已满。这时会再次调用 addWorker 方法，第二个参数传的 false，意味着限制添加线程的数量是根据 maximumPoolSize 来判断的，如果失败则调用拒绝策略对任务进行处理，整个 execute 方法结束。上面的 execute 方法中多次调用 addWorker，该方法的主要作用就是创建一个线程来执行任务。addWorker 的方法签名如下： 1addWorker(Runnable firstTask, boolean core) 第一个参数 firstTask 如果不为 null，则创建的线程首先执行 firstTask 任务，然后才会从队列中获取任务，否则会直接从队列中获取任务。第二个参数如果为 true，则表示限制添加线程时根据 corePoolSize 来判断，否则根据maximumPoolSize 来判断。我们看看 addWorker 方法的源码，方法源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 方法首先获取线程池 ctl 属性的值，该属性包含了线程池的运行状态和工作线程数，通过 runStateOf 获取线程池的运行状态，然后执行下面这个比较复杂的条件判断 第 ① 个条件表示此时线程池已经不再接受新任务了，接下来的 ②、③、④ 三个判断条件只要有一个不满足，那么方法就会返回 false，方法结束。第 ② 个条件表示线程池为关闭状态，处于关闭状态的线程池不会处理新提交的任务，但会处理完已处理的任务，第 ③ 个条件为 firstTask 为 null，第 ④ 个条件为队列不为空。我们看看如果线程池此时为关闭状态的情况，这种情况线程池不会接受新提交的任务，所以此时如果传入的 firstTask 不为 null，则会直接返回 false；然后如果 firstTask 为 null，并且队列 workQueue 为空，此时也会返回 false，因为此时队列里已经没有任务了，那么也不需要再添加线程了，然后接下来会进入一个循环。 第 ① 步 调用 workerCountOf 方法获取当前线程池的工作线程数第 ② 步 如果当前线程池的工作数大于 CAPACITY 也就是 ctl 的低 29 位的最大值，则返回 false，如果不大于 CAPACITY，然后根据 core （该方法的第二个参数）来判断是和 corePoolSize 比较还是和 maximumPoolSize 比较，如果比这个值大则返回 false。第 ③ 步 使用 ctl 的 compareAndSet 原子方法尝试把工作线程数 workerCount + 1，如果增加成功，退出第一层循环。第 ④ 步 如果增加线程池工作线程数失败，则重新获取 ctl 的值。第 ⑤ 步 调用 runStateOf 获取线程池的状态，如果不等于方法前面获取的 rs，说明线程池的状态已经改变了，回到第一层循环继续执行。接下来会启动线程执行任务，源码如下： 第 ① 步 根据 firstTask 创建 Worker 对象，每一个 Worker 对象都会创建一个线程，然后会使用重入锁 ReentrantLock 进行加锁操作。第 ② 步 调用 runStateOf 获取线程池的状态，然后进行一个条件判断，第一个 rs &lt; SHUTDOWN 表示线程池是运行状态。如果线程池是运行状态或者线程池是关闭状态并且 firstTask 为 null，那么就往线程池中加入线程（因为当线程池是 SHUTDOWN 状态时不会再向线程池添加新的任务，但会执行队列 workQueue 中的任务）。这里的 workers 是一个 HashSet，所以其 add 方法不是线程安全的，所以需要加锁操作。然后修改线程池中出现过的最大线程数量 largestPoolSize 记录和把是否添加成功标记 workerAdded 为 true。如果 workerAdded 为 true 那么会启动线程并把线程是否启动标记 workerStarted 改为 true。第 ③ 步 根据线程是否启动 workerStarted 标记来判断是否需要进行失败的操作。包含从 workers 移除当前的 worker、线程池的工作线程数减 1、尝试终端线程池。 线程池中线程是如何执行的线程池的线程执行是调用 Worker 的 thread 属性的 start 方法，而 thread 的 run 方法实际上调用了 Worker 类的 runWorker 方法，所以我们直接来看看 runWorker 方法的源码： 第 ① 步 获取第一个任务，while 循环不断地通过 getTask 方法从队列中获取任务。第 ② 步 这个判断条件目的是要保证如果线程池正在停止，要保证当前线程是中断状态，如果是的话，要保证当前线程不是终端状态。第 ③ 步 方法 beforeExecute 方法在类 ThreadPoolExecutor 中没有做任何操作，是留给子类去自定义在线程执行之前添加操作的方法。第 ④ 步 执行 task.run() 执行任务（PS：这里为什么是调用 run 方法而不是调用 start 方法呢？我们知道当调用了 start 方法后操作系统才会给我们创建一个独立的线程来运行，而调用 run 方法只是一个普通的方法调用，而线程池正好就是需要它是一个普通的方法才能进行任务的调度。我们可以想象一下，假如这里是调用的 Runnable 的 start 方法，那么会是什么结果呢。如果我们往一个核心线程数、最大线程数为 3 的线程池里丢了 500 个任务，那么它会额外的创建 500 个线程，同时每个任务都是异步执行的，结果一下子就执行完毕了，根本无法对任务进行调度。从而没法做到由这 3 个 Worker 线程来调度这 1000 个任务，而只有当做一个普通的 run 方法调用时才能满足线程池的这个要求）。第 ⑤ 步 方法 afterExecute 方法在类 ThreadPoolExecutor 中没有做任何操作，是留给子类去自定义在线程执行之后添加操作的方法。completedAbruptly 变量是用来表示在执行任务过程中是否出现了异常，processWorkerExit 方法中会对该变量的值进行判断。接下来我们看看 getTask 方法是如何从队列中获取任务的，方法源码如下： 第 ① 步 如果线程池不是运行状态，则判断线程池是否正在停止或者当前队列为空，如果条件满足将线程池的工作线程数减一并返回 null。因为如果当前线程池状态的值是 SHUTDOWN 或以上时，就不允许再向队列中添加任务了。第 ② 步 这里的 timed 变量用来标记是否需要线程进行超时控制，allowCoreThreadTimeOut 默认是 false，也就是核心线程不允许进行超时。wc &gt; corePoolSize 表示当前线程池中的工作线程数量大于核心线程数量，对于超过核心线程数量的这些线程，需要进行超时控制。第 ③ 步 第一个判断 wc &gt; maximumPoolSize 如果成立是因为可能在此方法执行阶段同时执行了线程池的 setMaximumPoolSize 方法；第二个判断 timed &amp;&amp; timedOut 如果成立表示当前操作需要进行超时控制，并且上次从队列中获取任务发生了超时（timeOut 变量的值表示上次从阻塞队列中取任务时是否超时）；第三个判断 wc &gt; 1 || workQueue.isEmpty() 如果线程池中工作线程数量大于 1，或者队列是空的，那么尝试将 workerCount 减一，如果减一失败，则返回重试。如果 wc == 1 时，也就说明当前线程是线程池中唯一的一个线程了。第 ④ 步 根据 timed 来判断，如果为 true，则通过阻塞队列的 poll 方法进行超时控制，如果在 keepAliveTime 时间内没有获取到任务，则返回 null，否则通过 take 方法，如果这时队列为空，则 take 方法会阻塞直到队列不为空。如果 r == null，说明已经超时，timedOut 设置为 true。第 ⑤ 步 如果获取任务时当前线程发生了中断，则设置 timedOut 为 false 并重新循环重试。 关闭线程池线程池的关闭一般都是使用 shutdown 方法和 shutdownNow 方法，两者的区别是前面的 shutdown 方法不会执行新的任务，但是会执行完当前正在执行的任务，而后面的 shutdownNow 方法会立即停止当前线程池，不管当前是否有线程在执行。一般都是使用 shutdown 方法来停止线程池，其方法源码如下： 12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(SHUTDOWN); interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125; advanceRunState(SHUTDOWN) 方法的作用是通过 CAS 原子操作将线程池的状态更改为关闭状态。interruptIdleWorkers 方法是对空闲的线程进行中断，其实是调用重载带参数的函数 interruptIdleWorkers(false)。然后 onShutdown 方法和上文提到的 beforeExecute、afterExecute 方法一样，在类 ThreadPoolExecutor 是空实现，也是个钩子函数。我们看看 interruptIdleWorkers 的实现源码： 123456789101112131415161718192021private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; 先进行加锁操作，然后遍历 workers 容器，也就是遍历线程池中的线程，对每个线程进行 tryLock 操作，如果成功说明线程空闲，则设置其中断标志位。而线程是否响应中断则交给我们定义任务的人来决定。 总结本文比较详细的分析了线程池任务的提交、线程的执行、线程池的关闭的工作流程。通过学习线程池相关的源码后，看到了在其内部用运用了很多多线程的解决方法，有如下几个方式： 通过定义重入锁 ReentrantLock 变量 mainLock 来解决并发多线程的安全问题 利用等待机制来实现线程之间的通讯问题除了内置的功能外，ThreadPoolExecutor 也向外提供了两个接口供我们自己扩展满足我们需求的线程池，这两个接口分别是：beforeExecute 任务执行前执行的方法，afterExecute 任务执行结束后执行的方法。]]></content>
      <categories>
        <category>Java</category>
        <category>线程池</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 线程池（一）]]></title>
    <url>%2Fpost%2Fbc557e1a.html</url>
    <content type="text"><![CDATA[线程池简介使用线程池可以很好的提高性能，线程池在运行之初就会创建一定数量的空闲线程，我们将一个任务提交给线程池，线程池就会使用一个空闲的线程来执行这个任务，该任务执行完后，该线程不会死亡，而是再次变成空闲状态返回线程池，等待下一个任务的到来。在使用线程池时，我们把要执行的任务提交给整个线程池，而不是提交给某个线程，线程池拿到提交的任务后，会在内部寻找是否还有空闲的线程，如果有，就将这个任务提交给某个空闲的线程，虽然一个线程同一时刻只能执行一个任务，但是我们可以向线程池提交多个任务。合理使用线程池有以下几个优点：① 降低资源消耗 多线程运行期间，系统不断的启动和关闭新线程，成本高，会过度消耗系统资源，通过重用存在的线程，减少对象创建、消亡的开销② 提高响应速度 当有任务到达时，任务可以不需要等待线程的创建，可以直接从线程池中取出空闲的线程来执行任务③ 方便线程管理 线程对计算机来说是很稀缺的资源，如果让他无限制创建，它不仅消耗系统的资源，还会降低系统的稳定性，我们使用线程池后可以统一进行分配和监控谈到线程池就会想到池化技术，核心思想就是把宝贵的资源放到一个池子中，每次要使用都从池子里面取，用完之后又放回池子让别人用。那么线程池在 Java 中是如何实现的呢？ Java 四种线程池在 Java 中 Executors 工具类给我们提供了四种不同使用场景的线程池的创建方法，分别为： newSingleThreadExecutor 只有一个线程来执行任务，适用于有顺序的任务的应用场景。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它，它可以保证任务按照指定顺序（FIFO，LIFO）执行，它还有可以指定线程工厂（ThreadFactory）的重载方法，可以自定义线程的创建行为 newFixedThreadPool 固定线程数的线程池，只有核心线程，核心线程的即为最大的线程数量，没有非核心线程。每次提交一个任务就创建一个线程，直到达到线程池的最大大小。线程池一旦达到最大值就会保持不变，如果当中的某个线程因为异常而结束，那么线程池会新建一个线程加入到线程池中。它还可以控制线程的最大并发数，超出的线程会在阻塞队列（LinkedBlockingQueue）中等待，同样它也有可以指定线程工厂（ThreadFactory）的重载方法，可以自定义线程的创建行为。 newCachedThreadPool 创建一个可缓存线程池，最大的线程个数为 2^31 - 1（Integer.MAX_VALUE），可以认为是无限大，若无可回收，则新建线程，如果线程池的大小超出了处理任务所需要的线程，那么就会回收部分空闲（60s 不执行任务）的线程。 newScheduledThreadPool 周期性执行任务的线程池，按照某种特定的计划执行线程中的任务，有核心线程，但也有非核心线程，非核心线程的大小也为无限大（Integer.MAX_VALUE：2^31 - 1），适用于执行周期性的任务。 Java 线程池参数详解上文说到的 Executors 工具类提供的四种适用于不同场景的线程池，通过查看源码可以发现最终都是调用 ThreadPoolExecutor 类来实现的，我们接下来深入了解这个类一些成员变量的具体含义。首先是ctl，其声明如下： 1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); 这个成员变量 ctl 主要用于存储线程池的工作状态以及线程池正在运行的线程数。很显然，要在一个整型变量中存储两部分数据，只能将其一分为二。其中的高 3bit 用于存储线程的状态，低 29bit 用于存储线程池中正在执行的线程数。 线程池的状态在 ThreadPoolExecutor 定义了线程池的五种状态（注意，这里说的是线程池状态，不是池中的线程的状态），当创建一个线程池时的状态为 RUNNING。 12345private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 线程池状态 含义 RUNNING 允许提交并处理任务 SHUTDOWN 不会处理新提交的任务，但会处理完已处理的任务 STOP 不会处理新提交的任务，也不会处理阻塞队列中未执行的任务，并设置正在执行任务的中断标志位 TIDYING 所有任务执行完毕，线程池中工作的线程数为 0，等待执行 terminated() 钩子方法 TERMINATED terminated() 钩子方法执行完毕 调用线程池的 shutdown 方法，将线程池由 RUNNING 状态转为 SHUTDOWN 状态。调用 shutdownNow 方法，将线程池由 RUNNING 状态转为 STOP 状态。SHUTDOWN 状态和 STOP 状态都会先变为 TIDYING 状态，最终都会变为 TERMINATED 状态。用图表示为： ThreadPoolExecutor 同时提供了以下三个方法来查看线程池的状态和池中正在执行的线程数 123private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; ThreadPoolExecutor 的构造函数该类参数最全的构造方法如下，这个方法决定了创建出来的线程池的各种属性： 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 各个参数的含义：corePoolSize 线程池中核心线程数的最大值maximumPoolSize 线程池中最多能拥有的线程数keepAliveTime 空闲线程存活时间unit 空闲线程存活时间的单位workQueue 用于存放任务的阻塞队列threadFactory 创建线程工厂handler 当 workQueue 已满，并且池中的线程数达到 maximumPoolSize 时，线程池继续添加新任务时采取的策略 下面通过一张图来更形象的理解线程池的这几个参数： corePoolSize、maximumPoolSize、workQueue 三者的关系，通过向线程池添加新的任务来说明着三者之间的关系： 如果没有空闲的线程执行该任务，并且池中运行的线程数小于corePoolSize时，则创建新的线程执行该任务 如果没有空闲的线程执行该任务，并且当池中正在执行的线程数大于corePoolSize时，新添加的任务进入workQueue排队（如果workQueue长度允许），等待空闲线程来执行 如果没有空闲的线程执行该任务，并且阻塞队列已满同时池中的线程数小于maximumPoolSize，则创建新的线程执行该任务 如果没有空闲的线程执行该任务，并且阻塞队列已满同时池中的线程数等于maximumPoolSize，则根据构造函数中的handler指定的策略来拒绝新添加的任务 在线程池中并没有标记出哪些线程是核心线程，哪些非核心线程，线程池它只关心核心线程的数量。下面这个是网上看到的一个形象的比喻： 如果把线程池比作一个单位的话，corePoolSize就表示正式工，线程就可以表示一个员工。当我们向单位委派一项工作时，如果单位发现正式工还没招满，单位就会招个正式工来完成这项工作。随着我们向这个单位委派的工作增多，即使正式工全部满了，工作还是干不完，那么单位只能按照我们新委派的工作按先后顺序将它们找个地方搁置起来，这个地方就是workQueue，等正式工完成了手上的工作，就到这里来取新的任务。如果不巧，年末了，各个部门都向这个单位委派任务，导致workQueue已经没有空位置放新的任务，于是单位决定招点临时工吧（临时工：又是我！）。临时工也不是想招多少就找多少，上级部门通过这个单位的maximumPoolSize确定了你这个单位的人数的最大值，换句话说最多招maximumPoolSize – corePoolSize个临时工。当然，在线程池中，谁是正式工，谁是临时工是没有区别，完全同工同酬。 keepAliveTime 和 unit 单位keepAliveTime 表示那些超出corePoolSize数量之外的线程的空闲时间大于keepAliveTime后就被清除了。 workQueue 任务队列workQueue决定了缓存任务的排队策略，对于不同的任务场景我们可以采取不同的策略，这个队列需要一个实现了BlockingQueue接口的任务等待队列。从ThreadPoolExecutor的文档中得知，官方一共给我们推荐了三种队列，分别是：SynchronousQueue、LinkedBlockingQueue、ArrayBlockingQueue。其中SynchronousQueue和ArrayBlockingQueue属于有限队列，LinkedBlockingQueue属于无限队列，具体作用如下： SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等待另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。 ArrayBlockingQueue：有界阻塞队列。一个由数组支持的有界阻塞队列。此队列按FIFO（先进先出）原则对元素进行排序。新元素插入到队列的尾部，队列获取操作则是从队列头部开始获得元素。这是一个典型的“有界缓存区”，固定大小的数组在其中保持生产者插入的元素和使用者提取的元素。一旦创建了这样的缓存区，就不能再增加其容量。试图向已满队列中放入元素会导致操作受阻塞，试图从空队列中提取元素将导致类似阻塞。 LinkedBlockingQueue：链表结构的阻塞队列，尾部插入元素，头部取出元素。LinkedBlockingQueue是我们在ThreadPoolExecutor线程池中常用的等待队列。它可以指定容量也可以不指定容量。由于它具有“无限容量”的特性，实际上任何无限容量的队列/栈都是有容量的，这个容量就是Integer.MAX_VALUE。LinkedBlockingQueue的实现是基于链表结构，而不是类似ArrayBlockingQueue那样的数组。但实际使用过程中，不需要关心它的内部实现，如果指定了LinkedBlockingQueue的容量大小，那么它反映出来的使用特性就和ArrayBlockingQueue类似了。 threadFactory 创建线程的工厂其实像ThreadPoolExecutor有的没有threadFactory参数的构造方法中使用的创建线程的工厂就是默认的工厂，比如下面这个构造方法： 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; 在这个构造方法中，创建线程的工厂的方法使用Executors.defaultThreadFactory()的工厂和ThreadPoolExecutor中的defaultHandler默认抛弃策略。使用 Executors.defaultThreadFactory创建的线程同属于相同的线程组，具有同为Thread.NORM_PRIORITY的优先级，以及名为pool-poolNumber.getAndIncrement()-thread-的线程名（poolNumber.getAndIncrement() 为线程池顺序序号），且创建的线程都是非守护进程。 handler 拒绝策略表示当workQueue已满，池中的线程数达到maximumPoolSize时，线程池拒绝添加新任务时采取的策略。从文档中得知，handler一般可以取以下四种值： 拒绝策略 含义 AbortPolicy 抛出 RejectedExecutionException 异常 CallerRunsPolicy 由向线程池提交任务的线程来执行该任务 DiscardPolicy 直接丢弃当前的任务 DiscardOldestPolicy 抛弃最旧的任务（最先提交而没有得到执行的任务） 个人觉得最优雅的方式还是AbortPolicy提供的处理方式：抛出异常，由开发人员进行处理。ThreadPoolExecutor默认的拒绝方式defaultHandler就是ThreadPoolExecutor.AbortPolicy。 合理配置线程池最后，我们要想合理的配置线程池，就必须首先分析任务特性，可以从以下几个角度来进行分析： 任务的性质任务性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务配置尽可能少的线程数量，如配置Ncpu+1个线程的线程池。IO 密集型任务则由于需要等待 IO 操作，线程并不是一直在执行任务，则配置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，则将其拆分成一个 CPU 密集型任务和一个 IO 密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率，如果这两个任务执行时间相差太大，则没必要进行分解。我们可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的 CPU 个数。 任务的优先级优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。 任务的执行时间执行时间不同的任务可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。 任务的依赖性依赖数据库连接池的任务，因为线程提交 SQL 后需要等待数据库返回结果，如果等待的时间越长 CPU 空闲时间就越长，那么线程数应该设置越大，这样才能更好的利用 CPU。建议使用有界队列，有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点，比如几千。有一次我们组使用的后台任务线程池的队列和线程池全满了，不断的抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行 SQL 变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞住，任务积压在线程池里。如果当时我们设置成无界队列，线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。当然我们的系统所有的任务是用的单独的服务器部署的，而我们使用不同规模的线程池跑不同类型的任务，但是出现这样问题时也会影响到其他任务。 参考文章：JAVA 线程池的分析和使用ThreadPoolExecutor 的 workQueue 任务队列详解]]></content>
      <categories>
        <category>Java</category>
        <category>线程池</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深挖 HashMap]]></title>
    <url>%2Fpost%2F99ea2970.html</url>
    <content type="text"><![CDATA[1.1 前言做过 java 开发的朋友们相信都很熟悉 HashMap 这个类，它是一个基于 hashing 原理用于存储 Key-Value 键值对的集合，其中的每一个键也叫做 Entry，这些键分别存储在一个数组当中，系统会根据 hash 方法来计算出 Key-Value 的存储位置，可以通过 key 快速存取 value。HashMap 基于 hashing 原理，当我们将一个键值对（Key-Value） 传入 put 方法时，它将调用这个 key 的 hashcode 方法计算出 key 的 hashcode 值，然后根据这个 hashcode 值来定位其存放数组的位置来存储对象（HashMap 使用链表来解决碰撞问题，当其发生碰撞了，对象将会存储在链表的下一个节点中，在链表的每个节点中存储 Entry 对象，在 JDK 1.8+ 中，当链表的节点个数超过一定值时会转为红黑树来进行存储），当通过 get 方法传入一个 key 来获取其对应的值时，也是先通过 key 的 hashcode 方法来定位其存储在数组的位置，然后通过键对象的 eqauls 方法找到对应的 value 值。接下来让我们看看其内部的一些实现细节。（PS：以下代码分析都是基于 JDK 1.8） 1.2 为什么容量始终是 2 的整数次幂因为获取 key 在数组中对应的下标是通过 key 的哈希值与数组的长度减一进行与运算来确定的（tab[(n - 1) &amp; hash]）。当数组的长度 n 为 2 的整数次幂，这样进行 n - 1 运算后，之前为 1 的位后面全是 1 ，这样就能保证 (n - 1) &amp; hash 后相应位的值既可能是 1 又可能是 0 ，这完全取决于 key 的哈希值，这样就能保证散列的均匀，同时与运算（位运算）效率高。如果数组的长度 n 不是 2 的整数次幂，会造成更多的 hash 冲突。HashMap 提供了如下四个重载的构造方法来满足不同的使用场景： 无参构造：HashMap()，使用该方法表示全部使用 HashMap 的默认配置参数 指定容量初始值构造：HashMap(int initialCapacity)，在初始化 HashMap 时指定其容量大小 指定容量初始值和扩容因子构造：HashMap(int initialCapacity, float loadFactor)，使用自定义初始化容量和扩容因子 通过 Map 来构造 HashMap：HashMap(Map&lt;? extends K, ? extends V&gt; m)，使用默认的扩容因子，其容量大小有传入的 Map 大小来决定 前三个构造方法最终都是调用第三个即自定义容量初始值和扩容因子构造 HashMap(int initialCapacity, float loadFactor)，其源码实现如下123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; 从源码实现可以看出，如果我们传入的初始容量值大于 MAXIMUM_CAPACITY 时，就设置容量为 MAXIMUM_CAPACITY，其值如下： 123456/** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; 也就是容量的最大值为 2 的 30 次方（1 &lt;&lt; 30）。我们知道，HashMap 的容量始终是 2 的整数次幂，不管我们传入的初始容量是什么，它都会使用最接近这个值并且是 2 的整数次幂作为 HashMap 的初始容量，这一步处理是通过 tableSizeFor 方法来实现的，我们看看它的源码： 通过方法的注释我们也可以知道（英语对于从事技术开发的人太重要了~~~），此方法的返回值始终是 2 的整数次幂，它是如何做到的呢？接下来我们通过一个例子一步一步来看，假设我们传入的初始容量大小 cap 的值 cap 为 15。 第 ① 步：将 cap - 1 后，n 的值为 14（15 - 1）。 第 ② 步：将 n 的值先右移 1 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ③ 步：将 n 的值先右移 2 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ④ 步：将 n 的值先右移 4 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ⑤ 步：将 n 的值先右移 8 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ⑥ 步：将 n 的值先右移 16 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 最后如果 n 的值小于 0，则返回 1，如果大于最大值 MAXIMUM_CAPACITY 则返回 MAXIMUM_CAPACITY，否则返回 n + 1。 现在 n 为 15，所以返回 n + 1（16），而 16 正好是 2 的 4 次幂。有的朋友可能会问，刚刚上文假设的初始容量大小 cap 是 15，本来就不是 2 的整数次幂，如果我传入初始容量的就是 2 的整数次幂那会怎么样呢？现在假设传的初始容量大小为 32（2 的 5 次方）看看结果是什么。 第 ① 步：将 cap - 1 后，n 的值为 31（32 - 1）。 第 ② 步：将 n 的值先右移 1 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ③ 步：将 n 的值先右移 2 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ④ 步：将 n 的值先右移 4 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ⑤ 步：将 n 的值先右移 8 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ⑥ 步：将 n 的值先右移 16 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 经过以上 6 步计算后得出 n 的值为 31，大于 0 小于 MAXIMUM_CAPACITY 返回 n + 1，所以经过计算后的初始容量大小为 32。稍微总结一下，我们可以得出：如果我们传入的初始容量大小不是 2 的整数次幂，那么经过计算后的初始容量大小为大于我们传入初始容量值的最小值并且是 2 的整数次幂。细心的朋友会发现，为什么第一步要进行 cap - 1 的操作呢？那是因为，如果不进行 - 1 运算的话，当我们传入的初始容量大小为 2 的整数次幂的时候，通过以上步骤计算出来的结果值为传入值的 2 倍。假设我们传入的初始容量大小为 32，此时没有第 ① 步（cap - 1）的操作，那么依次通过以上 ②、③、④、⑤、⑥ 后为 63，最后再进行 n + 1 操作，结果为 64 是 传入值 32 的 2 倍，显然和预期结果（32）不符。这个计算初始容量的算法还是很巧妙的，先进行了 -1 的操作，保证传入初始容量值为 2 的整数次幂的时候，返回传入的原始值。 1.3 hash 方法是如何实现的不管是通过 get 方法获取 key 对应的 Value 值或者通过 put 方法存储 Key-Value 键值对时，都会先根据 key 的哈希值定位到数组的位置，我们看看 HashMap 里的 hash 方法是如何实现的，源码如下： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 当 key 为 null 时，返回 0，否则进行 h = key.hashCode()) ^ (h &gt;&gt;&gt; 16 运算，先调用 key 的 hashCode 方法获取 key 的哈希值，然后与 key 的哈希值右移 16 位后的值进行异或运算（相同为 0，不同为 1，简称 同假异真），为什么获取 key 的哈希值还要再进行异或运算，直接返回 key 的哈希值好像也没什么问题，如果没有后面的异或运算，直接返回哈希值，我们假设数组的长度为 16，现在要往 HashMap 存入的三个键值对的 key 的哈希值分别为 32831、33554495、2097215，根据 hash 方法返回值定位到数组的位置（(n - 1) &amp; hash），以上三个值和 15（16 - 1）进行 &amp; 运算（都为 1 才为 1，其它情况都为 0） 如下： 可以发现以上三个哈希值都定位的数组下标为 15 的位置上。所以 hash 如果方法没有后面与哈希值右移 16 位后的值进行异或运算的话，当数组长度比较小时很容易造成 哈希碰撞，即多个 key（不同的哈希值）都会定位到数组上的同一个位置，也就是说会放入到同一个链表或者红黑树中，因为此时 key 的哈希值只有低位的才会参与运算，显然和我们的预期不符合。可见 hash 方法将 key 的哈希值与其右移 16 位后进行异或运算能减少哈希碰撞的次数，把高位和低位都参与了运算，提高了分散性。 1.4 总结HashMap 其实还有很多值得我们深入研究的点，看懂了上面两个方法后，不得不佩服作者的代码设计能力，JDK 中有很多优秀源码都值得我们好好品味，看代码的时候一定要多看几遍多问几个为什么，特别是经典的源代码，然后将这些思想运用到我们的实际工作中。]]></content>
      <categories>
        <category>Java</category>
        <category>原理</category>
      </categories>
      <tags>
        <tag>Java, 原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同步工具类]]></title>
    <url>%2Fpost%2Fee27c07f.html</url>
    <content type="text"><![CDATA[1.1 前言同步工具类可以是任何一个对象，只要它根据其自身的状态来协调线程的控制流。在容器中，有些也可以作为同步工具类，其它类型的同步工具类还包括闭锁（Latch）、信号量（Semaphore）以及栅栏（Barrier）。阻塞队列（eg: BlockQueue）是一种独特的类：它们不仅能作为保存对象的容器，还能协调生产者和消费者之间的控制流，因为它提供的 take 和 put 等方法将会阻塞，直到队列达到期望的状态。所有的同步工具类都包含一些特定的属性：它们封装了一些状态，这些状态将决定同步工具类的线程是继续执行还是等待，此外还提供了一些方法对其状态进行操作，以及另一些方法用于高效地等待同步工具类进入到预期状态。 1.2 闭锁闭锁是一种同步工具类，可以延迟线程的进度直到其到达终止状态。闭锁的作用相当于一扇门：在闭锁到达结束状态之前，这扇门一直是关闭的，并且没有任何线程能通过，当到达结束状态时，这扇门会打开并允许所有线程通过。当闭锁到达结束状态后，将不会再次改变状态，因此这扇门将永远保持打开状态。闭锁可以用来确保某些活动直到其它活动都完成后才继续执行。比如： 确保某个计算机在其需要的所有资源初始化后才能继续执行。 确保某个服务在其依赖的所有服务都已经启动后才启动。 等待直到某个操作的所有参与者都就绪后再继续执行。 1.2.1 CountDownLatchCountDownLatch 是一种灵活的闭锁实现，可以在上述各种情况中使用，它可以使一个或多个线程等待一组事件发生。闭锁状态包括一个计数器，该计数器被初始化为一个正数，表示需要等待事件的数量。countDown() 方法递减计数器，表示有一个事件已经发生了，而 await() 方法等待计数器达到 0 ，这表示所有需要等待的事件都已经发生。如果计数器的值非 0 ，那么 await() 方法会一直阻塞到计数器的值为 0 ，或者等待线程中断，或者等待超时。CountDownLatch 被用来同步一个或多个任务，强制它们等待由其它任务执行的一组操作完成。你可以向 CountDownLatch 对象设置一个初始计数值，任何在这个对象上调用 await() 的方法都将阻塞，直到这个计数值到达 0。其它任务在结束工作时，可以在该对象上调用 countDown() 方法来减小这个计数值。CountDownLatch 被设计为只触发一次，计数值不能重置。如果你需要重置计数值的版本，请看下文的 CyclicBarrier。把大象放入冰箱的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * @author mghio * @date: 2019-11-03 * @version: 1.0 * @description: 同步工具类 —— CountDownLatch * @since JDK 1.8 */public class CountDownLatchDemo &#123; private static CountDownLatch countDownLatch1 = new CountDownLatch(1); private static CountDownLatch countDownLatch2 = new CountDownLatch(1); public static void main(String[] args) &#123; final Thread thread1 = new Thread(() -&gt; &#123; System.out.println("step 1：打开冰箱门..."); // 对 countDownLatch1 倒计时 -1 countDownLatch1.countDown(); &#125;); final Thread thread2 = new Thread(() -&gt; &#123; try &#123; // 等待 countDownLatch1 倒计时，计时为 0 则往下运行 countDownLatch1.await(); System.out.println("step 2：把大象放入冰箱..."); // 对 countDownLatch2 倒计时 -1 countDownLatch2.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); final Thread thread3 = new Thread(() -&gt; &#123; try &#123; // 对 countDownLatch2 倒计时，计时为 0 则往下进行 countDownLatch2.await(); System.out.println("step 3：关上冰箱门..."); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); System.out.println("------- 把大象放入冰箱 --------"); thread3.start(); thread1.start(); thread2.start(); &#125;&#125; 以上代码输出结果： 1234------- 把大象放入冰箱 --------step 1：打开冰箱门...step 2：把大象放入冰箱...step 3：关上冰箱门... 1.2.2 FutureTaskFutureTask 也可以用作闭锁。它实现了 Future 的语义，表示一种抽象可生成结果的计算。 FutureTask 表示的计算是通过 Callable 来实现的，相当于一种可生成结果的 Runnable ，并且可以处于这三种状态：等待运行（Waiting to run）、正在运行（Running）和运行完成（Completed）。其中执行完成表示计算的所有可能结束方式，包括正常结束、由于取消结束和由于异常结束等。当 FutureTask 进入完成状态后，它就会永远停在这个状态上。get() 方法的行为取决于任务的状态。如果此时任务已经完成，那么 get() 方法会立即返回结果，否则将会阻塞直到任务进入到完成状态，然后返回结果或者抛出异常。FutureTask 将计算结果从执行计算的线程传递到获取这个结果的线程，而 FutureTask 的规范确保了这种传递过程能实现结果的安全发布。FutureTask 在 Executor 框架中表示异步任务，除此之外还可以用来表示一些耗时比较长的计算，这些计算可以在使用计算结果之前启动。以下示例使用其执行一个异步任务： 1234567891011121314151617181920212223242526272829303132/** * @author mghio * @date: 2019-11-03 * @version: 1.0 * @description: 同步工具类 —— FutureTask * @since JDK 1.8 */public class FutureTaskDemo &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; System.out.println("--------- 进入主线程执行任务"); ExecutorService threadPool = Executors.newCachedThreadPool(); System.out.println("--------- 提交异步任务"); FutureTask&lt;String&gt; future = new FutureTask&lt;&gt;(() -&gt; "成功获取 future 异步任务结果"); threadPool.execute(future); System.out.println("--------- 提交异步任务之后，立马返回到主线程继续往下执行"); Thread.sleep(1000); System.out.println("--------- 此时需要获取上面异步任务的执行结果"); boolean flag = true; while (flag) &#123; if (future.isDone() &amp;&amp; !future.isCancelled()) &#123; String futureResult = future.get(); System.out.println("--------- 异步任务返回的结果是：" + futureResult); flag = false; &#125; &#125; if (!threadPool.isShutdown()) &#123; threadPool.shutdown(); &#125; &#125;&#125; 以上代码输出结果为： 12345--------- 进入主线程执行任务--------- 提交异步任务--------- 提交异步任务之后，立马返回到主线程继续往下执行--------- 此时需要获取上面异步任务的执行结果--------- 异步任务返回的结果是：成功获取 future 异步任务结果 1.4 信号量计数信号量（Counting Semaphore）用来控制同时访问某个特定资源的操作数量，或者同时执行指定操作的数量。计数信号量还可以用来实现某种资源池或者对容器施加边界。Semaphore 中管理着一组虚拟的许可（permit），许可的初始数量可以通过构造函数来指定，在执行操作时可以首先获得许可（只要还有剩余的许可），并在使用以后释放许可。如果没有许可，那么 acquire() 将阻塞直到有许可或者直到终端或者直到超时。release() 方法将返回一个许可给信号量。Semaphore 可以用于实现资源池，例如数据库连接池。我们可以构造一个固定长度的资源池，当池为空时，请求资源将会失败，但你真正希望看到的行为是阻塞而不是失败，并且当池非空时解除阻塞。如果将 Semaphore 的计数值初始化为池的大小，并在从池中获取一个资源之前首先调用 acquire() 方法获取一个许可，在将资源返回给池之后调用 release() 方法释放许可，那么 acquire() 方法将一直阻塞直到资源池不为空。以下示例将使用 Semaphore 将 HashSet 容器变成有界的阻塞容器，信号量的计数值会初始化为容器容量的最大值。add 操作在向底层容器添加一个元素之前，首先要获取一个许可。如果 add 操作没有添加任何元素，那么会立刻释放许可。同样 remove 操作会释放一个许可，使更多的元素能够添加到容器中。底层的 Set 实现并不知道关于边界的任何信息。 12345678910111213141516171819202122232425262728293031323334353637383940/** * @author maguihai * @date: 2019-11-03 * @version: 1.0 * @description: 同步工具类 —— Semaphore * @since JDK 1.8 */public class BoundedHashSet&lt;T&gt; &#123; private final Set&lt;T&gt; set; private final Semaphore sem; public BoundedHashSet(int bound) &#123; this.set = Collections.synchronizedSet(new HashSet&lt;&gt;()); this.sem = new Semaphore(bound); &#125; public boolean add(T o) throws InterruptedException &#123; sem.acquire(); boolean wasAdded = false; try &#123; wasAdded = set.add(o); return wasAdded; &#125; finally &#123; if (!wasAdded) &#123; sem.release(); &#125; &#125; &#125; public boolean remove(T o) &#123; boolean wasRemoved = set.remove(o); if (wasRemoved) &#123; sem.release(); &#125; return wasRemoved; &#125;&#125; 1.5 栅栏我们已经看到通过闭锁来启动一组相关的操作，或者等待一组相关的操作结束。闭锁是一次性对象，一旦进入终止状态，就不能被重置。栅栏（Barrier）类似于闭锁，它能阻塞一组线程直到某个事件发生。栅栏与闭锁的关键区别在于：所有线程都必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其它线程。栅栏用于实现一些协议，例如几个家庭决定在某个地方集合：“所有人 6:00 在 KFC 碰头，到了以后要等其它人，之后再讨论下一步要做的事情”。CyclicBarrier 适用于这样的情况：你希望创建一组任务，他们并行执行工作，然后再运行下一个步骤之前等待，知道所有任务都完成（有点儿像线程的 join 方法）。它使得所有的并行任务都将处于栅栏处列队，因此可以一致的向前移动。这和上文的 CountDownLatch 非常像，只是 CountDownLatch 只是触发一次的事件，而 CyclicBarrier 可以重复使用。CyclicBarrier 可以使一定数量的参与方反复地在栅栏位置汇聚，它在并行迭代算法中非常有用：这种算法通常将一个问题拆分成一系列相互独立的子问题。当线程达到栅栏位置时将调用 await() 方法，这个方法将阻塞直到所有线程都到达栅栏位置。如果所有栅栏都到达栅栏了位置，那么栅栏将打开，此时所有的线程都被释放，而栅栏将被重置以便下次使用。如果对 await() 方法调用超时，或者线程被中断，那么栅栏就认为是被打破了，所有阻塞 await() 的调用都将终止并抛出 BrokenBarrierException。如果成功通过栅栏，那么 await() 将为每一个线程返回一个唯一的到达索引号，我们可以利用这些索引来“选举”产生一个领导线程，并在下一次迭代中由该领导线程执行一些特殊的工作。CyclicBarrier 还可以使你将一个栅栏操作传递给构造函数，这个一个 Runnable ，当成功通过栅栏时会（在一个子任务线程中）执行它，但是它在阻塞线程被释放前是不能执行的。使用示例： 123456789101112131415161718192021222324252627282930313233343536/** * @author mghio * @date: 2019-11-03 * @version: 1.0 * @description: 同步工具类 —— CyclicBarrier * @since JDK 1.8 */public class CyclicBarrieDemo &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newCachedThreadPool(); // 创建 CyclicBarrier 对象并设置 3 个公共屏障点 final CyclicBarrier cb = new CyclicBarrier(3); for (int i = 0; i &lt; 3; i++) &#123; Runnable runnable = () -&gt; &#123; try &#123; Thread.sleep((long) (Math.random() * 10000)); System.out.println("线程 " + Thread.currentThread().getName() + " 即将到达集合地点1，当前已有 " + cb.getNumberWaiting() + " 个已经到达，正在等候"); // 到此如果没有达到公共屏障点，则该线程处于等待状态，如果达到公共屏障点则所有处于等待的线程都继续往下运行 cb.await(); Thread.sleep((long) (Math.random() * 10000)); System.out.println("线程 " + Thread.currentThread().getName() + " 即将到达集合地点2，当前已有 " + cb.getNumberWaiting() + " 个已经到达，正在等候"); cb.await(); Thread.sleep((long) (Math.random() * 10000)); System.out.println("线程 " + Thread.currentThread().getName() + " 即将到达集合地点3，当前已有 " + cb.getNumberWaiting() + " 个已经到达，正在等候"); cb.await(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;; service.execute(runnable); &#125; service.shutdown(); &#125;&#125; 以上代码运行结果： 123456789线程 pool-1-thread-3 即将到达集合地点1，当前已有 0 个已经到达，正在等候线程 pool-1-thread-1 即将到达集合地点1，当前已有 1 个已经到达，正在等候线程 pool-1-thread-2 即将到达集合地点1，当前已有 2 个已经到达，正在等候线程 pool-1-thread-3 即将到达集合地点2，当前已有 0 个已经到达，正在等候线程 pool-1-thread-2 即将到达集合地点2，当前已有 1 个已经到达，正在等候线程 pool-1-thread-1 即将到达集合地点2，当前已有 2 个已经到达，正在等候线程 pool-1-thread-3 即将到达集合地点3，当前已有 0 个已经到达，正在等候线程 pool-1-thread-2 即将到达集合地点3，当前已有 1 个已经到达，正在等候线程 pool-1-thread-1 即将到达集合地点3，当前已有 2 个已经到达，正在等候]]></content>
      <categories>
        <category>Java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java, 并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 运行时数据区域]]></title>
    <url>%2Fpost%2F8a061473.html</url>
    <content type="text"><![CDATA[1.1 为什么要进行内存区域划分JVM规范 规定，JVM 在执行 Java 程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途。以及创建和销毁的时间，有的区域随着虚拟机进程的启动就存在了，而有些区域则依赖用户线程的启动和结束而建立和销毁。JVM 规范对 JVM 定义了运行时统一的内存划分规范，统一了标准，类似于 JDBC 规范一样。JVM 也有许多厂商的不同产品。比如下面的这些： 厂商 JVM Oracle-SUN Hotspot Oracle JRocket IBM J9 JVM 阿里 Taobao JVM 其内存区域划分规范对于 JVM 的含义类似于我们 Java 中的接口，都是起到了规范的作用，JVM 是一台可以运行 Java 应用程序的抽象的计算机。在 JVM 中存在三个重要的概念： JVM 规范：它定义了虚拟机运行的规范，但是由 Oracle（SUN）或者其它厂商实现 Java 运行时环境(JRE：Java Runtime Environment)：它是 JVM 规范的具体实现 JVM 实例：编写好 Java 代码之后，运行 Java 程序，此时就会创建 JMV 实例 对于 Java 程序员来说，在虚拟机自动内存管理机制的帮助下，不再需要为每一个对象去编写内存释放的代码，不要像 C 或者 C++ 要时刻注意着内存泄漏和内存溢出的问题，这种由虚拟机去管理一切看起来都很美好。不过，也正是因为 Java 设计者把内存控制全部交给了 JVM，一旦出现了内存泄漏和溢出方面的问题，如果不了解虚拟机是怎么分配运行时内存的，那么排查错误将是一项非常艰难的工作。 1.2 运行时数据区域的组成为什么我们经常把运行时数据区叫做 Java 内存模型（JMM：Java Memory Model），是因为运行时数据区太过于分散，没有联系，所以才会有 JVM 内存模型这个词，让我们把这些东西联系起来，方便记忆。JVM 运行时数据区中有些数据是一直存在的，被所有线程所共享。而有些区域则是线程私有的，伴随着线程的开始而创建，线程的结束而销毁。所以我们可以把JMM 分为两类：线程共享的、线程私有的。根据 JVM 虚拟机规范的规定，JVM 虚拟机运行时数据区划分如下图所示： 运行时数据区主要分为以下几个部分： 方法区 虚拟机栈 本地方法栈 堆 程序计数器 其中，按照线程在各个区域的数据是否共享划分为： 线程共享部分：方法区、Java 堆以及运行时常量池（归属于方法区） 线程私有部分：虚拟机栈、本地方法栈、程序计数器 接下来看看 Java 运行时数据区中各个部分的用途和特点： 方法区 1.1 什么是方法区在 JVM 中，方法区是可供各个线程共享运行时的内存区域。方法区与传统语言中的编译代码存储区或者操作系统进程的正文段的作用非常类似，它存储了每一个类的结构信息，例如运行时常量池、字段和方法数据、类的构造函数和普通方法的字节码内容、还包括一些类、实例、接口初始化的时候用到的特殊方法。在 Hotspot 虚拟机中，JDK 1.7 版本称作永久代（Permanent Generation），而在 JDK 1.8 则称为 元空间（Metapace）。方法区有个别名叫做非堆（Non-Heap），用于区别于 Java 堆区。默认最小值为 16 MB，最大值为 64 MB，可通过 -XX:PermSize 和 -XX:MaxPermSize 参数设置方法的大小。JDK 1.7 及之前的版本设置为： 12-XX:PermSize=10m-XX:MaxPermSize=55m JDK 1.8 及之后的版本设置为： 12-XX:MetaspaceSize=10m-XX:MaxMetaspaceSize=55m 1.2 方法区的特点 线程共享：方法区是堆的一个逻辑部分，因此和对一样是线程共享的。整个虚拟机中只有一个方法区。 永久代：方法区中的信息一般要长期存在，而且它又是堆的逻辑部分，因此用堆的划分方法，我们把方法区称作永久代（方法区是规范，永久代是实现）。 内存回收低：方法区中的信息一般需要长期存在，回收一遍内存之后可能之后少量信息无效。对方法区的内存回收主要是 对常量池的回收和对类型的卸载。 JVM 规范对方法区的定义比较宽松：和堆一样，允许固定大小，也允许可扩展大小，还允许不实现垃圾回收。 方法区是所有都线程共享的，在一定的条件下它也会被 GC，当方法区域需要使用的内存超过其允许的大小时，会抛出 OOM（OutOfMemory）错误信息。 1.3 运行时常量池类加载后，Class 文件结构中常量池中的数据将被存储在运行时常量池中。我们一般在一个类中通过 public static final 来声明一个常量或者声明一个字符串 String str = &quot;abc&quot;。这个类编译后产生的 Class 文件，这个类的所有信息都存储在这个 class 文件中，当这个类被 JVM 加载之后，class 文件中的常量就存放在方法区的运行时常量池中。而且在运行期间，可以向常量池添加新的常量。比如，String 类的 intern() 方法就能在运行期间向常量池中添加新的常量。当运行时常量池中的某些常量没有被对象引用，同时也没有被变量引用时，那么就需要垃圾收集器回收。JVM 为每个已加载的类型维护一个常量池，常量池就是这个类型用到的常量的一个有序集合。其包括直接常量(基本类型，String)和对其他类型、方法、字段的符号引用。即字面量和符号引用，其中字面量指的是整个类中的字面量。包含成员变量、静态方法、非静态方法等中的字面量。池中的数据和数组一样通过索引访问。 虚拟机栈 1.1 什么是虚拟机栈Java 虚拟机栈是描述 Java 方法运行过程的内存模型。Java 虚拟机栈会为每一个即将运行的方法创建一块叫做 栈帧 的区域，这块区域用于存储用于方法在运行时所需要的一些信息，这些信息具体包括： 局部变量表 操作数栈 动态链接 方法出口信息 其它信息 当一个方法即将被运行时，Java 虚拟机栈首先会在 Java 虚拟机栈中为该方法创建一块”栈帧”，栈帧中包含局部变量表，操作数栈，动态链接，方法出口信息等。当方法在运行过程中需要创建局部变量时，就将局部变量的值存入栈帧的局部变量表中。当这个方法执行完毕后，这个方法所对应的栈帧将会出栈，并释放内存空间。Java 虚拟机栈上数据都是私有的，其他线程都不能访问该线程的栈数据。在函数中定义的一些基本类型的变量数据和对象的引用变量都在函数的栈内存中分配。当在一段代码块中定义一个变量时，Java 就会在栈中为这个变量分配内存空间，当该变量退出该作用域后，Java 会自动释放掉为该变量所分配的内存空间，该内存空间可以立即被另作他用。 1.2 Java 虚拟机栈的特点 局部变量表的创建是在方法被执行的时候，随着栈帧的创建而创建。局部变量表的大小在程序的编译期间就确定下来了，在创建的时候需要事先指定好大小，在方法运行的过程中局部变量表的大小是不会发生改变的。 Java虚拟机栈会出现两种错误（StackOverFlowError 和 OutOfMemoryError），StackOverFlowError：若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候就会抛出 StackOverFlowError。OutOfMemoryError：若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈时内存用完了，无法再动态扩展了，此时就会抛出 StackOverFlowError。 虚拟机栈也是线程私有的，每个线程都有各自的 Java 虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。 栈中的数据在线程内部是共享的，要注意这种数据的共享与两个对象引用同 时指向一个对象的这种共享是不同的。它是由编译器完成的，它有利于节省空间。 本地方法栈 本地方法指的是使用 Java 以外的其他语言编写的代码，因为有些时候 Java 无法直接操作一些底层资源，只能通过 C 或汇编操作。因此需要通过本地方法来实现。而本地方法栈就是设计用来调用这些非 Java 语言方法的。会存放对应的局部变量信息、返回结果等。本地方法栈和 Java 虚拟机栈实现的功能类似，只不过本地方法栈是本地方法运行的内存模型。区别是虚拟机栈为虚拟机执行 Java 方法服务，而本地方法栈则是为虚拟机用到的 Native 方法服务，本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接以及出口信息等。方法执行完毕后相应的栈帧也会出栈并释放内存空间。也会抛出两种错误，StackOverFlowError 和 OutOfMemoryError。 堆 1.1 什么是堆堆是用来存放对象（类、接口、数组）的内存空间。几乎所有的对象都存储在堆中（实例创建后，成员变量也随对象存在堆中，随着垃圾回收进行释放）。堆是一个运行时数据区，在程序运行时动态分配内存。在堆中产生了一个数组对对象后，还可以在栈中定义一个特殊的变量，让栈用这个变量的取值等于数组或对象在堆地址内存中的首地址，栈中的这个变量就成了数组或对象的引用变量。引用变量就相当于是为数组和对象起的一个名称，以后就可以在程序中使用栈中的引用变量来访问堆中数组或对象。引用变量是普通的变量，定义时在栈中分配，引用变量在程序运行到其作用域外后释放。而数组和对象本身在堆中分配，即使程序运行到使用 new 产生数组或者对象的语句所在的代码之外，数组和对象本身占据的内存空间不会被释放，数组和对象在没有引用指向它的时候才会变为垃圾，不能再被使用。仍然占据内存空间不放，在随后的一个不确定的时期被 GC 垃圾回收收走。这也是 Java 比较占用内存的原因之一，实际上，栈中的变量指向堆内存的变量，这就是 Java 中的指针。 1.2 堆的特点 线程共享：整个 JVM 只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java 虚拟机栈、本地方法栈都是一个线程对应一个。 在虚拟机启动的时候创建。 垃圾回收的主要场所。 堆的大小既可以固定也可以扩展，但主流的虚拟机堆的大小是可扩展的。 堆可以分为：新生代和老年代新生代：新生代程序新创建的对象都在新生代分配的，新生代由 Eden Space 和两块大小相同的 Survivor Space（通常又称 S0 和 S1或 FROM 和 To ）构成，可通过 -Xmn 参数来指定新生代的大小，也可以通过 -XX:SurvivorRation 来调整 Eden Space 及 Survivor Space 的大小，因此新生代又可被分为：Eden，From Survivor，To Survivor。老年代：老年代用户存放经过多次新生代垃圾回收仍然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代。主要有两种情况：一种是 大对象，可通过启动参数设置 -XX:PretenureSizeThreshold=1024（单位为字节，默认为 0）来代表超过多大时就不再在新生代分配，而是直接在老年代分配。另一种是 大的数组对象，且数组中无引用外部对象。老年代所占的内存大小为 -Xmx 对应的值减去 -Xmn（新生代）对应的值。不同的区域存放具有不同生命周期的对象。这样可以根据不同的区域使用不同的垃圾回收算法，从而更具有针对性，从而更加高效。 JDK 1.8 及之后版本堆的内存空间分配老年代：三分之二的堆空间年轻代：三分之一的堆空间 eden 区： 十分之八的年轻代空间 survivor 0：十分之一的年轻代空间 survivor 1：十分之一的年轻代空间 程序计数器 1.1 什么是程序计数器程序计数器是一块比较小的内存空间，可以把它看作当前线程正在执行的字节码的行号指示器。程序计数器里面记录的是当前线程正在执行的那一条字节码指令的地址。当然，程序计数器是线程私有的。但是，如果当前线程执行的是一个线程本地的方法，那么此时这个线程的程序计数器为空。 本地方法为 Native Method，即由 native 修饰的方法。在定义一个 native 方法时，并不提供实现（类似 Java 中的接口或者抽象方法），因为其实现往往是由外面的 C 或者 C++ 等非 Java 语言实现的。 1.2 程序计数器的作用程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来一次读取指令，从而实现代码的流程控制，如顺序执行、选择、循环、异常处理等。 在多线程的条件下，程序计数器用来记录当前线程执行的位置，从而当线程被切换回来的时候能够知道这个线程上次运行到哪个地方了。 1.3 程序计数器的特点 是一块比较小的存储空间 是线程私有的，即每一个线程都有一个独立程序计数器 是唯一一个不会出现 OOM（OutOfMemoryError）的内存区域 声明周期随着线程的开始而创建，随着线程的终止而结束 方法区、永久代和元空间 1.1 方法区和永久代的关系涉及到内存模型，往往都会提到永久代，那么它和方法区又是什么关系呢？JVM 虚拟机规范 只是规定了有方法区这个概念和它的作用，并没有规定如何实现它。那么，在不同 JVM 上方法区的实现肯定是不同的。同时大多数公司用的 JVM 都是 Oracle 公司的 HotSpot。在 HotSpot 上把 GC 分代收集扩展至方法区，或者说使用永久代来实现方法区。因此，我们可以得到结论，永久代是 HotSpot 的概念，方式区是 JVM 规范的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现。其它的虚拟机实现并没有永久代这么一说。在 JDK 1.7 及之前的实现中，HotSpot 使用永久代实现方法区，HotSpot 使用 GC 分代来实现方法区内存回收，可以使用以下参数来调准方法区的大小： 12-XX:PermSize # 方法区初始大小-XX:MaxPermSize # 方法区最大大小（超过这个值会抛出 OutOfMemoryError 异常：java.lang.OutOfMemoryError：PermGen） 1.2 元空间对于 Java 8，HotSpot 取消了永久代，那么是不是也就没有方法了吗？当然不是，方法区是一个规范，规范没变，它就会一直在。那么取代永久代的就是元空间。它和永久代有什么不同呢？ 存储位置不同，永久代物理上是堆的一部分，和新生代、老年代地址是连续的，而元空间属于本地内存 存储内容不同，元空间存储类的元信息，静态变量和常量池等并入堆中。相当于永久代的数据被分到了堆和元空间中。 1.3 总结1.1 JVM 内存模型一共有两个“栈”，分别是 Java 虚拟机栈和本地方法栈两个“栈”功能类似，都是方法运行过程的内存模型。并且两个“栈”内部构造相同，都是方法私有的。只不过 Java 虚拟机栈描述的是 Java 方法运行过程的内存模型，而本地方法栈是描述 Java 本地方法运行过程的内存模型。 1.2 JVM 内存模型中一共有两个“堆”，分别是原本的堆和方法区方法区本质上还是属于堆的一个逻辑部分。堆中存放对象，方法区中存放类信息、常量、静态变量，即时编译器编译后的代码等。 1.3 堆是 JVM 中最大的一块内存区域，也是垃圾收集器主要工作的地方在创建对象的时候，非静态成员会被加载到堆内存中，并完成成员变量的初始化。也就是说所有的非静态成员（成员变量、成员方法、构造方法、构造代码块和普通代码块）都是保存在堆内存中的。但是方法调用的时候，调用的方法会在栈内存中执行，构造代码块也会在栈内存中执行。 1.4 线程私有与共享Java 虚拟机栈、程序计数器和本地方法栈都是线程私有的，也就是说每个线程都是各自的程序计数器、Java 虚拟机栈和本地方法栈。他们的生命周期和线程的生命周期一样。而堆、方法区则是线程共享的，在 JVM 中只有一个堆，一个方法区。并在 JVM 启动的时候就创建，直到 JVM 停止的时候才销毁。 参考文章 Java Memory Management for Java Virtual Machine (JVM) The Java® Virtual Machine Specification（Java SE 8 Edition）]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发之 ThreadLocal]]></title>
    <url>%2Fpost%2Fbfcdfeaf.html</url>
    <content type="text"><![CDATA[1.1 什么是 ThreadLocalThreadLocal 简单理解 Thread 即线程，Local 即本地，结合起来理解就是 每个线程都是本地独有的。在早期的计算机中不包含操作系统，从头到尾只执行一个程序，并且这个程序能访问计算中的所有资源，这对于计算机资源来说是一种浪费。要想充分发挥多处理器的强大计算能力，最简单的方式就是使用多线程。与串行程序相比，在并发程序中存在更多容易出错的地方。当访问共享数据时，通常需要使用同步来控制并发程序的访问。一种避免使用同步的方式就是让这部分共享数据变成不共享的，试想一下，如果只是在单个线程内对数据进行访问，那么就可以不用同步了，这种技术称为线程封闭（Thread Confinement），它是实现线程安全最简单的方式之一。当某个对象封闭在一个单个线程中时，这种用法会自动实现了线程安全，因为只有一个线程访问数据，从根本上避免了共享数据的线程安全问题，即使被封闭的对象本身不是线程安全的。要保证线程安全，并不是一定就需要同步，两者没有因果关系，同步只是保证共享数据征用时正确性的手段，如果一个方法本来就不涉及共享数据，那它就不需要任何同步措施去保证正确性。而维持线程封闭的一种规范用法就是使用 ThreadLoal，这个类能使当前线程中的某个值与保存的值关联起来。ThreadLocal 提供了 get() 与 set(T value) 等方法，set 方法为每个使用了该变量的线程都存有一份独立的副本，因此当我们调用 get 方法时总是返回由当前线程在调用 set 方法的时候设置的最新值。 1.2 ThreadLocal 的用法接下来通过一个示例代码说明 ThreadLocal 的使用方式，该示例使用了三个不同的线程 Main Thread、Thread-1 和 Thread-2 分别对同一个 ThreadLocal 对象中存储副本。 12345678910111213141516171819202122232425262728293031/** * @author mghio * @date: 2019-10-20 * @version: 1.0 * @description: Java 并发之 ThreadLocal * @since JDK 1.8 */public class ThreadLocalDemoTests &#123; private ThreadLocal&lt;String&gt; boolThreadLocal = ThreadLocal.withInitial(() -&gt; ""); @Test public void testUseCase() &#123; boolThreadLocal.set("main-thread-set"); System.out.printf("Main Thread: %s\n", boolThreadLocal.get()); new Thread("Thread-1") &#123; @Override public void run() &#123; boolThreadLocal.set("thread-1-set"); System.out.printf("Thread-1: %s\n", boolThreadLocal.get()); &#125; &#125;.start(); new Thread("Thread-2") &#123; @Override public void run() &#123; System.out.printf("Thread-2: %s\n", boolThreadLocal.get()); &#125; &#125;.start(); &#125;&#125; 打印的输出结果如下所示： 123Main Thread: main-thread-setThread-1: thread-1-setThread-2: 我们从输出结果可以看出，ThreadLocal 把不同的线程的数据进行隔离，互不影响，Thread-2 的线程因为我们没有重新设置值会使用 withInitial 方法设置的默认初始值 &quot;&quot;，在不同的线程对同一个 ThreadLocal 对象设置值，对不同的线程取出来的值不一样。接下来我们来分析一下源码，看看它是如何实现的。 1.3 ThreadLocal 的实现原理既然要对每个访问 ThreadLocal 变量的线程都要有自己的一份本地独立副本。我们很容易想到可以用一个 Map 结构去存储，它的键就是我们当前的线程，值是它在该线程内的实例。然后当我们使用该 ThreadLocal 的 get 方法获取实例值时，只需要使用 Thread.currentThread() 获取当前线程，以当前线程为键，从我们的 Map 中获取对应的实例值即可。结构示意图如下所示：上面这个方案可以满足前文所说的每个线程本地独立副本的要求。每个新的线程访问该 ThreadLocal 的时候，就会向 Map 中添加一条映射记录，而当线程运行结束时，应该从 Map 中清除该条记录，那么就会存在如下问题： 因为新增线程或者线程执行完都要操作这个 Map，所以需要保证 Map 是线程安全的。虽然可以使用 JDK 提供的 ConcurrentHashMap 来保证线程安全，但是它还是要通过使用锁来保证线程安全的。 当一个线程运行结束时要及时移除 Map 中对应的记录，不然可能会发生 内存泄漏 问题。 由于存在锁的问题，所有最终 JDK 并没有采用这个方案，而是使用无锁的 ThreadLocal。上述方案出现锁的原因是因为有两一个以上的线程同时访问同一个 Map 导致的。我们可以换一种思路来看这个问题，如果将这个 Map 由每个 Thread 维护，从而使得每个 Thread 只访问自己的 Map，那样就不会存在线程安全的问题，也不会需要锁了，因为是每个线程自己独有的，其它线程根本看不到其它线程的 Map 。这个方案如下图所示： 这个方案虽然不存在锁的问题，但是由于每个线程访问 ThreadLocal 变量后，都会在自己的 Map 内维护该 ThreadLoal 变量与具体存储实例的映射，如果我们不手动删除这些实例，可能会造成内存泄漏。我们进入到 Thread 的源码内可以看到其内部定义了一个 ThreadLocalMap 成员变量，如下图所示： ThreadLoalMap 类是一个类似 Map 的类，是 ThreadLocal 的内部类。它的 key 是 ThreadLocal ，一个 ThreadLocalMap 可以存储多个 key（ThreadLocal），它的 value 就对应着在 ThreadLocal 存储的 value。因此我们可以看出：每一个 Thread 都对应自己的一个 ThreadLocalMap ，而 ThreadLocalMap 可以存储多个以 ThreadLocal 为 key 的键值对。这里也解释了为什么我们使用多个线程访问同一个 ThreadLocal ，然后 get 到的确是不同数值。 上面对 ThreadLocal 进行了一些解释，接下来我们看看 ThreadLocal 具体是如何实现的。先看一下 ThreadLocal 类提供的几个常用方法： 1234567protected T initialValue() &#123; ... &#125;public void set(T value) &#123; ... &#125;public T get() &#123; ... &#125;public void remove() &#123; ... &#125; initialValue 方法是一个 protected 方法，一般是用来使用时进行重写，设置默认初始值的方法，它是一个延迟加载的方法，在。 set 方法是用来设置当前线程的变量副本的方法 get 方法是用获取 ThreadLocal 在当前线程中保存的变量副本 remove 方法是 JDK1.5+ 才提供的方法，是用来移除当前线程中的变量副本 initialValue 方法是在 setInitialValue 方法被调用的，由于 setInitialValue 方法是 private 方法，所以我们只能重写 initialValue 方法，我们看看 setInitialValue 的具体实现： 12345678910111213141516/** * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */ private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; &#125; 通过以上代码我们知道，会先调用 initialValue 获取初始值，然后使用当前线程从 Map 中获取线程对应 ThreadLocalMap，如果 map 不为 null，就设置键值对，如果为 null，就再创建一个 Map。首先我们看下在 getMap 方法中干了什么： 12345678910/** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; 可能大家没有想到的是，在 getMap 方法中，是调用当期线程 t，返回当前线程 t 中的一个成员变量 threadLocals 。那么我们继续到 Thread 类中源代码中看一下成员变量 threadLocals 到底是什么： 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 它实际上就是一个 ThreadLocalMap ，这个类型是 ThreadLocal 类内定义的一个内部类，我们看一下 ThreadLocalMap 的实现： 123456789101112131415161718192021222324252627282930313233/** * ThreadLocalMap is a customized hash map suitable only for * maintaining thread local values. No operations are exported * outside of the ThreadLocal class. The class is package private to * allow declaration of fields in class Thread. To help deal with * very large and long-lived usages, the hash table entries use * WeakReferences for keys. However, since reference queues are not * used, stale entries are guaranteed to be removed only when * the table starts running out of space. */ static class ThreadLocalMap &#123; /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as "stale entries" in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; ... &#125; 我们可以看到 ThreadLocalMap 的 Entry 继承了 WeakReference (弱引用)，并且使用 ThreadLocal 作为键值。 下面我们看下 createMap 方法的具体实现： 12345678910/** * Create the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @param firstValue value for the initial entry of the map */ void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; 直接 new 一个 ThreadLoalMap 对象，然后赋值给当前线程的 threadLocals 属性。 然后我们看一下 set 方法的实现： 1234567891011121314151617/** * Sets the current thread's copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the &#123;@link #initialValue&#125; * method to set the values of thread-locals. * * @param value the value to be stored in the current thread's copy of * this thread-local. */ public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; 首先获取当前线程，然后从线程的属性 threadLocals 获取当前线程对应的 ThreadLocalMap 对象，如果不为空，就以 this (ThreadLocal) 而不是当前线程 t 为 key，添加到 ThreadLocalMap 中。如果为空，那么就先创建后再加入。ThreadLocal 的 set 方法通过调用 replaceStaleEntry 方法回收键为 null 的 Entry 对象的值（即为具体实例）以及 Entry 对象本身从而防止内存泄漏。 接下来我们看一下 get 方法的实现： 123456789101112131415161718192021/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local */ public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 先获取当前线程，然后通过 getMap 方法传入当前线程获取到 ThreadLocalMap 。然后接着获取 Entry (key，value) 键值对，这里传入的是 this，而不是当前线程 t ，如果获取成功，则返回对应的 value，如果没有获取到，返回空，则调用 setInitialValue 方法返回 value。 至此，我们总结一下 ThreadLocal 是如何为每个线程创建变量副本的：首先，在每个线程 Thread 内部有个 ThreadLocal.ThreadLocalMap 类型的成员变量 threadLocals，这个 threadLocals 变量就是用来存储实际变量的副本的，它的键为当前 ThreadLocal ，value 为变量副本（即 T 类型的变量）。初始时，在 Thread 类里面， threadLocals 为 null，当通过 ThreadLocal 调用 set 或者 get 方法时，如果此前没有对当前线程的 threadLocals 进行过初始化操作，那么就会以当前 ThreadLocal 变量为键值，以 ThreadLocal 要保存的副本变量为 value，存到当前线程的 threadLocals 变量中。以后在当前线程中，如果要用到当前线程的副本变量，就可以通过 get 方法在当前线程的 threadLocals 变量中查找了。 1.4 总结ThreadLocal 设计的目的就是为了能够在当前线程中有属于自己的变量，并不是为了解决并发或者共享变量的问题。 通过 ThreadLocal 创建的副本是存储在每个线程自己的 threadLocals 变量中的 为何 threadLocals 的类型 ThreadLocalMap 的键值为 ThreadLocal 对象，因为每个线程中可有多个 threadLocal 变量，就像前文图片中的 ThreadLocal 和 ThreadLocal ，就是一个线程存在两个 threadLocal 变量 在进行 get 之前，必须先 set ，否则会报空指针异常，如果想在 get 之前不需要调用 set 就能正常访问的话，必须重写 initialValue 方法 ThreadLocal 适用于变量在线程间隔离且在方法间共享的场景 另外，内存泄漏的问题请参考博文：ThreadLocal 内存泄漏问题]]></content>
      <categories>
        <category>Java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 字符串 split 踩坑记]]></title>
    <url>%2Fpost%2F8bd965a0.html</url>
    <content type="text"><![CDATA[1.1 split 的坑前几天在公司对通过 FTP 方式上传的数据文件按照事先规定的格式进行解析后入库，代码的大概实现思路是这样的：先使用流进行文件读取，对文件的每一行数据解析封装成一个个对象，然后进行入库操作。本以为很简单的一个操作，然后写完代码后自己测试发现对文件的每一行进行字符串分割的时候存在问题，在这里做个简单的记录总结。在 Java 中使用 split 方法对字符串进行分割是经常使用的方法，经常在一些文本处理、字符串分割的逻辑中，需要按照一定的分隔符进行分割拆解。这样的功能，大多数情况下我们都会使用 String 中的 split 方法。关于这个方法，稍不注意很容易踩坑。 （1）split 的参数是正则表达式首先一个常见的问题，就是忘记了 String 的 split 方法的参数不是普通的字符串，而是正则表达式，例如下面的这两种使用方式都达不到我们的预期： 12345678910111213141516/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testStringSplitRegexArg() &#123; System.out.println(Arrays.toString("m.g.h.i.o".split("."))); System.out.println(Arrays.toString("m|g|h|i|o".split("|"))); &#125; &#125; 以上代码的结果输出为： 12[][m, |, g, |, h, |, i, |, o] 上面出错的原因是因为 . 和 | 都是正则表达式，应该用转义字符进行处理： 12"m.g.h.i.o".split("\\.")"m|g|h|i|o".split("\\|") 在 String 类中还有其它的和这个相似的方法，例如：replaceAll。 （2）split 会忽略分割后的空字符串大多数情况下我们都只会使用带一个参数的 split 方法，但是只带一个参数的 split 方法有个坑：就是此方法只会匹配到最后一个有值的地方，后面的会忽略掉，例如： 1234567891011121314151617/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testStringSplitSingleArg() &#123; System.out.println(Arrays.toString("m_g_h_i_o".split("_"))); System.out.println(Arrays.toString("m_g_h_i_o__".split("_"))); System.out.println(Arrays.toString("m__g_h_i_o_".split("_"))); &#125; &#125; 以上代码输出结果为： 123[m, g, h, i, o][m, g, h, i, o][m, , g, h, i, o] 像第二、三个输出结果其实和我们的预期是不符的，因为像一些文件上传其实有的字段通常是可以为空的，如果使用单个参数的 split 方法进行处理就会有问题。通过查看 API 文档 后，发现其实 String 中的 split 方法还有一个带两个参数的方法。第二个参数是一个整型类型变量，代表最多匹配上多少个，0 表示只匹配到最后一个有值的地方，单个参数的 split 方法的第二个参数其实就是 0，要想强制匹配可以选择使用负数（通常传入 -1 ），换成以下的写法，输出结果就和我们的预期一致了。 123"m_g_h_i_o".split("_", -1) // [m, g, h, i, o]"m_g_h_i_o__".split("_", -1) // [m, g, h, i, o, , ]"m__g_h_i_o_".split("_", -1) // [m, , g, h, i, o, ] （3）JDK 中字符串切割的其它 API在 JDK 中还有一个叫做 StringTokenizer 的类也可以对字符串进行切割，用法如下所示： 123456789101112131415161718/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testStringTokenizer() &#123; StringTokenizer st = new StringTokenizer("This|is|a|mghio's|blog", "|"); while (st.hasMoreElements()) &#123; System.out.println(st.nextElement()); &#125; &#125; &#125; 不过，我们从源码的 javadoc 上得知，这是从 JDK 1.0 开始就已经存在了，属于历史遗留的类，并且推荐使用 String 的 split 方法。 1.2 JDK 源码探究通过查看 JDK 中 String 类的源码，我们得知在 String 类中单个参数的 split 方法（split(String regex)）里面调用了两个参数的 split 方法（split(String regex, int limit)），两个参数的 split 方法，先根据传入第一个参数 regex 正则表达式分割字符串，第二个参数 limit 限定了分割后的字符串个数，超过数量限制的情况下前limit-1个子字符串正常分割，最后一个子字符串包含剩下所有字符。单个参数的重载方法将 limit 设置为 0。源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public String[] split(String regex, int limit) &#123; char ch = 0; if (((regex.value.length == 1 &amp;&amp; ".$|()[&#123;^?*+\\".indexOf(ch = regex.charAt(0)) == -1) || (regex.length() == 2 &amp;&amp; regex.charAt(0) == '\\' &amp;&amp; (((ch = regex.charAt(1))-'0')|('9'-ch)) &lt; 0 &amp;&amp; ((ch-'a')|('z'-ch)) &lt; 0 &amp;&amp; ((ch-'A')|('Z'-ch)) &lt; 0)) &amp;&amp; (ch &lt; Character.MIN_HIGH_SURROGATE || ch &gt; Character.MAX_LOW_SURROGATE)) &#123; int off = 0; int next = 0; boolean limited = limit &gt; 0; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); while ((next = indexOf(ch, off)) != -1) &#123; if (!limited || list.size() &lt; limit - 1) &#123; list.add(substring(off, next)); off = next + 1; &#125; else &#123; // last one //assert (list.size() == limit - 1); list.add(substring(off, value.length)); off = value.length; break; &#125; &#125; // If no match was found, return this if (off == 0) return new String[]&#123;this&#125;; // Add remaining segment if (!limited || list.size() &lt; limit) list.add(substring(off, value.length)); // Construct result int resultSize = list.size(); if (limit == 0) &#123; while (resultSize &gt; 0 &amp;&amp; list.get(resultSize - 1).length() == 0) &#123; resultSize--; &#125; &#125; String[] result = new String[resultSize]; return list.subList(0, resultSize).toArray(result); &#125; return Pattern.compile(regex).split(this, limit);&#125; 接下来让我们一起看看 String 的 split 方法是如何实现的。 （1）特殊情况判断 123456789(((regex.value.length == 1 &amp;&amp; ".$|()[&#123;^?*+\\".indexOf(ch = regex.charAt(0)) == -1) || (regex.length() == 2 &amp;&amp; regex.charAt(0) == '\\' &amp;&amp; (((ch = regex.charAt(1))-'0')|('9'-ch)) &lt; 0 &amp;&amp; ((ch-'a')|('z'-ch)) &lt; 0 &amp;&amp; ((ch-'A')|('Z'-ch)) &lt; 0)) &amp;&amp; (ch &lt; Character.MIN_HIGH_SURROGATE || ch &gt; Character.MAX_LOW_SURROGATE)) 第一个参数 regex 为单个字符时，将其赋值给 ch，并判断是否在元字符：「.$|()[{^?*+\」中 第一个参数 regex 为两个字符时，第一个字符为 \\（要表示一个\需要用两个\转义得到），第二个字符不在数字、大小写字母和 Unicode 编码 Character.MIN_HIGH_SURROGATE（’\uD800’）和 Character.MAX_LOW_SURROGATE（’\uDBFF’）之间。 （2）字符串分割第一次分割时，使用 off 和 next，off 指向每次分割的起始位置，next 指向分隔符的下标，完成一次分割后更新 off 的值，当 list 的大小等于 limit - 1 时，直接添加剩下的子字符串。 如果字符串不含有分隔符，则直接返回原字符串 如果字符串进行完第一次分割后，数量没有达到 limit - 1 的话，则剩余的字符串在第二次添加 如果传入的第二个参数 limit 等于 0 ，则从最后的字符串往前移动，将所有的空字符串（”“）全部清除 （3）正则匹配String 的 split 方法在不是上面的特殊情况下，会使用两个类 Pattern 与 Matcher 进行分割匹配处理，而且 Strig 中涉及正则的操作都是调用这两个类进行处理的。 Pattern 类我们可以将其理解为模式类，它主要是用来创建一个匹配模式，它的构造方法是私有的，不能直接创建该对象，可以通过 Pattern.complie(String regex) 简单的工厂方法创建一个正则表达式。 Matcher 类我们可以将其理解为匹配器类，它是用来解释 Pattern 类对字符串执行匹配操作的引擎，它的构造方法也是私有的，不能直接创建该对象，可以通过 Pattern.matcher(CharSequence input) 方法得到该类的实例。String 类的双参数 split 方法最后使用 Pattern 类的 compile 和 split 方法，如下：1return Pattern.compile(regex).split(this, limit); 首先调用 Pattern 类的静态方法 compile 获取 Pattern 模式类对象 123public static Pattern compile(String regex) &#123; return new Pattern(regex, 0);&#125; 接着调用 Pattern 的 split(CharSequence input, int limit) 方法，在这个方法中调 matcher(CharSequence input) 方法返回一个 Matcher 匹配器类的实例 m，与 String 类中 split 方法的特殊情况有些类似。 使用 m.find()、m.start()、m.end() 方法 每找到一个分割符，则更新 start 和 end 的位置 然后处理没找到分隔符、子字符串数量小于 limit 以及 limit = 0 的情况 1.3 其它的字符串分割方式 方式一：使用 org.apache.commons.lang3.StringUtils#split，此方法使用完整的字符串作为参数，而不是正则表达式。底层调用 splitWorker 方法（注意：此方法会忽略分割后的空字符串）12345678910111213141516/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testApacheCommonsLangStringUtils() &#123; System.out.println(Arrays.toString(StringUtils.split("m.g.h.i.o", "."))); System.out.println(Arrays.toString(StringUtils.split("m__g_h_i_o_", "_"))); &#125; &#125; 输出结果： 12[m, g, h, i, o][m, g, h, i, o] 方式二：使用 com.google.common.base.Splitter，使用 Google Guava 包中提供的分割器 splitter，它提供了更加丰富的分割结果处理的方法，比如对结果前后去除空格，去除空字符串等12345678910111213141516171819/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testApacheCommonsLangStringUtils() &#123; Iterable&lt;String&gt; result = Splitter.on("_").split("m__g_h_i_o_"); List&lt;String&gt; resultList = Lists.newArrayList(); result.forEach(resultList::add); System.out.println("stringList's size: " + resultList.size()); result.forEach(System.out::println); &#125; &#125; 输出结果： 1234567stringList's size: 7mghio 1.4 总结String 类中除了 split 方法外，有正则表达式接口的方法都是调用 Pattern（模式类）和 Matcher（匹配器类）进行实现的。JDK 源码的每一个如 final、private 的关键字都设计的十分严谨，多读类和方法中的javadoc，多注意这些细节对于阅读代码和自己写代码都有很大的帮助。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 字节码]]></title>
    <url>%2Fpost%2F192cb539.html</url>
    <content type="text"><![CDATA[1.1 什么是字节码？Java 在刚刚诞生之时曾经提出过一个非常著名的口号: “一次编写，到处运行（write once，run anywhere）”，这句话充分表达了软件开发人员对冲破平台界限的渴求。“与平台无关”的理想最终实现在操作系统的运用层上: 虚拟机提供商开发了许多可以运行在不同平台上的虚拟机，这些虚拟机都可以载入和执行同一种平台无关的字节码，从而实现了程序的“一次编写到处运行”。各种不同平台的虚拟机与所有平台都统一使用的程序存储格式—字节码（ByteCode），因此，可以看出字节码对 Java 生态的重要性。之所以被称为字节码，是因为字节码是由十六进制组成的，而 JVM（Java Virtual Machine）以两个十六进制为一组，即以字节为单位进行读取。在 Java 中使用 javac 命令把源代码编译成字节码文件，一个 .java 源文件从编译成 .class 字节码文件的示例如图 1 所示:图 1 对于从事基于 JVM 的语言的开发人员来说，比如: Java，了解字节码可以更准确、更直观的理解 Java 语言中更深层次的东西，比如通过字节码，可以很直观的看到 volatile 关键字如何在字节码上生效。另外，字节码增强技术在各种 ORM 框架、Spring AOP、热部署等一些应用中经常使用，深入理解其原理对于我们来说大有裨益。由于 JVM 规范的存在，只要最终生成了符合 JVM 字节码规范的文件都可以在 JVM 上运行，因此，这个也给其它各种运行在 JVM 上的语言（如: Scala、Groovy、Kotlin）提供了一个机会，可以扩展 Java 没有实现的特性或者实现一些语法糖。接下来就让我们就一起看看这个字节码文件结构到底是什么样的。 1.2 Java 字节码结构Java 源文件通过用 javac 命令编译后就会得到 .class 结尾的字节码文件，比如一个简单的 JavaCodeCompilerDemo 类如图 2 所示:图 2编译后生成的 .class 字节码文件，打开后是一堆 十六进制 数，如图 3 所示:图 3在上节提过，JVM 对于字节码规范是有要求的，打开编译后的字节码文件看似混乱无章，其实它是符合一定的结构规范的，JVM 规范要求每一个字节码文件都要由十部分固定的顺序组成的，接下来我们将一一介绍这部分，整体的组成结构如图 4 所示:图 4 （1）魔数（Magic Number）每个字节码文件的头 4 个字节称为 魔数（Magic Number），它的唯一作用是确定这个文件是否为一个能被虚拟机接受的 Class 文件。很多文件存储标准中都使用魔数来进行身份识别，譬如图片格式，如 gif 或者 jpg 等在文件头中都存有魔数。使用魔数而不是扩展名来进行识别主要是基于安全方面的考虑，因为文件扩展名可以随意改动。魔数的固定值为: 0xCAFEBABE，魔数放在文件头，JVM 可以根据文件的开头来判断这个文件是否可能是一个字节码文件，如果是，才会进行之后的操作。 有趣的是，魔数的固定值是 Java 之父 James Gosling 制定的，为 CafeBabe（咖啡宝贝），而 Java 的图标为一杯咖啡。 （2）版本号（Version）版本号为魔数之后的 4 个字节，前两个字节表示次版本号（Minor Version），后两个字节表示主版本号（Major Version），上图 3 中版本号为: “00 00 00 34”，次版本号转化为十进制为 0，主版本号转化为十进制 52（3 * 16^1 + 4 * 16^0 = 52），在 Oracle 官网中查询序号 52 对应的 JDK 版本为 1.8，所以编译该源代码文件的 Java 版本为 1.8.0。 （3）常量池（Constant Pool）紧接着主版本号之后的字节是常量池入口。常量池中存储两种类型常量: 字面量和符号运用。字面量为代码中声明为 final 的常量值，符号引用如类和接口的全局限定名、字段的名称和描述符、方法的名称和描述符。常量池整体上分为两部分: 常量池计数器和常量池数据区，如图 5 所示：图 5常量池计数器（constant_pool_count）: 由于常量池的数量不固定，所以需要先放置两个字节来表示常量池容量计数值，图 2 示例代码的字节码的前十个字节如下图 6 所示，将十六进制的 17 转为十进制的值为 33 (1 * 16^1 + 7 * 16^0 = 33)，排除下标 0，也就是说这个类文件有 32 个常量。图 6常量池数据区: 数据区是由（constant_pool_count - 1）个 cp_info 结构组成，一个 cp_info 的结构对应一个常量。在字节码中共有 14 种类型的 cp_info ，每种类型的结构都是固定的，如图 7 所示:图 7以 CONSTANT_Utf8_info 为例，它的结构如表 1 所示: 名称 长度 值 tag 1 字节 01 对应图 7 中 CONSTANT_Utf8_info 的标志栏中的值 length 2 字节 该 utf8 字符串的长度 bytes length 字节 length 个字节的具体数据 表 1 首先第一个字节 tag，它的取值对应图 7 中的 Tag，由于它的类型是 CONSTANT_Utf8_info，所以值为 01（十六进制）。接下来两个字节标识该字符串的长度 length，然后 length 个字节为这个字符串具体的值。从图 3 的字节码中摘取一个 cp_info 结构，将它翻译过来后，其含义为: 该常量为 utf8 字符串，长度为 7 字节，数据为: numberA，如图 8 所示: 图 8其它类型的 cp_info 结构在本文不在细说，和 CONSTANT_Utf8_info 的结构大同小异，都是先通过 tag 来标识类型，然后后续的 n 个字节来描述长度和数据。等我们对这些结构比较了解了之后，我们可以通过: javap -verbose JavaCodeCompilerDemo 命令查看 JVM 反编译后的完整常量池，可以看到反编译结果可以将每一个 cp_info 结构的类型和值都很明确的呈现出来，如图 9 所示:图 9 （4）访问标志（access_flag）常量池结束之后的两个字节，描述该 Class 是类还是接口，以及是否被 Public、Abstract、Final 等修饰符修饰。JVM 规范规定了如下表 2 所示的 9 种访问标志。需要注意的是，JVM 并没有穷举所有的访问标志，而是使用 按位或 操作来进行描述的，比如某个类的修饰符为 public final，则对应的访问修饰符的值为 ACC_PUBLIC | ACC_FINAL，即 0x0001 | 0x0010 = 0x0011。 标志名称 标志值 含义 ACC_PUBLIC 0x0001 字段是否为 public ACC_PRIVATE 0x0002 字段是否为 private ACC_PROTECTED 0x0004 字段是否为 protected ACC_STATIC 0x0008 字段是否为 static ACC_FINAL 0x0010 字段是否为 final ACC_VOLATILE 0x0040 字段是否为 volatile ACC_TRANSIENT 0x0080 字段是否为 transient ACC_SYNCHETIC 0x1000 字段是否为编译器自动产生 ACC_ENUM 0x4000 字段是否为 enum 表 2 （5）当前类名（this_class）访问标志后的两个字节，描述的是当前类的全限定名。这两个字节保存的值为常量池中的索引值，根据索引值就能在常量池中找到这个类的全限定名。 （6）父类名称（super_class）当前类名的后两个字节，描述父类的全限定名。这两个字节保存的值也是在常量池中的索引值，根据索引值就能在常量池中找到这个类的父类的全限定名。 （7）接口信息（interfaces）父类名称后的两个字节，描述这个类的接口计数器，即: 当前类或父类实现的接口数量。紧接着的 n 个字节是所有的接口名称的字符串常量在常量池的索引值。 （8）字段表（field_table）字段表用于描述类和接口中声明的变量，包含类级别的变量以及实例变量，但是不包含方法内部声明的 局部变量。字段表也分为两部分，第一部分是两个字节，描述字段个数，第二部分是每个字段的详细信息 field_info。字段表结构如图 10 所示:图 10以图 3 中的字节码字段表为例，如下图 11 所示。其中字段的访问标志查表 2，002 对应为 Private，通过索引下标在图 9 中常量池分别得到字段名为: numberA，描述符为: I（在JVM 中的I代表 Java 中的 int）。综上，就可以唯一确定出类 JavaCodeCompilerDemo 中声明的变量为: private int numberA 。图 11 （9）方法表（method_table）字段表结束后为方法表，方法表也是由两部分组成，第一部分为两个字节描述方法的个数，第二个部分为每个方法的详细信息。方法的详细信息包括：方法的访问标志、方法名、方法的描述符以及方法的属性，如图 12 所示:图 12方法的权限修饰符依然可以通过图 9 的值查询到，方法名和方法的描述符都是常量池的索引值，可以通过索引值在常量池中查询得到。而方法属性这个部分比较复杂，我们可以借助 javap -verbose 将其反编译为人们可读的信息进行解读。如图 13 所示。我们可以看到属性中包含三个部分: Code 区: 源代码对应的 JVM 指令操作码，我们在字节码增强的时候重点操作的就是这个部分。 LineNumberTable: 行号表，将 Code 区的操作码和源代码的行号对应，Debug 时会起到作用（即: 当源代码向下走一行，相应的需要走几个 JVM 指令操作码）。 LocalVariableTable: 本地变量表，包含 this 和局部变量，之所以可以在每一个非 static 的方法内部都可以调用到 this，是因为 JVM 将 this 作为每个方法的第一个参数隐式进行传入。图 13 （10）附加属性表（additional_attribute_table）字节码的最后一部分，存放了在文件中类或接口所定义的属性的基本信息。 1.3 Java 字节码操作集合在图 13 中，Code 区的编号是 0 ~ 10，就是 .java 源文件的方法源代码编译后让 JVM 真正执行的操作码。为了帮助人们理解，反编译后看到的是十六进制操作码所对应的助记符，十六进制值操作码和助记符的对应关系，以及每个操作码的具体作用可以查看 Oracle 官网，在需要的时候查阅即可。比如上图 13 的助记符为 iconst_2，对应图 3 中的字节码 0x05，作用是将 int 值 2 压入操作数栈中。以此类推，对 0 ~ 10 的助记符理解后就是整个 sum() 方法的操作数码实现。 1.4 查看字节码工具如果我们每次反编译都要使用 javap 命令的话，确实比较繁琐，这里我推荐大家一个 IDEA 插件: jclasslib。使用效果如图 14 所示: 代码编译后在菜单栏: View -&gt; Show Bytecode With jclasslib，可以很直观地看到当前字节码文件的类信息、常量池、方法区等信息，非常方便。图 14 1.5 总结Java 中字节码文件是 JVM 执行引擎的数据入口，也是 Java 技术体系的基础构成之一。了解字节码文件的组成结构对后面进一步了解虚拟机和深入学习 Java 有很重要的意义。本文较为详细的讲解了字节码文件结构的各个组成部分，以及每个部分的定义、数据结构和使用方法。强烈建议自己动手分析一下，会理解得更加深入。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hello world]]></title>
    <url>%2Fpost%2Fb1d4025b.html</url>
    <content type="text"><![CDATA[1234567public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println("Hello World ~~~"); &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
