<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[从 CPU 缓存看缓存的套路]]></title>
    <url>%2Fpost%2Ffa75f5d7.html</url>
    <content type="text"><![CDATA[一、前言不同存储技术的访问时间差异很大，从 计算机层次结构 可知，通常情况下，从高层往底层走，存储设备变得更慢、更便宜同时体积也会更大，CPU 和内存之间的速度存在着巨大的差异，此时就会想到计算机科学界中一句著名的话：计算机科学的任何一个问题，都可以通过增加一个中间层来解决。 二、引入缓存层为了解决速度不匹配问题，可以通过引入一个缓存中间层来解决问题，但是也会引入一些新的问题。现代计算机系统中，从硬件到操作系统、再到一些应用程序，绝大部分的设计都用到了著名的局部性原理，局部性通常有如下两种不同的形式： 时间局部性：在一个具有良好的时间局部性的程序当中，被引用过一次的内存位置，在将来一个不久的时间内很可能会被再次引用到。 空间局部性：在一个具有良好的空间局部性的程序当中，一个内存位置被引用了一次，那么在不久的时间内很可能会引用附近的位置。 有上面这个局部性原理为理论指导，为了解决二者速度不匹配问题就可以在 CPU 和内存之间加一个缓存层，于是就有了如下的结构： 三、何时更新缓存在 CPU 中引入缓存中间层后，虽然可以解决和内存速度不一致的问题，但是同时也面临着一个问题：当 CPU 更新了其缓存中的数据之后，要什么时候去写入到内存中呢？，比较容易想到的一个解决方案就是，CPU 更新了缓存的数据之后就立即更新到内存中，也就是说当 CPU 更新了缓存的数据之后就会从上到下更新，直到内存为止，英文称之为write through，这种方式的优点是比较简单，但是缺点也很明显，由于每次都需要访问内存，所以速度会比较慢。还有一种方法就是，当 CPU 更新了缓存之后并不马上更新到内存中去，在适当的时候再执行写入内存的操作，因为有很多的缓存只是存储一些中间结果，没必要每次都更新到内存中去，英文称之为write back，这种方式的优点是 CPU 执行更新的效率比较高，缺点就是实现起来会比较复杂。 上面说的在适当的时候写入内存，如果是单核 CPU 的话，可以在缓存要被新进入的数据取代时，才更新内存，但是在多核 CPU 的情况下就比较复杂了，由于 CPU 的运算速度超越了 1 级缓存的数据 I\O 能力，CPU 厂商又引入了多级的缓存结构，比如常见的 L1、L2、L3 三级缓存结构，L1 和 L2 为 CPU 核心独有，L3 为 CPU 共享缓存。 如果现在分别有两个线程运行在两个不同的核 Core 1 和 Core 2 上，内存中 i 的值为 1，这两个分别运行在两个不同核上的线程要对 i 进行加 1 操作，如果不加一些限制，两个核心同时从内存中读取 i 的值，然后进行加 1 操作后再分别写入内存中，可能会出现相互覆盖的情况，解决的方法相信大家都能想得到，第一种是只要有一个核心修改了缓存的数据之后，就立即把内存和其它核心更新。第二种是当一个核心修改了缓存的数据之后，就把其它同样复制了该数据的 CPU 核心失效掉这些数据，等到合适的时机再更新，通常是下一次读取该缓存的时候发现已经无效，才从内存中加载最新的值。 四、缓存一致性协议不难看出第一种需要频繁访问内存更新数据，执行效率比较低，而第二种会把更新数据推迟到最后一刻才会更新，读取内存，效率高（类似于懒加载）。 缓存一致性协议(MESI) 就是使用第二种方案，该协议主要是保证缓存内部数据的一致，不让系统数据混乱。MESI 是指 4 种状态的首字母。每个缓存存储数据单元（Cache line）有 4 种不同的状态，用 2 个 bit 表示，状态和对应的描述如下： 状态 描述 监听任务 M 修改 (Modified) 该 Cache line 有效，数据被修改了，和内存中的数据不一致，数据只存在于本 Cache 中 Cache line 必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成 S（共享）状态之前被延迟执行 E 独享、互斥 (Exclusive) 该 Cache line 有效，数据和内存中的数据一致，数据只存在于本 Cache 中 Cache line 必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成 S（共享）状态 S 共享 (Shared) 该 Cache line 有效，数据和内存中的数据一致，数据存在于很多 Cache 中 Cache line 必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该 Cache line 变成无效 I 无效 (Invalid) 该 Cache line 无效 无监听任务 下面看看基于缓存一致性协议是如何进行读取和写入操作的， 假设现在有一个双核的 CPU，为了描述方便，简化一下只看其逻辑结构： 单核读取步骤：Core 0 发出一条从内存中读取 a 的指令，从内存通过 BUS 读取 a 到 Core 0 的缓存中，因为此时数据只在 Core 0 的缓存中，所以将 Cache line 修改为 E 状态（独享），该过程用示意图表示如下： 双核读取步骤：首先 Core 0 发出一条从内存中读取 a 的指令，从内存通过 BUS 读取 a 到 Core 0 的缓存中，然后将 Cache line 置为 E 状态，此时 Core 1 发出一条指令，也是要从内存中读取 a，当 Core 1 试图从内存读取 a 的时候， Core 0 检测到了发生地址冲突（其它缓存读主存中该缓存行的操作），然后 Core 0 对相关数据做出响应，a 存储于这两个核心 Core 0 和 Core 1 的缓存行中，然后设置其状态为 S 状态（共享），该过程示意图如下： 假设此时 Core 0 核心需要对 a 进行修改了，首先 Core 0 会将其缓存的 a 设置为 M（修改）状态，然后通知其它缓存了 a 的其它核 CPU（比如这里的 Core 1）将内部缓存的 a 的状态置为 I（无效）状态，最后才对 a 进行赋值操作。该过程如下所示： 细心的朋友们可能已经注意到了，上图中内存中 a 的值（值为 1）并不等于 Core 0 核心中缓存的最新值（值为 2），那么要什么时候才会把该值更新到内存中去呢？就是当 Core 1 需要读取 a 的值的时候，此时会通知 Core 0 将 a 的修改后的最新值同步到内存（Memory）中去，在这个同步的过程中 Core 0 中缓存的 a 的状态会置为 E（独享）状态，同步完成后将 Core 0 和 Core 1 中缓存的 a 置为 S（共享）状态，示意图描述该过程如下所示： 至此，变量 a 在 CPU 的两个核 Core 0 和 Core 1 中回到了 S（共享）状态了，以上只是简单的描述了一下大概的过程，实际上这些都是在 CPU 的硬件层面上去保证的，而且操作比较复杂。 五、总结现在很多一些实现缓存功能的应用程序都是基于这些思想设计的，缓存把数据库中的数据进行缓存到速度更快的内存中，可以加快我们应用程序的响应速度，比如我们使用常见的 Redis 数据库可能是采用下面这些策略：① 首先应用程序从缓存中查询数据，如果有就直接使用该数据进行相应操作后返回，如果没有则查询数据库，更新缓存并且返回。② 当我们需要更新数据时，先更新数据库，然后再让缓存失效，这样下次就会先查询数据库再回填到缓存中去，可以发现，实际上底层的一些思想都是相通的，不同的只是对于特定的场景可能需要增加一些额外的约束。基础知识才是技术这颗大树的根，我们先把根栽好了，剩下的那些枝和叶都是比较容易得到的东西了。]]></content>
      <categories>
        <category>Java</category>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 集合类 List 的那些坑]]></title>
    <url>%2Fpost%2Fd7d0fc76.html</url>
    <content type="text"><![CDATA[现在的一些高级编程语言都会提供各种开箱即用的数据结构的实现，像 Java 编程语言的集合框架中就提供了各种实现，集合类包含 Map 和 Collection 两个大类，其中 Collection 下面的 List 列表是我们经常使用的集合类之一，很多的业务代码都离不开它，今天就来看看 List 列表的一些坑。 第一个坑：Arrays.asList 方法返回的 List 不支持增加、删除操作例如我们执行以下代码： 12List&lt;String&gt; strings = Arrays.asList("m", "g");strings.add("h"); 会抛出 java.lang.UnsupportedOperationException 异常，此时你内心 OS what？明明返回的 ArrayList 为啥不能往里面增加元素，这以后还能好好的增加元素吗？，然后果断开启 Debug 大法： 发现返回的 ArrayList 并不是我们常用的 java.util.ArrayList，而是 Arrays 的内部类 java.util.Arrays.ArrayList。进入方法 Arrays.asList 源码如下： 123public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; 方法返回的是 Arrays 的静态内部类 java.util.Arrays.ArrayList，该类虽然和 java.util.ArrayList 也继承自抽象类 java.util.AbstractList ，但是通过该类的源码发现它并没有对抽象父类AbstractList的 add 方法默认就是抛出 java.lang.UnsupportedOperationException 异常。 这个坑的根本原因是我们调用返回的 strings 的 add 方法是继承自抽象父类的 add 方法，而抽象父类的方法默认就是抛出 java.lang.UnsupportedOperationException 这个异常。 第二个坑，Arrays.asList 方法返回的新 List 和该方法原始入参数组修改会相互影响Arrays.asList 方法除了上面这个 不支持增加、删除元素 这个坑之外，还有另外一个坑： 从以上代码可以发现，对原始数组的修改会影响我们通过 Arrays.asList方法获得的新 List，深入 java.util.Arrays.ArrayList 的源码： 12345678910111213private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable &#123; private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) &#123; a = Objects.requireNonNull(array); &#125; ... &#125; 可以发现是直接使用了原始的数组，所有当我们使用 Arrays.asList 方式获得的 List 时要特别注意，因为共享了数组，相互修改时可能产生一些意想不到的 Bug。标准的姿势之一是将其作为 ArrayList 构造方法的参数重新 new 一个 List 出来即可（e.g. List&lt;String&gt; stringList = new ArrayList&lt;&gt;(Arrays.asList(arrays))）或者通过 Guava 库中的 Lists.newArrayList ，将返回的新 List 和原始的数组解耦，就不会再互相影响了。 第三个坑，直接遍历 List 集合删除元素会报错在直接遍历集合元素时增加、删除元素会报错，比如执行如下代码： 123456List&lt;String&gt; stringList = Lists.newArrayList("m", "g", "h");for (String s : stringList) &#123; if (Arrays.asList("m", "h").contains(s)) &#123; stringList.remove(s); &#125;&#125; 以上代码可以正常编译通过，但是执行时会抛出 java.util.ConcurrentModificationException 异常，查看其源码可以发现，删除元素方法 remove 会使集合结构发生修改，也就是 modCount（集合实际修改的次数）会修改，在循环过程中，会比较当前 List 的集合实际修改的次数 modCount 与迭代器修改的次数 expectedModCount ，而 expectedModCount 是初始化时的 modCount， 二者不相等，就会报 ConcurrentModificationException 异常。解决方法主要有两种方式，1.使用 ArrayList 的迭代器方式遍历，然后调用其中的方法。2.在 JDK 1.8+ 可以使用 removeIf 方法进行删除操作。 最后扎心一问：调用 ArrayList 的 remove 方法传入 int 基本类型的数字和 Integer 包装类型的数字，执行结果是不是一样的？]]></content>
      <categories>
        <category>Java</category>
        <category>List</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 基础概念进阶]]></title>
    <url>%2Fpost%2Ff92758d8.html</url>
    <content type="text"><![CDATA[上一篇 RabbitMQ 入门之基础概念 介绍了 RabbitMQ 的一些基础概念，本文再来介绍其中的一些细节和其它的进阶的概念。 消息生产者发送的消息不可达时如何处理RabbitMQ 提供了消息在传递过程中无法发送到一个队列（比如根据自己的类型和路由键没有找到匹配的队列）时将消息回传给消息发送方的功能，使用 RabbitMQ 的客户端提供 channel.basicPublish 方法的两个参数 mandatory 和 immediate (RabbitMQ 3.0 以下版本)，除此之外还提供了一个备份交换器可以将无法发送的消息存储起来处理，不用重新传回给发送方。 1.1 mandatory 参数mandatory 被定义在 RabbitMQ 提供的客户端的 channel.basicPublish 方法中，如下所示： 当把方法的 mandatory 参数设置为 true 时，那么会在交换器无法根据自身的类型和路由键找到一个符合要求的队列时，RabbitMQ 会自动调用 Basic.Return 把该消息回传给发送方也就是我们的消息生产者。反之，如果设置为 false 的话，消息就会被直接丢弃掉。那么问题来了，我们要如何去获取这些没有被发送出去的消息呢？RabbitMQ 给我们提供了事件监听机制来获取这种消息，可以通过 addReturnListener 方法添加一个 ReturnListener 来获取这种未发送到队列的消息，如下所示： 通过查看 ReturnListener 接口的源码可以看到，该接口只有一个方法，如果是 JDK8+ 的版本的话可以使用 Lambda 表达式来简化一些代码。 可以看出，当设置了 mandatory 参数时，还必须为生产者同时添加 ReturnListener 监听器的编程逻辑，这样就会使得生产者的代码变得更加复杂了，为了处理这种情况，RabbitMQ 提供了 备份交换器 来将没有成功路由出去的消息存储起来，当我们需要的时候再去处理即可。 1.2 immediate 参数该的参数同样也是在channel.basicPublish 方法中定义的，其官方描述如下： This flag tells the server how to react if the message cannot be routed to a queue consumer immediately. If this flag is set, the server will return an undeliverable message with a Return method. If this flag is zero, the server will queue the message, but with no guarantee that it will ever be consumed. 当把 immediate 参数设置为 true 时，如果交换器根据其类型和路由键找到符合要求的队列时，发现所有队列上没有任何消费者，则该消息并不会存入到队列中，会通过 Basic.Return 命令把消息回传给生产者。简而言之也就是说，当设置了 immediate 参数时，该消息关联的队列上存在消费者时，会立即发送消息到该队列中，反之如果匹配的队列上不存在任何消费者，则直接把消息回传给生产者。这里有一点需要注意的是：从 RabbitMQ 3.0 + 已经去除了该参数。 如何对消息和队列设置过期时间 （TTL）TTL 是 time to live 首字母的简称，RabbitMQ 中可以设置消息和队列的过期时间，我们先来看看要如何设置消息的过期时间。 1.1 消息 TTL 设置RabbitMQ 提供了两种设置消息的过期时间，第一种是通过队列的属性设置，该方式的特点就是队列中所有消息的过期时间都一致。还有一种是更小粒度的设置，就是对每条消息单独设置过期时间，这种方式更加灵活，每条消息的过期时间都可以不一样。这是你可能会问，如果同时设置了队列的过期属性和消息本身的过期属性，最终以哪个为准呢？结果是 RabbitMQ 会比较这两个 TTL 的值大小，以较小的那个为准。很容易想到，通过队列的属性的方式设置过期时间的话是在声明队列的时候指定，对应到客户端就是其提供的 channel.queueDeclare 方法的参数 arguments 指定，示例代码如下： 需要注意的是 x-message-ttl 参数的单位是毫秒。如果不设置 TLL，则表示该消息不会过期，如果将 TTL 设置为 0，表示除非此时可以把消息直接发送投递到消费者端去，否则就会直接丢弃该消息。 准对每条消息设置 TTL 的方法是在发送消息的时候设置的，对应到客户端方法是 channel.basicPublish 的 expiration 属性参数，具体设置代码如下： 这种设置方式，即使队列过期也不会立即从队列中移除，因为每条消息是否过期的判定是在发送到消费者是才进行的，如果此时发现已经过期才会删除消息。而对于第一种方式则会把已经过期的消息移到队列头部，然后 RabbitMQ 只要定期的从头开始扫描是否存在过期的消息即可。 1.2 队列 TTL 设置设置队列的过期时间使用的是客户端的 channel.queueDeclare 方法参数中的 x-expires 参数，其单位同样也是毫秒，不过需要注意的是它不能设置为 0。设置队列过期的代码如下所示： 上面代码创建了一个过期时间为 15 分钟的队列。 死信队列介绍死信交换器（DLX）的全称是 Dead-Letter-Exchange ，也称之为死信邮箱。简单来说就是当一个消息由于 消息被拒绝 、 消息过期 、 队列达到最大长度 时，变成死信（dead message）之后，会被重新发送到一个交换器中，这个交换器就是死信交换器，绑定在这个交换器上的队列就称之为死信队列。死信交换器实际上就是平常的交换器，可以在任何队列上指定，当在一个队列上设置死信交换器后，如果该队列出现死信时就会被 RabbitMQ 把死信消息重新发送到死信交换器上去，然后路由到死信队列中，我们可以监听这个队列来处理那些死信消息。为一个队列设置死信交换器是在生产者的声明队列的方法中设置 x-dead-letter-message 参数来实现的，如下所示： 同时也可以通过 x-dead-letter-routing-key 参数设置死信交互器的路由键，不设置默认使用原始度列的路由键。可以到 RabbitMQ 的后台管理界面，有 DLX 标志的就是死信队列。 RabbitMQ 提供的 DLX 是个比较实用的功能特性，它可以在我们消息不能被消费者正确消费的情况下放入到死信队列，后续我们可以通过这个死信队列的内容来查看异常情况来改造和优化系统。 延迟队列介绍顾名思义，延迟队列存储的是哪些需要等待指定时间后才能拿到的延迟消息，一个比较典型的场景就是订单 30 分钟后未支付取消订单。这里需要注意的是，在 RabbitMQ 中并没有直接提供延迟队列的功能，而是需要通过上面介绍的过期时间（TTL）和死信队列一起来实现，比如超时取消订单这个场景，我们可以让消费者订阅死信队列，设置正常的那个队列的超时时间为 30 分钟并绑定到该死信队列上，当消息超过 30 分钟未被处理后消息就会把发送到死信队列中，然后死信队列的消费者就可以在 30 分钟后成功的消费到该消息了。 同时当我们有其它的超时配置需求时也很方便扩展，比如可以在生产者发送消息的时候通过设置不同的路由键，通过路由键来将消息发送到与交换器绑定的不同队列中，然后这些队列分别设置不同的过期时间和与之相对应的死信队列，当消息过期时就会被 RabbitMQ 转发到相应的死信队列中，这样就可以去订阅相应的死信队列即可。 交换器、消息和队列持久化持久化可以提高可靠性，可以防止宕机或者重启等异常下数据的丢失，RabbitMQ 的持久化从组成结构上可以分为三个部分，即交换器持久化、消息持久化和队列持久化。 1.1 交换器持久化交换器持久化是在声明交换器时将 durable 参数设置为 true 来实现的。如果不设置持久化属性的话，当 RabbitMQ 服务重启后交换器的数据就会丢失，需要注意的是，是交换器的数据丢失，消息不会丢失，只是不能将消息发送到这个交换器中了，一般生产环境使用都会把该属性设置为持久化。 1.2 消息持久化交换器的持久化仅仅只是保证了交换器本身的元数据不会丢失，无法保证其存储的消息不会丢失，如果需要其内部存储的消息不丢失，则需要设置消息的持久化，通过将消息的投递模式(deliveryMode)设置为 2 即可实现消息的持久化，如下所示： 需要消息持久化的前提是其所在的队列也要设置持久化，假如仅仅只设置消息的持久化的话，RabbitMQ 重启之后队列消失，然后消息也会丢失。这里有点需要注意一下，虽然持久化可以提高可靠性，但是持久化是将数据存储到硬盘上，比直接操作内存要慢很多，所以对于哪些可靠性要求不高的业务不需要进行持久化。 1.3 队列持久化队列的持久化的设置和交换器持久化类似，同样也是在声明的时候通过 durable 参数设置为 true 实现的，如果不设置，当 RabbitMQ 重启后，相关的队列元数据也会丢失，相应的其存储的消息也会随之丢失掉。 将交换器、队列、消息都设置了持久化之后就能百分之百保证数据不丢失了吗？其实无法保证百分之百数据不丢失。比如消费者在订阅消费队列时将自动应答（autoAck）参数设置为 true 的话，在接收到消息后还没来得及处理就挂了，这时需要把自动应答设置 false，进行手动 ack 应答即可。还有一个就是由于不是实时持久化存盘，当消息存盘的过程中 RabbitMQ 宕机了，此时也会发生数据丢失，此时需要通过 RabbitMQ 的 镜像队列机制 来处理了。 总结本文主要介绍了一些参数具体使用时的设置细节和死信队列、延迟队列以及持久化等，还有一些比较重要的点没有涉及到，比如消息确认机制。“纸上得来终觉浅，绝知此事要躬行”，在了解一些基础的概念之后还是需要通过具体编码实践才能对其更加理解深刻。]]></content>
      <categories>
        <category>RabbitMQ</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 入门之基础概念]]></title>
    <url>%2Fpost%2Fc34b451f.html</url>
    <content type="text"><![CDATA[什么是消息队列（MQ）消息是在不同应用间传递的数据。这里的消息可以非常简单，比如只包含字符串，也可以非常复杂，包含多个嵌套的对象。消息队列（Message Queue）简单来说就是一种应用程序间的通讯方式，消息发送后立即返回，然后由消息系统保证消息的可靠性传输，消息生产者只需要把消息发到 MQ 中就可以了，不需要关心消息的消费，同样，消息消费者只管从 MQ 中拉取消息而不管是谁生产的消息，通过这样的一个“互相不知道对象存在”模式，将消息的生产者和消息的消费者解耦了。 什么场景下考虑使用消息队列从上面可以知道，消息队列是一种应用间的异步协作机制，那么我们什么时候需要用到 MQ 呢？以常见的订单系统为例，当用户点击「下单」后的业务逻辑可能包括：扣减库存、生成相应订单数据、发短信通知等。在项目和业务发展初期上面这些逻辑可能放在一起执行，随着业务的发展订单量的增加，需要提升系统服务的性能，此时就可以将一些不需要立即生效的操作拆分出来异步执行，比如发送短信通知等。这种场景下就可以使用 MQ ，在下单主流程（比如扣减库存、生成订单数据等）完成之后发送一条消息到 MQ 让主流程快速走完，然后由另外一个线程拉取 MQ 的消息，执行相应的业务逻辑。这里的例子主要是用消息队列来解耦。 RabbitMQ 的特点RabbitMQ 是一个由 Relang 语言开发的 AMQP 的开源实现。AMQP（Advanced Message Queue：高级消息队列协议）它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。RabbitMQ 最初起源于消息系统，用于在分布式系统中存储转发消息，具体有如下一些特点： 可靠性： RabbitMQ 使用一些机制来保证可靠性，比如持久化、传输确认机制（ack）和发布确认等。 灵活的路由策略： 在消息进入队列之前，通过 Exchange 来路由消息，对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对复杂的路由功能，可以将多个 Exchange 绑在一起，也通过插件机制实现自己的 Exchange。 消息集群： 多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker。 高可用： 队列可以在集群中的集群上进行镜像，使得在部分节点出问题的情况下队列仍然可用。 多种协议： RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等。 多语言客户端： RabbitMQ 几乎支持多有常用的语言，比如：Java、.NET 等 管理界面： RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方面。 RabbitMQ 安装（mac）和运行1、安装因为 RabbitMQ 依赖于 Erlang 语言，所以在安装 RabbitMQ 之前需要先安装 Erlang 环境，但是由于是 Mac 环境，可以使用 HomeBrew 安装，安装前先更新 brew： 1brew update 接着安装 RabbitMQ 即可，安装过程中会自动安装其所依赖的 Erlang。 2、运行RabbitMQ 的启动运行很简单，找到其安装目录后（使用 Homwbrew 安装的默认目录为：/usr/local/Cellar/rabbitmq），进入到目录的 sbin 目录下，可以看到有 6 个以 rabbitmq 开头的可执行文件，直接执行 rabbitmq-server 即可。 启动正常的话可以看到启动过程的日志信息和最后的 completed with 6 plugins，这也说明启动的时候默认加载了 6 个插件。 此时通过浏览器访问 http://localhost:15672 可以看到其管理界面（默认用户名和密码都是 guest），可以在 admin 选项卡页面新增用户，管理界面如下： PS： 以上方式不是后台启动，如果想让 RabbitMQ 后台守护进程的方式启动的话，可以在启动的时候加上 -detached 参数。 3、查询服务器状态在安装目录的 sbin 下面有个可执行文件 rabbitmqctl ，它提供了 RabbitMQ 管理需要的几乎一站式解决方案，绝大部分的运维命令它都可以提供。查询 RabbitMQ 服务器的状态信息可以用参数 status。 RabbitMQ 中的基础概念1、消息模型 几乎所有的 MQ 抽象来说都是一样的过程：消费者订阅某个队列，生产者生产消息，然后发布到队列中，最后将消息发送到监听该队列的消费者那里。如下图所示： 2、基本概念 上面上一个消息队列的抽象概述，具体到 RabbitMQ 有一些特有的概念，RabbitMQ 是 AMQP 协议的一个开源实现，其内部概念大都是 AMQP 协议的一些概念。 名称 描述 Message 消息 消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则是由一系列的可选属性组成，这些属性包括 routing-key（路由键）、priority（相对于其它消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。 Publisher 消息生产者 一个向交换机发送消息的客户端应用程序。 Exchange 交换器 用来接收生产者发送过来的消息，并将这些消息发送给服务器中的队列。 Binding 绑定 用于消息队列和交换器之间的关联，一个绑定就是一个基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue 消息队列 用来保存消息直到发送给消费者，它是消息的容器，也是消息的终点，一个消息可投入一个或多个队列，消息一直在队列里面，等待消费者连接到这个队列并将其取走。 Connection 网络连接 比如一个 TCP 连接。 Channel 信道 多路复用连接中的一条独立双向数据流通道，信道是建立在真实 TCP 连接内的虚拟连接，AMQP 命令都是通过信道发送出去的，不管是发布消息、订阅消息还是接收消息，这些动作都是通过信道完成的。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。 Consumer 消息的消费者 一个从消息队列中获取消息的客户端应用程序。 Virtual Host 虚拟主机 表示一批交换器、消息队列和相关对象。虚拟主机是共享相同身份认证和加密环境的对服务器域。每个 vhost 本质上是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。 3、AMQP 中的消息路由 AMQP 中消息路由过程和 Java 开发者熟悉的 JMS 存在一些差别，AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发送到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发到哪个队列。 4、Exchange 类型 Exchange 分发消息时根据类型的不同分发策略略有区别，目前共有四种类型：direct、fanout、topic、headers。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型即可。 4.1、direct 类型 消息中的路由键（routing key）如果和 Binding 中的 binding key 一致，交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为 “dog”，则只转发 routing key 标记为 “dog” 的消息，不会转发 “dog.puppy”，也不会转发 “dog.guard” 等等。它是完全匹配、单播的模式。 4.2、fanout 类型 每个发到 fanout 类型交换机的消息都会发到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得一份复制的消息。fanout 类型转发消息是最快的。 3、topic 类型 topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上，它将路由键和绑定的字符串切分成单词，这些单词之间用点隔开。它同样也识别两个通配符：符号 “#” 和符号 “*”。# 符号匹配 0 个或多个单词，* 符号匹配不多不少一个单词。 总结本文主要讲了关于 RabbitMQ 的安装以及基础概念的相关介绍，由于它是基于 Erlang 语言开发，可能对于部分 Java 开发者想了解其底层实现细节以及排查比较复杂的问题时不是很友好。]]></content>
      <categories>
        <category>RabbitMQ</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中队列同步器 AQS（AbstractQueuedSynchronizer）实现原理]]></title>
    <url>%2Fpost%2F4b00e13c.html</url>
    <content type="text"><![CDATA[前言在 Java 中通过 锁 来控制多个线程对共享资源的访问，使用 Java 编程语言开发的朋友都知道，可以通过 synchronized 关键字来实现锁的功能，它可以隐式的获取锁，也就是说我们使用该关键字并不需要去关心锁的获取和释放过程，但是在提供方便的同时也意味着其灵活性的下降。例如，有这样的一个场景，先获取锁 A，然后再获取锁 B，当锁 B 获取到之后，释放锁 A 同时获取锁 C，当获取锁 C 后，再释放锁 B 同时获取锁 D，依次类推，像这种比较复杂的场景，使用 synchronized 关键字就比较难实现了。在 Java SE 5 之后，新增加了 Lock 接口和一系列的实现类来提供和 synchronized 关键字一样的功能，它需要我们显示的进行锁的获取和释放，除此之外还提供了可响应中断的锁获取操作以及超时获取锁等同步特性。JDK 中提供的 Lock 接口实现类大部分都是聚合一个同步器 AQS 的子类来实现多线程的访问控制的，下面我们看看这个构建锁和其它同步组件的基础框架——队列同步器 AQS（AbstractQueuedSynchronizer）。 AQS 基础数据结构同步队列队列同步器 AQS（下文简称为同步器）主要是依赖于内部的一个 FIFO（first-in-first-out）双向队列来对同步状态进行管理的，当线程获取同步状态失败时，同步器会将当前线程和当前等待状态等信息封装成一个内部定义的节点 Node，然后将其加入队列，同时阻塞当前线程；当同步状态释放时，会将同步队列中首节点唤醒，让其再次尝试去获取同步状态。同步队列的基本结构如下： 队列节点 Node同步队列使用同步器中的静态内部类 Node 用来保存获取同步状态的线程的引用、线程的等待状态、前驱节点和后继节点。 同步队列中 Node 节点的属性名称和具体含义如下表所示： 属性类型和名称 描述 volatile int waitStatus 当前节点在队列中的等待状态 volatile Node prev 前驱节点，当节点加入同步队列时被赋值(使用尾部添加方式) volatile Node next 后继节点 volatile Thread thread 获取同步状态的线程 Node nextWaiter 等待队列中的后继节点，如果当前节点是共享的，则该字段是一个 SHARED 常量 每个节点线程都有两种锁模式，分别为 SHARED 表示线程以共享的模式等待锁，EXCLUSIVE 表示线程以独占的方式等待锁。同时每个节点的等待状态 waitStatus 只能取以下表中的枚举值： 枚举值 描述 SIGNAL 值为 -1，表示该节点的线程已经准备完毕，等待资源释放 CANCELLED 值为 1，表示该节点线程获取锁的请求已经取消了 CONDITION 值为 -2，表示该节点线程等待在 Condition 上，等待被其它线程唤醒 PROPAGATE 值为 -3，表示下一次共享同步状态获取会无限进行下去，只在 SHARED 情况下使用 0 值为 0，初始状态，初始化的默认值 同步状态 state同步器内部使用了一个名为 state 的 int 类型的变量表示同步状态，同步器的主要使用方式是通过继承，子类通过继承并实现它的抽象方法来管理同步状态，同步器给我们提供了如下三个方法来对同步状态进行更改。 方法签名 描述 protected final int getState() 获取当前同步状态 protected final void setState(int newState) 设置当前同步状态 protected final boolean compareAndSetState(int expect, int update) 使用 CAS 设置当前状态，该方法能够保证状态设置的原子性 在独享锁中同步状态 state 这个值通常是 0 或者 1（如果是重入锁的话 state 值就是重入的次数），在共享锁中 state 就是持有锁的数量。 独占式同步状态获取与释放同步器中提供了 acquire(int arg) 方法来进行独占式同步状态的获取，获取到了同步状态也就是获取到了锁，该方法源码如下所示： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 方法首先会调用 tryAcquire 方法尝试去获取锁，查看方法的源码可以发现，同步器并未对该方法进行实现（只是抛出一个不支持操作异常 UnsupportedOperationException），这个方法是需要后续同步组件的开发人员自己去实现的，如果方法返回 true 则表示当前线程成功获取到锁，调用 selfInterrupt() 中断当前线程（PS：这里留给大家一个问题：为什么获取了锁以后还要中断线程呢？），方法结束返回，如果方法返回 false 则表示当前线程获取锁失败，也就是说有其它线程先前已经获取到了锁，此时就需要把当前线程以及等待状态等信息添加到同步队列中，下面来看看同步器在线程未获取到锁时具体是如何实现。通过源码发现，当获取锁失败时，会执行判断条件与操作的后半部分 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，首先指定锁模式为 Node.EXCLUSIVE 调用 addWaiter 方法，该方法源码如下： 1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 通过方法参数指定的锁模式（共享锁 or 独占锁）和当前线程构造出一个 Node 节点，如果同步队列已经初始化，那么首先会进行一次从尾部加入队列的尝试，使用 compareAndSetTail 方法保证原子性，进入该方法源码可以发现是基于 sun.misc 包下提供的 Unsafe 类来实现的。如果首次尝试加入同步队列失败，会再次调用 enq 方法进行入队操作，继续跟进 enq 方法源码如下： 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 通过其源码可以发现和第一次尝试加入队列的代码类似，只是该方法里面加了同步队列初始化判断，使用 compareAndSetHead 方法保证设置头节点的原子性，同样它底层也是基于 Unsafe 类，然后外层套了一个 for (;;) 死循环，循环唯一的退出条件是从队尾入队成功，也就是说如果从该方法成功返回了就表示已经入队成功了，至此，addWaiter 执行完毕返回当前 Node 节点。然后以该节点作为 acquireQueued 方法的入参继续进行其它步骤，该方法如下所示： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 可以看到，该方法本质上也是通过一个死循环（自旋）去获取锁并且支持中断，在循环体外面定义两个标记变量，failed 标记是否成功获取到锁，interrupted 标记在等待的过程中是否被中断过。方法首先通过 predecessor 获取当前节点的前驱节点，当当前节点的前驱节点是 head 头节点时就调用 tryAcquire 尝试获取锁，也就是第二个节点则尝试获取锁，这里为什么要从第二个节点才尝试获取锁呢？是因为同步队列本质上是一个双向链表，在双向链表中，第一个节点并不存储任何数据是虚节点，只是起到一个占位的作用，真正存储数据的节点是从第二个节点开始的。如果成功获取锁，也就是 tryAcquire 方法返回 true 后，将 head 指向当前节点并把之前找到的头节点 p 从队列中移除，修改是否成功获取到锁标记，结束方法返回中断标记。如果当前节点的前驱节点 p 不是头节点或者前驱节点 p 是头节点但是获取锁操作失败，那么会调用 shouldParkAfterFailedAcquire 方法判断当前 node 节点是否需要被阻塞，这里的阻塞判断主要是为了防止长时间自旋给 CPU 带来非常大的执行开销，浪费资源。该方法源码如下： 123456789101112131415161718192021222324252627private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 方法参数为当前节点的前驱节点以及当前节点，主要是靠前驱节点来判断是否需要进行阻塞，首先获取到前驱节点的等待状态 ws，如果节点状态 ws 为 SIGNAL，表示前驱节点的线程已经准备完毕，等待资源释放，方法返回 true 表示可以阻塞，如果 ws &gt; 0，通过上文可以知道节点只有一个状态 CANCELLED（值为 1） 满足该条件，表示该节点线程获取锁的请求已经取消了，会通过一个 do-while 循环向前查找 CANCELLED 状态的节点并将其从同步队列中移除，否则进入 else 分支，使用 compareAndSetWaitStatus 原子操作将前驱节点的等待状态修改为 SIGNAL，以上这两种情况都不需要进行阻塞方法返回 false。当经过判断后需要阻塞的话，也就是 compareAndSetWaitStatus 方法返回 true 时，会通过 parkAndCheckInterrupt 方法阻塞挂起当前线程，并返回当前线程的中断标识。方法如下： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 线程阻塞是通过 LockSupport 这个工具类实现的，深入其源码可以发现它底层也是基于 Unsafe 类实现的。如果以上两个方法都返回 true 的话就更新中断标记。这里还有一个问题就是什么时候会将一个节点的等待状态 waitStatus 修改为 CANCELLED 节点线程获取锁的请求取消状态呢？细心的朋友可能已经发现了，在上文贴出的 acquireQueued 方法源码中的 finally 块中会根据 failed 标记来决定是否调用 cancelAcquire 方法，这个方法就是用来将节点状态修改为 CANCELLED 的，方法的具体实现留给大家去探索。至此 AQS 独占式同步状态获取锁的流程就完成了，下面通过一个流程图来看看整体流程： 下面再看看独占式锁释放的过程，同步器使用 release 方法来让我们进行独占式锁的释放，其方法源码如下： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 首先调用 tryRelease 方法尝试进行锁释放操作，继续跟进该方法发现同步器只是抛出了一个不支持操作异常 UnsupportedOperationException，这里和上文独占锁获取中 tryAcquire 方法是一样的套路，需要开发者自己定义锁释放操作。 通过其 JavaDoc 可以得知，如果返回 false，则表示释放锁失败，方法结束。该方法如果返回 true，则表示当前线程释放锁成功，需要通知队列中等待获取锁的线程进行锁获取操作。首先获取头节点 head，如果当前头节点不为 null，并且其等待状态不是初始状态（0），则解除线程阻塞挂起状态，通过 unparkSuccessor 方法实现，该方法源码如下： 1234567891011121314151617181920212223242526private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 首先获取头节点的等待状态 ws，如果状态值为负数（Node.SIGNAL or Node.PROPAGATE），则通过 CAS 操作将其改为初始状态（0），然后获取头节点的后继节点，如果后继节点为 null 或者后继节点状态为 CANCELLED（获取锁请求已取消），就从队列尾部开始寻找第一个状态为非 CANCELLED 的节点，如果该节点不为空则使用 LockSupport 的 unpark 方法将其唤醒，该方法底层是通过 Unsafe 类的 unpark 实现的。这里需要从队尾查找非 CANCELLED 状态的节点的原因是，在之前的获取独占锁失败时的入队 addWaiter 方法实现中，该方法如下： 假设一个线程执行到了上图中的 ① 处，② 处还没有执行，此时另一个线程恰好执行了 unparkSuccessor 方法，那么就无法通过从前向后查找了，因为节点的后继指针 next 还没赋值呢，所以需要从后往前进行查找。至此，独占式锁释放操作就结束了，同样的，最后我们也通过一个流程图来看看整个锁释放的过程： 独占式可中断同步状态获取同步器提供了 acquireInterruptibly 方法来进行可响应中断的获取锁操作，方法实现源码如下： 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; 方法首先检查当前线程的中断状态，如果已中断，则直接抛出中断异常 InterruptedException 即响应中断，否则调用 tryAcquire 方法尝试获取锁，如果获取成功则方法结束返回，获取失败调用 doAcquireInterruptibly 方法，跟进该方法如下： 12345678910111213141516171819202122private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 仔细观察可以发现该方法实现源码和上文中 acquireQueued 方法的实现基本上类似，只是这里把入队操作 addWaiter 放到了方法里面了，还有一个区别就是当在循环体内判断需要进行中断时会直接抛出异常来响应中断，两个方法的对比如下： 其它步骤和独占式锁获取一致，流程图大体上和不响应中断的锁获取差不多，只是在最开始多了一步线程中断状态检查和循环是会抛出中断异常而已。 独占式超时获取同步状态同步器提供了 tryAcquireNanos 方法可以超时获取同步状态（也就是锁），该方法提供了之前 synchronized 关键字不支持的超时获取的特性，通过该方法我们可以在指定时间段 nanosTimeout 内获取锁，如果获取到锁则返回 true，否则，返回 false。方法源码如下： 1234567public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; 首先会调用 tryAcquire 方法尝试获取一次锁，如果获取锁成功则立即返回，否则调用 doAcquireNanos 方法进入超时获取锁流程。通过上文可以得知，同步器的 acquireInterruptibly 方法在等待获取同步状态时，如果当前线程被中断了，会抛出中断异常 InterruptedException 并立刻返回。超时获取锁的流程其实是在响应中断的基础上增加了超时获取的特性，doAcquireNanos 方法的源码如下： 123456789101112131415161718192021222324252627282930private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 由以上方法实现源码可以看出，针对超时获取这里主要实现思路是：先使用当前时间加上参数传入的超时时间间隔 deadline 计算出超时的时间点，然后每次进行循环的时候使用超时时间点 deadline 减去当前时间得到剩余的时间 nanosTimeout，如果剩余时间小于 0 则证明当前获取锁操作已经超时，方法结束返回 false，反如果剩余时间大于 0。可以看到在里面执行自旋的时候和上面独占式同步获取锁状态 acquireQueued 方法那里是一样的套路，即当当前节点的前驱节点为头节点时调用 tryAcquire 尝试获取锁，如果获取成功则返回。 除了超时时间计算那里不同外，还有个不同的地方就是在超时获取锁失败之后的操作，如果当前线程获取锁失败，则判断剩余超时时间 nanosTimeout 是否小于 0，如果小于 0 则表示已经超时方法立即返回，反之则会判断是否需要进行阻塞挂起当前线程，如果通过 shouldParkAfterFailedAcquire 方法判断需要挂起阻塞当前线程，还要进一步比较超时剩余时间 nanosTimeout 和 spinForTimeoutThreshold 的大小，如果小于等于 spinForTimeoutThreshold 值（1000 纳秒）的话，将不会使当前线程进行超时等待，而是再次进行自旋过程。加后面这个判断的主要原因在于，在非常短（小于 1000 纳秒）的时间内的等待无法做到十分精确，如果这时还进行超时等待的话，反而会让我们指定 nanosTimeout 的超时从整体上给人感觉反而不太精确，因此，在剩余超时时间非常短的情况下，同步器会再次自旋进行超时获取锁的过程，独占式超时获取锁整个过程如下所示： 共享式同步状态获取与释放共享锁顾名思义就是可以多个线程共用一个锁，在同步器中使用 acquireShared 来获取共享锁（同步状态），方法源码如下： 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 首先通过 tryAcquireShared 尝试获取共享锁，该方法是一个模板方法在同步器中只是抛出一个不支持操作异常，需要开发人员自己去实现，同时方法的返回值有三种不同的类型分别代表三种不同的状态，其含义如下： 小于 0 表示当前线程获取锁失败 等于 0 表示当前线程获取锁成功，但是之后的线程在没有锁释放的情况下获取锁将失败，也就是说这个锁是共享模式下的最后一把锁了 大于 0 表示当前线程获取锁成功，并且还有剩余的锁可以获取 当方法 tryAcquireShared 返回值小于 0 时，也就是获取锁失败，将会执行方法 doAcquireShared，继续跟进该方法： 123456789101112131415161718192021222324252627private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 方法首先调用 addWaiter 方法封装当前线程和等待状态为共享模块的节点并将其添加到等待同步队列中，可以发现在共享模式下节点的 nextWaiter 属性是固定值 Node.SHARED。然后循环获取当前节点的前驱节点，如果前驱节点是头节点的话就尝试获取共享锁，如果返回值大于等于 0 表示获取共享锁成功，则调用 setHeadAndPropagate 方法，更新头节点同时如果有可用资源，则向后传播，唤醒后继节点，接下来会检查一下中断标识，如果已经中断则中断当前线程，方法结束返回。如果返回值小于 0，则表示获取锁失败，需要挂起阻塞当前线程或者继续自旋获取共享锁。下面看看 setHeadAndPropagate 方法的具体实现： 1234567891011121314151617181920212223242526private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 首先将当前获取到锁的节点设置为头节点，然后方法参数 propagate &gt; 0 时表示之前 tryAcquireShared 方法的返回值大于 0，也就是说当前还有剩余的共享锁可以获取，则获取当前节点的后继节点并且后继节点是共享节点时唤醒节点去尝试获取锁，doReleaseShared 方法是同步器共享锁释放的主要逻辑。 同步器提供了 releaseShared 方法来进行共享锁的释放，方法源码如下所示： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 首先调用 tryReleaseShared 方法尝试释放共享锁，方法返回 false 代表锁释放失败，方法结束返回 false，否则就表示成功释放锁，然后执行 doReleaseShared 方法，进行唤醒后继节点并检查它是否可以向后传播等操作。继续跟进该方法如下： 1234567891011121314151617181920212223242526272829private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 可以看到和独占式锁释放不同的是，在共享模式下，状态同步和释放可以同时执行，其原子性由 CAS 来保证，如果头节点改变了也会继续循环。每次共享节点在共享模式下唤醒时，头节点都会指向它，这样就可以保证可以获取到共享锁的所有后续节点都可以唤醒了。 如何自定义同步组件在 JDK 中基于同步器实现的一些类绝大部分都是聚合了一个或多个继承了同步器的类，使用同步器提供的模板方法自定义内部同步状态的管理，然后通过这个内部类去实现同步状态管理的功能，其实这从某种程度上来说使用了 模板模式。比如 JDK 中可重入锁 ReentrantLock、读写锁 ReentrantReadWriteLock、信号量 Semaphore 以及同步工具类 CountDownLatch 等，其源码部分截图如下： 通过上文可以知道，我们基于同步器可以分别自定义独占锁同步组件和共享锁同步组件，下面以实现一个在同一个时刻最多只允许 3 个线程访问，其它线程的访问将被阻塞的同步工具 TripletsLock 为例，很显然这个工具是共享锁模式，主要思路就是去实现一个 JDk 中的 Lock 接口来提供面向使用者的方法，比如，调用 lock 方法获取锁，使用 unlock 来对锁进行释放等，在 TripletsLock 类内部有一个自定义同步器 Sync 继承自同步器 AQS，用来对线程的访问和同步状态进行控制，当线程调用 lock 方法获取锁时，自定义同步器 Sync 先计算出获取到锁后的同步状态，然后使用 Unsafe 类操作来保证同步状态更新的原子性，由于同一时刻只能 3 个线程访问，这里我们可以将同步状态 state 的初始值设置为 3，表示当前可用的同步资源数量，当有线程成功获取到锁时将同步状态 state 减 1，有线程成功释放锁时将同步状态加 1，同步状态的取值范围为 0、1、2、3，同步状态为 0 时表示没有可用同步资源，这个时候如果有线程访问将被阻塞。下面来看看这个自定义同步组件的实现代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * @author mghio * @date: 2020-06-13 * @version: 1.0 * @description: * @since JDK 1.8 */public class TripletsLock implements Lock &#123; private final Sync sync = new Sync(3); private static final class Sync extends AbstractQueuedSynchronizer &#123; public Sync(int state) &#123; setState(state); &#125; Condition newCondition() &#123; return new ConditionObject(); &#125; @Override protected int tryAcquireShared(int reduceCount) &#123; for (; ;) &#123; int currentState = getState(); int newState = currentState - reduceCount; if (newState &lt; 0 || compareAndSetState(currentState, newState)) &#123; return newState; &#125; &#125; &#125; @Override protected boolean tryReleaseShared(int count) &#123; for (; ;) &#123; int currentState = getState(); int newState = currentState + count; if (compareAndSetState(currentState, newState)) &#123; return true; &#125; &#125; &#125; &#125; @Override public void lock() &#123; sync.acquireShared(1); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override public boolean tryLock() &#123; return sync.tryAcquireShared(1) &gt; 0; &#125; @Override public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; @Override public void unlock() &#123; sync.releaseShared(1); &#125; @Override public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125; 下面启动 20 个线程测试看看自定义同步同步工具类 TripletsLock 是否达到我们的预期。测试代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @author mghio * @date: 2020-06-13 * @version: 1.0 * @description: * @since JDK 1.8 */public class TripletsLockTest &#123; private final Lock lock = new TripletsLock(); private final DateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS"); @Test public void testTripletsLock() &#123; // 启动 20 个线程 for (int i = 0; i &lt; 20; i++) &#123; Thread worker = new Runner(); worker.setDaemon(true); worker.start(); &#125; for (int i = 0; i &lt; 20; i++) &#123; second(2); System.out.println(); &#125; &#125; private class Runner extends Thread &#123; @Override public void run() &#123; for (; ;) &#123; lock.lock(); try &#123; second(1); System.out.println(dateFormat.format(new Date()) + " ----&gt; " + Thread.currentThread().getName()); second(1); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; &#125; private static void second(long seconds) &#123; try &#123; TimeUnit.SECONDS.sleep(seconds); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 测试结果如下： 从以上测试结果可以发现，同一时刻只有三个线程可以获取到锁，符合预期，这里需要明确的是这个锁获取过程是非公平的。 总结本文主要是对同步器中的基础数据结构、独占式与共享式同步状态获取与释放过程做了简要分析，由于水平有限如有错误之处还请留言讨论。队列同步器 AbstractQueuedSynchronizer 是 JDK 中很多的一些多线程并发工具类的实现基础框架，对其深入学习理解有助于我们更好的去使用其特性和相关工具类。 参考文章 Java并发编程的艺术Java Synchronizer - AQS Learning从 ReentrantLock 的实现看 AQS 的原理及应用The java.util.concurrent Synchronizer Framework]]></content>
      <categories>
        <category>Java</category>
        <category>并发</category>
        <category>进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文让你快速上手 Mockito 单元测试框架]]></title>
    <url>%2Fpost%2F24042edf.html</url>
    <content type="text"><![CDATA[前言在计算机编程中，单元测试是一种软件测试方法，通过该方法可以测试源代码的各个单元功能是否适合使用。为代码编写单元测试有很多好处，包括可以及早的发现代码错误，促进更改，简化集成，方便代码重构以及许多其它功能。使用 Java 语言的朋友应该用过或者听过 Junit 就是用来做单元测试的，那么为什么我们还需要 Mockito 测试框架呢？想象一下这样的一个常见的场景，当前要测试的类依赖于其它一些类对象时，如果用 Junit 来进行单元测试的话，我们就必须手动创建出这些依赖的对象，这其实是个比较麻烦的工作，此时就可以使用 Mockito 测试框架来模拟那些依赖的类，这些被模拟的对象在测试中充当真实对象的虚拟对象或克隆对象，而且 Mockito 同时也提供了方便的测试行为验证。这样就可以让我们更多地去关注当前测试类的逻辑，而不是它所依赖的对象。 生成 Mock 对象方式要使用 Mockito，首先需要在我们的项目中引入 Mockito 测试框架依赖，基于 Maven 构建的项目引入如下依赖即可： 123456&lt;dependency&gt; &lt;groupId&gt;org.mockito&lt;/groupId&gt; &lt;artifactId&gt;mockito-core&lt;/artifactId&gt; &lt;version&gt;3.3.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 如果是基于 Gradle 构建的项目，则引入如下依赖： 1testCompile group: 'org.mockito', name: 'mockito-core', version: '3.3.3' 使用 Mockito 通常有两种常见的方式来创建 Mock 对象。 1、使用 Mockito.mock(clazz) 方式通过 Mockito 类的静态方法 mock 来创建 Mock 对象，例如以下创建了一个 List 类型的 Mock 对象： 1List&lt;String&gt; mockList = Mockito.mock(ArrayList.class); 由于 mock 方法是一个静态方法，所以通常会写成静态导入方法的方式，即 List&lt;String&gt; mockList = mock(ArrayList.class)。 2、使用 @Mock 注解方式第二种方式就是使用 @Mock 注解方式来创建 Mock 对象，使用该方式创需要注意的是要在运行测试方法前使用 MockitoAnnotations.initMocks(this) 或者单元测试类上加上 @ExtendWith(MockitoExtension.class) 注解，如下所示代码创建了一个 List 类型的 Mock 对象(PS: @BeforeEach 是 Junit 5 的注解，功能类似于 Junit 4 的 @Before 注解。)： 123456789101112131415161718/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 *///@ExtendWith(MockitoExtension.class)public class MockitoTest &#123; @Mock private List&lt;String&gt; mockList; @BeforeEach public void beforeEach() &#123; MockitoAnnotations.initMocks(this); &#125;&#125; 验证性测试Mockito 测试框架中提供了 Mockito.verify 静态方法让我们可以方便的进行验证性测试，比如方法调用验证、方法调用次数验证、方法调用顺序验证等，下面看看具体的代码。 验证方法单次调用验证方法单次调用的话直接 verify 方法后加上待验证调用方法即可，以下代码的功能就是验证 mockList 对象的 size 方法被调用一次。 12345678910111213141516171819/** * @author mghio * @date: 2020-05-28 * @version: 1.0 * @description: * @since JDK 1.8 */@ExtendWith(MockitoExtension.class)public class MockitoVerifyTest &#123; @Mock List&lt;String&gt; mockList; @Test void verify_SimpleInvocationOnMock() &#123; mockList.size(); verify(mockList).size(); &#125;&#125; 验证方法调用指定次数除了验证单次调用，我们有时候还需要验证一些方法被调用多次或者指定的次数，那么此时就可以使用 verify + times 方法来验证方法调用指定次数，同时还可以结合 atLeast + atMost 方法来提供调用次数范围，同时还有 never 等方法验证不被调用等。 1234567891011121314151617181920212223/** * @author mghio * @date: 2020-05-28 * @version: 1.0 * @description: * @since JDK 1.8 */@ExtendWith(MockitoExtension.class)public class MockitoVerifyTest &#123; @Mock List&lt;String&gt; mockList; @Test void verify_NumberOfInteractionsWithMock() &#123; mockList.size(); mockList.size(); verify(mockList, times(2)).size(); verify(mockList, atLeast(1)).size(); verify(mockList, atMost(10)).size(); &#125;&#125; 验证方法调用顺序同时还可以使用 inOrder 方法来验证方法的调用顺序，下面示例验证 mockList 对象的 size、add 和 clear 方法的调用顺序。 1234567891011121314151617181920212223242526/** * @author mghio * @date: 2020-05-28 * @version: 1.0 * @description: * @since JDK 1.8 */@ExtendWith(MockitoExtension.class)public class MockitoVerifyTest &#123; @Mock List&lt;String&gt; mockList; @Test void verify_OrderedInvocationsOnMock() &#123; mockList.size(); mockList.add("add a parameter"); mockList.clear(); InOrder inOrder = inOrder(mockList); inOrder.verify(mockList).size(); inOrder.verify(mockList).add("add a parameter"); inOrder.verify(mockList).clear(); &#125;&#125; 以上只是列举了一些简单的验证性测试，还有验证测试方法调用超时以及更多的验证测试可以通过相关官方文档探索学习。 验证方法异常异常测试我们需要使用 Mockito 框架提供的一些调用行为定义，Mockito 提供了 when(...).thenXXX(...) 来让我们定义方法调用行为，以下代码定义了当调用 mockMap 的 get 方法无论传入任何参数都会抛出一个空指针 NullPointerException 异常，然后通过 Assertions.assertThrows 来验证调用结果。 1234567891011121314151617181920/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */@ExtendWith(MockitoExtension.class)public class MockitoExceptionTest &#123; @Mock public Map&lt;String, Integer&gt; mockMap; @Test public void whenConfigNonVoidReturnMethodToThrowEx_thenExIsThrown() &#123; when(mockMap.get(anyString())).thenThrow(NullPointerException.class); assertThrows(NullPointerException.class, () -&gt; mockMap.get("mghio")); &#125;&#125; 同时 when(...).thenXXX(...) 不仅可以定义方法调用抛出异常，还可以定义调用方法后的返回结果，比如 when(mockMap.get(&quot;mghio&quot;)).thenReturn(21); 定义了当我们调用 mockMap 的 get 方法并传入参数 mghio 时的返回结果是 21。这里有一点需要注意，使用以上这种方式定义的 mock 对象测试实际并不会影响到对象的内部状态，如下图所示： 虽然我们已经在 mockList 对象上调用了 add 方法，但是实际上 mockList 集合中并没有加入 mghio，这时候如果需要对 mock 对象有影响，那么需要使用 spy 方式来生成 mock 对象。 1234567891011public class MockitoTest &#123; private List&lt;String&gt; mockList = spy(ArrayList.class); @Test public void add_spyMockList_thenAffect() &#123; mockList.add("mghio"); assertEquals(0, mockList.size()); &#125;&#125; 断点后可以发现当使用 spy 方法创建出来的 mock 对象调用 add 方法后，mghio 被成功的加入到 mockList 集合当中。 与 Spring 框架集成Mockito 框架提供了 @MockBean 注解用来将 mock 对象注入到 Spring 容器中，该对象会替换容器中任何现有的相同类型的 bean，该注解在需要模拟特定bean（例如外部服务）的测试场景中很有用。如果使用的是 Spring Boot 2.0+ 并且当前容器中已有相同类型的 bean 的时候，需要设置 spring.main.allow-bean-definition-overriding 为 true（默认为 false）允许 bean 定义覆盖。下面假设要测试通过用户编码查询用户的信息，有一个数据库操作层的 UserRepository，也就是我们等下要 mock 的对象，定义如下： 12345678910111213/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */@Repositorypublic interface UserRepository &#123; User findUserById(Long id);&#125; 还有用户操作的相关服务 UserService 类，其定义如下所示: 1234567891011121314151617181920/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */@Servicepublic class UserService &#123; private UserRepository userRepository; public UserService(UserRepository userRepository) &#123; this.userRepository = userRepository; &#125; public User findUserById(Long id) &#123; return userRepository.findUserById(id); &#125;&#125; 在测试类中使用 @MockBean 来标注 UserRepository 属性表示这个类型的 bean 使用的是 mock 对象，使用 @Autowired 标注表示 UserService 属性使用的是 Spring 容器中的对象，然后使用 @SpringBootTest 启用 Spring 环境即可。 123456789101112131415161718192021222324/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */@SpringBootTestpublic class UserServiceUnitTest &#123; @Autowired private UserService userService; @MockBean private UserRepository userRepository; @Test public void whenUserIdIsProvided_thenRetrievedNameIsCorrect() &#123; User expectedUser = new User(9527L, "mghio", "18288888880"); when(userRepository.findUserById(9527L)).thenReturn(expectedUser); User actualUser = userService.findUserById(9527L); assertEquals(expectedUser, actualUser); &#125;&#125; Mockito 框架的工作原理通过以上介绍可以发现， Mockito 非常容易使用并且可以方便的验证一些方法的行为，相信你已经看出来了，使用的步骤是先创建一个需要 mock 的对象 Target ，该对象如下： 1234567public class Target &#123; public String foo(String name) &#123; return String.format("Hello, %s", name); &#125;&#125; 然后我们直接使用 Mockito.mock 方法和 when(...).thenReturn(...) 来生成 mock 对象并指定方法调用时的行为，代码如下： 1234567@Testpublic void test_foo() &#123; String expectedResult = "Mocked mghio"; when(mockTarget.foo("mghio")).thenReturn(expectedResult); String actualResult = mockTarget.foo("mghio"); assertEquals(expectedResult, actualResult);&#125; 仔细观察以上 when(mockTarget.foo(&quot;mghio&quot;)).thenReturn(expectedResult) 这行代码，首次使用我也觉得很奇怪，when 方法的入参竟然是方法的返回值 mockTarget.foo(&quot;mghio&quot;)，觉得正确的代码应该是这样 when(mockTarget).foo(&quot;mghio&quot;)，但是这个写法实际上无法进行编译。既然 Target.foo 方法的返回值是 String 类型，那是不是可以使用如下方式呢？ 1Mockito.when("Hello, I am mghio").thenReturn("Mocked mghio"); 结果是编译通过，但是在运行时报错： 从错误提示可以看出，when 方法需要一个方法调用的参数，实际上它只需要 mock 对象方法调用在 when 方法之前就行，我们看看下面这个测试代码： 12345678@Testpublic void test_mockitoWhenMethod() &#123; String expectedResult = "Mocked mghio"; mockTarget.foo("mghio"); when("Hello, I am mghio").thenReturn(expectedResult); String actualResult = mockTarget.foo("mghio"); assertEquals(expectedResult, actualResult);&#125; 以上代码可以正常测试通过，结果如下： 为什么这样就可以正常测试通过？是因为当我们调用 mock 对象的 foo 方法时，Mockito 会拦截方法的调用然后将方法调用的详细信息保存到 mock 对象的上下文中，当调用到 Mockito.when 方法时，实际上是从该上下文中获取最后一个注册的方法调用，然后把 thenReturn 的参数作为其返回值保存，然后当我们的再次调用 mock 对象的该方法时，之前已经记录的方法行为将被再次回放，该方法触发拦截器重新调用并且返回我们在 thenReturn 方法指定的返回值。以下是 Mockito.when 方法的源码： 该方法里面直接使用了 MockitoCore.when 方法，继续跟进，该方法源码如下： 仔细观察可以发现，在源码中并没有用到参数 methodCall，而是从 MockingProgress 实例中获取 OngoingStubbing 对象，这个 OngoingStubbing 对象就是前文所提到的上下文对象。个人感觉是 Mockito 为了提供简洁易用的 API 然后才制造了 when 方法调用的这种“幻象”，简而言之，Mockito 框架通过方法拦截在上下文中存储和检索方法调用详细信息来工作的。 如何实现一个微型的 Mock 框架知道了 Mockito 的运行原理之后，接下来看看要如何自己去实现一个类似功能的 mock 框架出来，看到方法拦截这里我相信你已经知道了，其实这就是 AOP 啊，但是通过阅读其源码发现 Mockito 其实并没有使用我们熟悉的 Spring AOP 或者 AspectJ 做的方法拦截，而是通过运行时增强库 Byte Buddy 和反射工具库 Objenesis 生成和初始化 mock 对象的。现在，通过以上分析和源码阅读可以定义出一个简单版本的 mock 框架了，将自定义的 mock 框架命名为 imock。这里有一点需要注意的是，Mockito 有一个好处是，它不需要进行初始化，可以直接通过其提供的静态方法来立即使用它。在这里我们也使用相同名称的静态方法，通过 Mockito 源码： 很容易看出 Mockito 类最终都是委托给 MockitoCore 去实现的功能，而其只提供了一些面向使用者易用的静态方法，在这里我们也定义一个这样的代理对象 IMockCore，这个类中需要一个创建 mock 对象的方法 mock 和一个给方法设定返回值的 thenReturn 方法，同时该类中持有一个方法调用详情 InvocationDetail 集合列表，这个类是用来记录方法调用详细信息的，然后 when 方法仅返回列表中的最后一个 InvocationDetail，这里列表可以直接使用 Java 中常用的 ArrayList 即可，这里的 ArrayList 集合列表就实现了 Mockito 中的 OngoingStubbing 的功能。根据方法的三要素方法名、方法参数和方法返回值很容易就可以写出 InvocationDetail 类的代码，为了对方法在不同类有同名的情况区分，还需要加上类全称字段和重写该类的 equals 和 hashCode 方法（判断是否在调用方法集合列表时需要根据该方法判断），代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class InvocationDetail&lt;T&gt; &#123; private String attachedClassName; private String methodName; private Object[] arguments; private T result; public InvocationDetail(String attachedClassName, String methodName, Object[] arguments) &#123; this.attachedClassName = attachedClassName; this.methodName = methodName; this.arguments = arguments; &#125; public void thenReturn(T t) &#123; this.result = t; &#125; public T getResult() &#123; return result; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; InvocationDetail&lt;?&gt; behaviour = (InvocationDetail&lt;?&gt;) o; return Objects.equals(attachedClassName, behaviour.attachedClassName) &amp;&amp; Objects.equals(methodName, behaviour.methodName) &amp;&amp; Arrays.equals(arguments, behaviour.arguments); &#125; @Override public int hashCode() &#123; int result = Objects.hash(attachedClassName, methodName); result = 31 * result + Arrays.hashCode(arguments); return result; &#125;&#125; 接下来就是如何去创建我们的 mock 对象了，在这里我们也使用 Byte Buddy 和 Objenesis 库来创建 mock 对象，IMockCreator 接口定义如下： 123456789101112/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public interface IMockCreator &#123; &lt;T&gt; T createMock(Class&lt;T&gt; mockTargetClass, List&lt;InvocationDetail&gt; behaviorList);&#125; 实现类 ByteBuddyIMockCreator 使用 Byte Buddy 库在运行时动态生成 mock 类对象代码然后使用 Objenesis 去实例化该对象。代码如下： 123456789101112131415161718192021222324252627282930/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class ByteBuddyIMockCreator implements IMockCreator &#123; private final ObjenesisStd objenesisStd = new ObjenesisStd(); @Override public &lt;T&gt; T createMock(Class&lt;T&gt; mockTargetClass, List&lt;InvocationDetail&gt; behaviorList) &#123; ByteBuddy byteBuddy = new ByteBuddy(); Class&lt;? extends T&gt; classWithInterceptor = byteBuddy.subclass(mockTargetClass) .method(ElementMatchers.any()) .intercept(MethodDelegation.to(InterceptorDelegate.class)) .defineField("interceptor", IMockInterceptor.class, Modifier.PRIVATE) .implement(IMockIntercepable.class) .intercept(FieldAccessor.ofBeanProperty()) .make() .load(getClass().getClassLoader(), Default.WRAPPER).getLoaded(); T mockTargetInstance = objenesisStd.newInstance(classWithInterceptor); ((IMockIntercepable) mockTargetInstance).setInterceptor(new IMockInterceptor(behaviorList)); return mockTargetInstance; &#125;&#125; 基于以上分析我们可以很容易写出创建 mock 对象的 IMockCore 类的代码如下： 123456789101112131415161718192021222324/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class IMockCore &#123; private final List&lt;InvocationDetail&gt; invocationDetailList = new ArrayList&lt;&gt;(8); private final IMockCreator mockCreator = new ByteBuddyIMockCreator(); public &lt;T&gt; T mock(Class&lt;T&gt; mockTargetClass) &#123; T result = mockCreator.createMock(mockTargetClass, invocationDetailList); return result; &#125; @SuppressWarnings("unchecked") public &lt;T&gt; InvocationDetail&lt;T&gt; when(T methodCall) &#123; int currentSize = invocationDetailList.size(); return (InvocationDetail&lt;T&gt;) invocationDetailList.get(currentSize - 1); &#125;&#125; 提供给使用者的类 IMock 只是对 IMockCore 进行的简单调用而已，代码如下： 12345678910111213141516171819/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class IMock &#123; private static final IMockCore IMOCK_CORE = new IMockCore(); public static &lt;T&gt; T mock(Class&lt;T&gt; clazz) &#123; return IMOCK_CORE.mock(clazz); &#125; public static &lt;T&gt; InvocationDetail when(T methodCall) &#123; return IMOCK_CORE.when(methodCall); &#125;&#125; 通过以上步骤，我们就已经实现了一个微型的 mock 框架了，下面来个实际例子测试一下，首先创建一个 Target 对象： 1234567891011121314/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class Target &#123; public String foo(String name) &#123; return String.format("Hello, %s", name); &#125;&#125; 然后编写其对应的测试类 IMockTest 类如下： 12345678910111213141516171819202122/** * @author mghio * @date: 2020-05-30 * @version: 1.0 * @description: * @since JDK 1.8 */public class IMockTest &#123; @Test public void test_foo_method() &#123; String exceptedResult = "Mocked mghio"; Target mockTarget = IMock.mock(Target.class); IMock.when(mockTarget.foo("mghio")).thenReturn(exceptedResult); String actualResult = mockTarget.foo("mghio"); assertEquals(exceptedResult, actualResult); &#125;&#125; 以上测试的可以正常运行，达到了和 Mockito 测试框架一样的效果，运行结果如下： 上面只是列出了一些关键类的源码，自定义 IMock 框架的所有代码已上传至 Github 仓库 imock，感兴趣的朋友可以去看看。 总结本文只是介绍了 Mockito 的一些使用方法，这只是该框架提供的最基础功能，更多高级的用法可以去官网阅读相关的文档，然后介绍了框架中 when(...).thenReturn(...) 定义行为方法的实现方式并按照其源码思路实现了一个相同功能的简易版的 imock 。虽然进行单元测试有很多优点，但是也不可盲目的进行单元测试，在大部分情况下只要做好对项目中逻辑比较复杂、不容易理解的核心业务模块以及项目中公共依赖的模块的单元测试就可以了。 参考文章 MockitoObjenesisByte Buddy]]></content>
      <categories>
        <category>Java</category>
        <category>unit test</category>
        <category>mockito</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>test</tag>
        <tag>mockito</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在一台计算机上安装多个 JDK 版本]]></title>
    <url>%2Fpost%2F51e5bd99.html</url>
    <content type="text"><![CDATA[前言对于使用 Java 语言开发的朋友可能会遇到这种情况，有时想学习和探索 Java 的最新版本提供的一些新特性，比如 Java 11，但你无法将其安装在自己的计算机上，因为你的团队正在使用比这个旧的版本（我们目前用的 Java 8)，你并不想影响目前的项目。或者你目前是在维护和开发多个项目，而这些不同的项目使用的 JDK 版本不一样，比如那些维护的老项目使用的是 JDK 8，而新项目你打算使用比较新的版本 JDK 11，以上这些情况都需要在计算机上安装多个 JDK，并且应该能够在多个版本之间方便快速的切换。今天要介绍的主角 SDKMAN 可以很好的解决上面这种问题，它提供了在同一台计算机上对多个版本的开发工具包管理。需要注意的是：这个工具只适用于类 Unix 的系统（比如：Mac OSX、Linux、Cygwin、Solaris、FreeBSD 等）。 SDKMan 简介直接引用 SDKMan 官网上的介绍如下： SDKMAN! is a tool for managing parallel versions of multiple Software Development Kits on most Unix based systems. It provides a convenient Command Line Interface (CLI) and API for installing, switching, removing and listing Candidates. 简单来说就是其提供了管理多个版本开发工具包的能力，同时也提供了一些命令行接口让我们方便安装、版本切换、版本移除和显示版本列表。关于 SDKMan 还有几个要点如下： SDKMan 是由开源社区开发的，免费使用，。 SDKMan 是用 bash 编写的，它只需要您的系统上安装了 curl 和 zip / unzip 命令即可。 SDKMan 可以为 JVM 安装大约 29 个软件开发包，比如 Java、Groovy、Scala、Kotlin、Gradle、Maven、Spark、Spring Boot 等。 SDKMan 可以自动处理帮我们配置 *_HOME(e.g.:JAVA_HOME) 和 PATH 环境变量，因此我们不需要担心切换版本后这些环境变量的设置。 安装 SDKManSDKMan 可以运行在任何类 Unix 系统上，我们只需要在命令行输入以下命令即可安装： 1curl -s "https://get.sdkman.io" | bash 然后执行以下命令，加载文件 sdkman-init.sh 到当前环境，执行完该命令之后我们可以通过 sdk version 来验证是否安装成功，同时还可以通过 sdk help 命令显示有关 sdk 命令用法和帮助（PS: 对于使用 Windows 环境的朋友可以安装 Cygwin 或 Git Bash 运行以上命令）。 1source "$HOME/.sdkman/bin/sdkman-init.sh" 使用 SDKMan 安装 JDK前面已经介绍过，SDKMan 支持多达大约 29 个软件开发包管理，我们也可以使用 sdk list 命令来查看支持的完整列表，本文主要介绍 Java 相关的内容，可以通过命令 sdk list java 来查看支持安装的 Java 版本。 使用以下命令安装 Java 11 ： 1sdk install java 11.0.7.hs-adpt 该命令会花费一些时间，因为它会在我们的计算机上下载对应版本的 JDK，执行完成之后 SDKman 会自动给我们配置好 JAVA_HOME 和 PATH 等环境变量，可以通过 Java -version 命令验证。 现在，如果检查 Java 版本和 JAVA_HOME 环境变量，可以看到当前 Java 的版本已更新为 11.0.7。 可以使用以下命令来设置默认使用的 JDK 版本。 1sdk default java 11.0.7.hs-adpt 将 SDKMan 指向已安装 Java 版本如果在你安装 SDKMan 之前本地电脑已经安装了 JDK 版本，默认是无法识别到的，那么你需要进行以下配置才能让 SDKMan 识别已安装的版本，首先，第一步你要先找到你的 Java 安装目录，我本地 Mac 的安装目录是 /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk，然后使用命令 ln -s 来为 Java 安装目录建立符号链接。 多个 JDK 版本切换示例SDKMan 提供了命令 sdk use java &lt;version_want_to_use&gt; 在多个版本之间进行切换，使用 sdk use java jdk1.8.0_181.jdk 命令来使用之前本地安装的 Java 8。 使用命令 sdk use java 11.0.7.hs-adpt 来设置版本为 Java 11。 需要注意的是：使用命令 sdk use java &lt;version&gt; 只在当前会话有效，如果你关闭终端并再次打开它，则将使用以前安装的版本，不会改变你本地使用的版本，此时可以使用 sdk default java &lt;version&gt; 来设置永久生效。 如何卸载指定的 JDK 版本如果你想要卸载任何已安装的 JDK 版本，比如： 11.0.7.hs-adpt，可以使用以下命令卸载： 1sdk uninstall java 11.0.7.hs-adpt 此时，如果你想再次安装之前通过 SDKMan 卸载的版本，此时不会再次重新下载，会提示 Found a previously downloaded java 11.0.7.hs-adpt archive. Not downloading it again...，因为之前删除操作并没有真正的从你计算机上删除源压缩包文件。 IntelliJ IDEA 使用 SDMan 安装 JDKSDKMan 所有安装的 JDK 都放在目录 .sdkman/candidates/java/，你可以在你当前用户的 home 文件夹下面看到该文件夹（注意是隐藏文件夹）。 在 IntelliJ IDEA 中打开任何一个 Java 项目后，您可以按 Command + : 快捷键打开项目结构窗口，在 Project SDK 模块选择新建一个 JDK 后输入你需要的 JDK 版本在 SDKMan 中的路径即可。 因为 .sdkman 是隐藏文件夹不太方便查找，可以使用以下命令创建一个非隐藏文件夹指向它。 1ln -s ~/.sdkman ~/sdkman]]></content>
      <categories>
        <category>JDK</category>
        <category>Java</category>
        <category>版本管理工具</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>版本管理工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看了你就懂的同步与异步、阻塞与非阻塞]]></title>
    <url>%2Fpost%2F34755d6c.html</url>
    <content type="text"><![CDATA[前言在网上看到过很多讲有关同步与异步、阻塞与非阻塞的文章，但是很多都是抛出一堆相关定义，看了之后还是云里雾里的，对这几个概念还是不能很好的去区分它们。本文通过通俗易懂的语言和相关例子让你深入理解其本质。 同步与异步首先我们要明确的是，同步和异步都是针对两个或者两个以上的事物来说的。比如当我们在网上购物看中一件物品，然后去浏览该商品详情的时候，首先页面会先发送一个请求，后台服务器查询对应商品的相关数据，然后前端详情页面才根据返回数据展示该商品的详细信息。而此时你的网速比较差，一个详情页面等了将近一分钟才全部展示完成，这时候你问这个请求是同步还是异步？答案显然是同步请求，它给我们最直观的表现形式就是页面一直显示在加载中，商品的详情页面渲染必须要等待后台服务器返回商品详情数据后才能进行。也就是说下一个操作必须要等待上一个操作完成才能进行，它依赖于上一个操作的返回结果。 你可能会问，在同步的情况下，当一个事物正在进行操作的时候，其它的事物此时在干嘛呢？这个实际上并没有明确的规定，其实同步更多的是关注事物一个一个的串行执行的过程，保证不会交叉执行，至于某个时刻处于什么状态并不关心。这在计算机中大部分时候其它事物都是处于一个等待的状态，而我们人则要灵活得多，在我们日常生活中常用的同步手段就是排队，比如我们上下班坐地铁进行安检的时候，需要依次排队安检进站乘车，但是你在排队的过程是在看手机、聊天还是什么也不做都可以，安检人员并不会在意你在做什么，这种就是由于安检资源有限导致的同步。 对于同步这里有两个点需要注意，一是同步的范围，有时候并不需要全局的大范围的去同步，只需要在特定的操作同步即可，这样可以提升执行效率，比如 Java 语言中的同步方法和同步代码块。另一个是同步的粒度，并不是在一些大的操作粒度上才需要同步操作，小的粒度操作也需要同步操作，只是有的小粒度操作天然就已经是同步操作，并不需要我们人为的去添加同步操作控制。比如 Java 语言中的同步都是针对有两个或者两个以上线程的程序来说的，因为单线程的程序里它天然就是同步的。而异步则完全相反，在异步情况下多个事务可以同时进行，互不影响，你进行你的，我进行我的，谁都不用关心谁。总的来说就是: 同步 两个事物相互依赖，并且一个事物必须以依赖于另一事物的执行结果。比如在事物 A-&gt;B 事件模型中，你需要先完成事物 A 才能执行事物 B。也就是说，同步调用在被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。 异步 两个事物完全独立，一个事物的执行不需要等待另外一个事物的执行。也就是说，异步调用可以返回结果不需要等待结果返回，当结果返回的时候通过回调函数或者其他方式带着调用结果再做相关事情。 可以看出同步与异步是从行为角度描述事物的，你品，你细品。（PS：这里的多个事务可以指代不同的操作、不同的方法或者不同的代码语句等等） 阻塞与非阻塞所谓阻塞，简单来说就是发出一个请求不能立刻返回响应，要等所有的逻辑全处理完才能返回响应。非阻塞反之，发出一个请求立刻返回应答，不用等处理完所有逻辑。阻塞与非阻塞指的是单个线程内遇到同步等待时，是否在原地不做任何操作。堵车就是阻塞与非阻塞最好的例子，在一线城市生活过的朋友应该都有体会，在交通正常的时候汽车可以正常通行，就是非阻塞，上下班高峰的时候经常发生堵车，交通正常的时候半个小时车程，高峰期可能需要二、三个小时才能到。。。而且一旦发生交通堵塞，所有马路上的车子都一动不动，只能在车子里等待，就是阻塞，当然大多数人不会选择干等，他们会玩手机或者和朋友聊天等等，同样的在计算机里，阻塞就意味着停止执行停下来等待，非阻塞表明操作可以继续向下执行，但是在发生阻塞的时候计算机可就没有像人这么灵活了，通常计算机的处理方式就是挂起当前线程，然后干等着，阻塞结束后才继续执行该线程。可以看出阻塞和非阻塞描述的当前事物的状态（等待调用结果时的状态）。 结合前面介绍的同步与异步，两两组合就会有四种情况，分别是同步阻塞、同步非阻塞、异步阻塞和异步非阻塞。下面通过车道的例子来形象的解释这几种状态： 同步阻塞 只有一个车道，不能超车，所有车子依次行使，一次只能通过一辆车，尴尬的是这个车道还堵车了。 同步非阻塞 只有一个车道，不能超车，所有车子依次行使，一次只能通过一辆车，不过比较幸运这个车道没有堵车，可以正常通行。 异步阻塞 有两个或两个以上车道，每条马路都可以通行，不同车道上的车子可以并行行使，尴尬的是所有的车道都堵车了。 异步非阻塞 有两个或两个以上车道，每条马路都可以通行，不同车道上的车子可以并行行使，不过比较幸运的是没有一个车道堵车，都可以正常通行。 对应到我们计算机里也是一样的，同步阻塞相当于只有一个线程，而且该线程处于阻塞（Blocked）状态，同步非阻塞相当于只有一个线程，而且该线程处于运行（Running）状态。异步阻塞相当于有多个线程，而且所有线程都处于阻塞（Blocked）状态，异步非阻塞相当于有多个线程，而且所有线程都在正常运行。 总结很多程序思想都来源于生活，需要我们自己去寻找身边的场景多类比思考、总结归纳，这样才会理解得更深刻。]]></content>
      <categories>
        <category>Java</category>
        <category>IO模型</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IO模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在亿级数据中判断一个元素是否存在？]]></title>
    <url>%2Fpost%2Ffe76043.html</url>
    <content type="text"><![CDATA[前言在日常工作中，经常要判断一个元素是否在一个集合中。假设你要向浏览器添加一项功能，该功能可以通知用户输入的网址是否是恶意网址，此时你手上有大约 1000 万个恶意 URL 的数据集，你该如何实现该功能。按我之前的思维，要判断一个元素在不在当前的数据集中，首先想到的就是使用 hash table，通过哈希函数运行所有的恶意网址以获取其哈希值，然后创建出一个哈希表（数组）。这个方案有个明显的缺点，就是需要存储原始元素本身，内存占用大，而我们其实主要是关注 当前输入的网址在不在我们的恶意 URL 数据集中，也就是之前的恶意 URL 数据集的具体值是什么并不重要，通过吴军老师的《数学之美》了解到，对于这种场景大数据领域有个用于在海量数据情况下判断某个元素是否已经存在的算法很适合，关键的一点是该算法并不存储元素本身，这个算法就是 — 布隆过滤器(Bloom filter)。 原理布隆过滤器是由巴顿.布隆于一九七零年提出的，在 维基百科 中的描述如下： A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. 布隆过滤器是一个数据结构，它可以用来判断某个元素是否在集合内，具有运行快速，内存占用小的特点，它由一个很长的二进制向量和一系列随机映射函数组成。而高效插入和查询的代价就是，它是一个基于概率的数据结构，只能告诉我们一个元素绝对不在集合内，布隆过滤器的好处在于快速，省空间，但是有一定的误判率。布隆过滤器的基础数据结构是一个比特向量，假设有一个长度为 16 的比特向量，下面我们通过一个简单的示例来看看其工作原理，： 上图比特向量中的每一个空格表示一个比特, 空格下面的数字表示当前位置的索引。只需要简单的对输入进行多次哈希操作，并把对应于其结果的比特置为 1，就完成了向 Bloom filter 添加一个元素的操作。下图表示向布隆过滤器中添加元素 https://www.mghio.cn 和 https://www.abc.com 的过程，它使用了 func1 和 func2 两个简单的哈希函数。 当我们往集合里添加一个元素的时候, 可以检查该元素在应用对应哈希函数后的哈希值对比特向量的长度取余后的位置是否为 1，图中用 1 表示最新添加的元素对应位置。然后当我们要判断添加元素是否存在集合中的话，只需要简单的通过对该元素应用同样的哈希函数，然后看比特向量里对应的位置是否为 1 的方式来判断一个元素是否在集合里。如果不是，则该元素一定不再集合中，但是需要注意的是，如果是，你只知道元素可能在里面, 因为这些对应位置有可能恰巧是由其它元素或者其它元素的组合所引起的。以上就是布隆过滤器的实现原理。 如何自己实现布隆过滤器的思想比较简单，首先在构造方法中初始化了一个指定长度的 int 数组，在添加元素的时候通过哈希函数 func1 和 func2 计算出对应的哈希值，对数组长度取余后将对应位置置为 1，判断元素是否存在于集合中时，同样也是对元素用同样的哈希函数进行两次计算，取到对应位置的哈希值，只要存在位置的值为 0，则认为元素不存在。下面使用 Java 语言实现了上面示例中简单版的布隆过滤器： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class BloomFilter &#123; /** * 数组长度 */ private int size; /** * 数组 */ private int[] array; public BloomFilter(int size) &#123; this.size = size; this.array = new int[size]; &#125; /** * 添加数据 */ public void add(String item) &#123; int firstIndex = func1(item); int secondIndex = func2(item); array[firstIndex % size] = 1; array[secondIndex % size] = 1; &#125; /** * 判断数据 item 是否存在集合中 */ public boolean contains(String item) &#123; int firstIndex = func1(item); int secondIndex = func2(item); int firstValue = array[firstIndex % size]; int secondValue = array[secondIndex % size]; return firstValue != 0 &amp;&amp; secondValue != 0; &#125; /** * hash 算法 func1 */ private int func1(String key) &#123; int hash = 7; hash += 61 * hash + key.hashCode(); hash ^= hash &gt;&gt; 15; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 11; return Math.abs(hash); &#125; /** * hash 算法 func2 */ private int func2(String key) &#123; int hash = 7; for (int i = 0, len = key.length(); i &lt; len; i++) &#123; hash += key.charAt(i); hash += (hash &lt;&lt; 7); hash ^= (hash &gt;&gt; 17); hash += (hash &lt;&lt; 5); hash ^= (hash &gt;&gt; 13); &#125; return Math.abs(hash); &#125;&#125; 自己实现虽然简单但是有一个问题就是检测的误判率比较高，通过其原理可以知道，可我们可以提高数组长度以及 hash 计算次数来降低误报率，但是相应的 CPU、内存的消耗也会相应的提高，这需要我们根据自己的业务需要去权衡选择。 扎心一问哈希函数该如何设计？布隆过滤器里的哈希函数最理想的情况就是需要尽量的彼此独立且均匀分布，同时，它们也需要尽可能的快 (虽然 sha1 之类的加密哈希算法被广泛应用，但是在这一点上考虑并不是一个很好的选择)。 布隆过滤器应该设计为多大？个人认为布隆过滤器的一个比较好特性就是我们可以修改过滤器的错误率。一个大的过滤器会拥有比一个小的过滤器更低的错误率。假设在布隆过滤器里面有 k 个哈希函数，m 个比特位（也就是位数组长度），以及 n 个已插入元素，错误率会近似于 (1-ekn/m)k，所以你只需要先确定可能插入的数据集的容量大小 n，然后再调整 k 和 m 来为你的应用配置过滤器。 应该使用多少个哈希函数?显然，布隆过滤器使用的哈希函数越多其运行速度就会越慢，但是如果哈希函数过少，又会遇到误判率高的问题。所以这个问题上需要认真考虑，在创建一个布隆过滤器的时候需要确定哈希函数的个数，也就是说你需要提前预估集合中元素的变动范围。然而你这样做了之后，你依然需要确定比特位个数和哈希函数的个数的值。看起来这似乎这是一个十分困难的优化问题，但幸运的是，对于给定的 m（比特位个数）和 n（集合元素个数），最优的 k（哈希函数个数）值为: (m/n)ln(2)（PS：需要了解具体的推导过程的朋友可以参考维基百科）。也就是我们可以通过以下步骤来确定布隆过滤器的哈希函数个数： 确定 n（集合元素个数）的变动范围。 选定 m（比特位个数）的值。 计算 k（哈希函数个数）的最优值 对于给定的 n、m 和 k 计算错误率，如果这个错误率不能接受的话，可以继续回到第二步。 布隆过滤器的时间复杂度和空间复杂度?对于一个 m（比特位个数）和 k（哈希函数个数）值确定的布隆过滤器，添加和判断操作的时间复杂度都是 O(k)，这意味着每次你想要插入一个元素或者查询一个元素是否在集合中，只需要使用 k 个哈希函数对该元素求值，然后将对应的比特位标记或者检查对应的比特位即可。 总结布隆过滤器的实际应用很广泛，特别是那些要在大量数据中判断一个元素是否存在的场景。可以看到，布隆过滤器的算法原理比较简单，但要实际做一个生产级别的布隆过滤器还是很复杂的，谷歌的开源库 Guava 的 BloomFilter 提供了 Java 版的实现，用法很简单。最后留给大家一个问题：布隆过滤器支持元素删除吗？]]></content>
      <categories>
        <category>Java</category>
        <category>Bloom filter</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Bloom filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串操作 — Google Guava]]></title>
    <url>%2Fpost%2F3ae0ff4e.html</url>
    <content type="text"><![CDATA[前言Java 里字符串表示字符的不可变序列，创建后就不能更改。在我们日常的工作中，字符串的使用非常频繁，熟练的对其操作可以极大的提升我们的工作效率，今天要介绍的主角是 Google 开源的一个核心 Java 库 Guava，它提供了集合类型、不可变的集合、并发、I / O、缓存、字符串等许多实用功能。在本文中，我们将学习使用 Guava 中的 Strings 和 Splitter 字符串操作工具类。 如何使用Google Guava 会同步到 Maven Central 中，所以，如果你是 Maven 项目的话只需要在 pom.xml 文件中引入如下依赖即可： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;28.2-jre&lt;/version&gt;&lt;/dependency&gt; 对于 Gradle 项目在 build.gradle 中引入如下依赖即可： 1compile group: 'com.google.guava', name: 'guava', version: '28.2-jre' PS：28.2-jre 是编写本文时的最新版本，你可以从 Maven Central 中查看当前的最新版本。 为什么需要引入类库Google Guava 提供了很多实用的静态方法，这些可以解决开发人员在开发中所要完成的一些重复任务。当然，这个工作我们也可以自己做，但是引入类库它会降低错误发生的可能性，毕竟这些类库都是已经经过多年的生产验证。比如类库中 Strings 提供的一个方法 commonPrefix，它接受两个字符串并返回两个字符串之间的公共前缀（eg: abcd 和 abef 返回 ab）。你可以在脑子里想象一下在应用程序代码中面临这样的要求时，自己要如何编写代码来完成该操作，要自己实现这个功能，还是需要花费一些时间的，同时还需要考虑到各种边界异常情况。这就是类库提供给我们的最大价值之一，所以当我们需要的某种功能可以作为一种工具方法使用时，首先应该去寻找一些已存在的类库并去熟练使用的它们，而不是自己去实现。总结起来使用类库有如下几个原因： Google Guava 类库有人已经对其进行了彻底的测试，bug 出现的概率会比我们自己实现的小很多。 作为 Google Guava 的一部分，已经存在各种测试用例，用于测试实用程序的实现。如果我们自己编写代码实现的话，可能还要去编写和维护它们的测试。 StringsGoogle Guava 有许多实用的工具类和方法，不可能在一篇文章中都有介绍完，在本文中，只会介绍和字符串操作相关的两个工具类。首先第一个是 Strings 类，该类提供了操作 String 和 CharSequence 的实用方法。 nullToEmpty、emptyToNull 和 isNullOrEmptynullToEmpty 方法功能为：如果传入的字符串为 null，则返回一个空字符串 &quot;&quot;，否则按原样返回传入的字符串。 1234567@Testpublic void testStringsOfNullToEmpty() &#123; System.out.println(Strings.nullToEmpty("mghio")); // mghio System.out.println(Strings.nullToEmpty("")); // "" System.out.println(Strings.nullToEmpty(null)); // "" System.out.println(Strings.nullToEmpty(null).isEmpty()); // true&#125; emptyToNull 方法功能为：它与 nullToEmpty 相反，如果传入了空字符串，则返回 null，否则返回原始字符串。 123456@Testpublic void testStringsOfEmptyToNull() &#123; System.out.println(Strings.emptyToNull("mghio")); // mghio System.out.println(Strings.emptyToNull(null)); // null System.out.println(Strings.emptyToNull("")); // null&#125; isNullOrEmpty 方法功能为：如果传入的字符串为 null 或为空，则返回 true，否则返回 false。 123456@Testpublic void testStringsOfIsNullOrEmpty() &#123; System.out.println(Strings.isNullOrEmpty("mghio")); // false System.out.println(Strings.isNullOrEmpty("")); // true System.out.println(Strings.isNullOrEmpty(null)); // true&#125; padStart 和 padEnd这两个方法有三个参数，分别为：输入字符串、最小长度和要填充的字符，它将字符根据需要多次插入到输入字符串的开头，以使输入字符串的长度等于传入的最小长度。 12345@Testpublic void testStringsOfPadStart() &#123; System.out.println(Strings.padStart("9527", 6, '0')); // 009527 System.out.println(Strings.padStart("123456", 6, '0')); // 123456&#125; 在第一行代码中，将两次填充 0 以使最终的字符串长度等于我们传入的最小长度（6）。在第二行代码中，输入字符串长度本身具有所需的最小长度，因此未进行填充padEnd 方法和上面这个方法类似，只不过它是在字符的末尾而不是在开始处进行填充。 12345@Testpublic void testStringsOfPadEnd() &#123; System.out.println(Strings.padEnd("9527", 6, '0')); // 952700 System.out.println(Strings.padEnd("123456", 6, '0')); // 123456&#125; repeat该方法需要传入一个字符串和一个重复次数 count，它返回一个由原始字符串组成的字符串，该字符串重复了 count 次。 1234@Testpublic void testStringsRepeat() &#123; System.out.println(Strings.repeat("mghio", 3)); // mghiomghiomghio&#125; commonPrefix 和 commonSuffixcommonPrefix 方法返回传入的两个字符串之间最大的公共前缀，而 commonSuffix 方法返回传入两个字符串之间最大的公共后缀。 12345@Testpublic void testStrings() &#123; System.out.println(Strings.commonPrefix("mghio9527", "mghio666")); // mghio System.out.println(Strings.commonSuffix("iammghio", "nicemghio")); // mghio&#125; SplitterSplitter 类提供的功能正如其名（PS:一个好的命名很重要），它用于根据提供的分割符将字符串拆分为多个子字符串。我们可以通过传入一个分割符来获一个 Splitter 的实例，有了分割器之后，我们可以根据分割器的配置方式对字符串进行分割。 12345@Testpublic void testSplitterOfSplit() &#123; Iterable&lt;String&gt; result = Splitter.on(",").split("m,g,h,i,o"); System.out.println(result); // [m, g, h, i, o]&#125; 上面的例子中使用逗号进行分割，因此，它将传入的字符串 m,g,h,i,o 拆分为一个 Iterable &lt;String&gt;，然后当我们对其进行迭代遍历时会输出 [m, g, h, i, o]。 获取 Splitter 实例on 和 onPattern现在，我们来看看获得一个分割器 Splitter 的各种方法。on 方法有各种不同的重载版本，它们以字符、字符串或正则表达式作为分隔符，我们还可以将 Pattern 实例作为字符串传递给 onPattern 方法中。 123456789@Testpublic void testSplitterOfOn() &#123; Splitter wordSplitter = Splitter.on(":;"); // 下面这行输出结果 [the, text, is, separated, by, colon, semicolon] System.out.println(wordSplitter.split("the:;text:;is:;separated:;by:;colon:;semicolon")); Splitter patternBasedSplitter = Splitter.on(Pattern.compile("\\s+")); System.out.println(patternBasedSplitter.split("abc dmg hio")); // [abc, dmg, hio] System.out.println(Splitter.onPattern("\\s+").split("www mghio cn")); // [www, mghio, cn]&#125; fixedLengthfixedLength 也是最有用的方法之一，它可以将字符串分成给定长度的相等部分，需要注意的是，最后一个部分可能会小于给定的长度。 123456@Testpublic void testSplitterOfFixedLength() &#123; Splitter fixedLengthSplitter = Splitter.fixedLength(3); System.out.println(fixedLengthSplitter.split("iammghiojava")); // [iam, mgh, ioj, ava] System.out.println(fixedLengthSplitter.split("https://www.mghio.cn")); // [htt, ps:, //w, ww., mgh, io., cn]&#125; Splitter 修饰符方法Splitter 还提供了可以在更改或修改 Splitter 行为的常用方法。 trimResults这个方法可以从生成的分割器的结果字符串中删除前面和末尾的空格。 1234567@Testpublic void testSplitterOfTrimResult() &#123; Splitter commaSplitter = Splitter.on(","); System.out.println(commaSplitter.split("m, g, h, i, o")); // [m, g, h, i, o] Splitter commaSplitterWithTrim = commaSplitter.trimResults(); System.out.println(commaSplitterWithTrim.split("m, g, h, i, o")); // [m, g, h, i, o]&#125; 注意，第一个分割的结果在字符串 g、 h、i、o 之前有一个空格，使用 trimResults 方法后，将去除这些前导空格。 omitEmptyStrings这个方法会从结果中忽略所有空字符串。 1234567@Testpublic void testSplitterOfOmitEmptyStrings() &#123; Splitter commaSplitter = Splitter.on(","); System.out.println(commaSplitter.split("m,,g,h,i,o")); // [m, , g, h, i, o] Splitter commaSplitterWithNoEmptyString = commaSplitter.omitEmptyStrings(); System.out.println(commaSplitterWithNoEmptyString.split("m,,g,h,i,o")); // [m, g, h, i, o]&#125; 上面的 commaSplitterWithNoEmptyString 会从输出中删除空字符串的结果。 limit这个方法返回与原始分割器等效的分割器，但它会在达到指定的输入限制后将停止拆分，将后续剩余结果字符串作为一项输出，也就是说，我们可以通过的传入的参数指定结果中存在的最大项目数。需要注意的是：该方法在省略空字符串时，省略的字符串不计算在内。。 123456@Testpublic void testSplitterOfLimit() &#123; Splitter commaSplitter = Splitter.on(","); Splitter limitingCommaSplitter = commaSplitter.limit(3); System.out.println(limitingCommaSplitter.split("i,m,g,h,i,o")); // [i, m, g,h,i,o]&#125; 有一点需要注意，Splitter 是不可变的（这一点和 String 类似），因此，调用它的任何修饰符方法都将返回新的 Splitter，并且不会修改原始的 Splitter。 123456789@Testpublic void testSplitterImmutable() &#123; Splitter splitter = Splitter.on('/'); System.out.println("Before: " + splitter); // Before: com.google.common.base.Splitter@33b37288 splitter.trimResults(); // do nothing System.out.println("First: " + splitter); // First: com.google.common.base.Splitter@33b37288 splitter = splitter.trimResults(); // the returned splitter to be assigned System.out.println("Second: " + splitter); // Second: com.google.common.base.Splitter@77a57272&#125; splitToList我们前面已经使用的 split 方法，它返回的是一个 Iterable&lt;String&gt; 对象。而这里的 splitToList 方法返回一个 List&lt;String&gt;。由于分割方法返回的是 Iterable，因此它是惰性的。 123456@Testpublic void testSplitterOfSplitToList() &#123; Splitter commaSplitter = Splitter.on(","); List&lt;String&gt; result = commaSplitter.splitToList("m,g,h,i,o"); System.out.println(result); // [m, g, h, i, o]&#125; MapSplitterMapSplitter 顾名思义就是用来将一个将字符串拆分为 Map 对象的。我们可以使用 withKeyValueSeparator 方法从 Splitter 中获取 MapSplitter 对象，该方法接收一个字符、字符串或者 Splitter 对象作为参数。首先，根据原始的分割器将字符串分割为多个项，然后，使用传给 withKeyValueSeparator 方法的分割符将各个项分为 Map 键-值对。 1234567@Testpublic void testSplitterOfWithKeyValueSeparator() &#123; Splitter commaSplitter = Splitter.on(','); Splitter.MapSplitter keyValueSplitter = commaSplitter.withKeyValueSeparator('='); Map&lt;String, String&gt; map = keyValueSplitter.split("name=mghio,blog=mghio.cn"); System.out.println(map); // &#123;name=mghio, blog=mghio.cn&#125;&#125; 从结果可以看到，它分割为两个 entry （name=mghio 与 blog=mghio.cn）项，还有一个点需要注意的是：如果我们在原始的分割器上指定了任何修改器，则它们仅适用于该分割器，而不适用于 MapSplitter。 1234567@Testpublic void testSplitterOfWithKeyValueSeparatorAndModifiers() &#123; Splitter originalSplitter = Splitter.on(",").trimResults(); Splitter.MapSplitter keyValueSplitter = originalSplitter.withKeyValueSeparator('='); // 输出结果：&#123;name =mghio, blog= mghio.cn&#125; System.out.println(keyValueSplitter.split("name =mghio, blog= mghio.cn")); &#125; 由以上结果可以看出 trimResults 修饰方法仅适用于原始拆分器。因此，blog 开头的空格已被移除（使用 , 分割原始字符串时），但是，mghio.cn 开头的空格不会被移除（使用 = 分割成键值时）。 最后需要注意的是：MapSplitter 类被标记为 @Beta，这意味着类库中与 MapSplitter 相关的类和方法是实验性的，可以更改（以中断的方式），甚至将来版本可能删除。 总结在本文中，介绍了 Google Guava 库以及在项目或应用程序中使用它的好处，如何将其导入到我们的应用程序中使用。然后，介绍了 Guava 库中对字符串操作工具类（Strings 和 Splitter ）的一些基本用法，当然，这只是冰山一角，Guava 库还提供了其它很多有用的基础功能，需要我们自己去查询相关文档学习了解，感兴趣的朋友可以去看看它的实现源码，这个库的代码写得很优雅。 参考 StringsExplained Guava’s Strings Class]]></content>
      <categories>
        <category>Java</category>
        <category>Guava</category>
        <category>String</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何编写优雅的异步代码 — CompletableFuture]]></title>
    <url>%2Fpost%2F7b9ead86.html</url>
    <content type="text"><![CDATA[前言在我们的意识里，同步执行的程序都比较符合人们的思维方式，而异步的东西通常都不好处理。在异步计算的情况下，以回调表示的动作往往会分散在代码中，也可能相互嵌套在内部，如果需要处理其中一个步骤中可能发生的错误时，情况变得更加糟糕。Java 8 引入了很多的新特性，其中就包含了 CompletableFuture 类的引入，这让我们编写清晰可读的异步代码变得更加容易，该类功能非常强大，包含了超过 50 多个方法。。。 什么是 CompletableFutureCompletableFuture 类的设计灵感来自于 Google Guava 的 ListenableFuture 类，它实现了 Future 和 CompletionStage 接口并且新增了许多方法，它支持 lambda，通过回调利用非阻塞方法，提升了异步编程模型。它允许我们通过在与主应用程序线程不同的线程上（也就是异步）运行任务，并向主线程通知任务的进度、完成或失败，来编写非阻塞代码。 为什么要引入 CompletableFutureJava 的 1.5 版本引入了 Future，你可以把它简单的理解为运算结果的占位符，它提供了两个方法来获取运算结果。 get()：调用该方法线程将会无限期等待运算结果。 get(long timeout, TimeUnit unit)：调用该方法线程将仅在指定时间 timeout 内等待结果，如果等待超时就会抛出 TimeoutException 异常。 Future 可以使用 Runnable 或 Callable 实例来完成提交的任务，通过其源码可以看出，它存在如下几个问题： 阻塞 调用 get() 方法会一直阻塞，直到等待直到计算完成，它没有提供任何方法可以在完成时通知，同时也不具有附加回调函数的功能。 链式调用和结果聚合处理 在很多时候我们想链接多个 Future 来完成耗时较长的计算，此时需要合并结果并将结果发送到另一个任务中，该接口很难完成这种处理。 异常处理 Future 没有提供任何异常处理的方式。 以上这些问题在 CompletableFuture 中都已经解决了，接下来让我们看看如何去使用 CompletableFuture。 如何创建 CompletableFuture最简单的创建方式就是调用 CompletableFuture.completedFuture(U value) 方法来获取一个已经完成的 CompletableFuture 对象。 12345678910@Testpublic void testSimpleCompletableFuture() &#123; CompletableFuture&lt;String&gt; completableFuture = CompletableFuture.completedFuture("Hello mghio"); assertTrue(completableFuture.isDone()); try &#123; assertEquals("Hello mghio", completableFuture.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125;&#125; 需要注意的是当我们对不完整的 CompleteableFuture调用 get 方法的话，会由于 Future 未完成，因此 get 调用将永远阻塞，此时可以使用 CompletableFuture.complete 方法手动完成 Future。 任务异步处理当我们想让程序在后台异步执行任务而不关心任务的处理结果时，可以使用 runAsync 方法，该方法接收一个 Runnable 类型的参数返回 CompletableFuture&lt;Void&gt;。 123456789101112@Testpublic void testCompletableFutureRunAsync() &#123; AtomicInteger variable = new AtomicInteger(0); CompletableFuture&lt;Void&gt; runAsync = CompletableFuture.runAsync(() -&gt; process(variable)); runAsync.join(); assertEquals(100, variable.get());&#125;public void process(AtomicInteger variable) &#123; System.out.println(Thread.currentThread() + " Process..."); variable.set(100);&#125; 如果我们想让任务在后台异步执行而且需要获取任务的处理结果时，可以使用 supplyAsync 方法，该方法接收一个 Supplier&lt;T&gt; 类型的参数返回一个 CompletableFuture&lt;T&gt;。 12345678910111213@Testpublic void testCompletableFutureSupplyAsync() &#123; CompletableFuture&lt;String&gt; supplyAsync = CompletableFuture.supplyAsync(this::process); try &#123; assertEquals("Hello mghio", supplyAsync.get()); // Blocking &#125; catch (ExecutionException | InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;public String process() &#123; return "Hello mghio";&#125; 看到这里你可能会有个问题，上面执行 runAsync 和 supplyAsync 任务的线程是从哪里来的、谁创建的呢？实际上它和 Java 8 中的 parallelStream 类似， CompletableFuture 也是从全局 ForkJoinPool.commonPool() 获得的线程中执行这些任务的。同时，上面的两个方法也提供了自定义线程池去执行任务，其实你如果去了解过 CompletableFuture 的源码的话，你会发现其 API 中的所有方法都有个重载的版本，有或没有自定义 Executor 执行器。 1234567891011121314@Testpublic void testCompletableFutureSupplyAsyncWithExecutor() &#123; ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(2); CompletableFuture&lt;String&gt; supplyAsync = CompletableFuture.supplyAsync(this::process, newFixedThreadPool); try &#123; assertEquals("Hello mghio", supplyAsync.get()); // Blocking &#125; catch (ExecutionException | InterruptedException e) &#123; e.printStackTrace(); &#125;&#125;public String process() &#123; return "Hello mghio";&#125; 链式调用和结果聚合处理我们知道 CompletableFuture 的 get() 方法会一直阻塞直到获取到结果，CompletableFuture 提供了 thenApply、thenAccept 和 thenRun 等方法来避免这种情况，而且我们还可以添加任务完成后的回调通知。这几个方法的使用场景如下： thenApply 当我们如果要在从 Future 接收值后任务之前运行自定义的业务代码，然后要为此任务返回一些值时，则可以使用该方法 thenAccept 如果我们希望在从 Future 接收到一些值后执行任务之前运行自定义的业务代码而不关心返回结果值时，则可以使用该方法 thenRun 如果我们想在Future完成后运行自定义的业务代码，并且不想为此返回任何值时，则可以使用该方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Testpublic void testCompletableFutureThenApply() &#123; Integer notificationId = CompletableFuture.supplyAsync(this::thenApplyProcess) .thenApply(this::thenApplyNotify) // Non Blocking .join(); assertEquals(new Integer(1), notificationId);&#125;@Testpublic void testCompletableFutureThenAccept() &#123; CompletableFuture.supplyAsync(this::processVariable) .thenAccept(this::thenAcceptNotify) // Non Blocking .join(); assertEquals(100, variable.get());&#125;@Testpublic void testCompletableFutureThenRun() &#123; CompletableFuture.supplyAsync(this::processVariable) .thenRun(this::thenRunNotify) .join(); assertEquals(100, variable.get());&#125;private String processVariable() &#123; variable.set(100); return "success";&#125;private void thenRunNotify() &#123; System.out.println("thenRun completed notify ....");&#125;private Integer thenApplyNotify(Integer integer) &#123; return integer;&#125;private void thenAcceptNotify(String s) &#123; System.out.println( String.format("Thread %s completed notify ....", Thread.currentThread().getName()));&#125;public Integer thenApplyProcess() &#123; return 1;&#125; 如果有大量的异步计算，那么我们可以继续将值从一个回调传递到另一个回调中去，也就是使用链式调用方式，使用方式很简单。 12345678910111213141516171819202122232425262728@Testpublic void testCompletableFutureThenApplyAccept() &#123; CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .thenAccept((i) -&gt; notifyByEmail()).join();&#125;private void notifyByEmail() &#123; // business code System.out.println("send notify by email ...");&#125;private Double notifyBalance(Double d) &#123; // business code System.out.println(String.format("your balance is $%s", d)); return 9527D;&#125;private Double calculateBalance(Object o) &#123; // business code return 9527D;&#125;private Double findAccountNumber() &#123; // business code return 9527D;&#125; 比较细心的朋友可能注意到在所有前面的几个方法示例中，所有方法都是在同一线程上执行的。如果我们希望这些任务在单独的线程上运行时，那么我们可以使用这些方法对应的异步版本。 123456789101112131415@Testpublic void testCompletableFutureApplyAsync() &#123; ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(2); ScheduledExecutorService newSingleThreadScheduledExecutor = Executors .newSingleThreadScheduledExecutor(); CompletableFuture&lt;Double&gt; completableFuture = CompletableFuture .supplyAsync(this::findAccountNumber, newFixedThreadPool) // 从线程池 newFixedThreadPool 获取线程执行任务 .thenApplyAsync(this::calculateBalance, newSingleThreadScheduledExecutor) .thenApplyAsync(this::notifyBalance); Double balance = completableFuture.join(); assertEquals(9527D, balance);&#125; 执行结果处理thenCompose 方法适合有依赖性的任务处理，比如一个计算账户余额的业务：首先我们要先找到帐号，然后为该帐户计算余额，然后计算完成后再发送通知。所有这些任务都是依赖前一个任务的返回 CompletableFuture 结果，此时我们需要使用 thenCompose 方法，其实有点类似于 Java 8 流的 flatMap 操作。 123456789101112131415161718192021222324252627282930313233343536@Testpublic void testCompletableFutureThenCompose() &#123; Double balance = this.doFindAccountNumber() .thenCompose(this::doCalculateBalance) .thenCompose(this::doSendNotifyBalance).join(); assertEquals(9527D, balance);&#125;private CompletableFuture&lt;Double&gt; doSendNotifyBalance(Double aDouble) &#123; sleepSeconds(2); // business code System.out.println(String.format("%s doSendNotifyBalance ....", Thread.currentThread().getName())); return CompletableFuture.completedFuture(9527D);&#125;private CompletableFuture&lt;Double&gt; doCalculateBalance(Double d) &#123; sleepSeconds(2); // business code System.out.println(String.format("%s doCalculateBalance ....", Thread.currentThread().getName())); return CompletableFuture.completedFuture(9527D);&#125;private CompletableFuture&lt;Double&gt; doFindAccountNumber() &#123; sleepSeconds(2); // business code System.out.println(String.format("%s doFindAccountNumber ....", Thread.currentThread().getName())); return CompletableFuture.completedFuture(9527D);&#125;private void sleepSeconds(int timeout) &#123; try &#123; TimeUnit.SECONDS.sleep(timeout); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; thenCombine 方法主要是用于合并多个独立任务的处理结果。假设我们需要查找一个人的姓名和住址，则可以使用不同的任务来分别获取，然后要获得这个人的完整信息（姓名 + 住址），则需要合并这两种方法的结果，那么我们可以使用 thenCombine 方法。 12345678910111213141516171819202122@Testpublic void testCompletableFutureThenCombine() &#123; CompletableFuture&lt;String&gt; thenCombine = this.findName().thenCombine(this.findAddress(), (name, address) -&gt; name + address); String personInfo = thenCombine.join(); assertEquals("mghio Shanghai, China", personInfo);&#125;private CompletableFuture&lt;String&gt; findAddress() &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleepSeconds(2); // business code return "Shanghai, China"; &#125;);&#125;private CompletableFuture&lt;String&gt; findName() &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleepSeconds(2); // business code return "mghio "; &#125;);&#125; 等待多个任务执行完成在许多情况下，我们希望并行运行多个任务，并在所有任务完成后再进行一些处理。假设我们要查找 3 个不同用户的姓名并将结果合并。此时就可以使用 CompletableFuture 的静态方法 allOf，该方法会等待所有任务完成，需要注意的是该方法它不会返回所有任务的合并结果，因此我们必须手动组合任务的执行结果。 12345678910111213141516171819202122232425@Testpublic void testCompletableFutureAllof() &#123; List&lt;CompletableFuture&lt;String&gt;&gt; list = Lists.newArrayListWithCapacity(4); IntStream.range(0, 3).forEach(num -&gt; list.add(findName(num))); CompletableFuture&lt;Void&gt; allFuture = CompletableFuture .allOf(list.toArray(new CompletableFuture[0])); CompletableFuture&lt;List&lt;String&gt;&gt; allFutureList = allFuture .thenApply(val -&gt; list.stream().map(CompletableFuture::join).collect(Collectors.toList())); CompletableFuture&lt;String&gt; futureHavingAllValues = allFutureList .thenApply(fn -&gt; String.join("", fn)); String result = futureHavingAllValues.join(); assertEquals("mghio0mghio1mghio2", result);&#125;private CompletableFuture&lt;String&gt; findName(int num) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleepSeconds(2); // business code return "mghio" + num; &#125;);&#125; 异常处理在多线程中程序异常其实不太好处理，但是幸运的是在 CompletableFuture 中给我们提供了很方便的异常处理方式，在我们上面的例子代码中： 123456@Testpublic void testCompletableFutureThenCompose() &#123; Double balance = this.doFindAccountNumber() .thenCompose(this::doCalculateBalance) .thenCompose(this::doSendNotifyBalance).join();&#125; 在上面的代码中，三个方法 doFindAccountNumber、doCalculateBalance 和 doSendNotifyBalance 只要任意一个发生异常了，则之后调用的方法将不会运行。CompletableFuture 提供了三种处理异常的方式，分别是 exceptionally、handle 和 whenComplete 方法。第一种方式是使用 exceptionally 方法处理异常，如果前面的方法失败并发生异常，则会调用异常回调。 123456789101112@Testpublic void testCompletableFutureExceptionally() &#123; CompletableFuture&lt;Double&gt; thenApply = CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .exceptionally(ex -&gt; &#123; System.out.println("Exception " + ex.getMessage()); return 0D; &#125;); Double join = thenApply.join(); assertEquals(9527D, join);&#125; 第二种方式是使用 handle 方法处理异常，使用该方式处理异常比上面的 exceptionally 方式更为灵活，我们可以同时获取到异常对象和当前的处理结果。 12345678910111213141516@Testpublic void testCompletableFutureHandle() &#123; CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .handle((ok, ex) -&gt; &#123; System.out.println("最终要运行的代码..."); if (ok != null) &#123; System.out.println("No Exception !!"); &#125; else &#123; System.out.println("Exception " + ex.getMessage()); return -1D; &#125; return ok; &#125;);&#125; 第三种是使用 whenComplete 方法处理异常。 12345678910@Testpublic void testCompletableFutureWhenComplete() &#123; CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .whenComplete((result, ex) -&gt; &#123; System.out.println("result = " + result + ", ex = " + ex); System.out.println("最终要运行的代码..."); &#125;);&#125; 总结在本文中，介绍了 CompletableFuture 类的部分方法和使用方式，这个类的方法很多同时提供的功能也非常强大，在异步编程中使用的比较多，熟悉了基本的使用方法之后要深入了解还是要深入源码分析其实现原理。]]></content>
      <categories>
        <category>Java</category>
        <category>异步</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码中的坏味道]]></title>
    <url>%2Fpost%2Fa38c0645.html</url>
    <content type="text"><![CDATA[前言在日常生活中，当我们买的水果放久了之后会发出一种难闻的气味（“坏味道”），这个时候我们就应该把它扔掉。同样，代码也有“坏味道”，当然确定什么是和不是代码“坏味道”是主观的，它会随语言、开发人员和开发方法的不同而不同。在工作当中，很多时候都是在维护之前的项目和在此基础上增加一些新功能，为了能让项目代码易于理解和维护，要时刻注意代码中的“坏味道”，当发现代码如果有坏味道了，要及时去重构它使其变成优秀的整洁的代码。本文列举代码中一些常见的“坏味道”和相应的重构方案。 过长方法 (Long Method)这种“坏味道”表现为方法代码行数过长，方法行数越长，就越难以理解和维护它。一个比较有用的方案就是当你觉得需要对方法中的内容加注释的时候，你应该将这个代码段作为一个新方法提取出来，哪怕有时候仅仅是一行代码也可以这么做，而且方法的命名要尽量做到见名知意，如果局部变量和参数干扰到方法的提取，则可以使用引入参数对象来进行提取。一般情况下，方法中条件运算符和循环是可以将代码移至单独方法的一个很好的代码段，对于条件运算符，可以尝试分解条件，如果方法出现循环，可以尝试提取方法。 过大的类 (Large Class)这种“坏味道”表现为一个定义了很多的变量、方法代码行数很长的大类，刚开始的时候类通常都不“大”，一段时间之后，随着业务的发展新功能的增加，类通常都会就会变得越来越“大”，通常程序员都喜欢在原有的类上添加属性或者添加新的方法的方式来完成功能的开发，当一个类的代码行数过多或者功能职责过多的时候，就意味着我们应该将其拆分了，常用有以下三种不同的拆分方式： 提取新类，当大类的部分行为可以分解为一​​个单独的组件，则可以使用提取类的方式拆分。 提取子类，当大类的部分行为可以以不同的方式实现或在极少数情况下使用，则可以使用提取子类方式拆分。 提取接口，当有必要列出客户端可以使用的操作和行为的列表的时候，则可以提取接口的方式拆分。 通过重构大类，可以使开发人员无需记住一个类的大量属性，在许多情况下，将大类分成多个部分可以避免代码和功能的重复。 过长参数列表 (Long Parameter List)这种“坏味道”表现为一个方法超过三个以上的参数，当一个方法合并了几个算法之后就会可能出现过多参数的情况，这些参数用来控制方法将要运行哪种算法以及如何运行的。长参数列表也可能是由于我们将类的对象创建过程拆分产生的，想象这么一个场景，当我们把用于创建方法所需对象的代码片段从方法内部移至用于调用方法的代码，然后创建的对象作为参数传入方法，这样，原始类就不再了解对象之间的关系，依赖性降低了。当有多个这种对象需要创建之后，每个对象将需要自己的参数，这意味着参数列表会更长。随着时间的流逝，我们就会越来越难于理解这种方法的长参数列表的具体含义了，清除这种“坏味道”的方式就是将方法的参数列表封装成一个对象的属性。通过重构之后，可以使代码的可读性更高，代码更简短，同时可能还会让你看到以前未被注意的重复代码。 过多注释 (Too Many Comments)这种“坏味道”表现为一种方法充满解释性的注释，当开发者意识到自己的代码不直观或不明显时一般都会给代码加上相应的注释。写代码注释的意图通常都是好的，是为了可以有更好的可读性让后面易于维护，在这种情况下，代码注释就会掩盖了可以改进的可疑代码的“坏味道”，好的方法名或者类名就是最好的注释。 The best comment is a good name for a method or class. 当我们遇到没有注释就无法理解代码片段时，首先应该尝试以无需注释的方式更改代码结构，解决过多注释通常有以下几种方式： 提取变量，当如果要使用注释来解释复杂的表达式的时候，则可以使用“提取变量”的方式将表达式拆分为可理解的子表达式。 提取方法，当如果注释解释了一段代码片段，则可以通过提取方法的方式来将这一部分变成一个单独的方法，这个时候往往方法的名称就是注释的内容。 通过提取变量或者提取方法的方式可以使代码变得更加直观和明显。 Switch 滥用（Switch Abuse）这种“坏味道”表现为代码中存在一个复杂的 switch 运算符，通常，if 条件语句的代码可以分散在程序中的不同位置，当需要添加新条件后，就必须找到所有开关代码并进行修改。根据经验，当看到 switch 时，你第一时间应该想到要用多态性去重构代码。如果 switch 是基于类型判断的，可以使用“用子类替换”或“用状态/策略替换”。但是当运算符中没有太多条件，并且它们都使用不同的参数调用相同的方法，那么多态其实是多余的。在这种情况下，则可以使用“将参数替换为方法”，然后将该方法分解为多个较小的方法，并相应地更改 switch ，代码经过重构之后改进其的组织方式。当然如果 switch 操作只是执行简单的判断时，则没有必要进行代码重构。还有就是，在工厂设计模式（工厂方法和抽象工厂）使用开关运算符来选择创建的类时，也没有必要对其进行重构。 异曲同工类（Alternative Classes with Different Interfaces）这种“坏味道”表现为两个类有着相同的功能，但方法名称不同，产生这种代码的原因通常是创建其中一个类的程序员可能并不知道功能上等效的类已经存在。清除这种“坏味道”有以下几种方式： 方法重命名，重命名相同功能的方法，使它们在所有替代类中相同。 移动方法、添加参数和泛型方法使得方法的签名和实现相同。 如果仅仅是重复了方法的部分功能，可以使用提取相同父类的方式重构，在这种情况下，现有的类将成为该父类的子类。 通过重构异曲同工类后，可以去除掉不必要的重复代码，从而减少代码的行数，同时代码也会有更好的可读更易于理解。 临时变量滥用（Temporary Field）这种“坏味道”表现为一些临时变量仅在某些情况下才获得其值，在这些情况之外，它们都为空，通常，当我们在创建一个算法后需要定义一些临时变量以供该算法输入使用。此时，程序员往往会决定在类中为此算法去创建变量，而不是在方法中创建大量参数，导致这些变量仅在算法当中才会使用，其它地方都不会使用这些变量。一个应对的方式就是将这些临时变量和对其进行操作的所有代码都提取出来放到单独的类中。 重复代码（Duplicate Code）这种“坏味道”表现为两个或者多个代码片段看起来几乎相同，当我们多个人同时在同一项目中的不同部分上工作时，通常就会发生复制，产生重复的代码。因为正在实现不同的功能，因此可能并不知道其他人已经编写了类似的代码，这些代码其实是可以根据自己的需要进行复用的。当代码中的一些特定部分看起来不同但实际上实现相同的功能时，这样的代码有着更多细微的重复，这种情况下的代码重复可能很难找到和修复。如果重复代码在两个处于相同层次结构的子类出现时，我们可以通过以下方式进行重构： 提取方法，将重复的代码片段提取为方法然后放到共同的父类当中。 如果重复的代码在构造方法内部，则将其提取到父类的构造方法当中去，然后再在当前类的构造方法中使用 super 的方式调用父类构造方法。 如果重复的代码结构上相似但又不完全相同，那么则使用模板方法方式重构。 如果重复代码在两个或者多个不同的类出现时，我们可以通过以下方式进行重构： 如果这些类不是层次结构的一部分，可以使用提取共同父类的方式来为这些类创建一个保留所有之前的功能的单个父类。 当很难或者不可能创建父类，那么可以在其中的任意一个类中使用提取类的方式来重构，然后在其它类中使用刚刚创建出来的类。 通过重构合并重复的代码可以简化代码的结构并使其更加简短和易于后期维护。 总结本文总结了一些代码中常见的“坏味道”并给出了一些解决方法，重构是需要我们开发人员时刻都要去做的，要将重构始终贯穿在整个开发过程中，不断去发现代码中的“坏味道”，不断的持续的渐进重构。最后不管我们是如何去重构代码的，其背后的指导思想都是 Solid 原则。]]></content>
      <categories>
        <category>Java</category>
        <category>重构</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>重构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 垃圾收集技术]]></title>
    <url>%2Fpost%2F4615256d.html</url>
    <content type="text"><![CDATA[前言在计算机科学中，垃圾回收（GC: garbage collection）是内存自动管理的一种方式，它并不是同 Java 语言一起诞生的，实际上，早在 1959 年为了简化 Lisp 语言的手动内存管理，该语言的作者就开始使用了内存自动管理技术。 垃圾收集和手动内存管理刚好相反，后者需要编程人员自己去指定需要释放的对象然后将内存归还给操作系统，而前者不需要关心给对象分配的内存回收问题。Java 语言使用自动垃圾收集器来管理对象生命周期中的内存，要进行垃圾收集首先需要明确三个问题：1. 哪些内存需要回收、2. 什么时候进行回收、3. 怎么进行内存回收。接下来让我们一起看看 Java 语言对这些问题是如何处理的。 哪些内存需要回收为了方便管理和跨平台，Java 虚拟机规范规定在执行 Java 程序的时候把它所管理的内存划分为若干个不同的数据区域。这些区域都有着各自不同的用途以及创建和销毁的时间，有的数据区域随着用户线程的启动和结束而建立和销毁，有的区域会随着虚拟机进程的启动和停止而存在和销毁。更多有关运行时数据区域的内容请看 Java 运行时数据区域。由于 Java 运行时数据区域中的 程序计数器、虚拟机栈和本地方法栈和线程的生命周期一致，随线程的启动和结束而建立和销毁。而且当我们的类结构确定了之后，在编译期间，一个栈帧需要分配内存的大小基本上也就确定下来了，这三个区域的内存分配和收回都是具备确定性的，不需要我们过多的去考虑内存回收问题。主要考虑Java 堆和方法区的内存回收的问题。 什么时候进行回收在 Java 语言中，一个对象的生命周期分为以下三个阶段： 对象创建阶段 通常我们使用 new 关键字进行对象创建 e.g. Object obj = new Object();，当我们创建对象时，Java 虚拟机将分配一定大小的内存来存储该对象，分配的内存量可能会根据虚拟机厂商的不同而有所不同。 对象使用阶段 在这个阶段，对象被应用程序的其它对象使用（其它活动对象拥有指向它的引用）。在使用期间，该对象会一直驻留在内存当中，并且可能包含对其它对象的引用。 对象销毁阶段 垃圾收集系统监视对象，如果发现对象不被任何对象引用了，则进行该对象内存回收操作。 那么问题来了，该如何去判断一个对象有没有被引用呢？目前，主要有两种判断对象是否存活的算法，分别是 引用计数算法（Reference counting algorithm）和可达性分析算法（Accessibility analysis algorithm）。 引用计数算法首先我们看看引用计数算法是如何判断的，该算法的主要思想就是给每个对象都添加一个引用计数器，当该对象被变量或者另一个对象引用时该计数器值就会加 1，同时当对象的一个引用无效时，对象计数器的值会相应的减 1。当对象引用计数器的值为 0 时，说明该对象已经不再被引用了，那么就可以销毁对象进行内存回收操作了。这个算法的实现比较简单，对象是否“存活”的判断效率也比较高，这个算法看起来确实不错，但是它有个致命的缺点就是：无法解决对象间相互引用的问题。相互引用简单来说就是，有两个对象 object1 和 object2 都有一个引用类型字段 ref，并且做了如下赋值操作： 12object1.ref = object2;object2.ref = object1; 这两个对象除了上面这个赋值之外，不被其它任何对象引用，实际上这两个对象都不可能再被访问了，但是因为它们俩都互相引用了对方，导致引用计数器不为 0，导致使用引用计数器算法的 垃圾收集器 无法收集它们，它们就会一直存在于内存之中直到虚拟机进程结束。正是因为这个原因，市场上主流的 Java 虚拟机大部分都没有选用这个算法来管理内存，下面介绍的 可达性分析算法 就可以很好的避免了对象间相互引用的问题。 可达性分析算法Java 虚拟机是通过可达性分析算法来判断对象是否存活的，该算法的主要思想是将一系列称为 GC Root 的对象作为起点，向下进行搜索，搜索经过的路径称为引用链（Reference chain），当一个对象到 GC Root 对象没有任何引用链的时候，则表示该对象是不可达的，可以对其进行内存回收。 在 Java 虚拟机中，规定以下几种情况可以作为 GC Root 对象： 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中 Native 方法引用的对象 怎么进行内存回收当我们创建的对象不可达之后，Java 虚拟机会在后台自动去收集回收不可达对象的内存，自 Java 语言诞生以来，在垃圾收集算法上进行了许多更新，主要有标记-清除算法（Mark and sweep algorithm）、复制算法（Copying algorithm）、标记—整理算法（Mark and compact algorithm）和分代收集算法（Generational collection algorithm），根据这些算法实现的垃圾收集器在后台默默运行以释放内存，下面让我们看看它们是如何工作的。 标记-清除算法（mark and sweep algorithm）标记—清除算法是初始且非常基本的算法，主要分为以下两个阶段： 标记需要回收对象，找出程序中所有需要回收的对象并标记。 清除所有标记对象，在标记完成后统一回收被标记对象。 首先标记出需要回收的对象，标记完成后再统一回收被标记对象。这个算法是最基础的垃圾收集算法，后面将要介绍的几个算法都是在它的基础上优化改进的，算法主要有两个不足的地方：① 效率不高，标记和清除过程的效率都不高。② 空间利用率不高，标记清除之后会产生大量不连续的内存碎片，后面如果要分配大对象的时候由于连续内存不足可能会再次触发垃圾收集操作。 复制算法（copying algorithm）复制算法就是为了解决标记—清除算法的效率问题的，主要思想就是将可用的内存分为大小相等的两个部分，每一次都只使用其中的一块，当这块内存使用完了之后，就将依然存活的对象复制到另一块内存上去，然后再把这块含有可回收对象的内存清理掉，这样每次都是清理一半的连续内存了，就不会存在内存碎片的情况。但是这个算法的缺点也很明显，它把可用内存的大小缩小到了一半。 标记-整理算法（mark and compact algorithm）如果对象的存活率比较低的情况下，上面介绍的复制算法效率还是很高的，毕竟只要复制少部分存活对象到另一块内存中即可，但是当对象的存活率比较高时就会进行多次复制操作。比如老年代，老年代的对象是经过多次垃圾回收依然存活的对象，对象的存活率相对来说比较高，根据老年代的这个特点，于是针对这种情况就有了另一个算法称之为标记-整理算法，主要思想和其名字一样也是分为标记和整理两个阶段，第一个标记阶段依然和标记—清除算法一样，后面的第二个整理阶段就不是直接对可回收对象进行清理了，而是让所有存活的对象都向内存的同一侧移动，然后就直接清除掉另一侧的内存。 分代收集算法（generational collection algorithm）根据不同分代的特点，现在商业上的虚拟机针对不同的分代采取适合的垃圾收集，一般是把 Java 堆分为新生代和老年代。在新生代中，对象大部分存活时间都很短每次垃圾收集都会有很多的对象被清除，只有少部分对象可以存活下来，那么此时就可以使用复制算法，只需要复制出少部分存活的对象即可效率高。然而在老年代中大部分对象的存活时间比较长，则需采用标记-清除算法或者标记-整理算法来进行垃圾收集。垃圾收集算法对于垃圾回收来说类似于我们程序中的接口，是一套垃圾回收的指导算法，算法的具体实现我们称之为垃圾收集器。但是 Java 虚拟机规范中并没有对垃圾收集器的实现有任何规定。所以不同的厂商和不同版本的虚拟机实现的垃圾收集器也不一样，不过一般都会提供一些配置参数来让用户根据自身情况来设置所需的垃圾收集器。 JVM 相关 GC 配置Java 虚拟机部分垃圾收集（Garbage Collection，GC）相关配置如下 参数 描述 -Xms2048m 设置初始堆大小（新生代 + 老年代） -XX:InitialHeapSize=3g 设置初始堆大小（新生代 + 老年代） -Xmx3g 设置最大堆大小（新生代 + 老年代） -XX:MaxHeapSize=3g 设置最大堆大小（新生代 + 老年代） -XX:NewSize=128m 设置堆初始新生代大小 -XX:MaxNewSize=128m 设置堆最大新生代大小 -XX:PermSize=512m（JDK 1.7） 设置初始永久代（元空间）大小 -XX:MetaspaceSize=512m（JDK 1.8+） 设置初始永久代（元空间）大小 -XX:MaxPermSize=1g（JDK 1.7） 设置最大永久代（元空间）大小 -XX:MaxMetaspaceSize=1g（JDK 1.8+） 设置最大永久代（元空间）大小 -XX:+DisableExplicitGC 忽略应用程序对 System.gc() 方法的任何调用 -XX:+PrintGCDetails 打印输出 GC 收集相关信息 参考文章 深入理解Java虚拟机（第2版） Garbage collection (computer science) The Java® Virtual Machine Specification（Java SE 8 Edition）]]></content>
      <categories>
        <category>Java</category>
        <category>GC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务发现组件之 — Eureka]]></title>
    <url>%2Fpost%2F710bd10b.html</url>
    <content type="text"><![CDATA[前言现在流行的微服务体系结构正在改变我们构建应用程序的方式，从单一的单体服务转变为越来越小的可单独部署的服务（称为微服务），共同构成了我们的应用程序。当进行一个业务时不可避免就会存在多个服务之间调用，假如一个服务 A 要访问在另一台服务器部署的服务 B，那么前提是服务 A 要知道服务 B 所在机器的 IP 地址和服务对应的端口，最简单的方式就是让服务 A 自己去维护一份服务 B 的配置（包含 IP 地址和端口等信息），但是这种方式有几个明显的缺点：随着我们调用服务数量的增加，配置文件该如何维护；缺乏灵活性，如果服务 B 改变 IP 地址或者端口，服务 A 也要修改相应的文件配置；还有一个就是进行服务的动态扩容或缩小不方便。一个比较好的解决方案就是 服务发现（Service Discovery）。它抽象出来了一个注册中心，当一个新的服务上线时，它会将自己的 IP 和端口注册到注册中心去，会对注册的服务进行定期的心跳检测，当发现服务状态异常时将其从注册中心剔除下线。服务 A 只要从注册中心中获取服务 B 的信息即可，即使当服务 B 的 IP 或者端口变更了，服务 A 也无需修改，从一定程度上解耦了服务。服务发现目前业界有很多开源的实现，比如 apache 的 zookeeper、 Netflix 的 eureka、hashicorp 的 consul、 CoreOS 的 etcd。 Eureka 是什么Eureka 在 github 上对其的定义为 Eureka is a REST (Representational State Transfer) based service that is primarily used in the AWS cloud for locating services for the purpose of load balancing and failover of middle-tier servers.At Netflix, Eureka is used for the following purposes apart from playing a critical part in mid-tier load balancing. Eureka 是由 Netflix 公司开源，采用的是 Client / Server 模式进行设计，基于 http 协议和使用 Restful Api 开发的服务注册与发现组件，提供了完整的服务注册和服务发现，可以和 Spring Cloud 无缝集成。其中 Server 端扮演着服务注册中心的角色，主要是为 Client 端提供服务注册和发现等功能，维护着 Client 端的服务注册信息，同时定期心跳检测已注册的服务当不可用时将服务剔除下线，Client 端可以通过 Server 端获取自身所依赖服务的注册信息，从而完成服务间的调用。遗憾的是从其官方的 github wiki 可以发现，2.0 版本已经不再开源。但是不影响我们对其进行深入了解，毕竟服务注册、服务发现相对来说还是比较基础和通用的，其它开源实现框架的思想也是想通的。 服务注册中心（Eureka Server）我们在项目中引入 Eureka Server 的相关依赖，然后在启动类加上注解 @EnableEurekaServer，就可以将其作为注册中心，启动服务后访问页面如下： 我们继续添加两个模块 service-provider，service-consumer，然后在启动类加上注解 @EnableEurekaClient 并指定注册中心地址为我们刚刚启动的 Eureka Server，再次访问可以看到两个服务都已经注册进来了。 Demo 仓库地址：https://github.com/mghio/depth-in-springcloud 可以看到 Eureka 的使用非常简单，只需要添加几个注解和配置就实现了服务注册和服务发现，接下来我们看看它是如何实现这些功能的。 服务注册（Register）注册中心提供了服务注册接口，用于当有新的服务启动后进行调用来实现服务注册，或者心跳检测到服务状态异常时，变更对应服务的状态。服务注册就是发送一个 POST 请求带上当前实例信息到类 ApplicationResource 的 addInstance 方法进行服务注册。 可以看到方法调用了类 PeerAwareInstanceRegistryImpl 的 register 方法，该方法主要分为两步： 调用父类 AbstractInstanceRegistry 的 register 方法把当前服务注册到注册中心 调用 replicateToPeers 方法使用异步的方式向其它的 Eureka Server 节点同步服务注册信息 服务注册信息保存在一个嵌套的 map 中，它的结构如下： 第一层 map 的 key 是应用名称（对应 Demo 里的 SERVICE-PROVIDER），第二层 map 的 key 是应用对应的实例名称（对应 Demo 里的 mghio-mbp:service-provider:9999），一个应用可以有多个实例，主要调用流程如下图所示： 服务续约（Renew）服务续约会由服务提供者（比如 Demo 中的 service-provider）定期调用，类似于心跳，用来告知注册中心 Eureka Server 自己的状态，避免被 Eureka Server 认为服务时效将其剔除下线。服务续约就是发送一个 PUT 请求带上当前实例信息到类 InstanceResource 的 renewLease 方法进行服务续约操作。 进入到 PeerAwareInstanceRegistryImpl 的 renew 方法可以看到，服务续约步骤大体上和服务注册一致，先更新当前 Eureka Server 节点的状态，服务续约成功后再用异步的方式同步状态到其它 Eureka Server 节上，主要调用流程如下图所示： 服务下线（Cancel）当服务提供者（比如 Demo 中的 service-provider）停止服务时，会发送请求告知注册中心 Eureka Server 进行服务剔除下线操作，防止服务消费者从注册中心调用到不存在的服务。服务下线就是发送一个 DELETE 请求带上当前实例信息到类 InstanceResource 的 cancelLease 方法进行服务剔除下线操作。 进入到 PeerAwareInstanceRegistryImpl 的 cancel 方法可以看到，服务续约步骤大体上和服务注册一致，先在当前 Eureka Server 节点剔除下线该服务，服务下线成功后再用异步的方式同步状态到其它 Eureka Server 节上，主要调用流程如下图所示： 服务剔除（Eviction）服务剔除是注册中心 Eureka Server 在启动时就启动一个守护线程 evictionTimer 来定期（默认为 60 秒）执行检测服务的，判断标准就是超过一定时间没有进行 Renew 的服务，默认的失效时间是 90 秒，也就是说当一个已注册的服务在 90 秒内没有向注册中心 Eureka Server 进行服务续约（Renew），就会被从注册中心剔除下线。失效时间可以通过配置 eureka.instance.leaseExpirationDurationInSeconds 进行修改，定期执行检测服务可以通过配置 eureka.server.evictionIntervalTimerInMs 进行修改，主要调用流程如下图所示： 服务提供者（Service Provider）对于服务提供方（比如 Demo 中的 service-provider 服务）来说，主要有三大类操作，分别为 服务注册（Register）、服务续约（Renew）、服务下线（Cancel），接下来看看这三个操作是如何实现的。 服务注册（Register）一个服务要对外提供服务，首先要在注册中心 Eureka Server 进行服务相关信息注册，能进行这一步的前提是你要配置 eureka.client.register-with-eureka=true，这个默认值为 true，注册中心不需要把自己注册到注册中心去，把这个配置设为 false，这个调用比较简单，主要调用流程如下图所示： 服务续约（Renew）服务续约是由服务提供者方定期（默认为 30 秒）发起心跳的，主要是用来告知注册中心 Eureka Server 自己状态是正常的还活着，可以通过配置 eureka.instance.lease-renewal-interval-in-seconds 来修改，当然服务续约的前提是要配置 eureka.client.register-with-eureka=true，将该服务注册到注册中心中去，主要调用流程如下图所示： 服务下线（Cancel）当服务提供者方服务停止时，要发送 DELETE 请求告知注册中心 Eureka Server 自己已经下线，好让注册中心将自己剔除下线，防止服务消费方从注册中心获取到不可用的服务。这个过程实现比较简单，在类 DiscoveryClient 的 shutdown 方法加上注解 @PreDestroy，当服务停止时会自动触发服务剔除下线，执行服务下线逻辑，主要调用流程如下图所示： 服务消费者（Service Consumer）这里的服务消费者如果不需要被其它服务调用的话，其实只会涉及到两个操作，分别是从注册中心 获取服务列表（Fetch） 和 更新服务列表（Update）。如果同时也需要注册到注册中心对外提供服务的话，那么剩下的过程和上文提到的服务提供者是一致的，这里不再阐述，接下来看看这两个操作是如何实现的。 获取服务列表（Fetch）服务消费者方启动之后首先肯定是要先从注册中心 Eureka Server 获取到可用的服务列表同时本地也会缓存一份。这个获取服务列表的操作是在服务启动后 DiscoverClient 类实例化的时候执行的。 可以看出，能发生这个获取服务列表的操作前提是要保证配置了 eureka.client.fetch-registry=true，该配置的默认值为 true，主要调用流程如下图所示： 更新服务列表（Update）由上面的 获取服务列表（Fetch） 操作过程可知，本地也会缓存一份，所以这里需要定期的去到注册中心 Eureka Server 获取服务的最新配置，然后比较更新本地缓存，这个更新的间隔时间可以通过配置 eureka.client.registry-fetch-interval-seconds 修改，默认为 30 秒，能进行这一步更新服务列表的前提是你要配置 eureka.client.register-with-eureka=true，这个默认值为 true。主要调用流程如下图所示： 总结工作中项目使用的是 Spring Cloud 技术栈，它有一套非常完善的开源代码来整合 Eureka，使用起来非常方便。之前都是直接加注解和修改几个配置属性一气呵成的，没有深入了解过源码实现，本文主要是阐述了服务注册、服务发现等相关过程和实现方式，对 Eureka 服务发现组件有了更近一步的了解。 参考文章Netflix EurekaService Discovery in a Microservices Architecture]]></content>
      <categories>
        <category>Java</category>
        <category>服务发现</category>
        <category>Eureka</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>服务发现</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020 年 JVM 生态报告解读]]></title>
    <url>%2Fpost%2Fe09f0428.html</url>
    <content type="text"><![CDATA[前言做过 Java 开发的同学都知道，JVM（Java 虚拟机） 是 Java 实现的基础，虽然在平时工作中真正运用到的时候可能并不多，但是一个程序员想要上升到高级层次，那就必须知道 Java 到底是怎么运行的，这就有必要去学习了解 JVM 的相关知识了。学习 JVM 可以能更深入的理解 Java 这门语言，可以清楚知道Java程序是如何执行的以及为未来排查线上问题打下坚实的基础。接下来我们看看 2020 年的 JVM 生态报告和最新趋势，值得我们每个 Java 开发者去关注了解。 JDK 厂商占比Oracle JDK 和 Open JDK 加起来占比将近 60%，其中 Oracle JDK 占比略多一些，Oracle JDK 和 Open JDK 都是市场上的热门选择，我们看看二者之间的一些差异。Oracle JDK 更多的关注稳定性，更适合企业级用户，而 Open JDK 相对而言没有那么稳定，它会经常发布一些新特性。Oracle JDK 支持长期发布的更改，而 Open JDK 仅支持计划和完成下一个发行版，还有一个就是 Oracle JDK 是根据 二进制代码许可协议 获得许可，而 Open JDK 是根据 GPL v2 许可获得许可。使用 Oracle 平台时会产生一些许可影响。如 Oracle 宣布的那样，在没有商业许可的情况下，在 2019 年 1 月之后发布的 Oracle Java SE 8 的公开更新将无法用于商业，商业或生产用途。但是，Open JDK 是完全开源的，可以自由使用。 愿意付费用户占比很少只有 9% 的用户表示愿意为 JDK 支付费用，还有 86% 的用户表示并不想为 JDK 支付费用，可以看出大部分用户其实对 JDK 的付费使用还是不赞同的，目前来看，如果要真正实行付费模式还是有点难。不过人们选择为 JDK 支付费用时，Oracle 还是当之无愧的大赢家的。自从 JDK9 发布之后，以后每年的 3 月和 9 月都会发布一个新的版本，这个发布节奏的改变，这个对许多用户的版本更新策略还是有一定的影响。调查结果显示这个发布节奏的变更影响了三分之一的开发者们是否决定为其支付费用。 Java 8 仍然是主流版本从 Java 9 之后对 JDK 的结构做了很大的调整，这也是影响人们升级的原因之一，根据报告结果来看 Java 8 仍然是大家使用最多的版本，但是在 2018 年 9 月发布了第一个 LTS(长期支持) 版的 Java 11 之后，有四分之一的开发者在生产环境中使用了 Java 11。因为发布节奏的原因，大部分开发者还是不愿意每 6 个月就对版本进行一次更新，版本迁移成本其实也不低，还有新版本在生产环境的稳定性也是其中的一个考虑因素。 Kotlin 在 JVM 类语言中占比第二在 JVM 类语言语言中 Java 占比 86.9% 稳居第一，除了 Java 语言之外，Kotlin 语言在 JVM 类语言占比第二占比 5.5%，Kotlin 从去年的 2.4% 增加到今年的 5.5%，JVM 类语言的用户中 Kotlin 使用率的增长，因为它可以与 Java 无缝集成也不足为奇，像在 Spring Boot 框架中使用 Kotlin 进行开发也很容易。Kotlin 也一直在创新，积极拥抱 Java 的大腿，在 Java 的新版本中也在试图整合一些 Kotlin 的概念。 Spring 依然是 Java 框架中的王者有十分之六的开发者依赖 Spring 框架来构建他们的程序，这对于众多的第三方开源框架来说，这是一个很高的占比，Spring Framework 依然是 Java 开发框架中的王者，Spring 框架已经发布了很长一段时间了，通过长时间的改进和创新，无疑 Spring 现在已经成为 Java 生态系统中的最重要的框架。在众多的使用者中有将近三分之二的用户使用 Spring 5，可见大家对 Spring 框架的新版使用率还是很高的。 Spring Boot 是主流的服务器端 Web 框架服务器端依然是 Spring 的天下，其中有一半的人使用的是 Spring Boot 框架，还有将近的三分之一的人使用的是 Spring MVC 框架，前几年比较火的 Struts 框架已经开始没落了，这个占比和现在市场上比较流行微服务架构是分不开，因为 Spring Boot 框架天生就是为微服务而生的，它可以快速实现微服务。使用基于 Spring Boot 的 Spring Cloud 框架可以快速搭建一个分布式的服务或应用。 IntelliJ IDEA 是主流的开发工具IntelliJ IDEA 是 Java 开发者们使用最广泛的开发工具，调查结果显示有 62% 的开发人员使用社区免费版和付费终极版。Apache NetBeans 以 10% 的市场份额保持在第三位，和去年的调查结果一致。可以发现被业界广泛称赞的 VS Code 神级编辑器在 Java 开发人员中并没有想象的那么受欢迎。 Maven 是主流的项目构建管理工具Maven 是一个软件项目管理和自动构建的工具，由 Apache 基金会 维护。它基于项目对象模型(POM)概念，Maven 利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。调查结果显示它在排名仍是第一，一直都是主流的项目构建工具，排名第二的 Gradle 一直保持着增长的趋势，在 2019 年占比达到四分之一，而在 2012 年占比高达 40% 的老牌的构建工具 Ant 将逐渐退出舞台，到 2019 年占比不到 10%。可以明确的是，构建工具之间的竞争从不会停止，能否及时更新发布一些可以解决使用者痛点的工具是大家选择的因素之一。 Jenkins 仍然是持续集成工具中的王者和我们大多数 Java 开发人员的期望一致，Jenkins 以高达 58% 的占比排名稳居第一，排名第二的 GitLab 占比仅为 6%，有趣的是没有使用工具的也高达 12%，虽然不适用工具的人数占比比去年低了很多，但是这个占比还是让人有点儿惊讶。 生态报告来源：https://snyk.io/blog/jvm-ecosystem-report-2020 PS：关注公众号「mghio」，回复关键字 JVM 获取 2020 年 JVM 生态报告 PDF 版原文。]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统之 — CAP 定理]]></title>
    <url>%2Fpost%2F11cb7677.html</url>
    <content type="text"><![CDATA[前言在互联网时代，我们的应用都是分布式系统，部署在 N 台机器上。说到分布式系统我们就不得不说分布式系统的祖先——集中式系统。它和分布式系统是两个完全相反的概念，集中式系统就是把所有的程序和功能都放到一台主机上，从而对外提供服务。集中式系统的优点就是容易理解、维护方便，它的的弊端也很明显，如果这个主机出故障了那么整个系统就崩溃了。著名投资家巴菲特有个关于投资的名言： 不要把鸡蛋放在一个篮子里 对于我们的系统而言也是如此，我们不可能保证主机永远不坏、也无法保证自己的程序永远不会出 bug，所以问题是无法避免的，我们只能把“鸡蛋”分散到不同的“篮子”里，降低系统出故障的风险，这就是我们为什么需要分布式系统的原因之一。使用分布式系统的另一个理由就是扩展性，毕竟单台主机都会有性能的极限，分布式系统可以通过增加主机数量来实现横向水平性能的扩展。接下来我们看看分布式系统中的一个基本定理——CAP定理。 什么是 CAP 定理CAP 定理指出对于一个分布式系统来说，不可能同时满足以下三点： 一致性（Consistency） 可用性（Availability） 分区容错性（Partition tolerance） 定理看起来很简单，但是一致性、可用性、分区容错性究竟是代表什么意思呢？理解定理的最简单的方式就是想象一个有两个节点分别处在不同的分区（PS：可以简单的把分区理解为不同的子网络）的分布式系统。 场景假设我们假定一个很简单的分布式系统，系统由两个系统 S1 和 S2 组成。两个系统上面有两个相同的变量 K，该变量在两个系统对应的初始值为 V0。系统 S1 和 S2 可以进行通信同时也对外提供服务。我们假定的分布式系统如下所示： 客户端 client 可以向 S1 和 S2 任何一个系统发起读和写请求。当一个服务接收到发过来的请求后进行一些相关业务操作，然后返回给客户端 client，发起写请求的过程如下图所示： 客户端发起读请求的过程如下所示： 我们的分布式系统模型建立好了，接下来我们通过这个模型来分析CAP 定理中的一致性、可用性和分区容错性的具体含义。 一致性（Consistency）一致性要求在一个写操作完成之后的任何读操作都必须返回该值或者以后进行写操作的结果。在满足一致性的分布式系统中，客户端发起一个写请求到分布式系统的任何一个子系统中，然后再向该系统中任何一个子系统发起读请求查询该变量对应的值，都会返回上次更新的最新结果。客户端向一个不满足一致性的分布式系统发起写-读请求的过程如下所示： 当客户端向系统 S1 发送写请求(write V1)，得到成功返回响应后，再向系统 S2 发送读请求读取该变量的值，系统 S2 还是返回旧值 V0。另一方面，我们看看客户端向一个满足一致性的分布式系统发起写-读请求的过程： 在这个满足一致性的系统中，在上述过程中系统 S1 在返回客户端请求结果之前会先把最新值 V1 发送到系统 S2，然后才返回客户端的写请求结果。因此，当客户端再去请求系统 S2 的时候就会返回最新值 V1。 可用性（Availability）可用性要求在分布式系统中非故障节点收到的每一个请求都必须返回响应。在一个满足可用性的分布式系统中，如果客户端向系统中任意一个节点发送请求并且服务器没有崩溃的情况下，则该节点必须响应客户端，不管是哪个节点，只要收到请求，就必须告诉用户，到底是 V0 还是 V1，否则就不满足可用性，不允许服务器忽略客户端的请求。 分区容错性（Partition tolerance）分区容错表明当消息从一个节点向另一个节点发送消息的过程中，消息可能会丢失。以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在一致性和可用性之间做出选择。如果所有消息都无法发送的话，分布式系统的各个节点将无法同步消息。如下所示： 一般来说，分区容错无法避免，因此可以认为CAP定理的分区容错性总是成立。CAP 定理告诉我们，剩下的一致性和可用性无法同时做到。通常我们为了分区容错，我们的系统必须保证能够在任意网络分区下正常运行。 为何不能同时满足一致性和可用性我们现在知道了一致性、可用性、分区容错性所表示的具体含义，接下来看看为什么在一个分布式系统中不能同时满足一致性和可用性。我们假定存在一个同时满足这三个特性的系统。首先要做的就是对该系统进行分区，分区后系统如下所示： 下一步，客户端向分布式系统的节点 S1 发送一个写请求(write V1)，系统只要是可用的，该节点总是会返回响应。但是系统存在网络分区，因此节点 S1 无法将最新值 V1 通知节点 S2 去更新。如下所示： 接下来，客户端向分布式系统的节点 S2 发送一个读请求（read K）查询变量 K 的值，同样的，系统只要是可用的，该节点总是会返回响应，但是系统存在网络分区，因此节点 S2 无法从节点 S1 获取到最新值 V1 进行更新。如下所示： 客户端已经向节点 S1 发送写请求（write V1）成功后，再向节点 S2 发起读请求，得到的返回值是旧值 V0。这和我们假设的一致性冲突。如果要保证节点 S1 的一致性，那么节点 S1 必须在写操作时，锁定节点 S2 的读操作和写操作。只有当数据同步后，才能重新开放节点 S2 的读写操作。那么在锁定期间，S2不能读写，它就没有可用性了。再来看看，我们如果保证节点 S2 的可用性，那么就不能锁定节点 S2 的读写操作，所以一致性不成立。所以，节点 S2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性，如果追求所有节点的可用性，那就没法做到一致性了。 总结CAP定理指明了分布式系统的三大指标一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）不能同时满足，该定理是分布式系统的基本定理，也是理解分布式系统的起点。(PS: 像我们常用的注册中心 Eureka，因为节点之间的状态同步采用的异步方式，所以不能保证任意时刻各个节点间的状态一定是一致的，只能保证节点间最终状态是一致的。所以按照CAP理论，Eureka 的选择就是放弃了一致性，选择可用性和分区容错性。)]]></content>
      <categories>
        <category>分布式系统</category>
        <category>CAP定理</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>CAP定理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA 最新版（2019.3）激活教程]]></title>
    <url>%2Fpost%2Ff440d00b.html</url>
    <content type="text"><![CDATA[前言相信做 Java 开发的朋友们绝大部分人应该都是用 IntelliJ IDEA 作为开发工具，没用过的朋友们建议将你的开发工具换成这个，关于它的优点可以去 Google 一下，我之前都是用 Eclipse 作为开发工具，自从用过一次 IDEA 之后就再也回不去了。。。今天早上更新（作死）了一下 IDEA 到最新版（2019.3.1），安装完毕之后进入就提示说之前的激活码失效了，经过一顿搜索之后终于成功激活了，在此记录一下激活过程。 Step 1 升级 IDEA 到 2019.3 版本如果之前电脑安装过 IDEA，依次选择菜单项 IntelliJ IDEA -&gt; About IntelliJ IDEA 查看 IDEA 的版本（PS: windows 系统菜单项可能不同），如果不是 2019.3 版本，则要到 官网 下载 2019.3.1 版本，具体安装过程比较简单，安装过程有问题的朋友们请自行 Google。 Step 2 下载补丁包扫码关注微信公众号 mghio 后回复「idea」获取激活补丁包。 Step 3 编辑 IDEA 的 idea.vmoptions 文件经过 Step 1 安装完成之后，打开 IDEA 开发工具，然后它会提示要激活，这里我们先选择 试用 30 天。 然后将 Step 2 我们下载好的激活补丁包 jetbrains-agent.jar 拷贝到 IDEA 安装目录的 bin 目录下。 编辑 IDEA 的 idea.vmoptions（PS:推荐直接从IDEA中编辑），依次选择菜单项 Help -&gt; Edit Custom VM Optons...。 点击打开编辑，在其内容最后追加如下代码： 1-javaagent:你的 IDEA 的安装目录/bin/jetbrains-agent.jar Step 4 重启后输入激活码激活退出 IDEA 重新启动进入，依次选择菜单项 Help -&gt; Register...。 进入后选择 Activation code 以输入激活码方式激活，在第二步 Step 2 下载补丁包 中下载的 txt 文件（文件名：激活码.txt）为激活码，这里也贴一下，激活码如下（PS: 鼠标移至激活码区域，点击右侧 「复制」 按钮即可复制）： 1KNBB2QUUR1-eyJsaWNlbnNlSWQiOiJLTkJCMlFVVVIxIiwibGljZW5zZWVOYW1lIjoiZ2hib2tlIiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IiIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiQUMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiRFBOIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlBTIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkdPIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRNIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkNMIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJTMCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSRCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJQQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSTSIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJXUyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQiIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSU1UiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In1dLCJoYXNoIjoiMTI3OTY4NzcvMCIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-1iV7BA/baNqv0Q5yUnAphUmh66QhkDRX+qPL09ICuEicBqiPOBxmVLLCVUpkxhrNyfmOtat2LcHwcX/NHkYXdoW+6aS0S388xe1PV2oodiPBhFlEaOac42UQLgP4EidfGQSvKwC9tR1zL5b2CJPQKZ7iiHh/iKBQxP6OBMUP1T7j3Fe1rlxfYPc92HRZf6cO+C0+buJP5ERZkyIn5ZrVM4TEnWrRHbpL8SVNq4yqfc+NwoRzRSNC++81VDS3AXv9c91YeZJz6JXO7AokIk54wltr42FLNuKbozvB/HCxV9PA5vIiM+kZY1K0w5ytgxEYKqA87adA7R5xL/crpaMxHQ==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG/PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg/nYV31HLF7fJUAplI/1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4/G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd/GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt/wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59/THOT7NJQhr6AyLkhhJCdkzE2cob/KouVp4ivV7Q3Fc6HX7eepHAAF/DpxwgOrg9smX6coXLgfp0b1RU2u/tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB/40BjpMUrDRCeKuiBahC0DCoU/4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV/g== 部分朋友输入以上激活码后点击激活可能会出现如下报错提示：Your activation code could not be validated（error 1653219），未出现此错误提示的朋友可以跳过以下步骤。 出现此错误是因为没有屏蔽 account.jetbrains.com 的 443 端口，因此修改本地 hosts 文件在其内容追加以下内容即可。 10.0.0.0 https://account.jetbrains.com:443 修改保存 hosts 文件后，再次激活即可激活。 Step 5 验证是否激活重启 IDEA 后，依次选择菜单项 IntelliJ IDEA -&gt; About IntelliJ IDEA，可以看到激活到期日期为：2089-07-08。 至此， IntelliJ IDEA 激活完成。 总结以上激活步骤只针对 IntelliJ IDEA 的 2019.3.1 版本，不同的版本可能无法激活，在激活前请确认好你所使用的 IDEA 版本。激活码和激活补丁包要一起使用，单独使用无效，在激活过程中有问题请在文末留言区留言讨论。]]></content>
      <categories>
        <category>Java</category>
        <category>IDEA</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 反射机制（二）]]></title>
    <url>%2Fpost%2F7528c810.html</url>
    <content type="text"><![CDATA[前言在上篇 Java 反射机制（一） 介绍了一些 Java 反射相关的常用 API ，在知道了如何去使用反射之后，作为一个合格的工程师，下一步肯定是要去了解它的如何实现的，我们今天就来看看在 JDK 源码中是如何去实现反射的(PS:以下源码分析基于 JDK1.8)。 Field 类 set 方法的实现Field 类的 set 方法是在运行时用来动态修改一个类的属性的值，进入到 Field 类的 set 方法的源码如下： 1234567891011public void set(Object obj, Object value) throws IllegalArgumentException, IllegalAccessException&#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; getFieldAccessor(obj).set(obj, value);&#125; 首先根据 override 判断是否需要检查字段的访问权限，然后通过 getFieldAccessor 方法获得一个 FieldAccessor 字段访问者对象，最后调用的是 FieldAccessor 类的 set 方法进行下一步操作的，FieldAccessor 是一个接口，定义了对字段的一些操作，该接口有如下一些实现类： 要看 set 到底调用的是哪个实现类的方法，那么我们需要看看 getFieldAccessor() 返回的是哪个类的对象，下面是 getFieldAccessor 方法的源码实现： 12345678// security check is done before calling this methodprivate FieldAccessor getFieldAccessor(Object obj) throws IllegalAccessException&#123; boolean ov = override; FieldAccessor a = (ov) ? overrideFieldAccessor : fieldAccessor; return (a != null) ? a : acquireFieldAccessor(ov);&#125; 这里先通过 override 来获取不同的缓存的 FieldAccessor，其中 overrideFieldAccessor 代表本类覆盖父类的字段访问者对象缓存，fieldAccessor 是本类的字段访问器对象缓存。如果缓存存在的话就直接复用之前的对象，否则就调用 Field 类的 acquireFieldAccessor 方法获取。我们进入到 acquireFieldAccessor 方法中看看，方法源码如下： 123456789101112131415161718private FieldAccessor acquireFieldAccessor(boolean overrideFinalCheck) &#123; // First check to see if one has been created yet, and take it // if so FieldAccessor tmp = null; if (root != null) tmp = root.getFieldAccessor(overrideFinalCheck); if (tmp != null) &#123; if (overrideFinalCheck) overrideFieldAccessor = tmp; else fieldAccessor = tmp; &#125; else &#123; // Otherwise fabricate one and propagate it up to the root tmp = reflectionFactory.newFieldAccessor(this, overrideFinalCheck); setFieldAccessor(tmp, overrideFinalCheck); &#125; return tmp;&#125; 从 acquireFieldAccessor 的源码中我们可以看到，先判断是否已存在 FieldAccessor 对象，如果存在的话那么就会复用之前的 FieldAccessor 对象，否则就使用 reflectionFactory 工厂的 newFieldAccessor 方法生成一个新的 FieldAccessor 对象出来。所以我们就要进到 newFieldAccessor 方法里面看看是如何生成的，方法源码如下： 1234public FieldAccessor newFieldAccessor(Field var1, boolean var2) &#123; checkInitted(); return UnsafeFieldAccessorFactory.newFieldAccessor(var1, var2);&#125; 从 newFieldAccessor 方法代码可以得知，在方法里面是通过 UnsafeFieldAccessorFactory 类的 static 方法 newFieldAccessor 来生产 FieldAccessor 的，那么我们继续进入到 UnsafeFieldAccessorFactory 类的 newFieldAccessor 方法里面看看，方法源码如下： 123456789101112131415161718192021222324252627282930313233static FieldAccessor newFieldAccessor(Field var0, boolean var1) &#123; Class var2 = var0.getType(); boolean var3 = Modifier.isStatic(var0.getModifiers()); boolean var4 = Modifier.isFinal(var0.getModifiers()); boolean var5 = Modifier.isVolatile(var0.getModifiers()); boolean var6 = var4 || var5; boolean var7 = var4 &amp;&amp; (var3 || !var1); if (var3) &#123; UnsafeFieldAccessorImpl.unsafe.ensureClassInitialized(var0.getDeclaringClass()); if (!var6) &#123; if (var2 == Boolean.TYPE) &#123; return new UnsafeStaticBooleanFieldAccessorImpl(var0); &#125; else if (var2 == Byte.TYPE) &#123; return new UnsafeStaticByteFieldAccessorImpl(var0); &#125; else if (var2 == Short.TYPE) &#123; return new UnsafeStaticShortFieldAccessorImpl(var0); &#125; else if (var2 == Character.TYPE) &#123; return new UnsafeStaticCharacterFieldAccessorImpl(var0); &#125; else if (var2 == Integer.TYPE) &#123; return new UnsafeStaticIntegerFieldAccessorImpl(var0); &#125; else if (var2 == Long.TYPE) &#123; return new UnsafeStaticLongFieldAccessorImpl(var0); &#125; else if (var2 == Float.TYPE) &#123; return new UnsafeStaticFloatFieldAccessorImpl(var0); &#125; else &#123; return (FieldAccessor)(var2 == Double.TYPE ? new UnsafeStaticDoubleFieldAccessorImpl(var0) : new UnsafeStaticObjectFieldAccessorImpl(var0)); &#125; &#125; // 剩下的部分省略... &#125; &#125; 从以上 UnsafeFieldAccessorFactory 类的 newFieldAccessor 方法代码可以看出，方法里面通过类的字段修饰符类型和字段的类类型共同决定返回的 FieldAccessor 实现类，这里要注意一下方法里面这几个变量的含义： var3（isStatic）：静态属性，也就是 static 关键字修饰的属性。 var4（isFinal）：final 关键字修饰的属性。 var5（isVolatile）：valatile 关键字修饰的属性。 var6（isQualified）：valatile 关键字或者 final 关键字修饰的属性。 var7 (isReadOnly)：是否只读属性，final 关键字修饰的属性或者 static 关键字修饰并且不能覆盖（override = false）的属性 举一个例子，假设在一个类中的字段声明为 public static String name，那么返回的字段访问器为 UnsafeStaticCharacterFieldAccessorImpl，我们看看这个类的 set 方法是如何实现的，方法源码如下： 123456789101112131415public void set(Object var1, Object var2) throws IllegalArgumentException, IllegalAccessException &#123; if (this.isFinal) &#123; this.throwFinalFieldIllegalAccessException(var2); &#125; if (var2 == null) &#123; this.throwSetIllegalArgumentException(var2); &#125; if (var2 instanceof Character) &#123; unsafe.putChar(this.base, this.fieldOffset, (Character)var2); &#125; else &#123; this.throwSetIllegalArgumentException(var2); &#125;&#125; 从上面方法的代码得知，方法最终还是通过 Unsafe 类的 native 方法 putChar(Object var1, long var2, char var4) 来实现的，有关 Unsafe 类的介绍请看这篇文章（Java魔法类：Unsafe应用解析）。 Method 类 invoke 方法的实现Method 类的 invoke 方法用来在运行时动态调用对象的方法，我们进入到 Method 类的 invoke 方法中看看在 JDK 中到底是怎么做的，方法源码如下： 123456789101112131415public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; MethodAccessor ma = methodAccessor; // read volatile if (ma == null) &#123; ma = acquireMethodAccessor(); &#125; return ma.invoke(obj, args);&#125; 从以上方法代码我们可以看到，和上文说的的 Field 类一样，首先也是先根据 override 进行了一些权限检查，最后调用的是 MethodAccessor 的 invoke 方法进行处理，这个方法访问器 MethodAccessor 是一个接口，它只有一个操作方法调用的 invoke 方法，它有如下三个实现类： 要想知道 ma.invoke 具体调用的是哪个类的方法，我们需要看看方法 acquireMethodAccessor 返回的对象是哪个，该方法的源码如下： 123456789101112131415private MethodAccessor acquireMethodAccessor() &#123; // First check to see if one has been created yet, and take it // if so MethodAccessor tmp = null; if (root != null) tmp = root.getMethodAccessor(); if (tmp != null) &#123; methodAccessor = tmp; &#125; else &#123; // Otherwise fabricate one and propagate it up to the root tmp = reflectionFactory.newMethodAccessor(this); setMethodAccessor(tmp); &#125; return tmp;&#125; 从以上方法 acquireMethodAccessor 的源码可以看出，首先会先先判断是否已经存在了对应的 MethodAccessor 对象，如果有就会复用这个对象，否则就调用工厂 reflectionFactory 的 newMethodAccessor 方法生成一个 MethodAccessor 对象出来。那么我们就需要进入到方法 newMethodAccessor 中，方法源码如下： 1234567891011public MethodAccessor newMethodAccessor(Method var1) &#123; checkInitted(); if (noInflation &amp;&amp; !ReflectUtil.isVMAnonymousClass(var1.getDeclaringClass())) &#123; return (new MethodAccessorGenerator()).generateMethod(var1.getDeclaringClass(), var1.getName(), var1.getParameterTypes(), var1.getReturnType(), var1.getExceptionTypes(), var1.getModifiers()); &#125; else &#123; NativeMethodAccessorImpl var2 = new NativeMethodAccessorImpl(var1); DelegatingMethodAccessorImpl var3 = new DelegatingMethodAccessorImpl(var2); var2.setParent(var3); return var3; &#125;&#125; 从方法 newMethodAccessor 的代码可以看到，方法首先是使用 Method 对象作为入参生成了 NativeMethodAccessorImpl 对象，然后再使用 NativeMethodAccessorImpl 对象作为入参生成了 DelegatingMethodAccessorImpl 对象。这个使用了代理模式，将 NativeMethodAccessorImpl 交给了 DelegatingMethodAccessorImpl 类进行了代理，进入到代理类 DelegatingMethodAccessorImpl 中可以看到： 从上面的红色方框可以看到，在类 DelegatingMethodAccessorImpl 的构造方法中将参数赋值给类中的 delegate 属性，所有上所说的 ma.invoke 最终会进入到 DelegatingMethodAccessorImpl 代理类的 invoke，方法里调用的是 delegate 属性的 invoke 方法，该属性声明的类型为抽象类 MethodAccessorImpl，它有如下两个实现类： 按照上文所说的，这里的 delegate 属性是 NativeMethodAccessorImpl 对象，那么就进入到 NativeMethodAccessorImpl 的 invoke 方法中，方法源码如下： 12345678public Object invoke(Object var1, Object[] var2) throws IllegalArgumentException, InvocationTargetException &#123; if (++this.numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(this.method.getDeclaringClass())) &#123; MethodAccessorImpl var3 = (MethodAccessorImpl)(new MethodAccessorGenerator()).generateMethod(this.method.getDeclaringClass(), this.method.getName(), this.method.getParameterTypes(), this.method.getReturnType(), this.method.getExceptionTypes(), this.method.getModifiers()); this.parent.setDelegate(var3); &#125; return invoke0(this.method, var1, var2);&#125; 类 NativeMethodAccessorImpl 的 invoke 方法会先判断此次调用是否超过 ReflectionFactory.inflationThreshold() 方法返回的阈值（PS：默认的阈值大小为 15），如果超过了该阈值，则使用方法访问生成器重新生成一个 MethodAccessorImpl，并将 DelegatingMethodAccessorImpl 的 delegate 属性指向这个新生成的 MethodAccessorImpl 对象。从 Reflectionfactory 工厂类的一下注释： 可以得知 JVM 初次加载字节码实现反射的时候，使用 Method.invoke 和 Constructor.newInstance 方式加载所花费的时间是使用原生代码加载所花费的时间的 3 - 4 倍。这也就是我们平常说为什么频繁使用反射的应用需要花费更多的时间。JVM 作者们为了避免这种花费较长的加载时间，我们在第一次加载的时候重用了 JVM 的入口，之后切换到字节码实现的实现。正如注释所述，在 MethodAccessor 接口的实现中，有两个不同的版本，一个 Java 实现的，一个是 Native 实现的。Java 版本实现的版本在初始化的时需要比较多的时间，但长久来说性能会更好一些；而 Native 版本则正好相反，在初始化时相对较快，但是在运行一段时间之后性能就不如 Java 版本的了。为了权衡两种版本的特性，sun 公司的 JDK 使用了 inflation 机制，让 Java 方法在被反射调用时，开头的几次调用使用 native 版，等反射调用次数超过阈值时则生成一个专用的 MethodAccessor 实现类，生成其中的 invoke 方法的字节码，以后对该 Java 方法的反射调用就会使用 Java 版。 总结本文主要介绍反射调用 set(Object obj, Object value) 方法和 invoke(Object obj, Object... args) 方法的底层实现，由于水平有限本人暂时还没有能力分析 JVM 的实现，这里只分析到最终 native 方法的调用。底层会依赖到 Unsafe 类来执行一些低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升 Java 运行效率、增强 Java 语言底层资源操作能力方面起到了很大的作用。对于属性反射的方法 setXXX 和 getXXX 的实现分别对应 Unsafe 类的 putXXX 和 getXXX 方法，也就是说完全依赖 Unsafe 类中的 native 方法来实现的；对于方法反射的方法 invoke 底层调用的是 NativeMethodAccessorImpl 类的 invoke0 的 native 方法来实现的。对于反射构造器调用的实现，读者可以自己进入其源码进行分析，大体上和反射方法调用的实现类似。 参考文章 JAVA深入研究——Method的Invoke方法。]]></content>
      <categories>
        <category>Java</category>
        <category>反射</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 反射机制（一）]]></title>
    <url>%2Fpost%2F102cd3d9.html</url>
    <content type="text"><![CDATA[前言在 Java 中有两种方式可以让我们在运行时识别对象和类的信息。一种是 RTTI（运行时类型识别：Run-Time Type Identification），它假定了我们在编译时已经知道了所有的类型；另一种是我们本文要说的反射机制，它允许我们在运行时获取和使用类的信息。无论是 RTTI 还是反射，其本质都是一样的，都是去动态的获取类的信息。它们唯一不同的是，RTTI 在编译时期知道要解析的类型，而反射是在运行时才知道要解析的类型。 反射概述反射就是把 Java 类中的各个部分（属性、方法、构造方法等）映射成一个个对象。Class 类与 java.lang.reflect 类库一起对反射的概念提供了支持，类库中包含了 Field、Method 及 Constructor 类，每个类都实现了 Member 接口。这些类型的对象都是由 JVM 运行时创建的，用来表示未知类里对应的成员。这样我们就可以使用 Constructor 创建新的对象，用 get 和 set 方法读取和修改类中与 Field 对象关联的字段，用 invoke 方法调用类中与 Method 对象关联的方法等。Java 反射机制是在运行状态中的，对于任意一个类我们可以通过反射获取这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。重要的是，要认识到反射机制并没有什么特别之处，当我们通过反射和一个未知类型的对象打交道时，JVM 只是简单的对这个对象做检查，看它属于哪个类，在用它做其它事情之前必须先加载那个类 Class 对象。所以那个类的字节码文件对象对于 JVM 来说必须是可获取的，要么在本地机器上，要么通过网络获取。 反射 API 的使用想要通过反射获取一个类的信息之前，首先要先获取这个类的 Class 对象，在 Java 中所有类型都有与之关联的 Class 对象。 获取类的 Class 对象在 Java 中获取一个类的 Class 对象有三种方式：第 ① 种 使用 Class 类的 forName 静态方法，当我们知道一个类的全路径时，可以通过 Class.forName 方法获取类的 Class 对象。 12Class stringClass = Class.forName("java.lang.String");System.out.println(stringClass); 运行结果 1class java.lang.String 第 ② 种 使用 .class 获取，这种方式只适合在编译前就已经知道了要操作的 Class。 12Class stringClass = String.class;System.out.println(stringClass); 运行结果 1class java.lang.String 第 ③ 种 使用 getClass() 方法获取 12Class stringClass = "mghio".getClass();System.out.println(stringClass); 运行结果 1class java.lang.String 通过反射创建类对象通过反射创建类对象有两种方式： 第 ① 种 通过调用 Class 对象的 newInstance() 方法创建 12Class&lt;Person&gt; personClass = Person.class;Person person = personClass.newInstance(); 第 ② 种 通过调用 Constructor 对象的 newInstance() 方法创建 123Class&lt;Person&gt; personClass = Person.class;Constructor personConstructor = personClass.getConstructor();Person person = (Person) personConstructor.newInstance(); 两者的区别是，通过 Class 的 newInstance 方法只能通过无参构造方法创建，这就要求这个类必须有一个无参的构造方法，而通过 Constructor 的 newInstance 可以指定参数来选择特定的构造方法来创建对象。以下代码就是指定参数然后通过特定的构造方法创建对象的。 123Class&lt;Person&gt; personClass = Person.class;Constructor personConstructor = personClass.getConstructor();Person person = (Person) personConstructor.newInstance("mghio", "中国上海"); 通过反射获取类的属性Class 类提供了两种方式获取一个类的属性。第 ① 种 是通过 Class 对象的 getFields 方法获取类的属性，该方法只能获取类的 public 属性。 123Class&lt;Person&gt; personClass = Person.class;Field[] fields = personClass.getFields();System.out.println(Arrays.toString(fields)); 运行结果 12[public java.lang.String cn.mghio.blogmghiocode.reflect.Person.id, public java.lang.String cn.mghio.blogmghiocode.reflect.Person.name] 第 ② 种 是通过 Class 对象的 getDeclaredFields 方法获取类的属性，该方法可以获取类的所有属性（包括 private 修饰的属性）。 123Class&lt;Person&gt; personClass = Person.class;Field[] fields = personClass.getDeclaredFields();System.out.println(Arrays.toString(fields)); 运行结果 1234[public java.lang.String cn.mghio.blogmghiocode.reflect.Person.id, public java.lang.String cn.mghio.blogmghiocode.reflect.Person.name, protected java.lang.Integer cn.mghio.blogmghiocode.reflect.Person.age, private java.lang.String cn.mghio.blogmghiocode.reflect.Person.address] 通过反射获取类的方法Class 也提供了两种方式获取类的方法。第 ① 种 是通过 Class 对象的 getMethods 方法获取类的方法（包括继承而得的方法）。 123Class&lt;Person&gt; personClass = Person.class;Method[] methods = personClass.getMethods();System.out.println(Arrays.toString(methods)); 运行结果 12345[public java.lang.String cn.mghio.blogmghiocode.reflect.Person.toString(), public java.lang.String cn.mghio.blogmghiocode.reflect.Person.getAddress(), ...public final native java.lang.Class java.lang.Object.getClass(), public final native void java.lang.Object.notify()] 第 ② 种 是通过 Class 对象的 getDeclaredMethods 方法获取类的方法（只包含类中定义的方法，不包含继承而来的方法）。 123Class&lt;Person&gt; personClass = Person.class;Method[] methods = personClass.getDeclaredMethods();System.out.println(Arrays.toString(methods)); 运行结果 12345[public java.lang.String cn.mghio.blogmghiocode.reflect.Person.toString(), public java.lang.String cn.mghio.blogmghiocode.reflect.Person.getAddress(), ... protected void cn.mghio.blogmghiocode.reflect.Person.protectedMethod(), private void cn.mghio.blogmghiocode.reflect.Person.privateMethod()] 从以上结果可以看出这个方法只获取当前类中定义的方法，包含 private 方法，不会获取从父类中继承而来的方法。 通过反射获取类的构造方法Class 也提供了两种方式获取类的构造方法。第 ① 种 是通过 Class 对象的 getConstructors 方法获取类的构造方法（只能获取当前类的 public 构造方法）。 123Class&lt;Person&gt; personClass = Person.class;Constructor[] constructors = personClass.getConstructors();System.out.println(Arrays.toString(constructors)); 运行结果 1[public cn.mghio.blogmghiocode.reflect.Person(java.lang.String,java.lang.String,java.lang.Integer,java.lang.String)] 第 ② 种 是通过 Class 对象的 getDeclaredConstructors 方法获取类的构造方法（只包含类中定义的所有构造方法）。 123Class&lt;Person&gt; personClass = Person.class;Constructor[] constructors = personClass.getDeclaredConstructors();System.out.println(Arrays.toString(constructors)); 运行结果 123[public cn.mghio.blogmghiocode.reflect.Person(java.lang.String,java.lang.String,java.lang.Integer,java.lang.String), protected cn.mghio.blogmghiocode.reflect.Person(java.lang.String,java.lang.String), private cn.mghio.blogmghiocode.reflect.Person()] 通过反射获取类的类名Class 类提供了两种方式获取类的类名。第 ① 种 是通过 getName 方法获取类的全限定名（包含包名）。 123Class&lt;Person&gt; personClass = Person.class;String fullPersonClassName = personClass.getName();System.out.println(fullPersonClassName); 运行结果 1cn.mghio.blogmghiocode.reflect.Person 第 ② 种 是通过 Class 对象的 getSimpleName 方法获取类的类名（不包含包名）。 123 Class&lt;Person&gt; personClass = Person.class;String fullPersonClassName = personClass.getSimpleName();System.out.println(fullPersonClassName); 运行结果 1Person 通过反射获取类的修饰符可以通过 Class 类来获取一个类的修饰符，也就是我们熟知的 public、protected、private 等关键字，通过调用 getModifiers 方法来获取一个类的修饰符。 123Class&lt;Person&gt; personClass = Person.class;int modifyInt = personClass.getModifiers();System.out.println(modifyInt); 运行结果 11 返回 1 表示类 Person 的修饰符为 public，修饰符在 Modifier 类中都被包装成一个 int 类型的数字，部分修饰符定义如下 1234567891011121314151617/** * The &#123;@code int&#125; value representing the &#123;@code public&#125; * modifier. */public static final int PUBLIC = 0x00000001;/** * The &#123;@code int&#125; value representing the &#123;@code private&#125; * modifier. */public static final int PRIVATE = 0x00000002;/** * The &#123;@code int&#125; value representing the &#123;@code protected&#125; * modifier. */public static final int PROTECTED = 0x00000004; 通过反射获取类的包信息Class 对象通过 getPackage 方法获取类的包相关信息，可以使用 Class 对象通过如下的方式获取包信息 123Class&lt;Person&gt; personClass = Person.class;Package packageClazz = personClass.getPackage();System.out.println(packageClazz.getName()); 运行结果 1cn.mghio.blogmghiocode.reflect 通过反射获取类的父类可以通过 Class 类来获取一个类的父类，通过调用 getModifiers 方法来获取一个类的父类。 123Class&lt;Person&gt; personClass = Person.class;Class superclass = personClass.getSuperclass();System.out.println(superclass.getName()); 运行结果 1java.lang.Object 以上运行结果表示 Person 类的父类是 Object 类，可以看到 superclass 对象其实就是一个 Class 类的实例，所以也可以继续在这个对象上进行反射操作。 通过反射获取类的实现接口可以通过 Class 类来获取一个类的父类，通过调用 getInterfaces 方法来获取一个类实现的接口。 123Class&lt;Person&gt; personClass = Person.class;Class&lt;?&gt;[] interfaces = personClass.getInterfaces();System.out.println(Arrays.toString(interfaces)); 运行结果 1[interface cn.mghio.blogmghiocode.reflect.IPerson] 在 Java 中一个类可以实现多个接口，因此 getInterfaces 方法返回一个 Class 数组，在 Java 中接口也同样有对应的 Class 对象。这个方法需要注意的是，getInterfaces 方法仅仅只返回当前类所实现的接口。当前类的父类如果实现了接口，这些接口是不会在返回的 Class 集合中的，尽管实际上当前类其实已经实现了父类接口。 通过反射获取泛型信息当我们在声明一个类或者接口的时候可以指定它可以参数化，常用的 List 接口就是一个参数化接口的例子。比如想要检查 List 接口的参数化类型，我们是没有办法能知道它具体的参数化类型是什么。这个类型就可以是一个应用中所有的类型。但是，当你检查一个使用了被参数化的类型的变量或者方法，你可以获得这个被参数化类型的具体参数。第 ① 种 泛型方法返回类型 当你获得了 Method 对象，那么就可以获取到这个方法的泛型返回类型信息。如果方法是在一个被参数化类型之中（例如: T foo()），那么将无法获得它的具体类型，但是如果方法返回的是一个泛型类（例如：List foo()），那么就可以获得这个泛型类的具体参数化类型。下面这个例子中的类定义了一个返回类型是泛型的方法。 12345678910111213141516/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemo &#123; protected List&lt;Integer&gt; stringList = Arrays.asList(2, 55, 3, 90, 81); public List&lt;Integer&gt; getStringList()&#123; return this.stringList; &#125;&#125; 我们可以获取上面这个类 ReflectGenericDemo 的方法 getStringList 的泛型返回类型。 1234567891011121314151617181920212223242526/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemoTests &#123; @Test public void testMethodReturnGenericType() throws NoSuchMethodException &#123; Class&lt;ReflectGenericDemo&gt; reflectClass = ReflectGenericDemo.class; Method method = reflectClass.getMethod("getStringList", (Class&lt;?&gt;) null); Type returnType = method.getGenericReturnType(); if (returnType instanceof ParameterizedType) &#123; ParameterizedType type = (ParameterizedType) returnType; Type[] typeArguments = type.getActualTypeArguments(); for (Type typeArgument : typeArguments) &#123; Class typeArgumentClass = (Class) typeArgument; System.out.println("typeArgumentClass = " + typeArgumentClass); &#125; &#125; &#125;&#125; 运行结果 1typeArgumentClass = class java.lang.Integer typeArguments 数组只有一个值，这个数组中唯一的值是 Integer 的 Class 类的实例，同时 Class 类也实现了 Type 接口。 第 ② 种 泛型方法返回类型 泛型方法参数类型，我们也可以通过反射来获取方法参数的泛型类型。 12345678910111213141516/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemo &#123; protected List&lt;Integer&gt; stringList = Arrays.asList(2, 55, 3, 90, 81); public void setStringList(List&lt;Integer&gt; stringList) &#123; this.stringList = stringList; &#125;&#125; 可以通过以下方式获取方法参数的泛型类型。 12345678910111213141516171819202122232425262728/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemoTests &#123; @Test public void testMethodParameterGenericType() throws NoSuchMethodException &#123; Class&lt;ReflectGenericDemo&gt; reflectClass = ReflectGenericDemo.class; Method method = reflectClass.getMethod("setStringList", List.class); Type[] genericParameterTypes = method.getGenericParameterTypes(); for (Type genericParameterType : genericParameterTypes) &#123; if (genericParameterType instanceof ParameterizedType) &#123; ParameterizedType parameterizedType = (ParameterizedType) genericParameterType; Type[] parameterArgTypes = parameterizedType.getActualTypeArguments(); for (Type parameterArgType : parameterArgTypes) &#123; Class parameterArgClass = (Class) parameterArgType; System.out.println("parameterArgClass = " + parameterArgClass); &#125; &#125; &#125; &#125;&#125; 运行结果 1parameterArgClass = class java.lang.Integer 第 ③ 种 泛型变量类型 可以通过反射来访问类中定义变量的泛型类型，不管这个变量是一个类的静态成员变量或是实例成员变量。 123456789101112/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemo &#123; private List&lt;Integer&gt; stringList = Arrays.asList(2, 55, 3, 90, 81);&#125; 我们可以通过以下代码来获取类 ReflectGenericDemo 的私有变量 stringList 的泛型变量类型。 1234567891011121314151617181920212223242526/** * @author mghio * @date: 2019-12-29 * @version: 1.0 * @description: 通过反射获取泛型信息 * @since JDK 1.8 */public class ReflectGenericDemoTests &#123; @Test public void testFieldGenericType() throws NoSuchFieldException &#123; Class&lt;ReflectGenericDemo&gt; reflectClass = ReflectGenericDemo.class; Field field = reflectClass.getDeclaredField("stringList"); Type type = field.getGenericType(); if (type instanceof ParameterizedType) &#123; ParameterizedType fieldGenericType = (ParameterizedType) type; Type[] fieldGenericTypes = fieldGenericType.getActualTypeArguments(); for (Type genericType : fieldGenericTypes) &#123; Class fieldGenericTypeClass = (Class) genericType; System.out.println(fieldGenericTypeClass); &#125; &#125; &#125;&#125; 运行结果 1class java.lang.Integer 数组 fieldGenericTypes 只有一个元素，它代表类 Integer 的 Class 类的实例。我们可以得出通过反射获取泛型信息的套路都是先获取 Class 类对象，然后通过该对象获取相应的类，如果是要获取变量的泛型信息就先获取到 Field 类，如果是要获取方法的泛型信息就先获取到 Method 类，最后再通过是否是 ParameterizedType 的实例来判断是否是泛型类型。 总结我们介绍了 Java 泛型的基本使用，反射可能在我们日常的工作中不怎么接触到，但是，在很多框架中都有运用，比如，Spring 的 IOC/DI 也是反射；还有 JDBC 的 classForName 也是反射。所有深入了解 Java 反射机制很有必要。 方法 描述 Constructor getConstructor(Class[] params) 根据构造方法的参数，返回一个 public 类型的构造方法 Constructor getConstructors() 返回所有 public 类型的构造方法数组 Constructor getDeclaredConstructor(Class[] params) 根据构造方法的参数，返回一个具体的构造方法（所有的类型） Constructor getDeclaredConstructors() 返回该类中所有的构造方法数组（所有的类型） Method getMethod(String name, Class[] params) 根据方法名和参数，返回一个 public 类型的方法 Method[] getMethods() 返回所有 public 类型的方法数组 Method getDeclaredMethod(String name, Class[] params) 根据方法名和参数，返回一个具体的方法（所有的类型） Method[] getDeclaredMethods() 返回该类中的所有的方法数组（所有的类型） Field getField(String name) 根据变量名，返回一个 public 类型的成员变量 Field[] getFields() 返回 public 类型的成员变量的数组 Field getDeclaredField(String name) 根据变量名，返回一个成员变量（所有的类型） Field[] getDelcaredField() 返回所有成员变量组成的数组（所有的类型）]]></content>
      <categories>
        <category>Java</category>
        <category>反射</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用命令]]></title>
    <url>%2Fpost%2F817c7d82.html</url>
    <content type="text"><![CDATA[1.1 前言作为 Java 后端开发的我们，开发的项目绝大部分都是部署在 Linux 系统上的，因此熟练使用一些常用的 Linux 命令不管是对于日常开发、服务部署或者查找问题都非常有用。以下整理了一些常用的 Linux 常用命令。 1.2 文件管理1.2.1 ls 命令ls 命令是 Linux 最常用的命令之一，其功能是列出指定目录下的内容及其相关属性信息。默认状态下，ls 命令会列出当前目录的内容，它也可以带上一些参数来实现更多的功能。语法格式：ls [选项] [文件]常用参数 参数 描述 -a 显示所有文件及目录（包括以 . 开头的隐藏文件） -l 使用长格式列出文件及目录 -r 将文件以相反次序显示（默认按照英文字母次序） -t 根据最后的修改时间排序 -A 同 -a，但是不列出 .（当前目录）以及 ..（父级目录） -S 根据文件大小排序 -R 递归列出所有子目录 Examples 12345ls -a # 列出所有文件（包括隐藏文件）ls -l # 列出文件的详细信息ls / # 列出根目录（/）下的所有目录ls -ltr s* # 列出当前目录下所有名称是 s 开头的文件ls -AS # 列出当前目录下所有文件及目录并以文件大小进行排序 1.2.2 chown 命令Linux 是一种多用户多任务的操作系统，所有的文件都有一个拥有者。chown 命令就是用来将指定文件的拥有者改为指定的用户或者组（PS：用户和组都可以是名称或者其 ID），文件是以空格分开的要改变权限的文件列表，支持通配符。语法格式：chown [参数]常用参数 参数 描述 -R 对当前目录下的所有文件与子目录进行相同的拥有者变更 -c 若该文件拥有者确实已经更改，才显示其更改动作 -f 若该文件拥有者无法更改也不显示错误信息 -v 显示拥有者变更的详细信息 –version 显示版本 Examples 123456789101112131415# 将 change_usergroup_and_user_demo.txt 文件用户组与用户都改为 mghio[root@mghio ~]# ll change_usergroup_and_user_demo.txt-rw-r--r-- 1 root root 56 Dec 21 10:17 change_usergroup_and_user_demo.txt[root@mghio ~]# chown mghio:mghio change_usergroup_and_user_demo.txt[root@mghio ~]# ll change_usergroup_and_user_demo.txt-rw-r--r-- 1 mghio mghio 56 Dec 21 10:17 change_usergroup_and_user_demo.txt# 显示其更改动作[root@mghio ~]# ll change_usergroup_and_user_demo.txt-rw-r--r-- 1 root root 45 Dec 21 10:30 change_usergroup_and_user_demo.txt[root@mghio ~]# chown -c mghio:mghio change_usergroup_and_user_demo.txtchanged ownership of 'change_usergroup_and_user_demo.txt' to mghio:mghio 1.2.3 cp 命令cp 命令为英文单词 copy 的缩写，功能为复制文件或目录。cp 命令可以将多个文件复制到一个具体的文件名或者一个已经存在的目录下，也可以同时复制多个文件到一个指定的目录中。语法格式：cp [参数] [文件]常用参数 参数 描述 -f 若目标文件已经存在，则直接覆盖原文件 -i 若目标文件已经存在，则会询问是否覆盖 -p 保留原文件或者目录的属性 -r 递归复制文件和目录 -d 当复制符号链接时，把目标文件或者目录也建立符号链接，并指向和原文件或目录连接的原始文件或目录 -l 对原文件建立连接，而非复制文件 -s 对原文件建立符合连接，而非复制文件 -b 覆盖已经存在的文件目标前将目标文件备份 -v 详细显示 cp 命令的执行过程 Examples 12345678# 复制目录cp -R source_dir1 dest_dir2/# 将文件 demo1.txt 改名为 demo2.txtcp -f demo1.txt demo2.txt# 复制多个文件cp -r file1 file2 file3 dest_dir 1.2.4 mkdir 命令mkdir 命令是 make directories 的缩写，其功能是用来创建目录。默认状态下，如果要创建的目录如果已经存在，则提示已存在，而不会继续创建目录。所有我们在创建目录时，应该要保证新建的目录与它所在的目录下的文件没有重名，同时该命令还可以一次性创建多个目录。语法格式：mkdir [参数] [目录]常用参数 参数 描述 -p 递归创建多级目录 -m 建立目录的同时设置目录的权限 -v 显示目录的常见过程 Examples 1234567891011# 在当前目录下，创建一个名为 dir 的子目录mkdir dir# 在目录 /usr/mghio 下建立子目录 dir，并且设置文件属主有读（4）、写（2）和执行（1）权限，其它用户无法访问mkdir -m 700 /usr/mghio/dir# 一次性创建目录 dir1、dir2、dir3mkdir dir1 dir2 dir3# 递归创建目录mkdir -p /mghio/dir 1.2.5 mv 命令mv 命令为英文单词 move 的缩写，功能为移动文件或者对文件重新命名。mv 与 cp 命令的结果不同。mv 命令是将文件整个移走，文件名发生改变，但是个数没有增加。而 cp 命令是对文件进行复制操作，文件个数增加。语法格式：mv [参数]常用参数 参数 描述 -i 若存在同名文件，则会询问是否覆盖 -f 覆盖已经存在的文件时，不进行任何提示 -b 当文件存在时，覆盖前为其创建一个备份 -u 当原文件比目标文件新或者目标文件不存在时，才会执行 Examples 12345678# 将文件 file1 重命名为 file2mv file1 file2# 将文件 file 移动到目录 dest_dirmv file /dest_dir# 将目录 dir 下的所有文件移到当前目录mv /dir/* . 1.3 文档编辑1.3.1 cat 命令在 Linux 系统中有很多用于查看文件内容的命令，cat 命令就是用来查看内容较少的纯文本内容文件的。当文件内容较大时，文本内容会在屏幕上快速滚屏，我们通常都看不到所显示的内容。对于较长文件内容可以按 Ctrl+S 键来停止滚屏，以及 Ctrl+Q 键来恢复滚屏，按 Ctrl+C（中断）键则可以终止该命令的执行。对于大文件，推荐使用下文说的 more 命令。语法格式：cat [参数] [文件]常用参数 参数 描述 -n 显示行数（一个空行显示一个编号） -s 显示行数（多个空行只算一个编号） -b 显示行数（空行不编号） -E 每行结束显示 $ 符号 -T 将 TAB 字符显示为 ^| 符号 –version 显示版本信息 Examples 1234567891011121314151617# 查看文件内容 cat demo.txt# 查看文件内容，并显示行号cat -n demo.txt# 产查看文件的内容，并添加行数编号后输出到另外一个文件中cat -n mghio.log &gt; mghio_with_line_number.log# 清空文件内容cat /dev/null &gt; /mghio/demo.txt# 持续写入文件内容，直到碰到 `EOF` 符号后结束并保存cat &gt; demo.txt &lt;&lt; EOF&gt; Hello, World&gt; mghio&gt; EOF 1.3.2 more 命令more 命令用于将内容较长的文本文件内容（无法在一屏显示完）进行分屏显示，并且支持显示时定位关键字。对于内容比较少的文本内容推荐使用 cat 命令查看。语法格式：more [参数] [文件]常用参数 参数 描述 -num 指定每屏显示的内容行数 -l more 在通常情况下把 ^L 当遇到这个字符就会暂停，这个参数可以屏蔽这个特性 -f 计算实际的行数，而非自动换行的行数 -p 先清除屏幕在显示文本文件的剩余内容 -c 与 -p 相似，不滚屏，先显示内容在清除内容 -s 多个空行压缩成一行显示 -u 禁止下划线 +/pattern 在每个文档显示前搜寻该字（pattern），然后该字串之后开始显示 +num 从第 num 行开始显示 查看时的命令操作 命令 描述 Space 键 显示文本的下一屏内容 Enter 键 向下 n 行，需要定义，默认为 1 行 \ 键 接着输入一个模式，可以在文本中寻找下一个相匹配的模式 H 键 显示帮助屏 B 键 显示上一屏内容 Q 键 退出 more 命令 Ctrl + F、空格键 向下滚动一屏 Ctrl + B 返回上一屏 = 输出当前的行号 :f 输出文件名和当前的行号 V 调用 vi 编辑器 ! 调用 Shell， 并执行命令 Examples 1234567891011# 显示文件 demo.txt 的内容和已显示的百分比，显示之前先清屏more -dc demo.txt# 显示文件 demo.txt 的内容，每 10 行显示一次，而且在显示之前先清屏more -c -10 demo.txt# 显示文件 demo.txt 的内容，每 5 行显示一次，而且在显示之后再清屏more -p -5 demo.txt# 从第 20 行开始显示文件 demo.txt 的内容more +20 demo.txt 1.3.3 tail 命令tial 命令用于显示文件尾部的内容，默认在屏幕上显示指定文件的末尾 10 行。如果给定的文件不止一个，则在显示的每个文件前面加一个文件名标题，如果没有指定文件或者文件名为 -，则读取标准输入。语法格式：tail [参数]常用参数 命令 描述 –retry 即是在 tail 命令启动时，文件不可访问或者文件稍后变得不可访问，都始终尝试打开文件。使用此选项时需要与 —f 一起使用 -c 输出文件尾部的 N（N 为整数） 个字节内容 -f 显示文件最新追加的内容 -n 输出文件的尾部 N（N 为整数） 行内容 Examples 12345678# 显示文件 demo.txt 的最后 10 行tail demo.txt# 显示文件 demo.txt 的内容，从第 20 行至文件末尾tail +20 demo.txt# 显示文件 demo.txt 的最后 10 个字符tail -c 10 demo.txt 1.3.4 grep 命令grep 是英文 global search regular expression and print out the line 的简称。是全面搜索正则表达式，并将其打印出来。这个命令可以结合正则表达式使用，使用非常广泛。grep 命令的选项用于对搜索过程的补充，而其命令的模式十分灵活，可以是变量、字符串、正则表达式，需要注意的是，当我们的模式中包含了空格的话，要使用双引号将其引起来。语法格式：grep [参数]参数列表 命令 描述 -i 搜索时，忽略大小写 -c 只输出匹配行的数量 -l 只列出符合匹配的文件名，不列出具体匹配行 -n 列出所有匹配行，显示行号 -h 查询多文件时不显示文件名 -s 不显示不存在、没有匹配文本的错误信息 -v 显示不包含匹配文本的所有行 -w 匹配整词 -x 匹配整行 -r 递归搜索 -q 禁止输出任何结果，已退出状态表示搜索是否成功 -b 打印匹配行距文件头部的偏移量（以字节为单位） -o 与 -b 结合使用，打印匹配的词距文件头部的偏移量（以字节为单位） Examples 12345678910111213141516171819# 支持多文件查询并支持使用通配符[root@mghio ~]# grep mghio file_* /usr/demofile_1:mghiofile_1:mghioddkjflkdjfdlkfjlsdkjfile_2:mghiofile_4:dkfjlmghioejfkdsfile_4:mghio djftgffile_4:twetmghioedkfgj# 列出所有的匹配行，并显示行号[root@mghio ~]# grep mghio file_* /usr/demofile_1:1:mghiofile_1:3:mghioddkjflkdjfdlkfjlsdkjfile_2:4:mghiofile_4:8:dkfjlmghioejfkdsfile_4:11:mghio djftgffile_4:20:twetmghioedkfgj 1.3.5 echo 命令echo 命令用于在终端设备上输出字符串或者变量提取后的值，这是在 Linux 系统中最常用的几个命令之一，在 Linux 系统中，人们一般使用在变量前加上 $ 符号的方式提取出变量的值，例如：$PATH，然后再用 echo 命令予以输出。或者直接使用 echo 命令输出一段字符串到屏幕上，起到给用户提示的作用。语法格式：echo [参数] [字符串]常用参数 命令 描述 -n 不输出结尾的换行符 -e”\a” 发出警告音 -e”\b” 删除前面的一个字符 -e”\c” 结尾不加换行符 -e”\f” 换行，光标仍然停留在原来的坐标位置 -e”\n” 换行，光标移至行首 -e”\r” 光标移至首行，但是不换行 -E 禁止反斜杠转义，与 -e 参数功能相反 Examples 123456789101112131415# 输出一段字符串[root@mghio ~]# echo "mghio.cn" mghio.cn# 输出变量提取后的值[root@mghio ~]# echo $PATH/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin# 对内容进行转义，不让$符号的提取变量值功能生效[root@mghio ~]# echo \$PATH$PATH# 使用反引号符执行命令，并输出其结果到终端[root@mghio ~]# echo `date`Sat Dec 21 15:30:24 CST 2019 1.4 网络通讯1.4.1 ssh 命令ssh 命令是 openssh 套件中的客户端连接工具，可以给予 ssh 加密协议实现安全的远程登录服务器，实现对服务器的管理。语法格式：ssh [参数] [主机]常用参数 命令 描述 -1 强制使用 ssh 协议版本 1 -2 强制使用 ssh 协议版本 2 -4 强制使用 IPv4 地址 -6 强制使用 IPv6 地址 -A 开启认证代理连接转发功能 -a 关闭认证代理连接转发功能 -b&lt;IP地址&gt; 使用本机指定的地址作为对位连接的源 IP 地址 -C 请求压缩所有数据 -F&lt;配置文件&gt; 指定 ssh 指令的配置文件，默认的配置文件为 /etc/ssh/ssh_config -f 后台执行 ssh指令 -g 允许远程主机连接本机的转发端口 -i&lt;身份文件&gt; 指定身份文件（即私钥文件） -l&lt;登录名&gt; 指定连接远程服务器的登录用户名 -N 不执行远程指令 -o&lt;选项&gt; 指定配置选项 -p&lt;端口&gt; 指定远程服务器上的端口 -q 静默模式，所有的警告和诊断信息被禁止输出 Examples 12345# 登录远程服务器[root@mghio ~]# ssh 112.67.239.127# 用 mghio 用户连接远程服务器[root@linuxcool ~]# ssh -l mghio 112.67.239.127 1.4.2 sftp 命令sftp 命令全称是 Secure File Transfer Protocol。是一个交互式的文件传输程序，sftp 命令的运行和使用与 ftp 相似，但是 sftp 命令对传输的所有信息使用 ssh 加密 ，它还支持公钥认证和压缩等功能。语法格式：sftp [参数] [IP或主机名]常用参数 命令 描述 -B 指定传输文件缓冲区的大小 -l 使用 ssh 协议版本 1 -b 指定批处理文件 -C 使用压缩 -o 指定 ssh 选项 -F 指定 ssh 配置文件 -R 指定一次可以容忍多少请求数 Examples 12345678# 使用 sftp 命令连接到服务器[root@mghio ~]# sftp 112.67.239.127# 指定传输文件是缓冲区大小[root@mghio ~]# sftp -B 256 112.67.239.127# 在传输过程中使用压缩[root@linuxcool ~]# sftp -C 112.67.239.127 1.4.3 telnet 命令telnet 命令的功能是远端登入，执行 telnet 指令开启终端机阶段作业，并登入远端主机。telnet 命令可以帮助你从这台路由器远程登陆到远端开启了 telnet 服务的设备，包括路由器、交换机、Linux 服务器等，并且配置当前路由器的 telnet 服务。语法格式：telnet [参数]常用参数 命令 描述 -8 允许使用 8 位字符资料，包括输入与输出 -a 尝试自动登入远端系统 -b 使用别名指定远端主机名称 -c 不读取用户专属目录里的 .telnetrc 文件 -d 启动排错模式 -e 设置脱离字符 -E 滤除脱离字符 -f 此参数的效果和指定 -F 参数相同 -F 使用 Kerberos V5 认证时，加上此参数可把本地主机的认证数据上传到远端主机 -k 使用 Kerberos 认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名 -K 不自动登入远端主机 -l 指定要登入远端主机的用户名称 -L 允许输出8位字符资料 -n 指定文件记录相关信息 -r 使用类似 rlogin 指令的用户界面 -S 设置 telnet 连线所需的 IP TOS 信息 -x 假设主机有支持数据加密的功能，就使用它 -X 关闭指定的认证形态 Examples 12345# 登录远程主机[root@mghio ~]# telnet 112.67.239.127# 连接本地主机，端口号为 23[root@mghio ~]# telnet localhost 23 1.4.4 netstat 命令netstat 命令用于显示各种网络相关信息，如网络连接、路由表、接口状态、多播成员等。从整体上看，netstat 的输出结果为两部分：一个是 Active Internet connections 称为 有源 TCP 连接，其中 Recv-Q 和 Send-Q 指 %OA 的是接收队列和发送队列。另一个是 Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。语法格式：netstat [参数]常用参数 命令 描述 -a 显示所有连线中的 Socket -p 显示正在使用 Socket 的程序识别码和程序名称 -u 显示 UDP 传输协议的连线状况 -i 显示网络界面信息表单 -n 直接使用 IP 地址，不通过域名服务器 Examples 123456789101112# 显示详细的网络状况[root@mghio ~]# netstat -a# 显示当前 UDP 连接状况[root@mghio ~]# netstat -nu# 显示网卡列表[root@mghio ~]# netstat -iKernel Interface table Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 1500 0 181864 0 0 0 141278 0 0 0 BMRU lo 16436 0 3362 0 0 0 3362 0 0 0 LRU]]></content>
      <categories>
        <category>Linux笔记</category>
      </categories>
      <tags>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 多线程基础（二）]]></title>
    <url>%2Fpost%2F4ea48fa7.html</url>
    <content type="text"><![CDATA[简介在上篇 Java 多线程基础（一） 我们提到了一些线程的常用方法，这篇我们具体看看其中一些方法的使用以及方法的区别，让我们在工作中更好的使用。 wait 方法与 notify 方法在 Object 类中定义了 wait 方法和 notify 方法，wait 方法的作用是让当前线程进入等待状态，将当前线程置入 预执行队列，会在 wait 方法所在代码处停止执行，直到被通知或者被中断，在调用 wait 方法之前，线程必须获取该对象的锁，因此只能在同步方法或者同步代码块中调用 wait 方法，并且该方法会释放当前线程锁持有的锁。notify 方法是唤醒在当前对象上等待的单个线程，如果有多个线程等待，那么线程调度器会挑出一个 wait 的线程，对其发出 notify ，并使它等待获取该对象的对象锁，这意味着，即使收到了通知，线程也不会立即获取到对象锁，必须等待 notify 方法的线程释放锁才可以。和 wait 方法一样，notify 方法也只能在同步方法或者同步代码块中调用。它还有个相似的方法 notifyAll，它的作用是唤醒在当前对象上等待的所有线程。 下面通过一个生产者消费者来说明 wait 方法和 notify 方法的使用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * @author mghio * @date: 2019-12-14 * @version: 1.0 * @description: 线程 wait() 和 notify() 方法使用示例 * @since JDK 1.8 */public class ThreadWaitAndNotifyDemo &#123; public static void main(String[] args) &#123; Producer producer = new Producer(); producer.start(); new Consumer("Consumer One", producer).start(); new Consumer("Consumer Two", producer).start(); new Consumer("Consumer Three", producer).start(); new Consumer("Consumer Four", producer).start(); &#125; static class Producer extends Thread &#123; List&lt;String&gt; messageList = new ArrayList&lt;&gt;(2); @Override public void run() &#123; try &#123; while (true) &#123; Thread.sleep(2000); synchronized (messageList) &#123; String message = String.format("producer message [create time:%s]", LocalDateTime.now()); messageList.add(message); System.out.println("Producer " + getName() + " producer a msg: " + message); messageList.notify(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; String getMessage() &#123; synchronized (messageList) &#123; if (messageList.size() == 0) &#123; try &#123; messageList.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; return messageList.remove(0); &#125; &#125; &#125; static class Consumer extends Thread &#123; private Producer producer; public Consumer(String name, Producer producer) &#123; super(name); this.producer = producer; &#125; @Override public void run() &#123; while (true) &#123; String message = producer.getMessage(); System.out.println("Consumer " + getName() + " get a msg: " + message); &#125; &#125; &#125;&#125; 输出结果如下： 12345678Producer Thread-0 producer a msg: producer message [create time:2019-12-14T22:45:42.319]Consumer Consumer One get a msg: producer message [create time:2019-12-14T22:45:42.319]Producer Thread-0 producer a msg: producer message [create time:2019-12-14T22:45:44.324]Consumer Consumer Two get a msg: producer message [create time:2019-12-14T22:45:44.324]Producer Thread-0 producer a msg: producer message [create time:2019-12-14T22:45:46.325]Consumer Consumer Three get a msg: producer message [create time:2019-12-14T22:45:46.325]Producer Thread-0 producer a msg: producer message [create time:2019-12-14T22:45:48.328]Consumer Consumer Four get a msg: producer message [create time:2019-12-14T22:45:48.328] 消费者线程循环调用生产者的 getMessage 方法获取消息，如果消息列表 messageList 为空，则调用消息列表的 wait 方法让线程进入等待状态，生产者每隔 2 秒生成消息并放入消息列表 messageList 中，放入成功后调用 notify 方法唤醒一个处于 wait 状态的线程去消费消息，需要注意的是，在调用 wait 和 notify 方法时必须要先获得该对象的锁，上面的示例中是在 synchronized 代码块中调用的。 sleep 方法与 wait、notify 方法不同，sleep 方法定义在 Thread 类中，从方法名也可以知道，这个方法的作用就是让当前线程休眠，即调用该方法后当前线程会从运行状态(Running）状态进入到阻塞（休眠）状态（Blocked），同时该方法必须指定休眠的时间，当前线程的休眠时间会大于或者等于这个指定的休眠时间。当线程重新被唤醒时，线程会由阻塞状态（Blocked）变成就绪状态（Runnable），然后等待 CPU 的调度执行。sleep 方法的示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @author mghio * @date: 2019-12-14 * @version: 1.0 * @description: 线程 sleep() 方法使用示例 * @since JDK 1.8 */public class ThreadSleepDemo &#123; private static Object object = new Object(); public static void main(String[] args) &#123; MyThread myThreadOne = new MyThread("t1"); MyThread myThreadTwo = new MyThread("t2"); myThreadOne.start(); myThreadTwo.start(); &#125; static class MyThread extends Thread &#123; public MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; synchronized (object) &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(String.format("%s: %d", this.getName(), i)); if (i % 2 == 0) &#123; Thread.sleep(2000); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 输出结果如下： 12345678910t1: 0t1: 1t1: 2t1: 3t1: 4t2: 0t2: 1t2: 2t2: 3t2: 4 我们启动了两个线程 t1 和 t2，两个线程的 run 方法引用了同一个对象 object 的同步锁（synchronized (object)），虽然在第一个线程 t1 中当 i 被 2 整除时会调用 Thread.sleep(2000) 让当前线程休眠 2 s，但是此时线程 t2 也不会得到 cpu 的执行权去执行，因为 t1 线程调用 sleep 方法并没有释放object所持有的同步锁。如果我们注释掉 synchronized (object) 后再次执行该程序，线程 t1 和 t2 是可以交替执行的，注释之后的输出结果如下： 12345678910t2: 0t1: 0t1: 1t2: 1t1: 2t2: 2t2: 3t1: 3t2: 4t1: 4 yield 方法yield 方法定义在 Thread 类中，是线程特有的方法。此方法的主要作用是让步，它会使当前线程从运行状态（Running）变为就绪状态（Runnable），从而让其他具有同样优先级的处于就绪状态的线程获取到 CPU 执行权(PS: CPU 会从众多的处于就绪状态的线程里选择，也就是说，当前也就是刚刚的那个线程还是有可能会被再次执行到的，并不是说一定会执行其他线程而该线程在下一次中不会执行到)，但是，也并不能保证在当前线程调用 yield 之后，其它哪些具有相同优先级的线程就一定能获得执行权，也有可能是当前线程又进入到运行状态（Running）继续运行。yield 方法的示例代码如下： 123456789101112131415161718192021222324252627282930313233/** * @author mghio * @date: 2019-12-14 * @version: 1.0 * @description: 线程 yield() 方法使用示例 * @since JDK 1.8 */public class ThreadYieldDemo &#123; public static void main(String[] args) &#123; MyThread myThreadOne = new MyThread("t1"); MyThread myThreadTwo = new MyThread("t2"); myThreadOne.start(); myThreadTwo.start(); &#125; static class MyThread extends Thread &#123; MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(String.format("%s [%d] ---&gt; %d", this.getName(), this.getPriority(), i)); if (i % 2 == 0) &#123; yield(); &#125; &#125; &#125; &#125;&#125; 输出结果如下： 1234567891011121314151617181920t1 [5] ---&gt; 0t2 [5] ---&gt; 0t1 [5] ---&gt; 1t1 [5] ---&gt; 2t1 [5] ---&gt; 3t1 [5] ---&gt; 4t1 [5] ---&gt; 5t1 [5] ---&gt; 6t1 [5] ---&gt; 7t1 [5] ---&gt; 8t1 [5] ---&gt; 9t2 [5] ---&gt; 1t2 [5] ---&gt; 2t2 [5] ---&gt; 3t2 [5] ---&gt; 4t2 [5] ---&gt; 5t2 [5] ---&gt; 6t2 [5] ---&gt; 7t2 [5] ---&gt; 8t2 [5] ---&gt; 9 从以上输出结果可以看出，线程 t1 中的变量 i 在被 2 整除的时候，并没有切换到线程 t2 去执行，这也验证了我们上文说的，yield 方法虽然可以让线程由运行状态变成就绪状态，但是，它不一定会让其它线程获取 CPU 执行权从而进入到运行状态，即使这个其它线程和当前具有相同的优先级，yield 方法不会释放锁（证明方法只需将上面这个示例的 run 方法里面加上 synchronized (obj) 即可，此时 t2 线程会等到线程 t1 执行完毕后才会执行）。 join 方法在有些场景中我们需要在子线程去执行一些耗时的任务，但是我们的主线程又必须等待子线程执行完毕之后才能结束，那么此时就可以使用 join 方法了，该方法定义在 Thread 类中，方法的作用是：让主线程等待子线程执行结束之后才能继续执行，下面我们通过一个例子来看看： 123456789101112131415161718192021222324252627282930313233343536373839/** * @author mghio * @date: 2019-12-15 * @version: 1.0 * @description: 线程 join() 方法使用示例 * @since JDK 1.8 */public class ThreadJoinDemo &#123; public static void main(String[] args) &#123; try &#123; MyThread myThread = new MyThread("t1"); myThread.start(); myThread.join(); System.out.println(String.format("%s ---&gt; %s finish", LocalDateTime.now(), Thread.currentThread().getName())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; static class MyThread extends Thread &#123; MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; System.out.println(String.format("%s ---&gt; %s start", LocalDateTime.now(), this.getName())); // 模拟耗时操作 try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(String.format("%s ---&gt; %s finish", LocalDateTime.now(), this.getName())); &#125; &#125;&#125; 输出结果如下： 1232019-12-15T00:22:55.971 ---&gt; t1 start2019-12-15T00:22:57.984 ---&gt; t1 finish2019-12-15T00:22:57.985 ---&gt; main finish 在主线程 main 中通过 new MyThread(&quot;t1&quot;) 新建线程 t1。 接着，通过 t1.start() 启动线程 t1，在执行 t1.join()之后， 主线程会进入阻塞状态等待 t1 运行结束。子线程 t1 结束之后，会唤醒主线程，主线程重新获取 CPU 执行权，主线程继续往下运行。在使用了 join 方法之后主线程会等待子线程结束之后才会结束。 总结以上是线程一些常用的方法介绍和具体使用知识总结。]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 多线程基础（一）]]></title>
    <url>%2Fpost%2F7eb2637f.html</url>
    <content type="text"><![CDATA[简介在接触多线程之前，在我们程序中在任意时刻都只能执行一个步骤，称之为单线程。在单线程开发的程序中所有的程序路径都是顺序执行的，前面的必须先执行，后面的才会执行。单线程的优点也很明显，相对于多线程来说更加稳定、扩展性更强、程序开发相对比较容易。但是由于每次都要等上一个任务执行完成后才能开始新的任务，导致其效率比多线程低，甚至有时候应用程序会出现假死的现象。使用多线程有利于充分发挥多处理器的功能。通过创建多线程进程，每个线程在一个处理器上运行，从而实现应用程序的并发性，使每个处理器都得到充分运行。多线程是 Java 学习的非常重要的方面，是每个 Java 程序员必须掌握的基本技能。本文是有关 Java 多线程的一些基础知识总结。 进程与线程的区别进程进程是操作系统资源分配的基本单位，它是操作系统的基础，是一个程序及其数据在处理机上顺序执行时所发生的活动。一个程序进入内存运行，即变成一个进程。进程是处于运行过程中的程序，并且具有一定独立功能。进程的实质就是程序在操作系统中的一次执行过程，它是动态产生的、动态销毁的，拥有自己的生命周期和各种不同的运行状态。同时，进程还具有并发性，它可以同其他进程一起并发执行，按各自独立的、不可预知的速度向前推进（PS：并发性和并行性是不同的概念，并行指的是同一时刻，两个及两个以上的指令在多个处理器上同时执行。而并发指的是同一时刻只有一条指令执行，但是多个进程可以被 CPU 快速交换执行，给我们感觉好像是多个执行在同时执行一样）。 线程线程是任务调度和执行的基本单位，也被称为轻量级进程，线程由线程 ID，当前指令指针(PC），寄存器集合和堆栈组成。线程不拥有系统资源，它只会拥有一点儿在运行时必不可少的资源，但是它可以与同属于同一进程的线程共享该进程所拥有的所有资源。一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。 二者的区别 调度 线程作为调度和分配的基本单位，进程作为拥有资源的基本单位 并发性 不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行 拥有资源 进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源 系统开销 在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销 创建线程的方式在 Java 中使用 Thread 类代表线程，所有的线程对象都必须是 Thread 类或者其子类的实例，Java 中创建线程主要有以下三种方式： 方式一 继承 Thread 类step 1 定义一个类继承自 Thread 类，然后重写该类的 run 方法，这个方法的内容表示线程要完成的任务step 2 创建线程对象，即创建 Thread 类子类的实例step 3 调用步骤二中创建出来的对象的 start 方法来启动线程 12345678910111213141516171819202122232425/** * @author mghio * @date: 2019-12-07 * @version: 1.0 * @description: 通过继承 Thread 类的方式创建线程 * @since JDK 1.8 */public class CreateThreadByExtendsThread extends Thread &#123; @Override public void run() &#123; IntStream.rangeClosed(1, 10).forEach(i -&gt; System.out.println(Thread.currentThread().getName() + " " + i)); &#125; public static void main(String[] args) &#123; CreateThreadByExtendsThread threadOne = new CreateThreadByExtendsThread(); CreateThreadByExtendsThread threadTwo = new CreateThreadByExtendsThread(); CreateThreadByExtendsThread threadThree = new CreateThreadByExtendsThread(); threadOne.start(); threadTwo.start(); threadThree.start(); &#125;&#125; 方式二 实现 Runnable 接口step 1 定义一个类实现 Runnable 接口，然后实现该接口的 run 方法，这个方法的内容同样也表示线程要完成的任务step 2 创建 Runnable 接口实现类的实例，并使用该实例作为 Thraed 构造方法的参数创建 Thread 类的对象，该对象才是真正的线程对象step 3 调用线程对象的 start 方法来启动该线程 12345678910111213141516171819202122/** * @author mghio * @date: 2019-12-07 * @version: 1.0 * @description: 通过实现 Runnable 接口的方式创建线程 * @since JDK 1.8 */public class CreateThreadByImplementsRunnable implements Runnable &#123; @Override public void run() &#123; IntStream.rangeClosed(1, 10).forEach(i -&gt; System.out.println(Thread.currentThread().getName() + " " + i)); &#125; public static void main(String[] args) &#123; CreateThreadByImplementsRunnable target = new CreateThreadByImplementsRunnable(); new Thread(target, "thread-one").start(); new Thread(target, "thread-two").start(); new Thread(target, "thread-three").start(); &#125;&#125; 方式三 实现 Callable 接口step 1 定义一个类实现 Callable 接口，然后实现该接口的 call 方法，这个方法的内容同样也表示线程要完成的任务，并且有返回值step 2 创建 Callable 接口实现类的实例，使用 FutureTask 类来包装 Callable 对象，该 FutureTask 对象封装了 Callable 对象的 call 方法的返回值step 3 并使用 FutureTask 对象作为 Thraed 构造方法的参数创建 Thread 对象，并调用该对象的 start 方法启动线程step 4 调用 FutureTask 对象的 get 方法获取线程执行结束后的返回值 123456789101112131415161718192021222324252627282930313233343536373839/** * @author mghio * @date: 2019-12-07 * @version: 1.0 * @description: 通过实现 Callable 接口的方式创建线程 * @since JDK 1.8 */public class CreateThreadByImplementsCallable implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; AtomicInteger count = new AtomicInteger(); IntStream.rangeClosed(0, 10).forEach(i -&gt; &#123; System.out.println(Thread.currentThread().getName() + " " + i); count.getAndIncrement(); &#125;); return count.get(); &#125; public static void main(String[] args) &#123; CreateThreadByImplementsCallable target = new CreateThreadByImplementsCallable(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(target); IntStream.rangeClosed(0, 10).forEach(i -&gt; &#123; System.out.println(Thread.currentThread().getName() + " 的循环变量 i 的值" + i); if (i == 8) &#123; new Thread(futureTask, "有返回值的线程").start(); &#125; &#125;); try &#123; System.out.println("有返回值线程的返回值：" + futureTask.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 通过以上可以看出，其实通过实现 Runnable 接口和实现 Callable 接口这两种方式创建线程基本相同，采用实现 Runnable 和 Callable 接口的方式创建线程时，线程类只是实现接口，还可以继承其它类（PS：Java 单继承决定）。在这种方式下，多个线程可以共享同一个 target对象，所以非常适合多个相同线程来处理同一份资源的情况。还有一点就是，使用继承 Thread 类的方式创建多线程时，编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread() 方法，直接使用 this 即可获得当前线程。，在实际项目中如果使用这三种方式创建线程，如果创建关闭频繁会消耗系统资源影响性能，而使用线程池可以不用线程的时候放回线程池，用的时候再从线程池取，所以在我们项目开发中主要还是使用线程池，有关线程池的可以看看这两篇 Java 线程池（一）、Java 线程池（二）。 线程的几种状态线程是一个动态执行的过程，它也有一个从产生到死亡的过程，在 Java 中一个线程完整的生命周期一共包含以下五种状态：新建状态（New）当使用 new 关键字和 Thread 类或其子类创建一个线程对象后，那么线程就进入了新建状态，此时它和其它的 Java 对象一样，仅仅由 JVM 分配了内存，并初始化其成员变量值，它会一直保持这个状态直到调用该对象的 start 方法。 就绪状态（Runnable）当线程对象调用了 start 方法之后，该线程就进入了就绪状态。就绪状态的线程会放在一个就绪队列中，等待 JVM 里的调度器进行调度。处于就绪状态的线程，随时可能被 CPU 调度执行。 运行状态（Running）如果就绪状态的执行被 CPU 调度执行，就可以执行 run 方法，此时线程就处于线程状态。处于运行状态的线程最复杂，它可以变为阻塞状态、就绪状态和死亡状态。需要注意一点，线程变为运行状态之前的状态只能是就绪状态。 阻塞状态（Blocked）线程变为阻塞状态是因为某种原因放弃 CPU 的使用权，暂时停止运行，如果执行了 sleep、suspend 等方法，释放了所占用的资源之后，线程就从运行状态进入阻塞状态。等待睡眠时间结束或者获得设备资源之可以重新进入就绪状态。阻塞可以分为以下三种： 等待阻塞 处于运行状态的线程调用wait方法，会使线程进入等待阻塞状态 同步阻塞 当线程获取 synchronized 同步锁因为同步锁被其他线程占用而失败后，会使线程进入同步阻塞 其它阻塞 通过调用线程的sleep或join发出了 I/O 请求时，线程就会进入到阻塞状态。当sleep状态超时，join等待线程终止或超时，或者 I/O 处理完毕，线程重新回到就绪状态。 死亡状态（Dead）一个处于运行状态的线程执行完了 run 方法或者因为其它终止条件发生时，线程就会进入到死亡状态，该线程结束生命周期。以上线程各种状态的流转用一张图表示如下： 线程常用方法线程中常用的方法按照来源可以分为两类，一类是继承自 Object 类的方法，如下所示： 方法 描述 public final native void notify() 唤醒在此对象监视器上等待的单个线程，使其进入就绪状态 public final native void notifyAll() 唤醒在此对象监视器上等待的所有线程，使其进入就绪状态 public final void wait() 让当前线程处于·等待阻塞状态，直到其他线程调用此对象的notify方法或notifyAll方法，当前线程被唤醒，会释放它所持有的锁 public final native void wait(long timeout) 让当前线程处于·等待阻塞状态，直到其他线程调用此对象的notify方法或notifyAll方法，当前线程被唤醒 public final void wait(long timeout, int nanos) 让当前线程处于·等待阻塞状态，直到其他线程调用此对象的notify方法或notifyAll方法或者其他某个线程中断当前线程，或者已超过某个实际时间量，当前线程被唤醒 另一类是 Thread 类定义的方法，如下所示： 方法 描述 public static native void yield() 暂停当前正在执行的线程对象，并执行其他线程，yield 方法不会释放锁 public static native void sleep(long millis) 在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），sleep 方法不会释放锁 public final void join() 当某个程序执行流中调用其他线程的 join 方法时，调用线程将被阻塞，直到被 join 的线程执行完毕 public void interrupt() 用于中断本线程，这个方法被调用时，会立即将线程的中断标志设置为 true public static boolean interrupted() Thread 类的一个静态方法，它返回一个布尔类型指明当前线程是否已经被中断，interrupted 方法除了返回中断标记之外，它还会清除中断标记(即将中断标记设为 false) public boolean isInterrupted() Thread 类的一个实例方法，它返回一个布尔类型指明当前线程是否已经被中断，isInterrupted 方法仅仅返回中断标记，不会清楚终端标记 线程的优先级每一个 Java 线程都有一个优先级，这样有助于操作系统确定线程的调度顺序。Java 线程的优先级是一个整数，其取值范围是1（Thread.MIN_PRIORITY ）~ 10（Thread.MAX_PRIORITY ）。默认情况下，每一个线程都会分配一个优先级NORM_PRIORITY（5）。具有较高优先级的线程对程序更重要，并且应该在低优先级的线程之前分配处理器资源，Thread 类提供了 setPriority 和 getPriority 方法来更改和获取线程优先级（需要注意的是: 线程优先级不能保证线程执行的顺序，而且非常依赖于平台）。 参考文章 进程和线程的区别 Java多线程系列–“基础篇”05之 线程等待与唤醒]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 线程池（二）]]></title>
    <url>%2Fpost%2Fab706eb5.html</url>
    <content type="text"><![CDATA[简介在上篇 Java 线程池（一） 我们介绍了线程池中一些的重要参数和具体含义，这篇我们看一看在 Java 中是如何去实现线程池的，要想用好线程池，只知其然是远远不够的，我们需要深入实现源码去了解线程池的具体实现细节，这样才能更好的使用到我们的工作中，当出现问题时能快速找到问题根源所在。 线程池如何处理提交的任务我们向线程池提交任务有两种方式，分别是通过 submit 方法提交和通过 execute 方法提交，这两种方式的区别为 execute 只能提交 Runnable 类型的任务并且没有返回值，而 submit 既能提交 Runnable 类型的任务也能提交 Callable（JDK 1.5+）类型的任务并且会有一个类型 Future 的返回值，我们知道 Runnable 是没有返回值的，所以只有当提交 Callable 类型的任务时才会有返回值，而提交 Runnable 的返回值是 null。 execute 执行任务时，如果此时遇到异常会直接抛出，而 submit 不会直接抛出，只有在使用 Future 的 get 方法获取任务的返回结果时，才会抛出异常。通过查看 ThreadPoolExecutor 的源码我们发现，其 submit 方法是继承自其抽象父类 AbstractExecutorService 而来的，有三个重载的方法，分别可以提交 Runnable 类型和 Callable 类型的任务。无论是哪个 submit 方法最终还是调用了 execute 方法来实现的。方法源码如下： 1234567891011121314151617181920public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125;public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;&#125;public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125; 首先对提交的任务进行判非空指针后，三个方法都是调用 newTaskFor 方法把任务统一封装成 RunnableFuture 对象，然后把封装好的对象作为 execute 方法的入参去执行，而此时 execute 方法还未实现，这个方法是在 AbstractExecutorService 的继承类 ThreadPoolExecutor 中实现。下面看看 newTaskFor 方法是如何封装我们提交的任务的，两个重载方法的源码如下： 1234567protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable);&#125; 那么这个 FutureTask 是个什么东东呢，进入其源码发现它实现了 RunnableFuture 接口，而 RunnableFuture 接口的作用正如其名，它是 Runnable 和 Future 的结合体，表示一个能异步返回结果的线程。我们知道 Runnable 是不能返回结果的，所以上面第一个 newTaskFor(Runnable runnable, T value) 方法的第二个参数 value 的作用就是指定返回结果。其实最后也是通过 RunnableAdapter 把 Runnable 和 value 封装成 Callable 的。下面我们看看 execute 方法是怎么处理的，方法源码如下： 第 ① 步 获取当前的 ctl 值，在上篇 Java 线程池（一） 中说过，变量 ctl 存储了线程池的工作状态 runState 和线程池中正在运行的线程数 workerCount。第 ② 步 通过 workerCountOf 方法取出线程池中当前正在运行的线程数( ctl 低 29 位的值)，如果线程池当前工作线程数小于核心线程数 corePoolSize，则进行第 ③ 步。第 ③ 步 通过 addWorker 方法新建一个线程加到线程池中，addWorker 方法的第二个参数如果为 true 则限制添加线程的数量是根据 corePoolSize 来判断，反之则根据 maximumPoolSize 来判断，并把任务添加到该线程中。第 ④ 步 如果添加失败，则重新获取 ctl 的值。第 ⑤ 步 如果当前线程池的状态是运行状态（state &lt; SHUTDOWN）并且把任务成功添加到队列中。第 ⑥ 步 重新获取 ctl 的值，再次判断线程池的运行状态，如果不是运行状态，要从队列中移除任务，因为到这一步了，意味着之前已经把任务成功添加到队列中了，所以需要从队列移除。移除成功后调用拒绝策略对任务进行处理，整个 execute 方法结束（PS：为什么不在入队列之前就先判断线程池的状态呢？因为判断一个线程池工作处于运行状态到执行入队列操作这段时间，线程池可能已经被其它线程关闭了，所以提前判断其实毫无意义）。第 ⑦ 步 通过 workerCountOf 方法取出线程池中当前正在运行的线程数( ctl 低 29 位的值)，如果是 0 则执行 addWorker(null, false) 方法，第一个参数传 null 表示只是在线程池中创建一个线程出来，但是没有立即启动，因为我们创建线程池时可能要求核心线程数量为 0。第二个参数为 false 表示限制添加线程时根据 maximumPoolSize 来判断，如果当前线程池中正在运行线程数量大于 0 ，则直接返回，因为在上面第 ⑤ 步已经把任务成功添加到队列 workQueue 中，它会在将来的某个时刻执行到。第 ⑧ 步 如果执行到这个地方，只有两种情况，一种是线程池的状态已经不是运行状态了，另一种是线程池是运行状态，但是此时线程池的工作线程数大于等于核心线程数（workerCount &gt;= corePoolSize）并且队列 workQueue 已满。这时会再次调用 addWorker 方法，第二个参数传的 false，意味着限制添加线程的数量是根据 maximumPoolSize 来判断的，如果失败则调用拒绝策略对任务进行处理，整个 execute 方法结束。上面的 execute 方法中多次调用 addWorker，该方法的主要作用就是创建一个线程来执行任务。addWorker 的方法签名如下： 1addWorker(Runnable firstTask, boolean core) 第一个参数 firstTask 如果不为 null，则创建的线程首先执行 firstTask 任务，然后才会从队列中获取任务，否则会直接从队列中获取任务。第二个参数如果为 true，则表示限制添加线程时根据 corePoolSize 来判断，否则根据maximumPoolSize 来判断。我们看看 addWorker 方法的源码，方法源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 方法首先获取线程池 ctl 属性的值，该属性包含了线程池的运行状态和工作线程数，通过 runStateOf 获取线程池的运行状态，然后执行下面这个比较复杂的条件判断 第 ① 个条件表示此时线程池已经不再接受新任务了，接下来的 ②、③、④ 三个判断条件只要有一个不满足，那么方法就会返回 false，方法结束。第 ② 个条件表示线程池为关闭状态，处于关闭状态的线程池不会处理新提交的任务，但会处理完已处理的任务，第 ③ 个条件为 firstTask 为 null，第 ④ 个条件为队列不为空。我们看看如果线程池此时为关闭状态的情况，这种情况线程池不会接受新提交的任务，所以此时如果传入的 firstTask 不为 null，则会直接返回 false；然后如果 firstTask 为 null，并且队列 workQueue 为空，此时也会返回 false，因为此时队列里已经没有任务了，那么也不需要再添加线程了，然后接下来会进入一个循环。 第 ① 步 调用 workerCountOf 方法获取当前线程池的工作线程数第 ② 步 如果当前线程池的工作数大于 CAPACITY 也就是 ctl 的低 29 位的最大值，则返回 false，如果不大于 CAPACITY，然后根据 core （该方法的第二个参数）来判断是和 corePoolSize 比较还是和 maximumPoolSize 比较，如果比这个值大则返回 false。第 ③ 步 使用 ctl 的 compareAndSet 原子方法尝试把工作线程数 workerCount + 1，如果增加成功，退出第一层循环。第 ④ 步 如果增加线程池工作线程数失败，则重新获取 ctl 的值。第 ⑤ 步 调用 runStateOf 获取线程池的状态，如果不等于方法前面获取的 rs，说明线程池的状态已经改变了，回到第一层循环继续执行。接下来会启动线程执行任务，源码如下： 第 ① 步 根据 firstTask 创建 Worker 对象，每一个 Worker 对象都会创建一个线程，然后会使用重入锁 ReentrantLock 进行加锁操作。第 ② 步 调用 runStateOf 获取线程池的状态，然后进行一个条件判断，第一个 rs &lt; SHUTDOWN 表示线程池是运行状态。如果线程池是运行状态或者线程池是关闭状态并且 firstTask 为 null，那么就往线程池中加入线程（因为当线程池是 SHUTDOWN 状态时不会再向线程池添加新的任务，但会执行队列 workQueue 中的任务）。这里的 workers 是一个 HashSet，所以其 add 方法不是线程安全的，所以需要加锁操作。然后修改线程池中出现过的最大线程数量 largestPoolSize 记录和把是否添加成功标记 workerAdded 为 true。如果 workerAdded 为 true 那么会启动线程并把线程是否启动标记 workerStarted 改为 true。第 ③ 步 根据线程是否启动 workerStarted 标记来判断是否需要进行失败的操作。包含从 workers 移除当前的 worker、线程池的工作线程数减 1、尝试终端线程池。 线程池中线程是如何执行的线程池的线程执行是调用 Worker 的 thread 属性的 start 方法，而 thread 的 run 方法实际上调用了 Worker 类的 runWorker 方法，所以我们直接来看看 runWorker 方法的源码： 第 ① 步 获取第一个任务，while 循环不断地通过 getTask 方法从队列中获取任务。第 ② 步 这个判断条件目的是要保证如果线程池正在停止，要保证当前线程是中断状态，如果是的话，要保证当前线程不是终端状态。第 ③ 步 方法 beforeExecute 方法在类 ThreadPoolExecutor 中没有做任何操作，是留给子类去自定义在线程执行之前添加操作的方法。第 ④ 步 执行 task.run() 执行任务（PS：这里为什么是调用 run 方法而不是调用 start 方法呢？我们知道当调用了 start 方法后操作系统才会给我们创建一个独立的线程来运行，而调用 run 方法只是一个普通的方法调用，而线程池正好就是需要它是一个普通的方法才能进行任务的调度。我们可以想象一下，假如这里是调用的 Runnable 的 start 方法，那么会是什么结果呢。如果我们往一个核心线程数、最大线程数为 3 的线程池里丢了 500 个任务，那么它会额外的创建 500 个线程，同时每个任务都是异步执行的，结果一下子就执行完毕了，根本无法对任务进行调度。从而没法做到由这 3 个 Worker 线程来调度这 1000 个任务，而只有当做一个普通的 run 方法调用时才能满足线程池的这个要求）。第 ⑤ 步 方法 afterExecute 方法在类 ThreadPoolExecutor 中没有做任何操作，是留给子类去自定义在线程执行之后添加操作的方法。completedAbruptly 变量是用来表示在执行任务过程中是否出现了异常，processWorkerExit 方法中会对该变量的值进行判断。接下来我们看看 getTask 方法是如何从队列中获取任务的，方法源码如下： 第 ① 步 如果线程池不是运行状态，则判断线程池是否正在停止或者当前队列为空，如果条件满足将线程池的工作线程数减一并返回 null。因为如果当前线程池状态的值是 SHUTDOWN 或以上时，就不允许再向队列中添加任务了。第 ② 步 这里的 timed 变量用来标记是否需要线程进行超时控制，allowCoreThreadTimeOut 默认是 false，也就是核心线程不允许进行超时。wc &gt; corePoolSize 表示当前线程池中的工作线程数量大于核心线程数量，对于超过核心线程数量的这些线程，需要进行超时控制。第 ③ 步 第一个判断 wc &gt; maximumPoolSize 如果成立是因为可能在此方法执行阶段同时执行了线程池的 setMaximumPoolSize 方法；第二个判断 timed &amp;&amp; timedOut 如果成立表示当前操作需要进行超时控制，并且上次从队列中获取任务发生了超时（timeOut 变量的值表示上次从阻塞队列中取任务时是否超时）；第三个判断 wc &gt; 1 || workQueue.isEmpty() 如果线程池中工作线程数量大于 1，或者队列是空的，那么尝试将 workerCount 减一，如果减一失败，则返回重试。如果 wc == 1 时，也就说明当前线程是线程池中唯一的一个线程了。第 ④ 步 根据 timed 来判断，如果为 true，则通过阻塞队列的 poll 方法进行超时控制，如果在 keepAliveTime 时间内没有获取到任务，则返回 null，否则通过 take 方法，如果这时队列为空，则 take 方法会阻塞直到队列不为空。如果 r == null，说明已经超时，timedOut 设置为 true。第 ⑤ 步 如果获取任务时当前线程发生了中断，则设置 timedOut 为 false 并重新循环重试。 关闭线程池线程池的关闭一般都是使用 shutdown 方法和 shutdownNow 方法，两者的区别是前面的 shutdown 方法不会执行新的任务，但是会执行完当前正在执行的任务，而后面的 shutdownNow 方法会立即停止当前线程池，不管当前是否有线程在执行。一般都是使用 shutdown 方法来停止线程池，其方法源码如下： 12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(SHUTDOWN); interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125; advanceRunState(SHUTDOWN) 方法的作用是通过 CAS 原子操作将线程池的状态更改为关闭状态。interruptIdleWorkers 方法是对空闲的线程进行中断，其实是调用重载带参数的函数 interruptIdleWorkers(false)。然后 onShutdown 方法和上文提到的 beforeExecute、afterExecute 方法一样，在类 ThreadPoolExecutor 是空实现，也是个钩子函数。我们看看 interruptIdleWorkers 的实现源码： 123456789101112131415161718192021private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; 先进行加锁操作，然后遍历 workers 容器，也就是遍历线程池中的线程，对每个线程进行 tryLock 操作，如果成功说明线程空闲，则设置其中断标志位。而线程是否响应中断则交给我们定义任务的人来决定。 总结本文比较详细的分析了线程池任务的提交、线程的执行、线程池的关闭的工作流程。通过学习线程池相关的源码后，看到了在其内部用运用了很多多线程的解决方法，有如下几个方式： 通过定义重入锁 ReentrantLock 变量 mainLock 来解决并发多线程的安全问题 利用等待机制来实现线程之间的通讯问题除了内置的功能外，ThreadPoolExecutor 也向外提供了两个接口供我们自己扩展满足我们需求的线程池，这两个接口分别是：beforeExecute 任务执行前执行的方法，afterExecute 任务执行结束后执行的方法。]]></content>
      <categories>
        <category>Java</category>
        <category>线程池</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 线程池（一）]]></title>
    <url>%2Fpost%2Fbc557e1a.html</url>
    <content type="text"><![CDATA[线程池简介使用线程池可以很好的提高性能，线程池在运行之初就会创建一定数量的空闲线程，我们将一个任务提交给线程池，线程池就会使用一个空闲的线程来执行这个任务，该任务执行完后，该线程不会死亡，而是再次变成空闲状态返回线程池，等待下一个任务的到来。在使用线程池时，我们把要执行的任务提交给整个线程池，而不是提交给某个线程，线程池拿到提交的任务后，会在内部寻找是否还有空闲的线程，如果有，就将这个任务提交给某个空闲的线程，虽然一个线程同一时刻只能执行一个任务，但是我们可以向线程池提交多个任务。合理使用线程池有以下几个优点：① 降低资源消耗 多线程运行期间，系统不断的启动和关闭新线程，成本高，会过度消耗系统资源，通过重用存在的线程，减少对象创建、消亡的开销② 提高响应速度 当有任务到达时，任务可以不需要等待线程的创建，可以直接从线程池中取出空闲的线程来执行任务③ 方便线程管理 线程对计算机来说是很稀缺的资源，如果让他无限制创建，它不仅消耗系统的资源，还会降低系统的稳定性，我们使用线程池后可以统一进行分配和监控谈到线程池就会想到池化技术，核心思想就是把宝贵的资源放到一个池子中，每次要使用都从池子里面取，用完之后又放回池子让别人用。那么线程池在 Java 中是如何实现的呢？ Java 四种线程池在 Java 中 Executors 工具类给我们提供了四种不同使用场景的线程池的创建方法，分别为： newSingleThreadExecutor 只有一个线程来执行任务，适用于有顺序的任务的应用场景。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它，它可以保证任务按照指定顺序（FIFO，LIFO）执行，它还有可以指定线程工厂（ThreadFactory）的重载方法，可以自定义线程的创建行为 newFixedThreadPool 固定线程数的线程池，只有核心线程，核心线程的即为最大的线程数量，没有非核心线程。每次提交一个任务就创建一个线程，直到达到线程池的最大大小。线程池一旦达到最大值就会保持不变，如果当中的某个线程因为异常而结束，那么线程池会新建一个线程加入到线程池中。它还可以控制线程的最大并发数，超出的线程会在阻塞队列（LinkedBlockingQueue）中等待，同样它也有可以指定线程工厂（ThreadFactory）的重载方法，可以自定义线程的创建行为。 newCachedThreadPool 创建一个可缓存线程池，最大的线程个数为 2^31 - 1（Integer.MAX_VALUE），可以认为是无限大，若无可回收，则新建线程，如果线程池的大小超出了处理任务所需要的线程，那么就会回收部分空闲（60s 不执行任务）的线程。 newScheduledThreadPool 周期性执行任务的线程池，按照某种特定的计划执行线程中的任务，有核心线程，但也有非核心线程，非核心线程的大小也为无限大（Integer.MAX_VALUE：2^31 - 1），适用于执行周期性的任务。 Java 线程池参数详解上文说到的 Executors 工具类提供的四种适用于不同场景的线程池，通过查看源码可以发现最终都是调用 ThreadPoolExecutor 类来实现的，我们接下来深入了解这个类一些成员变量的具体含义。首先是ctl，其声明如下： 1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); 这个成员变量 ctl 主要用于存储线程池的工作状态以及线程池正在运行的线程数。很显然，要在一个整型变量中存储两部分数据，只能将其一分为二。其中的高 3bit 用于存储线程的状态，低 29bit 用于存储线程池中正在执行的线程数。 线程池的状态在 ThreadPoolExecutor 定义了线程池的五种状态（注意，这里说的是线程池状态，不是池中的线程的状态），当创建一个线程池时的状态为 RUNNING。 12345private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 线程池状态 含义 RUNNING 允许提交并处理任务 SHUTDOWN 不会处理新提交的任务，但会处理完已处理的任务 STOP 不会处理新提交的任务，也不会处理阻塞队列中未执行的任务，并设置正在执行任务的中断标志位 TIDYING 所有任务执行完毕，线程池中工作的线程数为 0，等待执行 terminated() 钩子方法 TERMINATED terminated() 钩子方法执行完毕 调用线程池的 shutdown 方法，将线程池由 RUNNING 状态转为 SHUTDOWN 状态。调用 shutdownNow 方法，将线程池由 RUNNING 状态转为 STOP 状态。SHUTDOWN 状态和 STOP 状态都会先变为 TIDYING 状态，最终都会变为 TERMINATED 状态。用图表示为： ThreadPoolExecutor 同时提供了以下三个方法来查看线程池的状态和池中正在执行的线程数 123private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; ThreadPoolExecutor 的构造函数该类参数最全的构造方法如下，这个方法决定了创建出来的线程池的各种属性： 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 各个参数的含义：corePoolSize 线程池中核心线程数的最大值maximumPoolSize 线程池中最多能拥有的线程数keepAliveTime 空闲线程存活时间unit 空闲线程存活时间的单位workQueue 用于存放任务的阻塞队列threadFactory 创建线程工厂handler 当 workQueue 已满，并且池中的线程数达到 maximumPoolSize 时，线程池继续添加新任务时采取的策略 下面通过一张图来更形象的理解线程池的这几个参数： corePoolSize、maximumPoolSize、workQueue 三者的关系，通过向线程池添加新的任务来说明着三者之间的关系： 如果没有空闲的线程执行该任务，并且池中运行的线程数小于corePoolSize时，则创建新的线程执行该任务 如果没有空闲的线程执行该任务，并且当池中正在执行的线程数大于corePoolSize时，新添加的任务进入workQueue排队（如果workQueue长度允许），等待空闲线程来执行 如果没有空闲的线程执行该任务，并且阻塞队列已满同时池中的线程数小于maximumPoolSize，则创建新的线程执行该任务 如果没有空闲的线程执行该任务，并且阻塞队列已满同时池中的线程数等于maximumPoolSize，则根据构造函数中的handler指定的策略来拒绝新添加的任务 在线程池中并没有标记出哪些线程是核心线程，哪些非核心线程，线程池它只关心核心线程的数量。下面这个是网上看到的一个形象的比喻： 如果把线程池比作一个单位的话，corePoolSize就表示正式工，线程就可以表示一个员工。当我们向单位委派一项工作时，如果单位发现正式工还没招满，单位就会招个正式工来完成这项工作。随着我们向这个单位委派的工作增多，即使正式工全部满了，工作还是干不完，那么单位只能按照我们新委派的工作按先后顺序将它们找个地方搁置起来，这个地方就是workQueue，等正式工完成了手上的工作，就到这里来取新的任务。如果不巧，年末了，各个部门都向这个单位委派任务，导致workQueue已经没有空位置放新的任务，于是单位决定招点临时工吧（临时工：又是我！）。临时工也不是想招多少就找多少，上级部门通过这个单位的maximumPoolSize确定了你这个单位的人数的最大值，换句话说最多招maximumPoolSize – corePoolSize个临时工。当然，在线程池中，谁是正式工，谁是临时工是没有区别，完全同工同酬。 keepAliveTime 和 unit 单位keepAliveTime 表示那些超出corePoolSize数量之外的线程的空闲时间大于keepAliveTime后就被清除了。 workQueue 任务队列workQueue决定了缓存任务的排队策略，对于不同的任务场景我们可以采取不同的策略，这个队列需要一个实现了BlockingQueue接口的任务等待队列。从ThreadPoolExecutor的文档中得知，官方一共给我们推荐了三种队列，分别是：SynchronousQueue、LinkedBlockingQueue、ArrayBlockingQueue。其中SynchronousQueue和ArrayBlockingQueue属于有限队列，LinkedBlockingQueue属于无限队列，具体作用如下： SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等待另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。 ArrayBlockingQueue：有界阻塞队列。一个由数组支持的有界阻塞队列。此队列按FIFO（先进先出）原则对元素进行排序。新元素插入到队列的尾部，队列获取操作则是从队列头部开始获得元素。这是一个典型的“有界缓存区”，固定大小的数组在其中保持生产者插入的元素和使用者提取的元素。一旦创建了这样的缓存区，就不能再增加其容量。试图向已满队列中放入元素会导致操作受阻塞，试图从空队列中提取元素将导致类似阻塞。 LinkedBlockingQueue：链表结构的阻塞队列，尾部插入元素，头部取出元素。LinkedBlockingQueue是我们在ThreadPoolExecutor线程池中常用的等待队列。它可以指定容量也可以不指定容量。由于它具有“无限容量”的特性，实际上任何无限容量的队列/栈都是有容量的，这个容量就是Integer.MAX_VALUE。LinkedBlockingQueue的实现是基于链表结构，而不是类似ArrayBlockingQueue那样的数组。但实际使用过程中，不需要关心它的内部实现，如果指定了LinkedBlockingQueue的容量大小，那么它反映出来的使用特性就和ArrayBlockingQueue类似了。 threadFactory 创建线程的工厂其实像ThreadPoolExecutor有的没有threadFactory参数的构造方法中使用的创建线程的工厂就是默认的工厂，比如下面这个构造方法： 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; 在这个构造方法中，创建线程的工厂的方法使用Executors.defaultThreadFactory()的工厂和ThreadPoolExecutor中的defaultHandler默认抛弃策略。使用 Executors.defaultThreadFactory创建的线程同属于相同的线程组，具有同为Thread.NORM_PRIORITY的优先级，以及名为pool-poolNumber.getAndIncrement()-thread-的线程名（poolNumber.getAndIncrement() 为线程池顺序序号），且创建的线程都是非守护进程。 handler 拒绝策略表示当workQueue已满，池中的线程数达到maximumPoolSize时，线程池拒绝添加新任务时采取的策略。从文档中得知，handler一般可以取以下四种值： 拒绝策略 含义 AbortPolicy 抛出 RejectedExecutionException 异常 CallerRunsPolicy 由向线程池提交任务的线程来执行该任务 DiscardPolicy 直接丢弃当前的任务 DiscardOldestPolicy 抛弃最旧的任务（最先提交而没有得到执行的任务） 个人觉得最优雅的方式还是AbortPolicy提供的处理方式：抛出异常，由开发人员进行处理。ThreadPoolExecutor默认的拒绝方式defaultHandler就是ThreadPoolExecutor.AbortPolicy。 合理配置线程池最后，我们要想合理的配置线程池，就必须首先分析任务特性，可以从以下几个角度来进行分析： 任务的性质任务性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务配置尽可能少的线程数量，如配置Ncpu+1个线程的线程池。IO 密集型任务则由于需要等待 IO 操作，线程并不是一直在执行任务，则配置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，则将其拆分成一个 CPU 密集型任务和一个 IO 密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率，如果这两个任务执行时间相差太大，则没必要进行分解。我们可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的 CPU 个数。 任务的优先级优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。 任务的执行时间执行时间不同的任务可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。 任务的依赖性依赖数据库连接池的任务，因为线程提交 SQL 后需要等待数据库返回结果，如果等待的时间越长 CPU 空闲时间就越长，那么线程数应该设置越大，这样才能更好的利用 CPU。建议使用有界队列，有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点，比如几千。有一次我们组使用的后台任务线程池的队列和线程池全满了，不断的抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行 SQL 变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞住，任务积压在线程池里。如果当时我们设置成无界队列，线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。当然我们的系统所有的任务是用的单独的服务器部署的，而我们使用不同规模的线程池跑不同类型的任务，但是出现这样问题时也会影响到其他任务。 参考文章：JAVA 线程池的分析和使用ThreadPoolExecutor 的 workQueue 任务队列详解]]></content>
      <categories>
        <category>Java</category>
        <category>线程池</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深挖 HashMap]]></title>
    <url>%2Fpost%2F99ea2970.html</url>
    <content type="text"><![CDATA[1.1 前言做过 java 开发的朋友们相信都很熟悉 HashMap 这个类，它是一个基于 hashing 原理用于存储 Key-Value 键值对的集合，其中的每一个键也叫做 Entry，这些键分别存储在一个数组当中，系统会根据 hash 方法来计算出 Key-Value 的存储位置，可以通过 key 快速存取 value。HashMap 基于 hashing 原理，当我们将一个键值对（Key-Value） 传入 put 方法时，它将调用这个 key 的 hashcode 方法计算出 key 的 hashcode 值，然后根据这个 hashcode 值来定位其存放数组的位置来存储对象（HashMap 使用链表来解决碰撞问题，当其发生碰撞了，对象将会存储在链表的下一个节点中，在链表的每个节点中存储 Entry 对象，在 JDK 1.8+ 中，当链表的节点个数超过一定值时会转为红黑树来进行存储），当通过 get 方法传入一个 key 来获取其对应的值时，也是先通过 key 的 hashcode 方法来定位其存储在数组的位置，然后通过键对象的 eqauls 方法找到对应的 value 值。接下来让我们看看其内部的一些实现细节。（PS：以下代码分析都是基于 JDK 1.8） 1.2 为什么容量始终是 2 的整数次幂因为获取 key 在数组中对应的下标是通过 key 的哈希值与数组的长度减一进行与运算来确定的（tab[(n - 1) &amp; hash]）。当数组的长度 n 为 2 的整数次幂，这样进行 n - 1 运算后，之前为 1 的位后面全是 1 ，这样就能保证 (n - 1) &amp; hash 后相应位的值既可能是 1 又可能是 0 ，这完全取决于 key 的哈希值，这样就能保证散列的均匀，同时与运算（位运算）效率高。如果数组的长度 n 不是 2 的整数次幂，会造成更多的 hash 冲突。HashMap 提供了如下四个重载的构造方法来满足不同的使用场景： 无参构造：HashMap()，使用该方法表示全部使用 HashMap 的默认配置参数 指定容量初始值构造：HashMap(int initialCapacity)，在初始化 HashMap 时指定其容量大小 指定容量初始值和扩容因子构造：HashMap(int initialCapacity, float loadFactor)，使用自定义初始化容量和扩容因子 通过 Map 来构造 HashMap：HashMap(Map&lt;? extends K, ? extends V&gt; m)，使用默认的扩容因子，其容量大小有传入的 Map 大小来决定 前三个构造方法最终都是调用第三个即自定义容量初始值和扩容因子构造 HashMap(int initialCapacity, float loadFactor)，其源码实现如下123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; 从源码实现可以看出，如果我们传入的初始容量值大于 MAXIMUM_CAPACITY 时，就设置容量为 MAXIMUM_CAPACITY，其值如下： 123456/** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; 也就是容量的最大值为 2 的 30 次方（1 &lt;&lt; 30）。我们知道，HashMap 的容量始终是 2 的整数次幂，不管我们传入的初始容量是什么，它都会使用最接近这个值并且是 2 的整数次幂作为 HashMap 的初始容量，这一步处理是通过 tableSizeFor 方法来实现的，我们看看它的源码： 通过方法的注释我们也可以知道（英语对于从事技术开发的人太重要了~~~），此方法的返回值始终是 2 的整数次幂，它是如何做到的呢？接下来我们通过一个例子一步一步来看，假设我们传入的初始容量大小 cap 的值 cap 为 15。 第 ① 步：将 cap - 1 后，n 的值为 14（15 - 1）。 第 ② 步：将 n 的值先右移 1 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ③ 步：将 n 的值先右移 2 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ④ 步：将 n 的值先右移 4 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ⑤ 步：将 n 的值先右移 8 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ⑥ 步：将 n 的值先右移 16 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 最后如果 n 的值小于 0，则返回 1，如果大于最大值 MAXIMUM_CAPACITY 则返回 MAXIMUM_CAPACITY，否则返回 n + 1。 现在 n 为 15，所以返回 n + 1（16），而 16 正好是 2 的 4 次幂。有的朋友可能会问，刚刚上文假设的初始容量大小 cap 是 15，本来就不是 2 的整数次幂，如果我传入初始容量的就是 2 的整数次幂那会怎么样呢？现在假设传的初始容量大小为 32（2 的 5 次方）看看结果是什么。 第 ① 步：将 cap - 1 后，n 的值为 31（32 - 1）。 第 ② 步：将 n 的值先右移 1 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ③ 步：将 n 的值先右移 2 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ④ 步：将 n 的值先右移 4 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ⑤ 步：将 n 的值先右移 8 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 第 ⑥ 步：将 n 的值先右移 16 位后与 n 进行 或运算（两者都为 0 结果为 0，其它情况都为 1），下面是具体的计算过程： 经过以上 6 步计算后得出 n 的值为 31，大于 0 小于 MAXIMUM_CAPACITY 返回 n + 1，所以经过计算后的初始容量大小为 32。稍微总结一下，我们可以得出：如果我们传入的初始容量大小不是 2 的整数次幂，那么经过计算后的初始容量大小为大于我们传入初始容量值的最小值并且是 2 的整数次幂。细心的朋友会发现，为什么第一步要进行 cap - 1 的操作呢？那是因为，如果不进行 - 1 运算的话，当我们传入的初始容量大小为 2 的整数次幂的时候，通过以上步骤计算出来的结果值为传入值的 2 倍。假设我们传入的初始容量大小为 32，此时没有第 ① 步（cap - 1）的操作，那么依次通过以上 ②、③、④、⑤、⑥ 后为 63，最后再进行 n + 1 操作，结果为 64 是 传入值 32 的 2 倍，显然和预期结果（32）不符。这个计算初始容量的算法还是很巧妙的，先进行了 -1 的操作，保证传入初始容量值为 2 的整数次幂的时候，返回传入的原始值。 1.3 hash 方法是如何实现的不管是通过 get 方法获取 key 对应的 Value 值或者通过 put 方法存储 Key-Value 键值对时，都会先根据 key 的哈希值定位到数组的位置，我们看看 HashMap 里的 hash 方法是如何实现的，源码如下： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 当 key 为 null 时，返回 0，否则进行 h = key.hashCode()) ^ (h &gt;&gt;&gt; 16 运算，先调用 key 的 hashCode 方法获取 key 的哈希值，然后与 key 的哈希值右移 16 位后的值进行异或运算（相同为 0，不同为 1，简称 同假异真），为什么获取 key 的哈希值还要再进行异或运算，直接返回 key 的哈希值好像也没什么问题，如果没有后面的异或运算，直接返回哈希值，我们假设数组的长度为 16，现在要往 HashMap 存入的三个键值对的 key 的哈希值分别为 32831、33554495、2097215，根据 hash 方法返回值定位到数组的位置（(n - 1) &amp; hash），以上三个值和 15（16 - 1）进行 &amp; 运算（都为 1 才为 1，其它情况都为 0） 如下： 可以发现以上三个哈希值都定位的数组下标为 15 的位置上。所以 hash 如果方法没有后面与哈希值右移 16 位后的值进行异或运算的话，当数组长度比较小时很容易造成 哈希碰撞，即多个 key（不同的哈希值）都会定位到数组上的同一个位置，也就是说会放入到同一个链表或者红黑树中，因为此时 key 的哈希值只有低位的才会参与运算，显然和我们的预期不符合。可见 hash 方法将 key 的哈希值与其右移 16 位后进行异或运算能减少哈希碰撞的次数，把高位和低位都参与了运算，提高了分散性。 1.4 总结HashMap 其实还有很多值得我们深入研究的点，看懂了上面两个方法后，不得不佩服作者的代码设计能力，JDK 中有很多优秀源码都值得我们好好品味，看代码的时候一定要多看几遍多问几个为什么，特别是经典的源代码，然后将这些思想运用到我们的实际工作中。]]></content>
      <categories>
        <category>Java</category>
        <category>原理</category>
      </categories>
      <tags>
        <tag>Java, 原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同步工具类]]></title>
    <url>%2Fpost%2Fee27c07f.html</url>
    <content type="text"><![CDATA[1.1 前言同步工具类可以是任何一个对象，只要它根据其自身的状态来协调线程的控制流。在容器中，有些也可以作为同步工具类，其它类型的同步工具类还包括闭锁（Latch）、信号量（Semaphore）以及栅栏（Barrier）。阻塞队列（eg: BlockQueue）是一种独特的类：它们不仅能作为保存对象的容器，还能协调生产者和消费者之间的控制流，因为它提供的 take 和 put 等方法将会阻塞，直到队列达到期望的状态。所有的同步工具类都包含一些特定的属性：它们封装了一些状态，这些状态将决定同步工具类的线程是继续执行还是等待，此外还提供了一些方法对其状态进行操作，以及另一些方法用于高效地等待同步工具类进入到预期状态。 1.2 闭锁闭锁是一种同步工具类，可以延迟线程的进度直到其到达终止状态。闭锁的作用相当于一扇门：在闭锁到达结束状态之前，这扇门一直是关闭的，并且没有任何线程能通过，当到达结束状态时，这扇门会打开并允许所有线程通过。当闭锁到达结束状态后，将不会再次改变状态，因此这扇门将永远保持打开状态。闭锁可以用来确保某些活动直到其它活动都完成后才继续执行。比如： 确保某个计算机在其需要的所有资源初始化后才能继续执行。 确保某个服务在其依赖的所有服务都已经启动后才启动。 等待直到某个操作的所有参与者都就绪后再继续执行。 1.2.1 CountDownLatchCountDownLatch 是一种灵活的闭锁实现，可以在上述各种情况中使用，它可以使一个或多个线程等待一组事件发生。闭锁状态包括一个计数器，该计数器被初始化为一个正数，表示需要等待事件的数量。countDown() 方法递减计数器，表示有一个事件已经发生了，而 await() 方法等待计数器达到 0 ，这表示所有需要等待的事件都已经发生。如果计数器的值非 0 ，那么 await() 方法会一直阻塞到计数器的值为 0 ，或者等待线程中断，或者等待超时。CountDownLatch 被用来同步一个或多个任务，强制它们等待由其它任务执行的一组操作完成。你可以向 CountDownLatch 对象设置一个初始计数值，任何在这个对象上调用 await() 的方法都将阻塞，直到这个计数值到达 0。其它任务在结束工作时，可以在该对象上调用 countDown() 方法来减小这个计数值。CountDownLatch 被设计为只触发一次，计数值不能重置。如果你需要重置计数值的版本，请看下文的 CyclicBarrier。把大象放入冰箱的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * @author mghio * @date: 2019-11-03 * @version: 1.0 * @description: 同步工具类 —— CountDownLatch * @since JDK 1.8 */public class CountDownLatchDemo &#123; private static CountDownLatch countDownLatch1 = new CountDownLatch(1); private static CountDownLatch countDownLatch2 = new CountDownLatch(1); public static void main(String[] args) &#123; final Thread thread1 = new Thread(() -&gt; &#123; System.out.println("step 1：打开冰箱门..."); // 对 countDownLatch1 倒计时 -1 countDownLatch1.countDown(); &#125;); final Thread thread2 = new Thread(() -&gt; &#123; try &#123; // 等待 countDownLatch1 倒计时，计时为 0 则往下运行 countDownLatch1.await(); System.out.println("step 2：把大象放入冰箱..."); // 对 countDownLatch2 倒计时 -1 countDownLatch2.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); final Thread thread3 = new Thread(() -&gt; &#123; try &#123; // 对 countDownLatch2 倒计时，计时为 0 则往下进行 countDownLatch2.await(); System.out.println("step 3：关上冰箱门..."); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); System.out.println("------- 把大象放入冰箱 --------"); thread3.start(); thread1.start(); thread2.start(); &#125;&#125; 以上代码输出结果： 1234------- 把大象放入冰箱 --------step 1：打开冰箱门...step 2：把大象放入冰箱...step 3：关上冰箱门... 1.2.2 FutureTaskFutureTask 也可以用作闭锁。它实现了 Future 的语义，表示一种抽象可生成结果的计算。 FutureTask 表示的计算是通过 Callable 来实现的，相当于一种可生成结果的 Runnable ，并且可以处于这三种状态：等待运行（Waiting to run）、正在运行（Running）和运行完成（Completed）。其中执行完成表示计算的所有可能结束方式，包括正常结束、由于取消结束和由于异常结束等。当 FutureTask 进入完成状态后，它就会永远停在这个状态上。get() 方法的行为取决于任务的状态。如果此时任务已经完成，那么 get() 方法会立即返回结果，否则将会阻塞直到任务进入到完成状态，然后返回结果或者抛出异常。FutureTask 将计算结果从执行计算的线程传递到获取这个结果的线程，而 FutureTask 的规范确保了这种传递过程能实现结果的安全发布。FutureTask 在 Executor 框架中表示异步任务，除此之外还可以用来表示一些耗时比较长的计算，这些计算可以在使用计算结果之前启动。以下示例使用其执行一个异步任务： 1234567891011121314151617181920212223242526272829303132/** * @author mghio * @date: 2019-11-03 * @version: 1.0 * @description: 同步工具类 —— FutureTask * @since JDK 1.8 */public class FutureTaskDemo &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; System.out.println("--------- 进入主线程执行任务"); ExecutorService threadPool = Executors.newCachedThreadPool(); System.out.println("--------- 提交异步任务"); FutureTask&lt;String&gt; future = new FutureTask&lt;&gt;(() -&gt; "成功获取 future 异步任务结果"); threadPool.execute(future); System.out.println("--------- 提交异步任务之后，立马返回到主线程继续往下执行"); Thread.sleep(1000); System.out.println("--------- 此时需要获取上面异步任务的执行结果"); boolean flag = true; while (flag) &#123; if (future.isDone() &amp;&amp; !future.isCancelled()) &#123; String futureResult = future.get(); System.out.println("--------- 异步任务返回的结果是：" + futureResult); flag = false; &#125; &#125; if (!threadPool.isShutdown()) &#123; threadPool.shutdown(); &#125; &#125;&#125; 以上代码输出结果为： 12345--------- 进入主线程执行任务--------- 提交异步任务--------- 提交异步任务之后，立马返回到主线程继续往下执行--------- 此时需要获取上面异步任务的执行结果--------- 异步任务返回的结果是：成功获取 future 异步任务结果 1.4 信号量计数信号量（Counting Semaphore）用来控制同时访问某个特定资源的操作数量，或者同时执行指定操作的数量。计数信号量还可以用来实现某种资源池或者对容器施加边界。Semaphore 中管理着一组虚拟的许可（permit），许可的初始数量可以通过构造函数来指定，在执行操作时可以首先获得许可（只要还有剩余的许可），并在使用以后释放许可。如果没有许可，那么 acquire() 将阻塞直到有许可或者直到终端或者直到超时。release() 方法将返回一个许可给信号量。Semaphore 可以用于实现资源池，例如数据库连接池。我们可以构造一个固定长度的资源池，当池为空时，请求资源将会失败，但你真正希望看到的行为是阻塞而不是失败，并且当池非空时解除阻塞。如果将 Semaphore 的计数值初始化为池的大小，并在从池中获取一个资源之前首先调用 acquire() 方法获取一个许可，在将资源返回给池之后调用 release() 方法释放许可，那么 acquire() 方法将一直阻塞直到资源池不为空。以下示例将使用 Semaphore 将 HashSet 容器变成有界的阻塞容器，信号量的计数值会初始化为容器容量的最大值。add 操作在向底层容器添加一个元素之前，首先要获取一个许可。如果 add 操作没有添加任何元素，那么会立刻释放许可。同样 remove 操作会释放一个许可，使更多的元素能够添加到容器中。底层的 Set 实现并不知道关于边界的任何信息。 12345678910111213141516171819202122232425262728293031323334353637383940/** * @author maguihai * @date: 2019-11-03 * @version: 1.0 * @description: 同步工具类 —— Semaphore * @since JDK 1.8 */public class BoundedHashSet&lt;T&gt; &#123; private final Set&lt;T&gt; set; private final Semaphore sem; public BoundedHashSet(int bound) &#123; this.set = Collections.synchronizedSet(new HashSet&lt;&gt;()); this.sem = new Semaphore(bound); &#125; public boolean add(T o) throws InterruptedException &#123; sem.acquire(); boolean wasAdded = false; try &#123; wasAdded = set.add(o); return wasAdded; &#125; finally &#123; if (!wasAdded) &#123; sem.release(); &#125; &#125; &#125; public boolean remove(T o) &#123; boolean wasRemoved = set.remove(o); if (wasRemoved) &#123; sem.release(); &#125; return wasRemoved; &#125;&#125; 1.5 栅栏我们已经看到通过闭锁来启动一组相关的操作，或者等待一组相关的操作结束。闭锁是一次性对象，一旦进入终止状态，就不能被重置。栅栏（Barrier）类似于闭锁，它能阻塞一组线程直到某个事件发生。栅栏与闭锁的关键区别在于：所有线程都必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其它线程。栅栏用于实现一些协议，例如几个家庭决定在某个地方集合：“所有人 6:00 在 KFC 碰头，到了以后要等其它人，之后再讨论下一步要做的事情”。CyclicBarrier 适用于这样的情况：你希望创建一组任务，他们并行执行工作，然后再运行下一个步骤之前等待，知道所有任务都完成（有点儿像线程的 join 方法）。它使得所有的并行任务都将处于栅栏处列队，因此可以一致的向前移动。这和上文的 CountDownLatch 非常像，只是 CountDownLatch 只是触发一次的事件，而 CyclicBarrier 可以重复使用。CyclicBarrier 可以使一定数量的参与方反复地在栅栏位置汇聚，它在并行迭代算法中非常有用：这种算法通常将一个问题拆分成一系列相互独立的子问题。当线程达到栅栏位置时将调用 await() 方法，这个方法将阻塞直到所有线程都到达栅栏位置。如果所有栅栏都到达栅栏了位置，那么栅栏将打开，此时所有的线程都被释放，而栅栏将被重置以便下次使用。如果对 await() 方法调用超时，或者线程被中断，那么栅栏就认为是被打破了，所有阻塞 await() 的调用都将终止并抛出 BrokenBarrierException。如果成功通过栅栏，那么 await() 将为每一个线程返回一个唯一的到达索引号，我们可以利用这些索引来“选举”产生一个领导线程，并在下一次迭代中由该领导线程执行一些特殊的工作。CyclicBarrier 还可以使你将一个栅栏操作传递给构造函数，这个一个 Runnable ，当成功通过栅栏时会（在一个子任务线程中）执行它，但是它在阻塞线程被释放前是不能执行的。使用示例： 123456789101112131415161718192021222324252627282930313233343536/** * @author mghio * @date: 2019-11-03 * @version: 1.0 * @description: 同步工具类 —— CyclicBarrier * @since JDK 1.8 */public class CyclicBarrieDemo &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newCachedThreadPool(); // 创建 CyclicBarrier 对象并设置 3 个公共屏障点 final CyclicBarrier cb = new CyclicBarrier(3); for (int i = 0; i &lt; 3; i++) &#123; Runnable runnable = () -&gt; &#123; try &#123; Thread.sleep((long) (Math.random() * 10000)); System.out.println("线程 " + Thread.currentThread().getName() + " 即将到达集合地点1，当前已有 " + cb.getNumberWaiting() + " 个已经到达，正在等候"); // 到此如果没有达到公共屏障点，则该线程处于等待状态，如果达到公共屏障点则所有处于等待的线程都继续往下运行 cb.await(); Thread.sleep((long) (Math.random() * 10000)); System.out.println("线程 " + Thread.currentThread().getName() + " 即将到达集合地点2，当前已有 " + cb.getNumberWaiting() + " 个已经到达，正在等候"); cb.await(); Thread.sleep((long) (Math.random() * 10000)); System.out.println("线程 " + Thread.currentThread().getName() + " 即将到达集合地点3，当前已有 " + cb.getNumberWaiting() + " 个已经到达，正在等候"); cb.await(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;; service.execute(runnable); &#125; service.shutdown(); &#125;&#125; 以上代码运行结果： 123456789线程 pool-1-thread-3 即将到达集合地点1，当前已有 0 个已经到达，正在等候线程 pool-1-thread-1 即将到达集合地点1，当前已有 1 个已经到达，正在等候线程 pool-1-thread-2 即将到达集合地点1，当前已有 2 个已经到达，正在等候线程 pool-1-thread-3 即将到达集合地点2，当前已有 0 个已经到达，正在等候线程 pool-1-thread-2 即将到达集合地点2，当前已有 1 个已经到达，正在等候线程 pool-1-thread-1 即将到达集合地点2，当前已有 2 个已经到达，正在等候线程 pool-1-thread-3 即将到达集合地点3，当前已有 0 个已经到达，正在等候线程 pool-1-thread-2 即将到达集合地点3，当前已有 1 个已经到达，正在等候线程 pool-1-thread-1 即将到达集合地点3，当前已有 2 个已经到达，正在等候]]></content>
      <categories>
        <category>Java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java, 并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 运行时数据区域]]></title>
    <url>%2Fpost%2F8a061473.html</url>
    <content type="text"><![CDATA[1.1 为什么要进行内存区域划分JVM规范 规定，JVM 在执行 Java 程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途。以及创建和销毁的时间，有的区域随着虚拟机进程的启动就存在了，而有些区域则依赖用户线程的启动和结束而建立和销毁。JVM 规范对 JVM 定义了运行时统一的内存划分规范，统一了标准，类似于 JDBC 规范一样。JVM 也有许多厂商的不同产品。比如下面的这些： 厂商 JVM Oracle-SUN Hotspot Oracle JRocket IBM J9 JVM 阿里 Taobao JVM 其内存区域划分规范对于 JVM 的含义类似于我们 Java 中的接口，都是起到了规范的作用，JVM 是一台可以运行 Java 应用程序的抽象的计算机。在 JVM 中存在三个重要的概念： JVM 规范：它定义了虚拟机运行的规范，但是由 Oracle（SUN）或者其它厂商实现 Java 运行时环境(JRE：Java Runtime Environment)：它是 JVM 规范的具体实现 JVM 实例：编写好 Java 代码之后，运行 Java 程序，此时就会创建 JMV 实例 对于 Java 程序员来说，在虚拟机自动内存管理机制的帮助下，不再需要为每一个对象去编写内存释放的代码，不要像 C 或者 C++ 要时刻注意着内存泄漏和内存溢出的问题，这种由虚拟机去管理一切看起来都很美好。不过，也正是因为 Java 设计者把内存控制全部交给了 JVM，一旦出现了内存泄漏和溢出方面的问题，如果不了解虚拟机是怎么分配运行时内存的，那么排查错误将是一项非常艰难的工作。 1.2 运行时数据区域的组成为什么我们经常把运行时数据区叫做 Java 内存模型（JMM：Java Memory Model），是因为运行时数据区太过于分散，没有联系，所以才会有 JVM 内存模型这个词，让我们把这些东西联系起来，方便记忆。JVM 运行时数据区中有些数据是一直存在的，被所有线程所共享。而有些区域则是线程私有的，伴随着线程的开始而创建，线程的结束而销毁。所以我们可以把JMM 分为两类：线程共享的、线程私有的。根据 JVM 虚拟机规范的规定，JVM 虚拟机运行时数据区划分如下图所示： 运行时数据区主要分为以下几个部分： 方法区 虚拟机栈 本地方法栈 堆 程序计数器 其中，按照线程在各个区域的数据是否共享划分为： 线程共享部分：方法区、Java 堆以及运行时常量池（归属于方法区） 线程私有部分：虚拟机栈、本地方法栈、程序计数器 接下来看看 Java 运行时数据区中各个部分的用途和特点： 方法区 1.1 什么是方法区在 JVM 中，方法区是可供各个线程共享运行时的内存区域。方法区与传统语言中的编译代码存储区或者操作系统进程的正文段的作用非常类似，它存储了每一个类的结构信息，例如运行时常量池、字段和方法数据、类的构造函数和普通方法的字节码内容、还包括一些类、实例、接口初始化的时候用到的特殊方法。在 Hotspot 虚拟机中，JDK 1.7 版本称作永久代（Permanent Generation），而在 JDK 1.8 则称为 元空间（Metapace）。方法区有个别名叫做非堆（Non-Heap），用于区别于 Java 堆区。默认最小值为 16 MB，最大值为 64 MB，可通过 -XX:PermSize 和 -XX:MaxPermSize 参数设置方法的大小。JDK 1.7 及之前的版本设置为： 12-XX:PermSize=10m-XX:MaxPermSize=55m JDK 1.8 及之后的版本设置为： 12-XX:MetaspaceSize=10m-XX:MaxMetaspaceSize=55m 1.2 方法区的特点 线程共享：方法区是堆的一个逻辑部分，因此和对一样是线程共享的。整个虚拟机中只有一个方法区。 永久代：方法区中的信息一般要长期存在，而且它又是堆的逻辑部分，因此用堆的划分方法，我们把方法区称作永久代（方法区是规范，永久代是实现）。 内存回收低：方法区中的信息一般需要长期存在，回收一遍内存之后可能之后少量信息无效。对方法区的内存回收主要是 对常量池的回收和对类型的卸载。 JVM 规范对方法区的定义比较宽松：和堆一样，允许固定大小，也允许可扩展大小，还允许不实现垃圾回收。 方法区是所有都线程共享的，在一定的条件下它也会被 GC，当方法区域需要使用的内存超过其允许的大小时，会抛出 OOM（OutOfMemory）错误信息。 1.3 运行时常量池类加载后，Class 文件结构中常量池中的数据将被存储在运行时常量池中。我们一般在一个类中通过 public static final 来声明一个常量或者声明一个字符串 String str = &quot;abc&quot;。这个类编译后产生的 Class 文件，这个类的所有信息都存储在这个 class 文件中，当这个类被 JVM 加载之后，class 文件中的常量就存放在方法区的运行时常量池中。而且在运行期间，可以向常量池添加新的常量。比如，String 类的 intern() 方法就能在运行期间向常量池中添加新的常量。当运行时常量池中的某些常量没有被对象引用，同时也没有被变量引用时，那么就需要垃圾收集器回收。JVM 为每个已加载的类型维护一个常量池，常量池就是这个类型用到的常量的一个有序集合。其包括直接常量(基本类型，String)和对其他类型、方法、字段的符号引用。即字面量和符号引用，其中字面量指的是整个类中的字面量。包含成员变量、静态方法、非静态方法等中的字面量。池中的数据和数组一样通过索引访问。 虚拟机栈 1.1 什么是虚拟机栈Java 虚拟机栈是描述 Java 方法运行过程的内存模型。Java 虚拟机栈会为每一个即将运行的方法创建一块叫做 栈帧 的区域，这块区域用于存储用于方法在运行时所需要的一些信息，这些信息具体包括： 局部变量表 操作数栈 动态链接 方法出口信息 其它信息 当一个方法即将被运行时，Java 虚拟机栈首先会在 Java 虚拟机栈中为该方法创建一块”栈帧”，栈帧中包含局部变量表，操作数栈，动态链接，方法出口信息等。当方法在运行过程中需要创建局部变量时，就将局部变量的值存入栈帧的局部变量表中。当这个方法执行完毕后，这个方法所对应的栈帧将会出栈，并释放内存空间。Java 虚拟机栈上数据都是私有的，其他线程都不能访问该线程的栈数据。在函数中定义的一些基本类型的变量数据和对象的引用变量都在函数的栈内存中分配。当在一段代码块中定义一个变量时，Java 就会在栈中为这个变量分配内存空间，当该变量退出该作用域后，Java 会自动释放掉为该变量所分配的内存空间，该内存空间可以立即被另作他用。 1.2 Java 虚拟机栈的特点 局部变量表的创建是在方法被执行的时候，随着栈帧的创建而创建。局部变量表的大小在程序的编译期间就确定下来了，在创建的时候需要事先指定好大小，在方法运行的过程中局部变量表的大小是不会发生改变的。 Java虚拟机栈会出现两种错误（StackOverFlowError 和 OutOfMemoryError），StackOverFlowError：若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候就会抛出 StackOverFlowError。OutOfMemoryError：若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈时内存用完了，无法再动态扩展了，此时就会抛出 StackOverFlowError。 虚拟机栈也是线程私有的，每个线程都有各自的 Java 虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。 栈中的数据在线程内部是共享的，要注意这种数据的共享与两个对象引用同 时指向一个对象的这种共享是不同的。它是由编译器完成的，它有利于节省空间。 本地方法栈 本地方法指的是使用 Java 以外的其他语言编写的代码，因为有些时候 Java 无法直接操作一些底层资源，只能通过 C 或汇编操作。因此需要通过本地方法来实现。而本地方法栈就是设计用来调用这些非 Java 语言方法的。会存放对应的局部变量信息、返回结果等。本地方法栈和 Java 虚拟机栈实现的功能类似，只不过本地方法栈是本地方法运行的内存模型。区别是虚拟机栈为虚拟机执行 Java 方法服务，而本地方法栈则是为虚拟机用到的 Native 方法服务，本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接以及出口信息等。方法执行完毕后相应的栈帧也会出栈并释放内存空间。也会抛出两种错误，StackOverFlowError 和 OutOfMemoryError。 堆 1.1 什么是堆堆是用来存放对象（类、接口、数组）的内存空间。几乎所有的对象都存储在堆中（实例创建后，成员变量也随对象存在堆中，随着垃圾回收进行释放）。堆是一个运行时数据区，在程序运行时动态分配内存。在堆中产生了一个数组对对象后，还可以在栈中定义一个特殊的变量，让栈用这个变量的取值等于数组或对象在堆地址内存中的首地址，栈中的这个变量就成了数组或对象的引用变量。引用变量就相当于是为数组和对象起的一个名称，以后就可以在程序中使用栈中的引用变量来访问堆中数组或对象。引用变量是普通的变量，定义时在栈中分配，引用变量在程序运行到其作用域外后释放。而数组和对象本身在堆中分配，即使程序运行到使用 new 产生数组或者对象的语句所在的代码之外，数组和对象本身占据的内存空间不会被释放，数组和对象在没有引用指向它的时候才会变为垃圾，不能再被使用。仍然占据内存空间不放，在随后的一个不确定的时期被 GC 垃圾回收收走。这也是 Java 比较占用内存的原因之一，实际上，栈中的变量指向堆内存的变量，这就是 Java 中的指针。 1.2 堆的特点 线程共享：整个 JVM 只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java 虚拟机栈、本地方法栈都是一个线程对应一个。 在虚拟机启动的时候创建。 垃圾回收的主要场所。 堆的大小既可以固定也可以扩展，但主流的虚拟机堆的大小是可扩展的。 堆可以分为：新生代和老年代新生代：新生代程序新创建的对象都在新生代分配的，新生代由 Eden Space 和两块大小相同的 Survivor Space（通常又称 S0 和 S1或 FROM 和 To ）构成，可通过 -Xmn 参数来指定新生代的大小，也可以通过 -XX:SurvivorRation 来调整 Eden Space 及 Survivor Space 的大小，因此新生代又可被分为：Eden，From Survivor，To Survivor。老年代：老年代用户存放经过多次新生代垃圾回收仍然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代。主要有两种情况：一种是 大对象，可通过启动参数设置 -XX:PretenureSizeThreshold=1024（单位为字节，默认为 0）来代表超过多大时就不再在新生代分配，而是直接在老年代分配。另一种是 大的数组对象，且数组中无引用外部对象。老年代所占的内存大小为 -Xmx 对应的值减去 -Xmn（新生代）对应的值。不同的区域存放具有不同生命周期的对象。这样可以根据不同的区域使用不同的垃圾回收算法，从而更具有针对性，从而更加高效。 JDK 1.8 及之后版本堆的内存空间分配老年代：三分之二的堆空间年轻代：三分之一的堆空间 eden 区： 十分之八的年轻代空间 survivor 0：十分之一的年轻代空间 survivor 1：十分之一的年轻代空间 程序计数器 1.1 什么是程序计数器程序计数器是一块比较小的内存空间，可以把它看作当前线程正在执行的字节码的行号指示器。程序计数器里面记录的是当前线程正在执行的那一条字节码指令的地址。当然，程序计数器是线程私有的。但是，如果当前线程执行的是一个线程本地的方法，那么此时这个线程的程序计数器为空。 本地方法为 Native Method，即由 native 修饰的方法。在定义一个 native 方法时，并不提供实现（类似 Java 中的接口或者抽象方法），因为其实现往往是由外面的 C 或者 C++ 等非 Java 语言实现的。 1.2 程序计数器的作用程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来一次读取指令，从而实现代码的流程控制，如顺序执行、选择、循环、异常处理等。 在多线程的条件下，程序计数器用来记录当前线程执行的位置，从而当线程被切换回来的时候能够知道这个线程上次运行到哪个地方了。 1.3 程序计数器的特点 是一块比较小的存储空间 是线程私有的，即每一个线程都有一个独立程序计数器 是唯一一个不会出现 OOM（OutOfMemoryError）的内存区域 声明周期随着线程的开始而创建，随着线程的终止而结束 方法区、永久代和元空间 1.1 方法区和永久代的关系涉及到内存模型，往往都会提到永久代，那么它和方法区又是什么关系呢？JVM 虚拟机规范 只是规定了有方法区这个概念和它的作用，并没有规定如何实现它。那么，在不同 JVM 上方法区的实现肯定是不同的。同时大多数公司用的 JVM 都是 Oracle 公司的 HotSpot。在 HotSpot 上把 GC 分代收集扩展至方法区，或者说使用永久代来实现方法区。因此，我们可以得到结论，永久代是 HotSpot 的概念，方式区是 JVM 规范的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现。其它的虚拟机实现并没有永久代这么一说。在 JDK 1.7 及之前的实现中，HotSpot 使用永久代实现方法区，HotSpot 使用 GC 分代来实现方法区内存回收，可以使用以下参数来调准方法区的大小： 12-XX:PermSize # 方法区初始大小-XX:MaxPermSize # 方法区最大大小（超过这个值会抛出 OutOfMemoryError 异常：java.lang.OutOfMemoryError：PermGen） 1.2 元空间对于 Java 8，HotSpot 取消了永久代，那么是不是也就没有方法了吗？当然不是，方法区是一个规范，规范没变，它就会一直在。那么取代永久代的就是元空间。它和永久代有什么不同呢？ 存储位置不同，永久代物理上是堆的一部分，和新生代、老年代地址是连续的，而元空间属于本地内存 存储内容不同，元空间存储类的元信息，静态变量和常量池等并入堆中。相当于永久代的数据被分到了堆和元空间中。 1.3 总结1.1 JVM 内存模型一共有两个“栈”，分别是 Java 虚拟机栈和本地方法栈两个“栈”功能类似，都是方法运行过程的内存模型。并且两个“栈”内部构造相同，都是方法私有的。只不过 Java 虚拟机栈描述的是 Java 方法运行过程的内存模型，而本地方法栈是描述 Java 本地方法运行过程的内存模型。 1.2 JVM 内存模型中一共有两个“堆”，分别是原本的堆和方法区方法区本质上还是属于堆的一个逻辑部分。堆中存放对象，方法区中存放类信息、常量、静态变量，即时编译器编译后的代码等。 1.3 堆是 JVM 中最大的一块内存区域，也是垃圾收集器主要工作的地方在创建对象的时候，非静态成员会被加载到堆内存中，并完成成员变量的初始化。也就是说所有的非静态成员（成员变量、成员方法、构造方法、构造代码块和普通代码块）都是保存在堆内存中的。但是方法调用的时候，调用的方法会在栈内存中执行，构造代码块也会在栈内存中执行。 1.4 线程私有与共享Java 虚拟机栈、程序计数器和本地方法栈都是线程私有的，也就是说每个线程都是各自的程序计数器、Java 虚拟机栈和本地方法栈。他们的生命周期和线程的生命周期一样。而堆、方法区则是线程共享的，在 JVM 中只有一个堆，一个方法区。并在 JVM 启动的时候就创建，直到 JVM 停止的时候才销毁。 参考文章 Java Memory Management for Java Virtual Machine (JVM) The Java® Virtual Machine Specification（Java SE 8 Edition）]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 并发之 ThreadLocal]]></title>
    <url>%2Fpost%2Fbfcdfeaf.html</url>
    <content type="text"><![CDATA[1.1 什么是 ThreadLocalThreadLocal 简单理解 Thread 即线程，Local 即本地，结合起来理解就是 每个线程都是本地独有的。在早期的计算机中不包含操作系统，从头到尾只执行一个程序，并且这个程序能访问计算中的所有资源，这对于计算机资源来说是一种浪费。要想充分发挥多处理器的强大计算能力，最简单的方式就是使用多线程。与串行程序相比，在并发程序中存在更多容易出错的地方。当访问共享数据时，通常需要使用同步来控制并发程序的访问。一种避免使用同步的方式就是让这部分共享数据变成不共享的，试想一下，如果只是在单个线程内对数据进行访问，那么就可以不用同步了，这种技术称为线程封闭（Thread Confinement），它是实现线程安全最简单的方式之一。当某个对象封闭在一个单个线程中时，这种用法会自动实现了线程安全，因为只有一个线程访问数据，从根本上避免了共享数据的线程安全问题，即使被封闭的对象本身不是线程安全的。要保证线程安全，并不是一定就需要同步，两者没有因果关系，同步只是保证共享数据征用时正确性的手段，如果一个方法本来就不涉及共享数据，那它就不需要任何同步措施去保证正确性。而维持线程封闭的一种规范用法就是使用 ThreadLoal，这个类能使当前线程中的某个值与保存的值关联起来。ThreadLocal 提供了 get() 与 set(T value) 等方法，set 方法为每个使用了该变量的线程都存有一份独立的副本，因此当我们调用 get 方法时总是返回由当前线程在调用 set 方法的时候设置的最新值。 1.2 ThreadLocal 的用法接下来通过一个示例代码说明 ThreadLocal 的使用方式，该示例使用了三个不同的线程 Main Thread、Thread-1 和 Thread-2 分别对同一个 ThreadLocal 对象中存储副本。 12345678910111213141516171819202122232425262728293031/** * @author mghio * @date: 2019-10-20 * @version: 1.0 * @description: Java 并发之 ThreadLocal * @since JDK 1.8 */public class ThreadLocalDemoTests &#123; private ThreadLocal&lt;String&gt; boolThreadLocal = ThreadLocal.withInitial(() -&gt; ""); @Test public void testUseCase() &#123; boolThreadLocal.set("main-thread-set"); System.out.printf("Main Thread: %s\n", boolThreadLocal.get()); new Thread("Thread-1") &#123; @Override public void run() &#123; boolThreadLocal.set("thread-1-set"); System.out.printf("Thread-1: %s\n", boolThreadLocal.get()); &#125; &#125;.start(); new Thread("Thread-2") &#123; @Override public void run() &#123; System.out.printf("Thread-2: %s\n", boolThreadLocal.get()); &#125; &#125;.start(); &#125;&#125; 打印的输出结果如下所示： 123Main Thread: main-thread-setThread-1: thread-1-setThread-2: 我们从输出结果可以看出，ThreadLocal 把不同的线程的数据进行隔离，互不影响，Thread-2 的线程因为我们没有重新设置值会使用 withInitial 方法设置的默认初始值 &quot;&quot;，在不同的线程对同一个 ThreadLocal 对象设置值，对不同的线程取出来的值不一样。接下来我们来分析一下源码，看看它是如何实现的。 1.3 ThreadLocal 的实现原理既然要对每个访问 ThreadLocal 变量的线程都要有自己的一份本地独立副本。我们很容易想到可以用一个 Map 结构去存储，它的键就是我们当前的线程，值是它在该线程内的实例。然后当我们使用该 ThreadLocal 的 get 方法获取实例值时，只需要使用 Thread.currentThread() 获取当前线程，以当前线程为键，从我们的 Map 中获取对应的实例值即可。结构示意图如下所示：上面这个方案可以满足前文所说的每个线程本地独立副本的要求。每个新的线程访问该 ThreadLocal 的时候，就会向 Map 中添加一条映射记录，而当线程运行结束时，应该从 Map 中清除该条记录，那么就会存在如下问题： 因为新增线程或者线程执行完都要操作这个 Map，所以需要保证 Map 是线程安全的。虽然可以使用 JDK 提供的 ConcurrentHashMap 来保证线程安全，但是它还是要通过使用锁来保证线程安全的。 当一个线程运行结束时要及时移除 Map 中对应的记录，不然可能会发生 内存泄漏 问题。 由于存在锁的问题，所有最终 JDK 并没有采用这个方案，而是使用无锁的 ThreadLocal。上述方案出现锁的原因是因为有两一个以上的线程同时访问同一个 Map 导致的。我们可以换一种思路来看这个问题，如果将这个 Map 由每个 Thread 维护，从而使得每个 Thread 只访问自己的 Map，那样就不会存在线程安全的问题，也不会需要锁了，因为是每个线程自己独有的，其它线程根本看不到其它线程的 Map 。这个方案如下图所示： 这个方案虽然不存在锁的问题，但是由于每个线程访问 ThreadLocal 变量后，都会在自己的 Map 内维护该 ThreadLoal 变量与具体存储实例的映射，如果我们不手动删除这些实例，可能会造成内存泄漏。我们进入到 Thread 的源码内可以看到其内部定义了一个 ThreadLocalMap 成员变量，如下图所示： ThreadLoalMap 类是一个类似 Map 的类，是 ThreadLocal 的内部类。它的 key 是 ThreadLocal ，一个 ThreadLocalMap 可以存储多个 key（ThreadLocal），它的 value 就对应着在 ThreadLocal 存储的 value。因此我们可以看出：每一个 Thread 都对应自己的一个 ThreadLocalMap ，而 ThreadLocalMap 可以存储多个以 ThreadLocal 为 key 的键值对。这里也解释了为什么我们使用多个线程访问同一个 ThreadLocal ，然后 get 到的确是不同数值。 上面对 ThreadLocal 进行了一些解释，接下来我们看看 ThreadLocal 具体是如何实现的。先看一下 ThreadLocal 类提供的几个常用方法： 1234567protected T initialValue() &#123; ... &#125;public void set(T value) &#123; ... &#125;public T get() &#123; ... &#125;public void remove() &#123; ... &#125; initialValue 方法是一个 protected 方法，一般是用来使用时进行重写，设置默认初始值的方法，它是一个延迟加载的方法，在。 set 方法是用来设置当前线程的变量副本的方法 get 方法是用获取 ThreadLocal 在当前线程中保存的变量副本 remove 方法是 JDK1.5+ 才提供的方法，是用来移除当前线程中的变量副本 initialValue 方法是在 setInitialValue 方法被调用的，由于 setInitialValue 方法是 private 方法，所以我们只能重写 initialValue 方法，我们看看 setInitialValue 的具体实现： 12345678910111213141516/** * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */ private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; &#125; 通过以上代码我们知道，会先调用 initialValue 获取初始值，然后使用当前线程从 Map 中获取线程对应 ThreadLocalMap，如果 map 不为 null，就设置键值对，如果为 null，就再创建一个 Map。首先我们看下在 getMap 方法中干了什么： 12345678910/** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; 可能大家没有想到的是，在 getMap 方法中，是调用当期线程 t，返回当前线程 t 中的一个成员变量 threadLocals 。那么我们继续到 Thread 类中源代码中看一下成员变量 threadLocals 到底是什么： 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 它实际上就是一个 ThreadLocalMap ，这个类型是 ThreadLocal 类内定义的一个内部类，我们看一下 ThreadLocalMap 的实现： 123456789101112131415161718192021222324252627282930313233/** * ThreadLocalMap is a customized hash map suitable only for * maintaining thread local values. No operations are exported * outside of the ThreadLocal class. The class is package private to * allow declaration of fields in class Thread. To help deal with * very large and long-lived usages, the hash table entries use * WeakReferences for keys. However, since reference queues are not * used, stale entries are guaranteed to be removed only when * the table starts running out of space. */ static class ThreadLocalMap &#123; /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as "stale entries" in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; ... &#125; 我们可以看到 ThreadLocalMap 的 Entry 继承了 WeakReference (弱引用)，并且使用 ThreadLocal 作为键值。 下面我们看下 createMap 方法的具体实现： 12345678910/** * Create the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @param firstValue value for the initial entry of the map */ void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; 直接 new 一个 ThreadLoalMap 对象，然后赋值给当前线程的 threadLocals 属性。 然后我们看一下 set 方法的实现： 1234567891011121314151617/** * Sets the current thread's copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the &#123;@link #initialValue&#125; * method to set the values of thread-locals. * * @param value the value to be stored in the current thread's copy of * this thread-local. */ public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; 首先获取当前线程，然后从线程的属性 threadLocals 获取当前线程对应的 ThreadLocalMap 对象，如果不为空，就以 this (ThreadLocal) 而不是当前线程 t 为 key，添加到 ThreadLocalMap 中。如果为空，那么就先创建后再加入。ThreadLocal 的 set 方法通过调用 replaceStaleEntry 方法回收键为 null 的 Entry 对象的值（即为具体实例）以及 Entry 对象本身从而防止内存泄漏。 接下来我们看一下 get 方法的实现： 123456789101112131415161718192021/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local */ public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 先获取当前线程，然后通过 getMap 方法传入当前线程获取到 ThreadLocalMap 。然后接着获取 Entry (key，value) 键值对，这里传入的是 this，而不是当前线程 t ，如果获取成功，则返回对应的 value，如果没有获取到，返回空，则调用 setInitialValue 方法返回 value。 至此，我们总结一下 ThreadLocal 是如何为每个线程创建变量副本的：首先，在每个线程 Thread 内部有个 ThreadLocal.ThreadLocalMap 类型的成员变量 threadLocals，这个 threadLocals 变量就是用来存储实际变量的副本的，它的键为当前 ThreadLocal ，value 为变量副本（即 T 类型的变量）。初始时，在 Thread 类里面， threadLocals 为 null，当通过 ThreadLocal 调用 set 或者 get 方法时，如果此前没有对当前线程的 threadLocals 进行过初始化操作，那么就会以当前 ThreadLocal 变量为键值，以 ThreadLocal 要保存的副本变量为 value，存到当前线程的 threadLocals 变量中。以后在当前线程中，如果要用到当前线程的副本变量，就可以通过 get 方法在当前线程的 threadLocals 变量中查找了。 1.4 总结ThreadLocal 设计的目的就是为了能够在当前线程中有属于自己的变量，并不是为了解决并发或者共享变量的问题。 通过 ThreadLocal 创建的副本是存储在每个线程自己的 threadLocals 变量中的 为何 threadLocals 的类型 ThreadLocalMap 的键值为 ThreadLocal 对象，因为每个线程中可有多个 threadLocal 变量，就像前文图片中的 ThreadLocal 和 ThreadLocal ，就是一个线程存在两个 threadLocal 变量 在进行 get 之前，必须先 set ，否则会报空指针异常，如果想在 get 之前不需要调用 set 就能正常访问的话，必须重写 initialValue 方法 ThreadLocal 适用于变量在线程间隔离且在方法间共享的场景 另外，内存泄漏的问题请参考博文：ThreadLocal 内存泄漏问题]]></content>
      <categories>
        <category>Java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 字符串 split 踩坑记]]></title>
    <url>%2Fpost%2F8bd965a0.html</url>
    <content type="text"><![CDATA[1.1 split 的坑前几天在公司对通过 FTP 方式上传的数据文件按照事先规定的格式进行解析后入库，代码的大概实现思路是这样的：先使用流进行文件读取，对文件的每一行数据解析封装成一个个对象，然后进行入库操作。本以为很简单的一个操作，然后写完代码后自己测试发现对文件的每一行进行字符串分割的时候存在问题，在这里做个简单的记录总结。在 Java 中使用 split 方法对字符串进行分割是经常使用的方法，经常在一些文本处理、字符串分割的逻辑中，需要按照一定的分隔符进行分割拆解。这样的功能，大多数情况下我们都会使用 String 中的 split 方法。关于这个方法，稍不注意很容易踩坑。 （1）split 的参数是正则表达式首先一个常见的问题，就是忘记了 String 的 split 方法的参数不是普通的字符串，而是正则表达式，例如下面的这两种使用方式都达不到我们的预期： 12345678910111213141516/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testStringSplitRegexArg() &#123; System.out.println(Arrays.toString("m.g.h.i.o".split("."))); System.out.println(Arrays.toString("m|g|h|i|o".split("|"))); &#125; &#125; 以上代码的结果输出为： 12[][m, |, g, |, h, |, i, |, o] 上面出错的原因是因为 . 和 | 都是正则表达式，应该用转义字符进行处理： 12"m.g.h.i.o".split("\\.")"m|g|h|i|o".split("\\|") 在 String 类中还有其它的和这个相似的方法，例如：replaceAll。 （2）split 会忽略分割后的空字符串大多数情况下我们都只会使用带一个参数的 split 方法，但是只带一个参数的 split 方法有个坑：就是此方法只会匹配到最后一个有值的地方，后面的会忽略掉，例如： 1234567891011121314151617/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testStringSplitSingleArg() &#123; System.out.println(Arrays.toString("m_g_h_i_o".split("_"))); System.out.println(Arrays.toString("m_g_h_i_o__".split("_"))); System.out.println(Arrays.toString("m__g_h_i_o_".split("_"))); &#125; &#125; 以上代码输出结果为： 123[m, g, h, i, o][m, g, h, i, o][m, , g, h, i, o] 像第二、三个输出结果其实和我们的预期是不符的，因为像一些文件上传其实有的字段通常是可以为空的，如果使用单个参数的 split 方法进行处理就会有问题。通过查看 API 文档 后，发现其实 String 中的 split 方法还有一个带两个参数的方法。第二个参数是一个整型类型变量，代表最多匹配上多少个，0 表示只匹配到最后一个有值的地方，单个参数的 split 方法的第二个参数其实就是 0，要想强制匹配可以选择使用负数（通常传入 -1 ），换成以下的写法，输出结果就和我们的预期一致了。 123"m_g_h_i_o".split("_", -1) // [m, g, h, i, o]"m_g_h_i_o__".split("_", -1) // [m, g, h, i, o, , ]"m__g_h_i_o_".split("_", -1) // [m, , g, h, i, o, ] （3）JDK 中字符串切割的其它 API在 JDK 中还有一个叫做 StringTokenizer 的类也可以对字符串进行切割，用法如下所示： 123456789101112131415161718/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testStringTokenizer() &#123; StringTokenizer st = new StringTokenizer("This|is|a|mghio's|blog", "|"); while (st.hasMoreElements()) &#123; System.out.println(st.nextElement()); &#125; &#125; &#125; 不过，我们从源码的 javadoc 上得知，这是从 JDK 1.0 开始就已经存在了，属于历史遗留的类，并且推荐使用 String 的 split 方法。 1.2 JDK 源码探究通过查看 JDK 中 String 类的源码，我们得知在 String 类中单个参数的 split 方法（split(String regex)）里面调用了两个参数的 split 方法（split(String regex, int limit)），两个参数的 split 方法，先根据传入第一个参数 regex 正则表达式分割字符串，第二个参数 limit 限定了分割后的字符串个数，超过数量限制的情况下前limit-1个子字符串正常分割，最后一个子字符串包含剩下所有字符。单个参数的重载方法将 limit 设置为 0。源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public String[] split(String regex, int limit) &#123; char ch = 0; if (((regex.value.length == 1 &amp;&amp; ".$|()[&#123;^?*+\\".indexOf(ch = regex.charAt(0)) == -1) || (regex.length() == 2 &amp;&amp; regex.charAt(0) == '\\' &amp;&amp; (((ch = regex.charAt(1))-'0')|('9'-ch)) &lt; 0 &amp;&amp; ((ch-'a')|('z'-ch)) &lt; 0 &amp;&amp; ((ch-'A')|('Z'-ch)) &lt; 0)) &amp;&amp; (ch &lt; Character.MIN_HIGH_SURROGATE || ch &gt; Character.MAX_LOW_SURROGATE)) &#123; int off = 0; int next = 0; boolean limited = limit &gt; 0; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); while ((next = indexOf(ch, off)) != -1) &#123; if (!limited || list.size() &lt; limit - 1) &#123; list.add(substring(off, next)); off = next + 1; &#125; else &#123; // last one //assert (list.size() == limit - 1); list.add(substring(off, value.length)); off = value.length; break; &#125; &#125; // If no match was found, return this if (off == 0) return new String[]&#123;this&#125;; // Add remaining segment if (!limited || list.size() &lt; limit) list.add(substring(off, value.length)); // Construct result int resultSize = list.size(); if (limit == 0) &#123; while (resultSize &gt; 0 &amp;&amp; list.get(resultSize - 1).length() == 0) &#123; resultSize--; &#125; &#125; String[] result = new String[resultSize]; return list.subList(0, resultSize).toArray(result); &#125; return Pattern.compile(regex).split(this, limit);&#125; 接下来让我们一起看看 String 的 split 方法是如何实现的。 （1）特殊情况判断 123456789(((regex.value.length == 1 &amp;&amp; ".$|()[&#123;^?*+\\".indexOf(ch = regex.charAt(0)) == -1) || (regex.length() == 2 &amp;&amp; regex.charAt(0) == '\\' &amp;&amp; (((ch = regex.charAt(1))-'0')|('9'-ch)) &lt; 0 &amp;&amp; ((ch-'a')|('z'-ch)) &lt; 0 &amp;&amp; ((ch-'A')|('Z'-ch)) &lt; 0)) &amp;&amp; (ch &lt; Character.MIN_HIGH_SURROGATE || ch &gt; Character.MAX_LOW_SURROGATE)) 第一个参数 regex 为单个字符时，将其赋值给 ch，并判断是否在元字符：「.$|()[{^?*+\」中 第一个参数 regex 为两个字符时，第一个字符为 \\（要表示一个\需要用两个\转义得到），第二个字符不在数字、大小写字母和 Unicode 编码 Character.MIN_HIGH_SURROGATE（’\uD800’）和 Character.MAX_LOW_SURROGATE（’\uDBFF’）之间。 （2）字符串分割第一次分割时，使用 off 和 next，off 指向每次分割的起始位置，next 指向分隔符的下标，完成一次分割后更新 off 的值，当 list 的大小等于 limit - 1 时，直接添加剩下的子字符串。 如果字符串不含有分隔符，则直接返回原字符串 如果字符串进行完第一次分割后，数量没有达到 limit - 1 的话，则剩余的字符串在第二次添加 如果传入的第二个参数 limit 等于 0 ，则从最后的字符串往前移动，将所有的空字符串（”“）全部清除 （3）正则匹配String 的 split 方法在不是上面的特殊情况下，会使用两个类 Pattern 与 Matcher 进行分割匹配处理，而且 Strig 中涉及正则的操作都是调用这两个类进行处理的。 Pattern 类我们可以将其理解为模式类，它主要是用来创建一个匹配模式，它的构造方法是私有的，不能直接创建该对象，可以通过 Pattern.complie(String regex) 简单的工厂方法创建一个正则表达式。 Matcher 类我们可以将其理解为匹配器类，它是用来解释 Pattern 类对字符串执行匹配操作的引擎，它的构造方法也是私有的，不能直接创建该对象，可以通过 Pattern.matcher(CharSequence input) 方法得到该类的实例。String 类的双参数 split 方法最后使用 Pattern 类的 compile 和 split 方法，如下：1return Pattern.compile(regex).split(this, limit); 首先调用 Pattern 类的静态方法 compile 获取 Pattern 模式类对象 123public static Pattern compile(String regex) &#123; return new Pattern(regex, 0);&#125; 接着调用 Pattern 的 split(CharSequence input, int limit) 方法，在这个方法中调 matcher(CharSequence input) 方法返回一个 Matcher 匹配器类的实例 m，与 String 类中 split 方法的特殊情况有些类似。 使用 m.find()、m.start()、m.end() 方法 每找到一个分割符，则更新 start 和 end 的位置 然后处理没找到分隔符、子字符串数量小于 limit 以及 limit = 0 的情况 1.3 其它的字符串分割方式 方式一：使用 org.apache.commons.lang3.StringUtils#split，此方法使用完整的字符串作为参数，而不是正则表达式。底层调用 splitWorker 方法（注意：此方法会忽略分割后的空字符串）12345678910111213141516/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testApacheCommonsLangStringUtils() &#123; System.out.println(Arrays.toString(StringUtils.split("m.g.h.i.o", "."))); System.out.println(Arrays.toString(StringUtils.split("m__g_h_i_o_", "_"))); &#125; &#125; 输出结果： 12[m, g, h, i, o][m, g, h, i, o] 方式二：使用 com.google.common.base.Splitter，使用 Google Guava 包中提供的分割器 splitter，它提供了更加丰富的分割结果处理的方法，比如对结果前后去除空格，去除空字符串等12345678910111213141516171819/** * @author mghio * @date: 2019-10-13 * @version: 1.0 * @description: Java 字符串 split 踩坑记 * @since JDK 1.8 */ public class JavaStringSplitTests &#123; @Test public void testApacheCommonsLangStringUtils() &#123; Iterable&lt;String&gt; result = Splitter.on("_").split("m__g_h_i_o_"); List&lt;String&gt; resultList = Lists.newArrayList(); result.forEach(resultList::add); System.out.println("stringList's size: " + resultList.size()); result.forEach(System.out::println); &#125; &#125; 输出结果： 1234567stringList's size: 7mghio 1.4 总结String 类中除了 split 方法外，有正则表达式接口的方法都是调用 Pattern（模式类）和 Matcher（匹配器类）进行实现的。JDK 源码的每一个如 final、private 的关键字都设计的十分严谨，多读类和方法中的javadoc，多注意这些细节对于阅读代码和自己写代码都有很大的帮助。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 字节码]]></title>
    <url>%2Fpost%2F192cb539.html</url>
    <content type="text"><![CDATA[1.1 什么是字节码？Java 在刚刚诞生之时曾经提出过一个非常著名的口号: “一次编写，到处运行（write once，run anywhere）”，这句话充分表达了软件开发人员对冲破平台界限的渴求。“与平台无关”的理想最终实现在操作系统的运用层上: 虚拟机提供商开发了许多可以运行在不同平台上的虚拟机，这些虚拟机都可以载入和执行同一种平台无关的字节码，从而实现了程序的“一次编写到处运行”。各种不同平台的虚拟机与所有平台都统一使用的程序存储格式—字节码（ByteCode），因此，可以看出字节码对 Java 生态的重要性。之所以被称为字节码，是因为字节码是由十六进制组成的，而 JVM（Java Virtual Machine）以两个十六进制为一组，即以字节为单位进行读取。在 Java 中使用 javac 命令把源代码编译成字节码文件，一个 .java 源文件从编译成 .class 字节码文件的示例如图 1 所示:图 1 对于从事基于 JVM 的语言的开发人员来说，比如: Java，了解字节码可以更准确、更直观的理解 Java 语言中更深层次的东西，比如通过字节码，可以很直观的看到 volatile 关键字如何在字节码上生效。另外，字节码增强技术在各种 ORM 框架、Spring AOP、热部署等一些应用中经常使用，深入理解其原理对于我们来说大有裨益。由于 JVM 规范的存在，只要最终生成了符合 JVM 字节码规范的文件都可以在 JVM 上运行，因此，这个也给其它各种运行在 JVM 上的语言（如: Scala、Groovy、Kotlin）提供了一个机会，可以扩展 Java 没有实现的特性或者实现一些语法糖。接下来就让我们就一起看看这个字节码文件结构到底是什么样的。 1.2 Java 字节码结构Java 源文件通过用 javac 命令编译后就会得到 .class 结尾的字节码文件，比如一个简单的 JavaCodeCompilerDemo 类如图 2 所示:图 2编译后生成的 .class 字节码文件，打开后是一堆 十六进制 数，如图 3 所示:图 3在上节提过，JVM 对于字节码规范是有要求的，打开编译后的字节码文件看似混乱无章，其实它是符合一定的结构规范的，JVM 规范要求每一个字节码文件都要由十部分固定的顺序组成的，接下来我们将一一介绍这部分，整体的组成结构如图 4 所示:图 4 （1）魔数（Magic Number）每个字节码文件的头 4 个字节称为 魔数（Magic Number），它的唯一作用是确定这个文件是否为一个能被虚拟机接受的 Class 文件。很多文件存储标准中都使用魔数来进行身份识别，譬如图片格式，如 gif 或者 jpg 等在文件头中都存有魔数。使用魔数而不是扩展名来进行识别主要是基于安全方面的考虑，因为文件扩展名可以随意改动。魔数的固定值为: 0xCAFEBABE，魔数放在文件头，JVM 可以根据文件的开头来判断这个文件是否可能是一个字节码文件，如果是，才会进行之后的操作。 有趣的是，魔数的固定值是 Java 之父 James Gosling 制定的，为 CafeBabe（咖啡宝贝），而 Java 的图标为一杯咖啡。 （2）版本号（Version）版本号为魔数之后的 4 个字节，前两个字节表示次版本号（Minor Version），后两个字节表示主版本号（Major Version），上图 3 中版本号为: “00 00 00 34”，次版本号转化为十进制为 0，主版本号转化为十进制 52（3 * 16^1 + 4 * 16^0 = 52），在 Oracle 官网中查询序号 52 对应的 JDK 版本为 1.8，所以编译该源代码文件的 Java 版本为 1.8.0。 （3）常量池（Constant Pool）紧接着主版本号之后的字节是常量池入口。常量池中存储两种类型常量: 字面量和符号运用。字面量为代码中声明为 final 的常量值，符号引用如类和接口的全局限定名、字段的名称和描述符、方法的名称和描述符。常量池整体上分为两部分: 常量池计数器和常量池数据区，如图 5 所示：图 5常量池计数器（constant_pool_count）: 由于常量池的数量不固定，所以需要先放置两个字节来表示常量池容量计数值，图 2 示例代码的字节码的前十个字节如下图 6 所示，将十六进制的 17 转为十进制的值为 33 (1 * 16^1 + 7 * 16^0 = 33)，排除下标 0，也就是说这个类文件有 32 个常量。图 6常量池数据区: 数据区是由（constant_pool_count - 1）个 cp_info 结构组成，一个 cp_info 的结构对应一个常量。在字节码中共有 14 种类型的 cp_info ，每种类型的结构都是固定的，如图 7 所示:图 7以 CONSTANT_Utf8_info 为例，它的结构如表 1 所示: 名称 长度 值 tag 1 字节 01 对应图 7 中 CONSTANT_Utf8_info 的标志栏中的值 length 2 字节 该 utf8 字符串的长度 bytes length 字节 length 个字节的具体数据 表 1 首先第一个字节 tag，它的取值对应图 7 中的 Tag，由于它的类型是 CONSTANT_Utf8_info，所以值为 01（十六进制）。接下来两个字节标识该字符串的长度 length，然后 length 个字节为这个字符串具体的值。从图 3 的字节码中摘取一个 cp_info 结构，将它翻译过来后，其含义为: 该常量为 utf8 字符串，长度为 7 字节，数据为: numberA，如图 8 所示: 图 8其它类型的 cp_info 结构在本文不在细说，和 CONSTANT_Utf8_info 的结构大同小异，都是先通过 tag 来标识类型，然后后续的 n 个字节来描述长度和数据。等我们对这些结构比较了解了之后，我们可以通过: javap -verbose JavaCodeCompilerDemo 命令查看 JVM 反编译后的完整常量池，可以看到反编译结果可以将每一个 cp_info 结构的类型和值都很明确的呈现出来，如图 9 所示:图 9 （4）访问标志（access_flag）常量池结束之后的两个字节，描述该 Class 是类还是接口，以及是否被 Public、Abstract、Final 等修饰符修饰。JVM 规范规定了如下表 2 所示的 9 种访问标志。需要注意的是，JVM 并没有穷举所有的访问标志，而是使用 按位或 操作来进行描述的，比如某个类的修饰符为 public final，则对应的访问修饰符的值为 ACC_PUBLIC | ACC_FINAL，即 0x0001 | 0x0010 = 0x0011。 标志名称 标志值 含义 ACC_PUBLIC 0x0001 字段是否为 public ACC_PRIVATE 0x0002 字段是否为 private ACC_PROTECTED 0x0004 字段是否为 protected ACC_STATIC 0x0008 字段是否为 static ACC_FINAL 0x0010 字段是否为 final ACC_VOLATILE 0x0040 字段是否为 volatile ACC_TRANSIENT 0x0080 字段是否为 transient ACC_SYNCHETIC 0x1000 字段是否为编译器自动产生 ACC_ENUM 0x4000 字段是否为 enum 表 2 （5）当前类名（this_class）访问标志后的两个字节，描述的是当前类的全限定名。这两个字节保存的值为常量池中的索引值，根据索引值就能在常量池中找到这个类的全限定名。 （6）父类名称（super_class）当前类名的后两个字节，描述父类的全限定名。这两个字节保存的值也是在常量池中的索引值，根据索引值就能在常量池中找到这个类的父类的全限定名。 （7）接口信息（interfaces）父类名称后的两个字节，描述这个类的接口计数器，即: 当前类或父类实现的接口数量。紧接着的 n 个字节是所有的接口名称的字符串常量在常量池的索引值。 （8）字段表（field_table）字段表用于描述类和接口中声明的变量，包含类级别的变量以及实例变量，但是不包含方法内部声明的 局部变量。字段表也分为两部分，第一部分是两个字节，描述字段个数，第二部分是每个字段的详细信息 field_info。字段表结构如图 10 所示:图 10以图 3 中的字节码字段表为例，如下图 11 所示。其中字段的访问标志查表 2，002 对应为 Private，通过索引下标在图 9 中常量池分别得到字段名为: numberA，描述符为: I（在JVM 中的I代表 Java 中的 int）。综上，就可以唯一确定出类 JavaCodeCompilerDemo 中声明的变量为: private int numberA 。图 11 （9）方法表（method_table）字段表结束后为方法表，方法表也是由两部分组成，第一部分为两个字节描述方法的个数，第二个部分为每个方法的详细信息。方法的详细信息包括：方法的访问标志、方法名、方法的描述符以及方法的属性，如图 12 所示:图 12方法的权限修饰符依然可以通过图 9 的值查询到，方法名和方法的描述符都是常量池的索引值，可以通过索引值在常量池中查询得到。而方法属性这个部分比较复杂，我们可以借助 javap -verbose 将其反编译为人们可读的信息进行解读。如图 13 所示。我们可以看到属性中包含三个部分: Code 区: 源代码对应的 JVM 指令操作码，我们在字节码增强的时候重点操作的就是这个部分。 LineNumberTable: 行号表，将 Code 区的操作码和源代码的行号对应，Debug 时会起到作用（即: 当源代码向下走一行，相应的需要走几个 JVM 指令操作码）。 LocalVariableTable: 本地变量表，包含 this 和局部变量，之所以可以在每一个非 static 的方法内部都可以调用到 this，是因为 JVM 将 this 作为每个方法的第一个参数隐式进行传入。图 13 （10）附加属性表（additional_attribute_table）字节码的最后一部分，存放了在文件中类或接口所定义的属性的基本信息。 1.3 Java 字节码操作集合在图 13 中，Code 区的编号是 0 ~ 10，就是 .java 源文件的方法源代码编译后让 JVM 真正执行的操作码。为了帮助人们理解，反编译后看到的是十六进制操作码所对应的助记符，十六进制值操作码和助记符的对应关系，以及每个操作码的具体作用可以查看 Oracle 官网，在需要的时候查阅即可。比如上图 13 的助记符为 iconst_2，对应图 3 中的字节码 0x05，作用是将 int 值 2 压入操作数栈中。以此类推，对 0 ~ 10 的助记符理解后就是整个 sum() 方法的操作数码实现。 1.4 查看字节码工具如果我们每次反编译都要使用 javap 命令的话，确实比较繁琐，这里我推荐大家一个 IDEA 插件: jclasslib。使用效果如图 14 所示: 代码编译后在菜单栏: View -&gt; Show Bytecode With jclasslib，可以很直观地看到当前字节码文件的类信息、常量池、方法区等信息，非常方便。图 14 1.5 总结Java 中字节码文件是 JVM 执行引擎的数据入口，也是 Java 技术体系的基础构成之一。了解字节码文件的组成结构对后面进一步了解虚拟机和深入学习 Java 有很重要的意义。本文较为详细的讲解了字节码文件结构的各个组成部分，以及每个部分的定义、数据结构和使用方法。强烈建议自己动手分析一下，会理解得更加深入。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hello world]]></title>
    <url>%2Fpost%2Fb1d4025b.html</url>
    <content type="text"><![CDATA[1234567public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println("Hello World ~~~"); &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
